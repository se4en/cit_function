{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","listItem":[{"#tail":"\n","@confidence":"0.970912333333333","#text":"\n2) Assuming that the occurrence of each word is\nindependent of the occurrence of other words in the\ndocument then:\n"},{"#tail":"\n","@confidence":"0.9205368125","#text":"\n1) Fix the size s of the training set for (s=N/3, N/2,\n2N/3, or N-1) to perform 1/3-2/3, 50/50, 2/3-1/3 or\nleave-one-out cross validation.\n2) Set the number of trials T. If s=N-1, fix the\nnumber of trials T=N; else, T=40.\n3) For trial r=1 to T\n3.1 Select randomly s documents from X as\nlabeled documents into training set X lr .\n3.2 Store the remaining documents (X- X lr ) as\nunlabeled documents into X ur (as if they were\nunlabeled).\n3.3 Train NB using X lr . (Compute Equation (2)\nand Equation (4))\n3.4 Use trained NB to compute the class of each\nelement in X ur using Equation (4)\n3.5 Compute error rate Er,i , on X\n"}],"figure":[{"#tail":"\n","@confidence":"0.5097815","#text":"\n(1):\nAC(D)=argmaxCi { P(Ci|D). i=1,2,...C}\n"},{"#tail":"\n","@confidence":"0.450455866666667","#text":"\nu\nr for each\ncategory (i=1,2...,c) using Equation (7):\nEr,i = ? = |X |1k u ikError /|Xu |i=1,2,?,c\nNext r (return to step 3).\n4.1 Compute the average error rate for each class\nover all trials:\nAvgErrori,s.= ? = T 1r ir, /TE i=1,2,?,c\n4.2 Compute the maximum error rate for each\nclass over all trials:\nMaxErrori,s = Max Tr ...,2,1= {Er,i} i=1,2,?,c\n4.3 Get the minimum error rate for each class\nover all trials:\nMinErrori,s = Min Tr ...,2,1= {Er,i} i=1,2,?,c.\nNext s (return to step 1)\n"},{"#tail":"\n","@confidence":"0.981044727272727","#text":"\nCategor\ny\nhealt\nh\nBusines\ns\nCultur\ne\nScienc\ne\nSport\n"},{"#tail":"\n","@confidence":"0.950504833333333","#text":"\nCategor\ny\nHealt\nh\nBusines\ns\nCultur\ne\nScienc\ne\nSpor\nt\n"},{"#tail":"\n","@confidence":"0.8712863125","#text":"\nExperiments\n#terms/roots\n1/3-\n2/3\n1/2-\n1/2\n2/3-\n1/3\nLeave-\none-out\n50 75.2(69.92,77.42) 64.88(60.32,68.4) 53.48(49.62,56.14) 36.9(0,100)\n100 73.44(67.2,77) 62.58(59,66.7) 49.44(46.62,53.96) 33.7(0,100)\n500 71.82(65.94,75.5) 60.32(55.9,64.24) 48.96(45.66,52.3) 33.16(0,100)\n1000 69.54(64.06,72.12) 57.08(52.58,62.1) 46.96(42.84,50.76) 32.18(0,100)\n2000 66.18(61.3,69) 53.96(46.9,66) 44.38(40.8,47.58) 31.22(0,100)\n5000 67(62,69.9) 55(48.1,56.5) 46(42,49) 32.1(0,100)\n"},{"#tail":"\n","@confidence":"0.983445370370371","#text":"\nCategorization error rates versus\nnumber of roots in vocabulary\n0\n10\n20\n30\n40\n50\n60\n70\n80\n50 100 500 1000 2000 5000\nNumber of roots in vocabulary\nCa\nteg\nor\niza\ntio\nn e\nrro\nr r\nate\ns 1/3-2/3\n1/2-1/2\n2/3-1/3\nLeave-\none-out\n"}],"address":{"#tail":"\n","@confidence":"0.90427","#text":"\nP.O. Box 104, Ifrane 53000, Morocco\n"},"author":{"#tail":"\n","@confidence":"0.820359","#text":"\nMohamed EL KOURDI Amine BENSAID? Tajje-eddine RACHIDI\n"},"equation":[{"#tail":"\n","@confidence":"0.9861075","#text":"\nP(Ci|D)=[P(Ci)*P(D |Ci)]/P(D). i=1,2,...C\n( 1)\n"},{"#tail":"\n","@confidence":"0.9242185","#text":"\nCompute P(wk/Cj)= (Nk,j +1)/( nj + |Textj |)\n( 3)\n"},{"#tail":"\n","@confidence":"0.7815265","#text":"\nP(D|Cj)=P({w1, w2,..., wn}|Cj)\n( 4)\n"},{"#tail":"\n","@confidence":"0.980668","#text":"\nP(w1,...,wn|Cj)=P(w1|Cj)*P(w2|Cj)*...*P(wn|Cj) (5)\n"},{"#tail":"\n","@confidence":"0.9967875","#text":"\nErrorik= ??\n?\n??\n? ?= ii C )AC(D and ,C )L(D iff 1\notherwise 0\nkk (6)\n"},{"#tail":"\n","@confidence":"0.983354","#text":"\nClassErrori = ? = |X |1k iku Error / |Xu |(7)\n"}],"subsectionHeader":[{"#tail":"\n","@confidence":"0.978775","#text":"\n4.1 The classifier module\n"},{"#tail":"\n","@confidence":"0.980399","#text":"\n4.2 The learning module\n"},{"#tail":"\n","@confidence":"0.990888","#text":"\n5.1 The data set\n"},{"#tail":"\n","@confidence":"0.997955","#text":"\n5.2 Cross validation\n"},{"#tail":"\n","@confidence":"0.947554","#text":"\n5.3 Experiments using an evaluation set\n"}],"title":{"#tail":"\n","@confidence":"0.840427","#text":"\nAutomatic Arabic Document Categorization Based on the Na?ve Bayes Algorithm\n"},"@confidence":"0.000000","reference":[{"#tail":"\n","@confidence":"0.8281956","#text":"\n(SVM) and AdaBoost. If the similarity between\nNB?s performance for English and Arabic is any\nindication, SVM and AdaBoost should be the next\ncandidates for application to Arabic Document\ncategorization.\n"},{"#tail":"\n","@confidence":"0.9997748","#text":"\nR. Al-Shalabi, and M. Evens, &quot;A computational\nmorphology system for Arabic,? In Workshop on\nComputational Approaches to Semitic Languages,\nCOLING-ACL98, 1998.\nB. Cestink, &quot;Estimating probabilities: A crucial task\nin machine learning,&quot; Proceedings of the Ninth\nEuropean Conference on Artificial Intelligence, pp.\n147--149, London, 1990.\nK. Crammer and Y. Singer, ?A Family of Additive\nOnline Algorithms for Category Ranking,? JMLR,\nv. 3, pp. 1025-1058, Feb. 2003.\nR. H. Creecy, B. M. Masand, S. J. Smith, and D. L.\nWaltz, ?Trading mips and memory for knowledge\nengineering,? Communication of the ACM, Vol. 35,\nNo. 8, pp. 48--64, August 1992.\nM. El Kourdi, T. Rachidi, and A. Bensaid, &quot;A\nconcatenative approach to Arabic word root\nextraction,&quot; in progress, 2004.\nY.C. Fang, S. Parthasarathy and F. Schwartz,\n&quot;Using clustering to boost text classification,&quot;\nICDM Workshop on Text Mining (TextDM'01),\n2001.\nY. Houmame, Towards an Arabic Information\nRetrieval System, MS thesis, AlAkhawayn\nUniversity, Morocco, 1999.\nT. Joachims, Learning to classify text using SVM,\nKluwer Academic Publishers, 2002.\nK. Lang, &quot;Newsweeder: Learning to filter netnews,&quot;\nProceedings of the Twelfth International\nConference on Machine Learning, 1995.\nD. Lewis, M. Ringnette, &quot;Comparison of two\nlearning algorithms for text categorization,&quot;\nProceedings of the Third Annual Symposium on\nDocument Analysis and Information Retrieval\n(SDAIR'94), 1994.\nD. Lewis, Yiming Yang, Tony G. Rose, Fan Li, ?A\nNew Benchmark Collection for Text Categorization\nResearch,? JMLR, v. 5, pp. 361-397, Apr. 2004.\nT. Mitchell. Machine learning. McGraw Hill, 1997.\nK. Nigam, A. K. McCallum, S. Thrun, and\nT.Mitchell, &quot;Text classification from labeled and\nunlabeled documents using EM,&quot; Machine\nLearning, vol. 39, pp. 103--134, 2000.\nT. Rachidi, O. Iraqi, M. Bouzoubaa, A. Ben Al\nKhattab, M. El Kourdi, A. Zahi, and A. Bensaid,\n?Barq: distributed multilingual Internet search\nengine with focus on Arabic language,?\nProceedings of IEEE Conf. on Sys., Man and\nCyber., Washington DC, October 5-8, pp. , 2003.\nM. Rogati and Y. Yang. ?High-performing feature\nselection for text classification,? ACM CIKM 2002.\nSakhr software company's website:\nwww.sakhrsoft.com, 2004.\nG. Salton and C. S. Yang, &quot;On the specification of\nterm values in automatic indexing&quot;, Journal of\nDocumentation, Vol. 29, No. 4, pp. 351--372, 1973.\nF. Sebastiani, ?Machine learning in automated text\ncategorization,? ACM Computing Surveys, v.34 n.1,\np.1-47, March 2002.\nK. Tzeras and S. Hartman, &quot;Automatic indexing\nbased on Bayesian inference networks,&quot; Proc 16th\nAnn Int ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval (SIGIR'93),\npp. 22--34, 1993.\n(Wiene and Pedersen, 1995) E. Wiener, J. O.\nPedersen, and A. S. Zeigend, &quot;A neural network\napproach to topic spotting,&quot; Proceedings of the\nFourth Symposium on Document Analysis and\nInformation Retrieval (SDAIR'95), 1995.\nM. Yahyaoui, &quot;Toward an Arabic web page\nclassifier,&quot; Master project. AUI. 2001.\nY. Yang, ?An evaluation of statistical approaches to\ntext categorization,? Journal of Information\nRetrieval, Vol. 1, Number 1-2, pp. 69--90, 1999.\nY. Yang and X. Liu, ?A re-examination of text\ncategorization methods,? Proceedings of ACM\nSIGIR Conference on Research and Development in\nInformation Retrieval (SIGIR'99), pp 42--49, 1999.\nR. B. Yates, and B. R. Neto, Modern information\nretrieval. Addison-Wesley ISBN 0-201-39829-X,\n1999.\nYang, Y., Pedersen J.P. A Comparative Study on\nFeature Selection in Text Categorization\nProceedings of the 14th International Conference\non Machine Learning, pp. 412-420, 1997.\n"}],"#tail":"\n","bodyText":[{"#tail":"\n","@confidence":"0.993899","#text":"\nThis paper deals with automatic classification of\nArabic web documents. Such a classification is very\nuseful for affording directory search functionality,\nwhich has been used by many web portals and\nsearch engines to cope with an ever-increasing\nnumber of documents on the web. In this paper,\nNaive Bayes (NB) which is a statistical machine\nlearning algorithm, is used to classify non-vocalized\nArabic web documents (after their words have been\ntransformed to the corresponding canonical form,\ni.e., roots) to one of five pre-defined categories.\nCross validation experiments are used to evaluate\nthe NB categorizer. The data set used during these\nexperiments consists of 300 web documents per\ncategory. The results of cross validation in the\nleave-one-out experiment show that, using 2,000\nterms/roots, the categorization accuracy varies from\none category to another with an average accuracy\nover all categories of 68.78 %. Furthermore, the\nbest categorization performance by category during\ncross validation experiments goes up to 92.8%.\nFurther tests carried out on a manually collected\nevaluation set which consists of 10 documents from\neach of the 5 categories, show that the overall\nclassification accuracy achieved over all categories\nis 62%, and that the best result by category reaches\n90%.\n"},{"#tail":"\n","@confidence":"0.999317833333333","#text":"\nWith the explosive growth of text documents on\nthe web, relevant information retrieval has become\na crucial task to satisfy the needs of different end\nusers. To this end, automatic text categorization has\nemerged as a way to cope with such a problem.\nAutomatic text (or document) categorization\nattempts to replace and save human effort required\nin performing manual categorization. It consists of\nassigning and labeling documents using a set of pre-\ndefined categories based on document contents. As\nsuch, one of the primary objectives of automatic\ntext categorization has been the enhancement and\nthe support of information retrieval tasks to tackle\nproblems, such as information filtering and routing,\nclustering of related documents, and the\nclassification of documents into pre-specified\nsubject themes. Automatic text categorization has\nbeen used in search engines, digital library systems,\nand document management systems (Yang, 1999).\nSuch applications have included electronic email\nfiltering, newsgroups classification, and survey data\ngrouping. Barq for instance uses automatic\ncategorization to provide similar documents feature\n(Rachidi et al, 2003). In this paper, NB which is a\nstatistical machine learning algorithm is used to\nlearn to classify non-vocalized1 Arabic web text\ndocuments.\nThis paper is organized as follows. Section 2,\nbriefly describe related works in the area of\nautomatic text categorization. Section 3 describes\nthe preprocessing undergone by documents for the\npurpose of categorization; it describes in particular\nthe preprocessing specific to the Arabic language.\nIn section 4 Na?ve Bayes (NB), the learning\nalgorithm used in this paper for document\ncategorization is presented. Section 5 outlines the\nexperimental setting, as well as the experiments\ncarried out to evaluate the performance of the NB\nclassifier. It also gives the numerical results with\ntheir analysis and interpretation. Section 6\nsummarizes the work and suggests some ideas for\nfuture works.\n"},{"#tail":"\n","@confidence":"0.990255185185185","#text":"\nMany machine learning algorithms have been\napplied for many years to text categorization. They\n1 Most modern Arabic writing (web, novels, articles) are\nwritten without vowels.\ninclude decision tree learning and Bayesian\nlearning, nearest neighbor learning, and artificial\nneural networks, early such works may be found in\n(Lewis and Ringnette, 1994), (Creecy and Masand,\n1992) and (Wiene and Pedersen, 1995),\nrespectively.\nThe bulk of the text categorization work has been\ndevoted to cope with automatic categorization of\nEnglish and Latin character documents. For\nexample, (Fang et al, 2001) discusses the\nevaluation of two different text categorization\nstrategies with several variations of their feature\nspaces. A good study comparing document\ncategorization algorithms can be found in (Yang\nand Liu, 1999). More recently, (Sebastiani, 2002)\nhas performed a good survey of document\ncategorization; recent works can also be found in\n(Joachims, 2002), (Crammer and Singer, 2003), and\n(Lewis et al, 2004).\nConcerning Arabic, one automatic categorizer has\nbeen reported to have been put under operational\nuse to classify Arabic documents; it is referred to as\n&quot;Sakhr's categorizer&quot; (Sakhr, 2004). Unfortunately,\nthere is no technical documentation or specification\nconcerning this Arabic categorizer. Sakhr's\nmarketing literature claims that this categorizer is\nbased on Arabic morphology and some research that\nhas been carried out on natural language processing.\nThe present work evaluates the performance on\nArabic documents of the Na?ve Bayes algorithm\n(NB) - one of the simplest algorithms applied to\nEnglish document categorization (Mitchell, 1997).\nThe aim of this work is to gain some insight as to\nwhether Arabic document categorization (using NB)\nis sensitive to the root extraction algorithm used or\nto different data sets. This work is a continuation of\nthat initiated in (Yahyaoui, 2001), which reports an\noverall NB classification correctness of 75.6%, in\ncross validation experiments, on a data set that\nconsists of 100 documents for each of 12 categories\n(the data set is collected from different Arabic\nportals). A 50% overall classification accuracy is\nalso reported when testing with a separately\ncollected evaluation set (3 documents for each of\nthe 12 categories). The present work expands the\nwork in (Yahyaoui, 2001) by experimenting with\nthe use of a better root extraction algorithm (El\nKourdi, 2004) for document preprocessing, and\nusing a different data set, collected from the largest\nArabic site on the web: aljazeera.net.\n"},{"#tail":"\n","@confidence":"0.999146095238095","#text":"\nPrior to applying document categorization\ntechniques to an Arabic document, the latter is\ntypically preprocessed: it is parsed, in order to\nremove stopwords (these are conjunction and\ndisjunction words etc.). In addition, at this stage in\nthis work, vowels are stripped from the full text\nrepresentation when the document is (fully or\npartially) voweled/vocalized. Then roots are\nextracted for words in the document.\nIn Arabic, however, the use of stems will not\nyield satisfactory categorization. This is mainly due\nto the fact that Arabic is a non-concatenative\nlanguage (Al-Shalabi and Evens, 1998), and that the\nstem/infix obtained by suppression of infix and\nprefix add-ons is not the same for words derived\nfrom the same origin called the root. The infix form\n(or stem) needs further to be processed in order to\nobtain the root. This processing is not\nstraightforward: it necessitates expert knowledge in\nArabic language word morphology (Al-Shalabi and\nEvens, 1998). As an example, two close roots (i.e.,\nroots made of the same letters), but semantically\ndifferent, can yield the same infix form thus\ncreating ambiguity.\nThe root extraction process is concerned with the\ntransformation of all Arabic word derivatives to\ntheir single common root or canonical form. This\nprocess is very useful in terms of reducing and\ncompressing the indexing structure, and in taking\nadvantage of the semantic/conceptual relationships\nbetween the different forms of the same root. In this\nwork, we use the Arabic root extraction technique in\n(El Kourdi, 2004). It compares favorably to other\nstemming or root extraction algorithms (Yates and\nNeto, 1999; Al-Shalabi and Evens, 1998; and\nHoumame, 1999), with a performance of over 97%\nfor extracting the correct root in web documents,\nand it addresses the challenge of the Arabic broken\nplural and hollow verbs. In the remainder of this\npaper, we will use the term &quot;root&quot; and &quot;term&quot;\ninterchangeably to refer to canonical forms obtained\nthrough this root extraction process.\n"},{"#tail":"\n","@confidence":"0.99489","#text":"\nThe classifier module is considered to be the core\ncomponent of the document categorizer. It is\nresponsible for classifying given Arabic documents\nto their target class. This is performed using the\nNaive Bayes (NB) algorithm. The NB classifier\ncomputes a posteriori probabilities of classes, using\nestimates obtained from a training set of labeled\ndocuments. When an unlabeled document is\npresented, the a posteriori probability is computed\nfor each class using (1) in Figure 1; and the\nunlabeled document is then assigned to the class\nwith the largest a posteriori probability.\nA posteriori probability computation\nLet D be a document represented as a set of finite\nterms D={w1, w2,..., w3}.\nLet C be the number of target classes.\nLet docsi be the number of documents in category\nC,i and |Examples |be the number of documents in\nthe training set of labeled documents.\nLet n be the total number of distinct stems in Ci\nLet Nk be the number of times wk occurs in Ci\nThen the a posteriori probability as given by\nBayes theorem is:\n"},{"#tail":"\n","@confidence":"0.949180428571429","#text":"\nWhen comparing a posteriori probabilities for the\nsame document D, P(D) is the same for all\ncategories and will not affect the comparison.\nThe other quantities in (1) are estimated from the\ntraining set using NB learning (see Figure 2).\nThe assigned class AC(D) to document D is the\nclass with largest a posteriori probability given by\n"},{"#tail":"\n","@confidence":"0.951195791666667","#text":"\nThe main task of the learning module is to learn\nfrom a set of labeled documents with predefined\ncategories in order to allow the categorizer to\nclassify the newly encountered documents D and to\nassign them to each of the predefined target\ncategories Ci. This module is based on the NB\nlearning algorithm given in Figure 2. The learning\nmodule is one way of estimating the needed\nquantities in (1) by learning from a training set of\ndocuments.\nNB learning algorithm\nLet D be a document represented as a set of finite\nterms/roots D={w1, w2,..., wn}.\nLet docsi be the number of documents in category\nCi , and |Examples |be the number of documents in\nthe training set of labeled documents.\nStep 1: collect the vocabulary, which is defined as\nthe set of distinct words in the whole training set\nStep2: For each category Ci do the following\nCompute P(Cj) =  |docsj |/|Examples|\n(2)\nwhere docsj is the number of training documents\nfor the category is Cj.\nFor each root wk in Vocabulary\n"},{"#tail":"\n","@confidence":"0.7881981","#text":"\nwhere Nk,j is the number of times wk occurs in Cj,\nnj is the total number of distinct terms in all training\ndocuments labeled Cj, and Textj is a single\ndocuments generated by concatenating all the\ntraining documents for category Cj .\nEquation (2) and (3) make use of the following\ntwo assumptions:\n1) Assuming that the order of the words in a\ndocument does not affect the classification of the\ndocument:\n"},{"#tail":"\n","@confidence":"0.790062933333333","#text":"\nalgorithm for document categorization\nThe m-estimate method (with m equal to the size\nof word vocabulary) (Cestink, 1990) is used to\ncompute the probability terms and handle zero\ncount probabilities (smoothing). Equation (3) gives\nan estimate for P(wk/Cj).\nVarious assumptions are needed in order to\nsimplify Equation (1), whose computations are\notherwise expensive. These assumptions are\napplied in Figure 2 to obtain the needed quantities\nfor the class-conditional probabilities (Equations (4)\nand (5)). These assumptions are:\n1. The probability of encountering a specific word\nwithin a document is the same regardless the word\nposition. In other words, P(wi=w|Cj)= P(wm= w|Cj)\nfor every i, j, and m where i and m are different\npossible positions of the same word within the\ndocument. This assumption allows representing a\ndocument as a bag of word (Equation (4) in Figure\n2).\n2. The probability of occurrence of a word is\nindependent of the occurrence of other words in the\nsame document. This is reflected in Equation (5):\nP(w1,...,wn|Cj)=P(w1|Cj)*P(w2|Cj)*...*P(wn|Cj). It is\nin fact a na?ve assumption, but it significantly\nreduces computation costs, since the number of\nprobabilities that should be computed is decreased.\nEven though this assumption does not hold in\nreality, NB performs surprisingly well for text\nclassification (Mitchell, 1997).\n"},{"#tail":"\n","@confidence":"0.996495818181818","#text":"\nFor classification problems, it is customary to\nmeasure a classifier?s performance in terms of\nclassification error rate. A data set of documents is\nused with known category/class label L(Dk) for each\ndocument Dk. The set is split into two subsets: a\ntraining set and a testing set. The trained classifier is\nused to assign a class AC(Dk) using Equation (3) to\neach document (Dk) in the test set, as if its true class\nlabel were not known. If AC(Dk) matches L(Dk), the\nclassification is considered correct; otherwise, it is\ncounted as an error:\n"},{"#tail":"\n","@confidence":"0.958504","#text":"\nFor a given class, the error rate is computed as the\nratio of the number of errors made on the whole test\nset of unlabeled documents (Xu) to the cardinality\n|Xu |of this set. For a given class Ci, the error rate is\ncomputed as:\n"},{"#tail":"\n","@confidence":"0.9992515","#text":"\nIn order to measure the performance of the NB\nalgorithm on Arabic document classification, we\nconducted several experiments: we performed cross\nvalidation using the original space (using all the\nwords in the documents), cross validation\nexperiments based on feature selection (using a\nsubset of terms/roots only), and experiments based\non an independently constructed evaluation set. The\nfollowing paragraphs describe the data set used, and\nthe experiments.\n"},{"#tail":"\n","@confidence":"0.954343833333333","#text":"\nWe have collected 300 web documents for each\nof five categories from the website\nwww.aljazeera.net, which is the website of\nAljazeera (the Qatari television news channel in\nArabic). This site contains over seven million\n(7,000,000) documents corresponding to the\nprograms broadcast on the television channel; it is\narguably the most visited Arabic web site.\nAljazeera.net presents documents in (manually\nconstructed) categories. The five (5) categories\nused for this work are: sports, business, culture and\nart, science, and health.\n"},{"#tail":"\n","@confidence":"0.914543333333333","#text":"\nIn cross validation, a fixed number of documents\nis reserved for testing (as if they were unlabeled\ndocuments) and the remainder are used for training\n(as labeled documents). Several such partitions of\nthe data set are constructed, by making random\nsplits of the data set. NB's performance is evaluated\nseveral times, using the different random partitions.\nThen the error statistics are aggregated. The steps of\nthe cross validation experiments are delineated in\nFigure 3 next:\nCross validation steps\nLet X be the entire data seto f N=1500 documents\nc =5 is the number of different categories\nEr,i will store the error rate for category i during\ntrial r.\n"},{"#tail":"\n","@confidence":"0.977831","#text":"\nIn these experiments, each document in data set X\nis represented by all word roots in the document.\nThe cross validation experiments described in\n"},{"#tail":"\n","@confidence":"0.9686572","#text":"\nobtained in the leave-one-out experiment (as\nillustrated in Table 1). Table 2, Table 3, Table 4,\nand Table 5 represent, respectively, the confusion\nmatrices of the cross validation experiments. The\npercentages reported in an entry of a confusion\nmatrix correspond to the percentage of documents\nthat are known to actually belong to the category\ngiven by the row header of the matrix, but that are\nassigned by NB to the category given by the column\nheader.\n"},{"#tail":"\n","@confidence":"0.991543651162791","#text":"\nwith no feature extraction (Leave-one-out)\nThe diagonals in tables 2-5 indicate higher\nclassification performance for categories: Sport and\nBusiness than for the categories: Culture, Science,\nand health. Moreover, the leave-one-out experiment\nyields the best result by category as illustrated in\nTable 5 compared to the error rates reported in\ntables 2-4. Tables 2-5 revealed that error rates by\ncategory decrease from experiment to experiment.\nIn other words, the error rates recorded in 1/3-2/3\nexperiment are higher than those in 1/2-1/2\nexperiment, those in 1/2-1/2 experiment are higher\nthan those in 2/3-1/3 experiment, and those obtained\nin the 2/3-1/3 experiment are higher than those in\nthe leave-one-out experiment. Thus, larger training\nsets yield higher accuracy when all the data set\nterms are used.\nWhen investigating some of the\nmisclassifications/confusions made by NB, we have\nnoticed that misclassified documents, in fact,\ncontain large number of words that are\nrepresentative of other categories. In other words,\ndocuments that are known to belong to a category\ncontain numerous words that have higher frequency\nin other categories. Therefore, these words have\nhigher influence on the prediction that will be made\nby the classifier. For instance, the confusion matrix\nin Table 5 shows that 30% of Culture documents\nhave been misclassified in the Sports category. The\nmisclassified documents contain words that are\nmore frequent in the Sports category such as ?????\n(Arabic for prize and for trophy), ??? (Arabic for\nchampion and for lead character), and ????? (Arabic\nfor scoring and for recording).\n5.2.2. Cross-validation, using feature selection\nFeature selection techniques have been widely\nused in information retrieval as a means for coping\nwith the large number of words in a document; a\nselection is made to keep only the more relevant\nwords. Various feature selection techniques have\nbeen used in automatic text categorization; they\ninclude document frequency (DF), information gain\n(IG) (Tzeras and Hartman, 1993), minimum\ndescription length principal (Lang, 1995), and the ?2\nstatistic. (Yang and Pedersen, 1997) has found\nstrong correlations between DF, IG and the ?2\nstatistic for a term. On the other hand, (Rogati and\nYang, 2002) reports the ?2 to produce best\nperformance. In this paper, we use TF-IDF (a kind\nof augmented DF) as a feature selection criterion, in\norder to ensure results are comparable with those in\n(Yahyaoui, 2001).\nTF-IDF (term frequency-inverse document\nfrequency) is one of the widely used feature\nselection techniques in information retrieval (Yates\nand Neto, 1999). Specifically, it is used as a metric\nfor measuring the importance of a word in a\ndocument within a collection, so as to improve the\nrecall and the precision of the retrieved documents.\nWhile the TF measurement concerns the importance\nof a term in a given document, IDF seeks to\nmeasure the relative importance of a term in a\ncollection of documents. The importance of each\nterm is assumed to be inversely proportional to the\nnumber of documents that contain that term. TF is\ngiven by TFD,t, and it denotes frequency of term t in\ndocument D. IDF is given by IDFt = log(N/dft),\nwhere N is the number of documents in the\ncollection, and dft is the number of documents\ncontaining the term t. (Salton and Yang, 1973)\nproposed the combination of TF and IDF as\nweighting schemes, and it has been shown that their\nproduct gave better performance. Thus, the weight\nof each term/root in a document is given by wD,t =\nTFD,t * IDFt.\nWe have conducted five cross validation\nexperiments based on TF-IDF. Experiments are\nbased on selecting, in turn, 50, 100, 500, 1000, and\n2000 terms that best represent the predefined 5\ncategories. We have repeated the experiments in\nFigure 3 for each number of terms. A summary of\nthe results is presented in Table 6. The performance\nlevels obtained are comparable to those obtained\nwithout feature selection. Figure 4 plots average\ncategorization error rates versus the number of\nterms used for different trials.\n"},{"#tail":"\n","@confidence":"0.855897","#text":"\nnumber of terms.\n"},{"#tail":"\n","@confidence":"0.998891828571429","#text":"\nCross validation has been used to determine the\naverage performance of NB for Arabic text\ncategorization, and to design training sets that\nproduce the best performance. This experiment,\nbased on a separately and independently constructed\nevaluation set, is designed to evaluate the\nperformance of NB on a set of documents that have\nnever been submitted to the classifier. For this\npurpose, we further carefully collected manually 10\ndocuments from Aljazeera.net for each of the 5\npredefined categories. For each category, we have\nselected documents that best represent the\nvariability in the category. We refer to this\ncollection of documents as the evaluation set. This\nset is presented to the classifier for categorization.\nFor testing on the evaluation set, trained NB\nclassifiers are used. For each category, we use the\nNB classifier that has been trained using the training\nset that produced the best category classification\naccuracy in cross validation experiments. In our\ncase, we have used the whole set as a training set\n(1,500) represented by 2,000 terms since the best\ncross validation accuracy was obtained in leave-\none-out experiment with 2,000 terms. Table 7\nsummarizes NB?s performance results when tested\nusing the evaluation set. The results obtained have\nshown higher performance for the Sports and the\nBusiness categories with a classification accuracy\nthat is higher than 70%. The performance of other\ncategories ranges from 40% to 60%. The average\naccuracy over all categories is 62%.\nThe results obtained in the evaluation set\nexperiment are very consistent with the\nperformance obtained in cross validation\nexperiments.\n"},{"#tail":"\n","@confidence":"0.9750994","#text":"\nTo sum up, this work has been carried out to\nautomatically classify Arabic documents using the\nNB algorithm, with the use of a different data set, a\ndifferent number of categories, and a different root\nextraction algorithm from those used in (Yahyaoui,\n2001). In this work, the average accuracy over all\ncategories is: 68.78% in cross validation and 62% in\nevaluation set experiments. The corresponding\nperformances in (Yahyaoui, 2001) are 75.6% and\n50%, respectively. Thus, the overall performance\n(including cross validation and evaluation set\nexperiments) in this work is comparable to that in\n(Yahyaoui, 2001). This offers some indication that\nthe performance of NB algorithm in classifying\nArabic documents is not sensitive to the Arabic root\nextraction algorithm. Future work will be directed at\nexperimenting with other root extraction algorithms.\nFurther improvement of NB?s performance may be\neffected by using unlabeled documents; e.g., EM\nhas been used successfully for this purpose in\n(Nigam et al, 200), where EM has increased the\nclassification accuracy by 30% for classifying\nEnglish documents. Two (English) document\ncategorization algorithms have been reported to\nproduce best results: Support Vector Machines\n"}],"#text":"\n","affiliation":{"#tail":"\n","@confidence":"0.9529095","#text":"\nSchool of Science & Engineering\nAlakhawayn University\n"},"sectionHeader":[{"#tail":"\n","@confidence":"0.610671","@genericHeader":"method","#text":"\n?Corresponding Author\nAbstract\n"},{"#tail":"\n","@confidence":"0.793406","@genericHeader":"method","#text":"\nKeywords: Na?ve Bayes, Arabic document\n"},{"#tail":"\n","@confidence":"0.998257","@genericHeader":"method","#text":"\n1 Introduction\n"},{"#tail":"\n","@confidence":"0.998129","@genericHeader":"method","#text":"\n2 Related Works\n"},{"#tail":"\n","@confidence":"0.836191","@genericHeader":"method","#text":"\n3 Preprocessing of document\n"},{"#tail":"\n","@confidence":"0.997493","@genericHeader":"method","#text":"\n4 NB for document categorization\n"},{"#tail":"\n","@confidence":"0.979623","@genericHeader":"evaluation","#text":"\n5 Experiments and results\n"},{"#tail":"\n","@confidence":"0.998808","@genericHeader":"conclusions","#text":"\n6 Conclusions\n"},{"#tail":"\n","@confidence":"0.618364","@genericHeader":"references","#text":"\nReferences\n"}],"tableCaption":[{"#tail":"\n","@confidence":"0.7839105","#text":"\nTable 1. The error rates of NB over all categories in\ncross validation experiments (with feature extraction)\n"},{"#tail":"\n","@confidence":"0.7402115","#text":"\nTable 2. Confusion Matrix results for cross\nvalidation, with no feature extraction (1/3-2/3).\n"},{"#tail":"\n","@confidence":"0.740213","#text":"\nTable 3. Confusion Matrix results for cross\nvalidation, with no feature extraction (1/2-1/2).\n"},{"#tail":"\n","@confidence":"0.8335215","#text":"\nTable 4. Confusion Matrix results for cross\nvalidation, with no feature extraction (2/3-1/3).\n"},{"#tail":"\n","@confidence":"0.998736","#text":"\nTable 5. Confusion Matrix results for cross validation,\n"},{"#tail":"\n","@confidence":"0.8630975","#text":"\nTable 6. The overall error rate of NB in cross\nvalidation experiments using feature selection, in\n"},{"#tail":"\n","@confidence":"0.8544285","#text":"\nTable 7. Classification accuracy on the evaluation set\nusing Leave-one-out and TF-IDF with 2,000 roots/terms\n"}],"keyword":{"#tail":"\n","@confidence":"0.487778","#text":"\ncategorization, cross validation, TF-IDF.\n"},"figureCaption":[{"#tail":"\n","@confidence":"0.978553","#text":"\nFigure 1. A posteriori probability reduction.\n"},{"#tail":"\n","@confidence":"0.98691","#text":"\nFigure 2. The Na?ve Bayes (supervised) learning\n"},{"#tail":"\n","@confidence":"0.7884655","#text":"\nFigure 3. Cross validation experiments.\n5.2.1. Experiments without feature extraction\n"},{"#tail":"\n","@confidence":"0.888313","#text":"\nFigure 3, is conducted. Table 1 reports the error\nrates obtained over all categories during the cross\nvalidation experiments. The smallest error rate is\n"},{"#tail":"\n","@confidence":"0.999486","#text":"\nFigure 4. Categorization error rates versus\n"}],"table":[{"#tail":"\n","@confidence":"0.9786885","#text":"\nCross-validation Experiments\n1/3-2/3 1/2-1/2 2/3-1/3 Leave-one-out\nAvg 67% 55% 46% 32.1%\nMax 69.9% 56.5% 49% 100%\nError\nRate Min 62% 48.1% 42% 0%\n"},{"#tail":"\n","@confidence":"0.996814166666667","#text":"\nCategory Health Business Culture Science Sport\nHealth 22% 27% 3% 8% 40%\nBusiness 7% 39% 10% 18% 26%\nCulture 13% 18% 27% 7% 35%\nScience 14% 15% 8% 30% 33%\nSport 16% 12% 17% 8% 47%\n"},{"#tail":"\n","@confidence":"0.733242444444444","#text":"\nHealth 32% 22.5% 3.2% 8% 34.3\n%\nBusines\ns\n8.2% 50% 10.7% 13.3% 17.8\n%\nCulture 8% 20% 39% 3% 30%\nScience 16% 9.8% 7.2% 46% 21%\nSport 12% 8% 16% 4% 60%\n"},{"#tail":"\n","@confidence":"0.9935134","#text":"\nHealth 46% 12% 6% 8% 28%\nBusiness 4.8% 63% 7% 9.2% 16%\nCulture 7.1% 16.8% 42% 6.1% 28%\nScience 8.1% 10.8% 9.1% 46% 26%\nSport 7.2% 5% 6.8% 5% 76%\n"},{"#tail":"\n","@confidence":"0.984725125","#text":"\nCategory\nname\nHealth Business Culture Science Sport\nHealth 58.0% 13% 4% 3.7% 21.3%\nBusiness 4.6% 73.5% 5.3% 4.6% 12%\nCulture 2.3% 10% 57.0% 0.7% 30%\nScience 13.3% 5.3% 2.3% 59.1% 20%\nSport 2.0% 1.3% 3.6% 1.3% 91.8%\n"},{"#tail":"\n","@confidence":"0.893941714285714","#text":"\nformat: Avg(Min, Max)\nCategory NB accuracy\nHealth 50%\nBusiness 70%\nCulture 40%\nScience 60%\nSport 90%\n"}],"email":{"#tail":"\n","@confidence":"0.933072","#text":"\n[M.Elkourdi, A.Bensaid, T.Rachidi]@alakhawayn.ma\n"}}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.287299","#tail":"\n","@no":"0","note":{"#tail":"\n","@confidence":"0.436828","#text":"Corresponding Author"},"address":{"#tail":"\n","@confidence":"0.995741","#text":"P.O. Box 104, Ifrane 53000, Morocco"},"#text":"\n","affiliation":{"#tail":"\n","@confidence":"0.9957965","#text":"School of Science & Engineering Alakhawayn University"},"author":{"#tail":"\n","@confidence":"0.976782","#text":"Mohamed EL_KOURDI Amine BENSAID Tajje-eddine RACHIDI"},"abstract":{"#tail":"\n","@confidence":"0.999840535714286","#text":"This paper deals with automatic classification of Arabic web documents. Such a classification is very useful for affording directory search functionality, which has been used by many web portals and search engines to cope with an ever-increasing number of documents on the web. In this paper, Naive Bayes (NB) which is a statistical machine learning algorithm, is used to classify non-vocalized Arabic web documents (after their words have been transformed to the corresponding canonical form, i.e., roots) to one of five pre-defined categories. Cross validation experiments are used to evaluate the NB categorizer. The data set used during these experiments consists of 300 web documents per category. The results of cross validation in the leave-one-out experiment show that, using 2,000 terms/roots, the categorization accuracy varies from one category to another with an average accuracy over all categories of 68.78 %. Furthermore, the best categorization performance by category during cross validation experiments goes up to 92.8%. Further tests carried out on a manually collected evaluation set which consists of 10 documents from each of the 5 categories, show that the overall classification accuracy achieved over all categories is 62%, and that the best result by category reaches 90%."},"keyword":{"#tail":"\n","@confidence":"0.8570785","#text":"Keywords: Na?ve Bayes, Arabic document categorization, cross validation, TF-IDF."},"title":{"#tail":"\n","@confidence":"0.999458","#text":"Automatic Arabic Document Categorization Based on the Na?ve Bayes Algorithm"},"email":{"#tail":"\n","@confidence":"0.967535","#text":"[M.Elkourdi,A.Bensaid,T.Rachidi]@alakhawayn.ma"}}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"R. Al-Shalabi, and M. Evens, &quot;A computational morphology system for Arabic,? In Workshop on Computational Approaches to Semitic Languages, COLING-ACL98, 1998. B. Cestink, &quot;Estimating probabilities: A crucial task in machine learning,&quot; Proceedings of the Ninth European Conference on Artificial Intelligence, pp."},"#text":"\n","pages":{"#tail":"\n","#text":"pp."},"marker":{"#tail":"\n","#text":"Al-Shalabi, Evens, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"Preprocessing of document Prior to applying document categorization techniques to an Arabic document, the latter is typically preprocessed: it is parsed, in order to remove stopwords (these are conjunction and disjunction words etc.). In addition, at this stage in this work, vowels are stripped from the full text representation when the document is (fully or partially) voweled/vocalized. Then roots are extracted for words in the document. In Arabic, however, the use of stems will not yield satisfactory categorization. This is mainly due to the fact that Arabic is a non-concatenative language (Al-Shalabi and Evens, 1998), and that the stem/infix obtained by suppression of infix and prefix add-ons is not the same for words derived from the same origin called the root. The infix form (or stem) needs further to be processed in order to obtain the root. This processing is not straightforward: it necessitates expert knowledge in Arabic language word morphology (Al-Shalabi and Evens, 1998). As an example, two close roots (i.e., roots made of the same letters), but semantically different, can yield the same infix form thus creating ambiguity. The root extraction process is concerned with the transformation of all Ar","@endWordPosition":"1022","@position":"6887","annotationId":"T1","@startWordPosition":"1019","@citStr":"Al-Shalabi and Evens, 1998"}},"title":{"#tail":"\n","#text":"A computational morphology system for Arabic,?"},"booktitle":{"#tail":"\n","#text":"In Workshop on Computational Approaches to Semitic Languages, COLING-ACL98,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"R Al-Shalabi"},{"#tail":"\n","#text":"M Evens"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1990"},"rawString":{"#tail":"\n","#text":"147--149, London, 1990."},"#text":"\n","pages":{"#tail":"\n","#text":"147--149"},"marker":{"#tail":"\n","#text":"1990"},"location":{"#tail":"\n","#text":"London,"},"@valid":"false"},{"volume":{"#tail":"\n","#text":"3"},"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"K. Crammer and Y. Singer, ?A Family of Additive Online Algorithms for Category Ranking,? JMLR, v. 3, pp. 1025-1058, Feb. 2003."},"journal":{"#tail":"\n","#text":"JMLR,"},"#text":"\n","pages":{"#tail":"\n","#text":"1025--1058"},"marker":{"#tail":"\n","#text":"Crammer, Singer, 2003"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"eecy and Masand, 1992) and (Wiene and Pedersen, 1995), respectively. The bulk of the text categorization work has been devoted to cope with automatic categorization of English and Latin character documents. For example, (Fang et al, 2001) discusses the evaluation of two different text categorization strategies with several variations of their feature spaces. A good study comparing document categorization algorithms can be found in (Yang and Liu, 1999). More recently, (Sebastiani, 2002) has performed a good survey of document categorization; recent works can also be found in (Joachims, 2002), (Crammer and Singer, 2003), and (Lewis et al, 2004). Concerning Arabic, one automatic categorizer has been reported to have been put under operational use to classify Arabic documents; it is referred to as &quot;Sakhr's categorizer&quot; (Sakhr, 2004). Unfortunately, there is no technical documentation or specification concerning this Arabic categorizer. Sakhr's marketing literature claims that this categorizer is based on Arabic morphology and some research that has been carried out on natural language processing. The present work evaluates the performance on Arabic documents of the Na?ve Bayes algorithm (NB) - one of the simpl","@endWordPosition":"685","@position":"4686","annotationId":"T2","@startWordPosition":"682","@citStr":"Crammer and Singer, 2003"}},"title":{"#tail":"\n","#text":"A Family of Additive Online Algorithms for Category Ranking,?"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"K Crammer"},{"#tail":"\n","#text":"Y Singer"}]}},{"volume":{"#tail":"\n","#text":"35"},"#tail":"\n","date":{"#tail":"\n","#text":"1992"},"rawString":{"#tail":"\n","#text":"R. H. Creecy, B. M. Masand, S. J. Smith, and D. L. Waltz, ?Trading mips and memory for knowledge engineering,? Communication of the ACM, Vol. 35, No. 8, pp. 48--64, August 1992."},"journal":{"#tail":"\n","#text":"Communication of the ACM,"},"#text":"\n","pages":{"#tail":"\n","#text":"48--64"},"marker":{"#tail":"\n","#text":"Creecy, Masand, Smith, Waltz, 1992"},"title":{"#tail":"\n","#text":"Trading mips and memory for knowledge engineering,?"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"R H Creecy"},{"#tail":"\n","#text":"B M Masand"},{"#tail":"\n","#text":"S J Smith"},{"#tail":"\n","#text":"D L Waltz"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"M. El Kourdi, T. Rachidi, and A. Bensaid, &quot;A concatenative approach to Arabic word root extraction,&quot; in progress, 2004."},"#text":"\n","marker":{"#tail":"\n","#text":"El Kourdi, Rachidi, Bensaid, 2004"},"title":{"#tail":"\n","#text":"A concatenative approach to Arabic word root extraction,&quot; in progress,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"M El Kourdi"},{"#tail":"\n","#text":"T Rachidi"},{"#tail":"\n","#text":"A Bensaid"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Y.C. Fang, S. Parthasarathy and F. Schwartz, &quot;Using clustering to boost text classification,&quot; ICDM Workshop on Text Mining (TextDM'01), 2001."},"#text":"\n","marker":{"#tail":"\n","#text":"Fang, Parthasarathy, Schwartz, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"e works. 2 Related Works Many machine learning algorithms have been applied for many years to text categorization. They 1 Most modern Arabic writing (web, novels, articles) are written without vowels. include decision tree learning and Bayesian learning, nearest neighbor learning, and artificial neural networks, early such works may be found in (Lewis and Ringnette, 1994), (Creecy and Masand, 1992) and (Wiene and Pedersen, 1995), respectively. The bulk of the text categorization work has been devoted to cope with automatic categorization of English and Latin character documents. For example, (Fang et al, 2001) discusses the evaluation of two different text categorization strategies with several variations of their feature spaces. A good study comparing document categorization algorithms can be found in (Yang and Liu, 1999). More recently, (Sebastiani, 2002) has performed a good survey of document categorization; recent works can also be found in (Joachims, 2002), (Crammer and Singer, 2003), and (Lewis et al, 2004). Concerning Arabic, one automatic categorizer has been reported to have been put under operational use to classify Arabic documents; it is referred to as &quot;Sakhr's categorizer&quot; (Sakhr, 200","@endWordPosition":"629","@position":"4299","annotationId":"T3","@startWordPosition":"626","@citStr":"Fang et al, 2001"}},"title":{"#tail":"\n","#text":"Using clustering to boost text classification,&quot;"},"booktitle":{"#tail":"\n","#text":"ICDM Workshop on Text Mining (TextDM'01),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Y C Fang"},{"#tail":"\n","#text":"S Parthasarathy"},{"#tail":"\n","#text":"F Schwartz"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"MS thesis,"},"date":{"#tail":"\n","#text":"1999"},"institution":{"#tail":"\n","#text":"AlAkhawayn University,"},"rawString":{"#tail":"\n","#text":"Y. Houmame, Towards an Arabic Information Retrieval System, MS thesis, AlAkhawayn University, Morocco, 1999."},"#text":"\n","marker":{"#tail":"\n","#text":"Houmame, 1999"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" yield the same infix form thus creating ambiguity. The root extraction process is concerned with the transformation of all Arabic word derivatives to their single common root or canonical form. This process is very useful in terms of reducing and compressing the indexing structure, and in taking advantage of the semantic/conceptual relationships between the different forms of the same root. In this work, we use the Arabic root extraction technique in (El Kourdi, 2004). It compares favorably to other stemming or root extraction algorithms (Yates and Neto, 1999; Al-Shalabi and Evens, 1998; and Houmame, 1999), with a performance of over 97% for extracting the correct root in web documents, and it addresses the challenge of the Arabic broken plural and hollow verbs. In the remainder of this paper, we will use the term &quot;root&quot; and &quot;term&quot; interchangeably to refer to canonical forms obtained through this root extraction process. 4 NB for document categorization 4.1 The classifier module The classifier module is considered to be the core component of the document categorizer. It is responsible for classifying given Arabic documents to their target class. This is performed using the Naive Bayes (NB) algo","@endWordPosition":"1194","@position":"7975","annotationId":"T4","@startWordPosition":"1193","@citStr":"Houmame, 1999"}},"title":{"#tail":"\n","#text":"Towards an Arabic Information Retrieval System,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Y Houmame"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"T. Joachims, Learning to classify text using SVM, Kluwer Academic Publishers, 2002."},"#text":"\n","marker":{"#tail":"\n","#text":"Joachims, 2002"},"publisher":{"#tail":"\n","#text":"Kluwer Academic Publishers,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"gnette, 1994), (Creecy and Masand, 1992) and (Wiene and Pedersen, 1995), respectively. The bulk of the text categorization work has been devoted to cope with automatic categorization of English and Latin character documents. For example, (Fang et al, 2001) discusses the evaluation of two different text categorization strategies with several variations of their feature spaces. A good study comparing document categorization algorithms can be found in (Yang and Liu, 1999). More recently, (Sebastiani, 2002) has performed a good survey of document categorization; recent works can also be found in (Joachims, 2002), (Crammer and Singer, 2003), and (Lewis et al, 2004). Concerning Arabic, one automatic categorizer has been reported to have been put under operational use to classify Arabic documents; it is referred to as &quot;Sakhr's categorizer&quot; (Sakhr, 2004). Unfortunately, there is no technical documentation or specification concerning this Arabic categorizer. Sakhr's marketing literature claims that this categorizer is based on Arabic morphology and some research that has been carried out on natural language processing. The present work evaluates the performance on Arabic documents of the Na?ve Bayes algor","@endWordPosition":"681","@position":"4658","annotationId":"T5","@startWordPosition":"680","@citStr":"Joachims, 2002"}},"title":{"#tail":"\n","#text":"Learning to classify text using SVM,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"T Joachims"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"rawString":{"#tail":"\n","#text":"K. Lang, &quot;Newsweeder: Learning to filter netnews,&quot; Proceedings of the Twelfth International Conference on Machine Learning, 1995."},"#text":"\n","marker":{"#tail":"\n","#text":"Lang, 1995"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"? (Arabic for prize and for trophy), ??? (Arabic for champion and for lead character), and ????? (Arabic for scoring and for recording). 5.2.2. Cross-validation, using feature selection Feature selection techniques have been widely used in information retrieval as a means for coping with the large number of words in a document; a selection is made to keep only the more relevant words. Various feature selection techniques have been used in automatic text categorization; they include document frequency (DF), information gain (IG) (Tzeras and Hartman, 1993), minimum description length principal (Lang, 1995), and the ?2 statistic. (Yang and Pedersen, 1997) has found strong correlations between DF, IG and the ?2 statistic for a term. On the other hand, (Rogati and Yang, 2002) reports the ?2 to produce best performance. In this paper, we use TF-IDF (a kind of augmented DF) as a feature selection criterion, in order to ensure results are comparable with those in (Yahyaoui, 2001). TF-IDF (term frequency-inverse document frequency) is one of the widely used feature selection techniques in information retrieval (Yates and Neto, 1999). Specifically, it is used as a metric for measuring the importance of","@endWordPosition":"3339","@position":"20945","annotationId":"T6","@startWordPosition":"3338","@citStr":"Lang, 1995"}},"title":{"#tail":"\n","#text":"Newsweeder: Learning to filter netnews,&quot;"},"booktitle":{"#tail":"\n","#text":"Proceedings of the Twelfth International Conference on Machine Learning,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"K Lang"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"D. Lewis, M. Ringnette, &quot;Comparison of two learning algorithms for text categorization,&quot; Proceedings of the Third Annual Symposium on Document Analysis and Information Retrieval (SDAIR'94), 1994."},"#text":"\n","marker":{"#tail":"\n","#text":"Lewis, Ringnette, 1994"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"e experimental setting, as well as the experiments carried out to evaluate the performance of the NB classifier. It also gives the numerical results with their analysis and interpretation. Section 6 summarizes the work and suggests some ideas for future works. 2 Related Works Many machine learning algorithms have been applied for many years to text categorization. They 1 Most modern Arabic writing (web, novels, articles) are written without vowels. include decision tree learning and Bayesian learning, nearest neighbor learning, and artificial neural networks, early such works may be found in (Lewis and Ringnette, 1994), (Creecy and Masand, 1992) and (Wiene and Pedersen, 1995), respectively. The bulk of the text categorization work has been devoted to cope with automatic categorization of English and Latin character documents. For example, (Fang et al, 2001) discusses the evaluation of two different text categorization strategies with several variations of their feature spaces. A good study comparing document categorization algorithms can be found in (Yang and Liu, 1999). More recently, (Sebastiani, 2002) has performed a good survey of document categorization; recent works can also be found in (Joachims, 200","@endWordPosition":"592","@position":"4056","annotationId":"T7","@startWordPosition":"589","@citStr":"Lewis and Ringnette, 1994"}},"title":{"#tail":"\n","#text":"Comparison of two learning algorithms for text categorization,&quot;"},"booktitle":{"#tail":"\n","#text":"Proceedings of the Third Annual Symposium on Document Analysis and Information Retrieval (SDAIR'94),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"D Lewis"},{"#tail":"\n","#text":"M Ringnette"}]}},{"volume":{"#tail":"\n","#text":"5"},"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"D. Lewis, Yiming Yang, Tony G. Rose, Fan Li, ?A New Benchmark Collection for Text Categorization Research,? JMLR, v. 5, pp. 361-397, Apr. 2004."},"journal":{"#tail":"\n","#text":"JMLR,"},"#text":"\n","pages":{"#tail":"\n","#text":"361--397"},"marker":{"#tail":"\n","#text":"Lewis, Yang, Rose, Li, 2004"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"e and Pedersen, 1995), respectively. The bulk of the text categorization work has been devoted to cope with automatic categorization of English and Latin character documents. For example, (Fang et al, 2001) discusses the evaluation of two different text categorization strategies with several variations of their feature spaces. A good study comparing document categorization algorithms can be found in (Yang and Liu, 1999). More recently, (Sebastiani, 2002) has performed a good survey of document categorization; recent works can also be found in (Joachims, 2002), (Crammer and Singer, 2003), and (Lewis et al, 2004). Concerning Arabic, one automatic categorizer has been reported to have been put under operational use to classify Arabic documents; it is referred to as &quot;Sakhr's categorizer&quot; (Sakhr, 2004). Unfortunately, there is no technical documentation or specification concerning this Arabic categorizer. Sakhr's marketing literature claims that this categorizer is based on Arabic morphology and some research that has been carried out on natural language processing. The present work evaluates the performance on Arabic documents of the Na?ve Bayes algorithm (NB) - one of the simplest algorithms applied to","@endWordPosition":"690","@position":"4711","annotationId":"T8","@startWordPosition":"687","@citStr":"Lewis et al, 2004"}},"title":{"#tail":"\n","#text":"A New Benchmark Collection for Text Categorization Research,?"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"D Lewis"},{"#tail":"\n","#text":"Yiming Yang"},{"#tail":"\n","#text":"Tony G Rose"},{"#tail":"\n","#text":"Fan Li"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"T. Mitchell. Machine learning. McGraw Hill, 1997."},"#text":"\n","marker":{"#tail":"\n","#text":"Mitchell, 1997"},"publisher":{"#tail":"\n","#text":"McGraw Hill,"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" categorizer has been reported to have been put under operational use to classify Arabic documents; it is referred to as &quot;Sakhr's categorizer&quot; (Sakhr, 2004). Unfortunately, there is no technical documentation or specification concerning this Arabic categorizer. Sakhr's marketing literature claims that this categorizer is based on Arabic morphology and some research that has been carried out on natural language processing. The present work evaluates the performance on Arabic documents of the Na?ve Bayes algorithm (NB) - one of the simplest algorithms applied to English document categorization (Mitchell, 1997). The aim of this work is to gain some insight as to whether Arabic document categorization (using NB) is sensitive to the root extraction algorithm used or to different data sets. This work is a continuation of that initiated in (Yahyaoui, 2001), which reports an overall NB classification correctness of 75.6%, in cross validation experiments, on a data set that consists of 100 documents for each of 12 categories (the data set is collected from different Arabic portals). A 50% overall classification accuracy is also reported when testing with a separately collected evaluation set (3 documents ","@endWordPosition":"782","@position":"5360","annotationId":"T9","@startWordPosition":"781","@citStr":"Mitchell, 1997"},{"#tail":"\n","#text":" positions of the same word within the document. This assumption allows representing a document as a bag of word (Equation (4) in Figure 2). 2. The probability of occurrence of a word is independent of the occurrence of other words in the same document. This is reflected in Equation (5): P(w1,...,wn|Cj)=P(w1|Cj)*P(w2|Cj)*...*P(wn|Cj). It is in fact a na?ve assumption, but it significantly reduces computation costs, since the number of probabilities that should be computed is decreased. Even though this assumption does not hold in reality, NB performs surprisingly well for text classification (Mitchell, 1997). 5 Experiments and results For classification problems, it is customary to measure a classifier?s performance in terms of classification error rate. A data set of documents is used with known category/class label L(Dk) for each document Dk. The set is split into two subsets: a training set and a testing set. The trained classifier is used to assign a class AC(Dk) using Equation (3) to each document (Dk) in the test set, as if its true class label were not known. If AC(Dk) matches L(Dk), the classification is considered correct; otherwise, it is counted as an error: Errorik= ?? ? ?? ? ?= ii C ","@endWordPosition":"2003","@position":"12918","annotationId":"T10","@startWordPosition":"2002","@citStr":"Mitchell, 1997"}]},"title":{"#tail":"\n","#text":"Machine learning."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"T Mitchell"}}},{"volume":{"#tail":"\n","#text":"39"},"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"K. Nigam, A. K. McCallum, S. Thrun, and T.Mitchell, &quot;Text classification from labeled and unlabeled documents using EM,&quot; Machine Learning, vol. 39, pp. 103--134, 2000."},"#text":"\n","pages":{"#tail":"\n","#text":"103--134"},"marker":{"#tail":"\n","#text":"Nigam, McCallum, Thrun, Mitchell, 2000"},"title":{"#tail":"\n","#text":"Text classification from labeled and unlabeled documents using EM,&quot;"},"booktitle":{"#tail":"\n","#text":"Machine Learning,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"K Nigam"},{"#tail":"\n","#text":"A K McCallum"},{"#tail":"\n","#text":"S Thrun"},{"#tail":"\n","#text":"T Mitchell"}]}},{"#tail":"\n","date":{"#tail":"\n"},"rawString":{"#tail":"\n","#text":"T. Rachidi, O. Iraqi, M. Bouzoubaa, A. Ben Al Khattab, M. El Kourdi, A. Zahi, and A. Bensaid, ?Barq: distributed multilingual Internet search engine with focus on Arabic language,? Proceedings of IEEE Conf. on Sys., Man and Cyber., Washington DC, October 5-8, pp. , 2003."},"#text":"\n","pages":{"#tail":"\n","#text":"pp. ,"},"marker":{"#tail":"\n","#text":"Rachidi, Iraqi, Bouzoubaa, Khattab, El Kourdi, Zahi, Bensaid, "},"location":{"#tail":"\n","#text":"Washington DC,"},"title":{"#tail":"\n","#text":"Barq: distributed multilingual Internet search engine with focus on Arabic language,?"},"booktitle":{"#tail":"\n","#text":"Proceedings of IEEE Conf. on Sys., Man and Cyber.,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"T Rachidi"},{"#tail":"\n","#text":"O Iraqi"},{"#tail":"\n","#text":"M Bouzoubaa"},{"#tail":"\n","#text":"A Ben Al Khattab"},{"#tail":"\n","#text":"M El Kourdi"},{"#tail":"\n","#text":"A Zahi"},{"#tail":"\n","#text":"A Bensaid"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"M. Rogati and Y. Yang. ?High-performing feature selection for text classification,? ACM CIKM 2002."},"journal":{"#tail":"\n","#text":"ACM CIKM"},"#text":"\n","marker":{"#tail":"\n","#text":"Rogati, Yang, 2002"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"n, using feature selection Feature selection techniques have been widely used in information retrieval as a means for coping with the large number of words in a document; a selection is made to keep only the more relevant words. Various feature selection techniques have been used in automatic text categorization; they include document frequency (DF), information gain (IG) (Tzeras and Hartman, 1993), minimum description length principal (Lang, 1995), and the ?2 statistic. (Yang and Pedersen, 1997) has found strong correlations between DF, IG and the ?2 statistic for a term. On the other hand, (Rogati and Yang, 2002) reports the ?2 to produce best performance. In this paper, we use TF-IDF (a kind of augmented DF) as a feature selection criterion, in order to ensure results are comparable with those in (Yahyaoui, 2001). TF-IDF (term frequency-inverse document frequency) is one of the widely used feature selection techniques in information retrieval (Yates and Neto, 1999). Specifically, it is used as a metric for measuring the importance of a word in a document within a collection, so as to improve the recall and the precision of the retrieved documents. While the TF measurement concerns the importance of a","@endWordPosition":"3369","@position":"21115","annotationId":"T11","@startWordPosition":"3366","@citStr":"Rogati and Yang, 2002"}},"title":{"#tail":"\n","#text":"High-performing feature selection for text classification,?"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"M Rogati"},{"#tail":"\n","#text":"Y Yang"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Sakhr software company's website: www.sakhrsoft.com, 2004."},"#text":"\n","marker":{"#tail":"\n","#text":"2004"},"title":{"#tail":"\n","#text":"Sakhr software company's website: www.sakhrsoft.com,"},"@valid":"true"},{"volume":{"#tail":"\n","#text":"29"},"#tail":"\n","date":{"#tail":"\n","#text":"1973"},"rawString":{"#tail":"\n","#text":"G. Salton and C. S. Yang, &quot;On the specification of term values in automatic indexing&quot;, Journal of Documentation, Vol. 29, No. 4, pp. 351--372, 1973."},"journal":{"#tail":"\n","#text":"Journal of Documentation,"},"#text":"\n","pages":{"#tail":"\n","#text":"351--372"},"marker":{"#tail":"\n","#text":"Salton, Yang, 1973"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" within a collection, so as to improve the recall and the precision of the retrieved documents. While the TF measurement concerns the importance of a term in a given document, IDF seeks to measure the relative importance of a term in a collection of documents. The importance of each term is assumed to be inversely proportional to the number of documents that contain that term. TF is given by TFD,t, and it denotes frequency of term t in document D. IDF is given by IDFt = log(N/dft), where N is the number of documents in the collection, and dft is the number of documents containing the term t. (Salton and Yang, 1973) proposed the combination of TF and IDF as weighting schemes, and it has been shown that their product gave better performance. Thus, the weight of each term/root in a document is given by wD,t = TFD,t * IDFt. We have conducted five cross validation experiments based on TF-IDF. Experiments are based on selecting, in turn, 50, 100, 500, 1000, and 2000 terms that best represent the predefined 5 categories. We have repeated the experiments in Figure 3 for each number of terms. A summary of the results is presented in Table 6. The performance levels obtained are comparable to those obtained withou","@endWordPosition":"3554","@position":"22188","annotationId":"T12","@startWordPosition":"3551","@citStr":"Salton and Yang, 1973"}},"title":{"#tail":"\n","#text":"On the specification of term values in automatic indexing&quot;,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"G Salton"},{"#tail":"\n","#text":"C S Yang"}]}},{"volume":{"#tail":"\n","#text":"34"},"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"F. Sebastiani, ?Machine learning in automated text categorization,? ACM Computing Surveys, v.34 n.1, p.1-47, March 2002."},"journal":{"#tail":"\n","#text":"ACM Computing Surveys,"},"#text":"\n","pages":{"#tail":"\n","#text":"1--47"},"marker":{"#tail":"\n","#text":"Sebastiani, 2002"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"g, nearest neighbor learning, and artificial neural networks, early such works may be found in (Lewis and Ringnette, 1994), (Creecy and Masand, 1992) and (Wiene and Pedersen, 1995), respectively. The bulk of the text categorization work has been devoted to cope with automatic categorization of English and Latin character documents. For example, (Fang et al, 2001) discusses the evaluation of two different text categorization strategies with several variations of their feature spaces. A good study comparing document categorization algorithms can be found in (Yang and Liu, 1999). More recently, (Sebastiani, 2002) has performed a good survey of document categorization; recent works can also be found in (Joachims, 2002), (Crammer and Singer, 2003), and (Lewis et al, 2004). Concerning Arabic, one automatic categorizer has been reported to have been put under operational use to classify Arabic documents; it is referred to as &quot;Sakhr's categorizer&quot; (Sakhr, 2004). Unfortunately, there is no technical documentation or specification concerning this Arabic categorizer. Sakhr's marketing literature claims that this categorizer is based on Arabic morphology and some research that has been carried out on natural l","@endWordPosition":"664","@position":"4551","annotationId":"T13","@startWordPosition":"663","@citStr":"Sebastiani, 2002"}},"title":{"#tail":"\n","#text":"Machine learning in automated text categorization,?"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"F Sebastiani"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"K. Tzeras and S. Hartman, &quot;Automatic indexing based on Bayesian inference networks,&quot; Proc 16th Ann Int ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'93), pp. 22--34, 1993."},"#text":"\n","pages":{"#tail":"\n","#text":"22--34"},"marker":{"#tail":"\n","#text":"Tzeras, Hartman, 1993"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" words that are more frequent in the Sports category such as ????? (Arabic for prize and for trophy), ??? (Arabic for champion and for lead character), and ????? (Arabic for scoring and for recording). 5.2.2. Cross-validation, using feature selection Feature selection techniques have been widely used in information retrieval as a means for coping with the large number of words in a document; a selection is made to keep only the more relevant words. Various feature selection techniques have been used in automatic text categorization; they include document frequency (DF), information gain (IG) (Tzeras and Hartman, 1993), minimum description length principal (Lang, 1995), and the ?2 statistic. (Yang and Pedersen, 1997) has found strong correlations between DF, IG and the ?2 statistic for a term. On the other hand, (Rogati and Yang, 2002) reports the ?2 to produce best performance. In this paper, we use TF-IDF (a kind of augmented DF) as a feature selection criterion, in order to ensure results are comparable with those in (Yahyaoui, 2001). TF-IDF (term frequency-inverse document frequency) is one of the widely used feature selection techniques in information retrieval (Yates and Neto, 1999). Specifically, it ","@endWordPosition":"3333","@position":"20894","annotationId":"T14","@startWordPosition":"3330","@citStr":"Tzeras and Hartman, 1993"}},"title":{"#tail":"\n","#text":"Automatic indexing based on Bayesian inference networks,&quot;"},"booktitle":{"#tail":"\n","#text":"Proc 16th Ann Int ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'93),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"K Tzeras"},{"#tail":"\n","#text":"S Hartman"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"rawString":{"#tail":"\n","#text":"(Wiene and Pedersen, 1995) E. Wiener, J. O."},"#text":"\n","marker":{"#tail":"\n","#text":"1995"},"@valid":"false"},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"rawString":{"#tail":"\n","#text":"Pedersen, and A. S. Zeigend, &quot;A neural network approach to topic spotting,&quot; Proceedings of the Fourth Symposium on Document Analysis and Information Retrieval (SDAIR'95), 1995."},"#text":"\n","marker":{"#tail":"\n","#text":"Pedersen, Zeigend, 1995"},"title":{"#tail":"\n","#text":"A neural network approach to topic spotting,&quot;"},"booktitle":{"#tail":"\n","#text":"Proceedings of the Fourth Symposium on Document Analysis and Information Retrieval (SDAIR'95),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Pedersen"},{"#tail":"\n","#text":"A S Zeigend"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"M. Yahyaoui, &quot;Toward an Arabic web page classifier,&quot; Master project. AUI. 2001."},"#text":"\n","marker":{"#tail":"\n","#text":"Yahyaoui, 2001"},"publisher":{"#tail":"\n","#text":"AUI."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ic categorizer. Sakhr's marketing literature claims that this categorizer is based on Arabic morphology and some research that has been carried out on natural language processing. The present work evaluates the performance on Arabic documents of the Na?ve Bayes algorithm (NB) - one of the simplest algorithms applied to English document categorization (Mitchell, 1997). The aim of this work is to gain some insight as to whether Arabic document categorization (using NB) is sensitive to the root extraction algorithm used or to different data sets. This work is a continuation of that initiated in (Yahyaoui, 2001), which reports an overall NB classification correctness of 75.6%, in cross validation experiments, on a data set that consists of 100 documents for each of 12 categories (the data set is collected from different Arabic portals). A 50% overall classification accuracy is also reported when testing with a separately collected evaluation set (3 documents for each of the 12 categories). The present work expands the work in (Yahyaoui, 2001) by experimenting with the use of a better root extraction algorithm (El Kourdi, 2004) for document preprocessing, and using a different data set, collected from","@endWordPosition":"824","@position":"5606","annotationId":"T15","@startWordPosition":"823","@citStr":"Yahyaoui, 2001"},{"#tail":"\n","#text":" relevant words. Various feature selection techniques have been used in automatic text categorization; they include document frequency (DF), information gain (IG) (Tzeras and Hartman, 1993), minimum description length principal (Lang, 1995), and the ?2 statistic. (Yang and Pedersen, 1997) has found strong correlations between DF, IG and the ?2 statistic for a term. On the other hand, (Rogati and Yang, 2002) reports the ?2 to produce best performance. In this paper, we use TF-IDF (a kind of augmented DF) as a feature selection criterion, in order to ensure results are comparable with those in (Yahyaoui, 2001). TF-IDF (term frequency-inverse document frequency) is one of the widely used feature selection techniques in information retrieval (Yates and Neto, 1999). Specifically, it is used as a metric for measuring the importance of a word in a document within a collection, so as to improve the recall and the precision of the retrieved documents. While the TF measurement concerns the importance of a term in a given document, IDF seeks to measure the relative importance of a term in a collection of documents. The importance of each term is assumed to be inversely proportional to the number of document","@endWordPosition":"3404","@position":"21320","annotationId":"T16","@startWordPosition":"3403","@citStr":"Yahyaoui, 2001"},{"#tail":"\n","#text":"r the Sports and the Business categories with a classification accuracy that is higher than 70%. The performance of other categories ranges from 40% to 60%. The average accuracy over all categories is 62%. The results obtained in the evaluation set experiment are very consistent with the performance obtained in cross validation experiments. 6 Conclusions To sum up, this work has been carried out to automatically classify Arabic documents using the NB algorithm, with the use of a different data set, a different number of categories, and a different root extraction algorithm from those used in (Yahyaoui, 2001). In this work, the average accuracy over all categories is: 68.78% in cross validation and 62% in evaluation set experiments. The corresponding performances in (Yahyaoui, 2001) are 75.6% and 50%, respectively. Thus, the overall performance (including cross validation and evaluation set experiments) in this work is comparable to that in (Yahyaoui, 2001). This offers some indication that the performance of NB algorithm in classifying Arabic documents is not sensitive to the Arabic root extraction algorithm. Future work will be directed at experimenting with other root extraction algorithms. Fur","@endWordPosition":"4122","@position":"25919","annotationId":"T17","@startWordPosition":"4121","@citStr":"Yahyaoui, 2001"}]},"title":{"#tail":"\n","#text":"Toward an Arabic web page classifier,&quot; Master project."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"M Yahyaoui"}}},{"volume":{"#tail":"\n","#text":"1"},"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"Y. Yang, ?An evaluation of statistical approaches to text categorization,? Journal of Information Retrieval, Vol. 1, Number 1-2, pp. 69--90, 1999."},"journal":{"#tail":"\n","#text":"Journal of Information Retrieval,"},"#text":"\n","pages":{"#tail":"\n","#text":"69--90"},"marker":{"#tail":"\n","#text":"Yang, 1999"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"n effort required in performing manual categorization. It consists of assigning and labeling documents using a set of predefined categories based on document contents. As such, one of the primary objectives of automatic text categorization has been the enhancement and the support of information retrieval tasks to tackle problems, such as information filtering and routing, clustering of related documents, and the classification of documents into pre-specified subject themes. Automatic text categorization has been used in search engines, digital library systems, and document management systems (Yang, 1999). Such applications have included electronic email filtering, newsgroups classification, and survey data grouping. Barq for instance uses automatic categorization to provide similar documents feature (Rachidi et al, 2003). In this paper, NB which is a statistical machine learning algorithm is used to learn to classify non-vocalized1 Arabic web text documents. This paper is organized as follows. Section 2, briefly describe related works in the area of automatic text categorization. Section 3 describes the preprocessing undergone by documents for the purpose of categorization; it describes in pa","@endWordPosition":"383","@position":"2634","annotationId":"T18","@startWordPosition":"382","@citStr":"Yang, 1999"}},"title":{"#tail":"\n","#text":"An evaluation of statistical approaches to text categorization,?"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Y Yang"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"Y. Yang and X. Liu, ?A re-examination of text categorization methods,? Proceedings of ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'99), pp 42--49, 1999."},"#text":"\n","pages":{"#tail":"\n","#text":"42--49"},"marker":{"#tail":"\n","#text":"Yang, Liu, 1999"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"on tree learning and Bayesian learning, nearest neighbor learning, and artificial neural networks, early such works may be found in (Lewis and Ringnette, 1994), (Creecy and Masand, 1992) and (Wiene and Pedersen, 1995), respectively. The bulk of the text categorization work has been devoted to cope with automatic categorization of English and Latin character documents. For example, (Fang et al, 2001) discusses the evaluation of two different text categorization strategies with several variations of their feature spaces. A good study comparing document categorization algorithms can be found in (Yang and Liu, 1999). More recently, (Sebastiani, 2002) has performed a good survey of document categorization; recent works can also be found in (Joachims, 2002), (Crammer and Singer, 2003), and (Lewis et al, 2004). Concerning Arabic, one automatic categorizer has been reported to have been put under operational use to classify Arabic documents; it is referred to as &quot;Sakhr's categorizer&quot; (Sakhr, 2004). Unfortunately, there is no technical documentation or specification concerning this Arabic categorizer. Sakhr's marketing literature claims that this categorizer is based on Arabic morphology and some research tha","@endWordPosition":"660","@position":"4516","annotationId":"T19","@startWordPosition":"657","@citStr":"Yang and Liu, 1999"}},"title":{"#tail":"\n","#text":"A re-examination of text categorization methods,?"},"booktitle":{"#tail":"\n","#text":"Proceedings of ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'99),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Y Yang"},{"#tail":"\n","#text":"X Liu"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"R. B. Yates, and B. R. Neto,  Modern information retrieval. Addison-Wesley ISBN 0-201-39829-X, 1999."},"#text":"\n","pages":{"#tail":"\n","#text":"0--201"},"marker":{"#tail":"\n","#text":"Yates, Neto, 1999"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" of the same letters), but semantically different, can yield the same infix form thus creating ambiguity. The root extraction process is concerned with the transformation of all Arabic word derivatives to their single common root or canonical form. This process is very useful in terms of reducing and compressing the indexing structure, and in taking advantage of the semantic/conceptual relationships between the different forms of the same root. In this work, we use the Arabic root extraction technique in (El Kourdi, 2004). It compares favorably to other stemming or root extraction algorithms (Yates and Neto, 1999; Al-Shalabi and Evens, 1998; and Houmame, 1999), with a performance of over 97% for extracting the correct root in web documents, and it addresses the challenge of the Arabic broken plural and hollow verbs. In the remainder of this paper, we will use the term &quot;root&quot; and &quot;term&quot; interchangeably to refer to canonical forms obtained through this root extraction process. 4 NB for document categorization 4.1 The classifier module The classifier module is considered to be the core component of the document categorizer. It is responsible for classifying given Arabic documents to their target class. T","@endWordPosition":"1187","@position":"7927","annotationId":"T20","@startWordPosition":"1184","@citStr":"Yates and Neto, 1999"},{"#tail":"\n","#text":"ion gain (IG) (Tzeras and Hartman, 1993), minimum description length principal (Lang, 1995), and the ?2 statistic. (Yang and Pedersen, 1997) has found strong correlations between DF, IG and the ?2 statistic for a term. On the other hand, (Rogati and Yang, 2002) reports the ?2 to produce best performance. In this paper, we use TF-IDF (a kind of augmented DF) as a feature selection criterion, in order to ensure results are comparable with those in (Yahyaoui, 2001). TF-IDF (term frequency-inverse document frequency) is one of the widely used feature selection techniques in information retrieval (Yates and Neto, 1999). Specifically, it is used as a metric for measuring the importance of a word in a document within a collection, so as to improve the recall and the precision of the retrieved documents. While the TF measurement concerns the importance of a term in a given document, IDF seeks to measure the relative importance of a term in a collection of documents. The importance of each term is assumed to be inversely proportional to the number of documents that contain that term. TF is given by TFD,t, and it denotes frequency of term t in document D. IDF is given by IDFt = log(N/dft), where N is the number ","@endWordPosition":"3425","@position":"21475","annotationId":"T21","@startWordPosition":"3422","@citStr":"Yates and Neto, 1999"}]},"title":{"#tail":"\n","#text":"Modern information retrieval."},"booktitle":{"#tail":"\n","#text":"Addison-Wesley ISBN"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"R B Yates"},{"#tail":"\n","#text":"B R Neto"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Yang, Y., Pedersen J.P. A Comparative Study on Feature Selection in Text Categorization Proceedings of the 14th International Conference on Machine Learning, pp. 412-420, 1997."},"#text":"\n","pages":{"#tail":"\n","#text":"412--420"},"marker":{"#tail":"\n","#text":"Yang, Pedersen, 1997"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" ??? (Arabic for champion and for lead character), and ????? (Arabic for scoring and for recording). 5.2.2. Cross-validation, using feature selection Feature selection techniques have been widely used in information retrieval as a means for coping with the large number of words in a document; a selection is made to keep only the more relevant words. Various feature selection techniques have been used in automatic text categorization; they include document frequency (DF), information gain (IG) (Tzeras and Hartman, 1993), minimum description length principal (Lang, 1995), and the ?2 statistic. (Yang and Pedersen, 1997) has found strong correlations between DF, IG and the ?2 statistic for a term. On the other hand, (Rogati and Yang, 2002) reports the ?2 to produce best performance. In this paper, we use TF-IDF (a kind of augmented DF) as a feature selection criterion, in order to ensure results are comparable with those in (Yahyaoui, 2001). TF-IDF (term frequency-inverse document frequency) is one of the widely used feature selection techniques in information retrieval (Yates and Neto, 1999). Specifically, it is used as a metric for measuring the importance of a word in a document within a collection, so as ","@endWordPosition":"3347","@position":"20994","annotationId":"T22","@startWordPosition":"3344","@citStr":"Yang and Pedersen, 1997"}},"title":{"#tail":"\n","#text":"A Comparative Study on Feature Selection in Text Categorization"},"booktitle":{"#tail":"\n","#text":"Proceedings of the 14th International Conference on Machine Learning,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Y Yang"},{"#tail":"\n","#text":"J P Pedersen"}]}}]}}]}}
