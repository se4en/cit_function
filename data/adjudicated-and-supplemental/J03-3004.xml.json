{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","note":{"#tail":"\n","@confidence":"0.210079","#text":"\nComputational Linguistics Volume 29, Number 3\n"},"listItem":[{"#tail":"\n","@confidence":"0.869759","#text":"\n? School of Computing, Dublin 9, Ireland. E-mail: away@computing.dcu.ie\n? School of Computing, Dublin 9, Ireland. E-mail: ngough@computing.dcu.ie\n"},{"#tail":"\n","@confidence":"0.925456166666667","#text":"\n(3) La plupart ont formule? des critiques, mais certains ont fait des\nobservations mesquines.\nAn alternative translation that might be derived from the TM entries in (1) is that in\n(4):\n(4) La plupart ont formule? des critiques, mais certains comportaient des\nobservations mesquines.\n"},{"#tail":"\n","@confidence":"0.9258265","#text":"\n? language learning (Green 1979; Mori and Moeser 1983; Morgan, Meier,\nand Newport 1989)\n? monolingual grammar induction (Juola 1998)\n? grammar optimization (Juola 1994)\n? insights into universal grammar (Juola 1998)\n? machine translation (Juola 1994, 1997; Veale and Way 1997; Gough, Way,\n"},{"#tail":"\n","@confidence":"0.932685727272727","#text":"\n(6) a. You can attach a phone to the connector =? Vous pouvez re?lier un\nte?le?phone au connecteur.\nb. Connect only the keyboard and a mouse =? Connectez uniquement\nle clavier et une souris.\nLet us now confront the EBMT system with the new input string in (7):\n(7) You can attach a mouse to the connector.\nThis could be correctly translated by the EBMT system by isolating the useful trans-\nlation fragments in (8):\n(8) a. You can attach =? Vous pouvez re?lier (from (6a))\nb. a mouse =? une souris (from (6b))\nc. to the connector =? au connecteur (from (6a))\n"},{"#tail":"\n","@confidence":"0.689820333333333","#text":"\n2. Deriving Translation Resources from Web-Based MT Systems\nAll EBMT systems, from the initial proposal by Nagao (1984) to the recent collection\nof Carl and Way (2003), are premised on the availability of subsentential alignments\n"},{"#tail":"\n","@confidence":"0.9624345","#text":"\n? Learnability (Zernik and Dyer 1987)\n? Text generation (Hovy 1988; Milosavljevic, Tulloch, and Dale 1996)\n? Speech generation (Rayner and Carter 1997)\n? Localization (Scha?ler 1996)\n"},{"#tail":"\n","@confidence":"0.876359333333333","#text":"\n(19) English:\n<DET> The man looks\n<PREP> at <DET> the woman\nFrench:\n<DET> L? homme regarde\n<DET> la femme\n"},{"#tail":"\n","@confidence":"0.944824666666667","#text":"\n(21) <DET> The man likes <DET> the woman =?\n<DET> La femme pla??t <PREP> a` <DET> l? homme.\nThat is, without recourse to a lexicon or information about the relative distribution of\nwords and their translations, we would derive the marker chunks in (22):\n(22) a. <DET> The man likes =? <DET> La femme pla??t\nb. <DET> the woman =? <DET> l? homme\n"},{"#tail":"\n","@confidence":"0.854502","#text":"\n(25) ? [das], [which] ?\n? [ist], [is] ?\n? [was], [what] ?\n? [Sie], [you] ?\n? [wollten], [wanted] ?\n? [das ist], [which is] ?\n? [das ist was], [which is what] ?\n? [das ist was Sie], [which is what you] ?\n? [das ist was Sie wollten], [which is what you wanted] ?\n"},{"#tail":"\n","@confidence":"0.8530602","#text":"\nComputational Linguistics Volume 29, Number 3\n(33) a. P(la maison  |the house) = 8/10\nb. P(le domicile  |the house) = 2/10\nc. P(s?e?croula  |collapsed) = 1/7\nd. P(s?effondra  |collapsed) = 6/7\n"},{"#tail":"\n","@confidence":"0.947634857142857","#text":"\nGiven the aligned segments in (36), the correct translations (37) would be built:\n(37) a. Une maison s?e?croula.\nb. Une maison s?effondra.\nc. Un domicile s?e?croula.\nd. Un domicile s?effondra.\nHowever, in addition, the mistranslations in (38) would be constructed:\n(38) a. *Un maison s?e?croula.\n"},{"#tail":"\n","@confidence":"0.8630825","#text":"\nWay and Gough wEBMT\nb. *Un maison s?effondra.\nc. *Une domicile s?e?croula.\nd. *Une domicile s?effondra.\n"},{"#tail":"\n","@confidence":"0.976632545454545","#text":"\n(39) Noun phrases:\n? the heavy use of management fees last year\n? an increase through issues of new shares and convertible bonds\n? a space-based defense shield for official acts by the congressman\nSentences:\n? The bright red one interferes with the genes that are responsible for\ncollecting pollen.\n? A more recent novel permitted the new basket product.\n? The area with the museums and the charities is under something of a\ncloud.\n? Reducing the supply of goods as commissions to middlemen permitted\n"},{"#tail":"\n","@confidence":"0.78243975","#text":"\nfrom\n? each of the three individual on-line MT systems (A, B, and C)\n? each pair of on-line MT systems (AB, AC, and BC)\n? all three on-line MT systems (ABC).\n"},{"#tail":"\n","@confidence":"0.893970333333333","#text":"\n? 1: Contains major syntactic errors and is unintelligible\n? 2: Contains minor syntactic errors and is intelligible\n? 3: Contains no syntactic errors and is intelligible\n"},{"#tail":"\n","@confidence":"0.8014456","#text":"\n(40) A little girl misplaced a full page =? Une petite fille misplaced une\npleine page.\nThat is, although misplaced was present in the system?s database, it was not present in\nthe correct context. That is, it appeared in the phrasal lexicon, as shown in (41):\n(41) were misplaced =? ont e?te? e?gare?s\n"},{"#tail":"\n","@confidence":"0.820239333333333","#text":"\nsystem is 14, when translation fragments from all three systems are merged (ABC),\n224 translations are produced. Combining systems in this way means that all possible\ncombinations of chunks from the systems are produced: That is, the number of trans-\nlations generated via AB is much larger than those derived from either A or B, as now\nchunks from A and B may be combined to produce new translations that could not\nbe generated from the individual knowledge sources. As a further example, consider\nthe translation of the NP the total at risk a year. When fragments from systems A and\nB are combined, the ?best? translation is comprised of the chunk combination AAB,\nthat is, the three-chunk combination in (44), with the first two chunks obtained from\nsystem A, and the last from system B:\n(44) [Athe total], [Aat risk], [Ba year]\nThat is, the translation of this NP improves when the performance of system AB is\n"},{"#tail":"\n","@confidence":"0.6506385","#text":"\nby the on-line MT systems are shown in (46):\n(46) Input: Her short term interest rates link the issues.\nSystem A: Son lien a` court terme de taux d?intere?t les questions.\nwEBMT ABC: Ses taux d?intere?t a` court terme lient les questions.\n"}],"figure":[{"#tail":"\n","@confidence":"0.862437666666667","#text":"\n(15)\n<QUANT> all uses\n<PREP> of asbestos\n"},{"#tail":"\n","@confidence":"0.512245333333333","#text":"\n(16)\n<QUANT> all uses : tous usages\n<PREP> of asbestos : d? asbeste\n"},{"#tail":"\n","@confidence":"0.9722256","#text":"\n(23)\n<QUANT> all : tous\n<PREP> of : d?\n<LEX> uses : usages\n<LEX> asbestos : asbeste\n"},{"#tail":"\n","@confidence":"0.949310888888889","#text":"\n(24)\n<DET> the board : le conseil\n<DET> the : le\n<PREP> to <QUANT> 14 members : a` 14 membres\n<QUANT> 14 members : 14 membres\n<LEX> expanding : augmente\n<LEX> board : conseil\n<PREP> to : a`\n<LEX> members : membres\n"},{"#tail":"\n","@confidence":"0.79259875","#text":"\n<DET> major concern : inquie?tude majeure\nWords found in word-level lexicon:\n<DET> a : une\n<LEX> is : est\n"},{"#tail":"\n","@confidence":"0.950685842105263","#text":"\n(34) a. P(la maison s?e?croula  |the house collapsed) = 810 .\n1\n7 =\n8\n70\nb. P(le domicile s?e?croula  |the house collapsed) = 210 .\n1\n7 =\n2\n70\nc. P(la maison s?effondra  |the house collapsed) = 810 .\n6\n7 =\n48\n70\nd. P(le domicile s?effondra  |the house collapsed) = 210 .\n6\n7 =\n12\n"},{"#tail":"\n","@confidence":"0.9117008125","#text":"\n(35) Marker lexicon:\n<DET> the house : la maison\n<DET> the house : le domicile\nWord-level lexicon:\n<LEX> collapsed : s?e?croula\n<LEX> collapsed : s?effondra\nIf the input string were instead a house collapsed, and the NP a house were absent from\nthe marker lexicon, then a translation could be formed via the chunks in (36):\n(36) Generalized marker lexicon:\n<DET> house : maison\n<DET> house : domicile\nWord-level lexicon:\n<LEX> collapsed : s?e?croula\n<LEX> collapsed : s?effondra\n<DET> a : un\n<DET> a : une\n"},{"#tail":"\n","@confidence":"0.994324153846154","#text":"\nWay and Gough wEBMT\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nA B C\n"},{"#tail":"\n","@confidence":"0.764174333333333","#text":"\nTable 6\nNumber of translations produced for the\nNP a plan for reducing debt over 20 years.\nSystem(s) Number of Translations\nA 14\nB 10\nC 5\nAB 108\nAC 72\nBC 42\nABC 224\nThe results obtained regarding the ranking of the ?best? translation appear in\n"},{"#tail":"\n","@confidence":"0.981527375","#text":"\nComputational Linguistics Volume 29, Number 3\n0\n20\n40\n60\n80\n100\nAB BC AC ABC\n"}],"author":{"#tail":"\n","@confidence":"0.996286","#text":"\nAndy Way? Nano Gough?\n"},"equation":{"#tail":"\n","@confidence":"0.233519","#text":"\n(13)\n"},"subsectionHeader":[{"#tail":"\n","@confidence":"0.504235","#text":"\nWay and Gough wEBMT\n"},{"#tail":"\n","@confidence":"0.992762","#text":"\n2.1 The Phrasal Lexicon\n"},{"#tail":"\n","@confidence":"0.659358","#text":"\nComputational Linguistics Volume 29, Number 3\n2.2 The Marker Lexicons\n"},{"#tail":"\n","@confidence":"0.514556","#text":"\nWay and Gough wEBMT\n"},{"#tail":"\n","@confidence":"0.511541","#text":"\nWay and Gough wEBMT\n"},{"#tail":"\n","@confidence":"0.99657","#text":"\n2.3 Summary\n"},{"#tail":"\n","@confidence":"0.999785","#text":"\n3.1 Segmentation of the Input\n"},{"#tail":"\n","@confidence":"0.998511","#text":"\n3.2 Retrieving Translation Chunks\n"},{"#tail":"\n","@confidence":"0.999706","#text":"\n3.3 Calculation of Weights\n"},{"#tail":"\n","@confidence":"0.989683","#text":"\n4.1 Experiments Using Single Knowledge Sources\n"},{"#tail":"\n","@confidence":"0.3002","#text":"\nWay and Gough wEBMT\n"},{"#tail":"\n","@confidence":"0.986559","#text":"\n4.2 Experiments Using Multiple Knowledge Sources\n"},{"#tail":"\n","@confidence":"0.562697","#text":"\nWay and Gough wEBMT\n"},{"#tail":"\n","@confidence":"0.999086","#text":"\n4.3 Summary\n"},{"#tail":"\n","@confidence":"0.993221","#text":"\n4.4 Relative Gain of EBMT\n"},{"#tail":"\n","@confidence":"0.563059","#text":"\nWay and Gough wEBMT\n"},{"#tail":"\n","@confidence":"0.998602","#text":"\n4.5 Evaluating Individual On-line MT Systems\n"},{"#tail":"\n","@confidence":"0.564296","#text":"\nWay and Gough wEBMT\n"}],"subsubsectionHeader":[{"#tail":"\n","@confidence":"0.838506","#text":"\n4.1.1 Sentences. The test set comprised 200 sentences, with an average sentence length\n"},{"#tail":"\n","@confidence":"0.800356","#text":"\nExperiment 1: Third-Person Plural Subjects\n"},{"#tail":"\n","@confidence":"0.992358","#text":"\nExperiment 2: Seeding the Databases with More Examples\n"},{"#tail":"\n","@confidence":"0.611898","#text":"\n4.1.2 Experiment 3: Noun Phrases. The test set comprised 500 noun phrases, with an\n"},{"#tail":"\n","@confidence":"0.59402","#text":"\n4.2.1 Experiment 4: Translating Sentences by Combining Fragments from Different\n"},{"#tail":"\n","@confidence":"0.364498","#text":"\n4.2.2 Experiment 5: Combining Fragments from Different Systems and Seeding the\n"},{"#tail":"\n","@confidence":"0.469555","#text":"\n4.2.3 Experiment 6: Translating Noun Phrases by Combining Fragments from Dif-\n"}],"footnote":[{"#tail":"\n","@confidence":"0.767136","#text":"\n3 We refer the interested reader to the excellent and comprehensive bibliography on parallel text\nprocessing available at http://www.up.univ-mrs.fr/?veronis/biblios/ptp.htm.\n"},{"#tail":"\n","@confidence":"0.986705333333333","#text":"\n4 http://www.freetranslation.com\n5 http://trans.voila.fr\n6 http://www.logomedia.net\n"},{"#tail":"\n","@confidence":"0.9321685","#text":"\n3rd p.s:3\n3rd p.p:3\n3rd p.p/s:3\n3rd\n"},{"#tail":"\n","@confidence":"0.606528428571429","#text":"\n3rd p.s:3\n3rd p.p:3\n3rd p.s/p:3\n3rd\np.s/p:3+2\nFigure 2\nTranslation quality improves when system databases are seeded with more translation pairs\n"},{"#tail":"\n","@confidence":"0.434298","#text":"\n9 Such a translation would be a candidate for post hoc validation via the Web (cf. Section 5), but the\ncorrect translation lignes cellulaires mobiles pour les ouvriers is produced in any case by system C,\nrendering this unnecessary.\n"}],"construct":{"#tail":"\n","@confidence":"0.795290857142857","#text":"\n<DET> {the, a, an, those, these, . . . }\n<PREP> {in, on, out, with, from, to, under, . . . }\n<QUANT> {all, some, few, many, . . . }\n<CONJ> {and, or, . . . }\n<POSS> {my, your, our,. . . }\n<PRON> {I, you, he, she, it,. . . }\nA similar set (14) was produced for French, the target language in our wEBMT system:\n(14)\n<DET> {le, la, l?, les, ce, ces, ceux, cet, . . . }\n<PREP> {dans, sur, avec, de, a`, sous, . . . }\n<QUANT> {tous, tout, toutes, certain, quelques, beaucoup, . . . }\n<CONJ> {et, ou, . . . }\n<POSS> {mon, ma, mes, ton, ta, tes, notre, nos, . . . }\n<PRON> {je, j?, tu, il, elle, . . . }\n"},"title":{"#tail":"\n","@confidence":"0.5365605","#text":"\nc? 2003 Association for Computational Linguistics\nwEBMT: Developing and Validating an\nExample-Based Machine Translation\nSystem Using the World Wide Web\n"},"@confidence":"0.000000","reference":[{"#tail":"\n","@confidence":"0.994780125","#text":"\nAhrenberg, Lars, Mikael Andersson, and\nMagnus Merkel. 2002. A system for\nincremental and interactive word linking.\nIn Proceedings of the Third International\nConference on Language Resources and\nEvaluation (LREC), pages 485?490, Las\nPalmas, Canary Islands, Spain.\nBecker, Joseph. 1975. The phrasal lexicon. In\nProceedings of the International Workshop on\nTheoretical Issues in Natural Language\nProcessing, pages 70?73, Cambridge, MA.\nBlock, Hans-Ulrich. 2000. Example-based\nincremental synchronous interpretation.\nIn Wolfgang Wahlster, editor, Verbmobil:\nFoundations of Speech-to-Speech Translation,\nSpringer Verlag, Berlin/Heidelberg/New\n"},{"#tail":"\n","@confidence":"0.999727577235772","#text":"\nComputational Linguistics Volume 29, Number 3\nYork, pages 411?417.\nBod, Rens, Remko Scha, and Khalil Sima?an,\neditors. 2003. Data-Oriented Parsing. CSLI\nPublications, Stanford, CA.\nBoutsis, Sotiris, and Stelios Piperidis. 1998.\nAligning clauses in parallel texts. In\nProceedings of the Third Conference on\nEmpirical Methods in Natural Language\nProcessing, pages 17?26, Granada, Spain.\nBrown, Ralf. 2000. Automated\ngeneralization of translation examples. In\nEighteenth International Conference on\nComputational Linguistics: COLING 2000 in\nEurope, pages 125?131, Saarbru?cken,\nGermany.\nBrown, Ralf. 2003. Clustered transfer-rule\ninduction for example-based translation.\nIn Michael Carl and Andy Way, editors,\nRecent Advances in Example-Based Machine\nTranslation. Kluwer Academic, Dordrecht,\nthe Netherlands, pages 287?305.\nCarl, Michael. 1999. Inducing translation\ntemplates for example-based machine\ntranslation. In Machine Translation Summit\nVII, pages 250?258, Singapore.\nCarl, Michael, and Andy Way, editors. 2003.\nRecent Advances in Example-Based Machine\nTranslation. Kluwer Academic, Dordrecht,\nthe Netherlands.\nCarl, Michael, Andy Way, and Reinhard\nScha?ler. 2002. Toward a hybrid integrated\ntranslation environment. In Stephen\nRichardson, editor, Machine Translation:\nFrom Research to Real Users: Fifth Conference\nof the Association for Machine Translation in\nthe Americas (AMTA-2002). Lecture Notes\nin Artificial Intelligence 2499. Springer\nVerlag, Berlin/Heidelberg, pages 11?20.\nCicekli, Ilyas, and Altay Gu?venir. 1996.\nLearning translation rules from a\nbilingual corpus. In Proceedings of the\nSecond International Conference on New\nMethods in Language Processing, pages\n90?97, Ankara, Turkey.\nFrederking, Robert, and Sergei Nirenburg.\n1994. Three heads are better than one. In\nProceedings of the Fourth Conference on\nApplied Natural Language Processing\n(ANLP-94), pages 95?100, Stuttgart,\nGermany.\nFrederking, Robert, Sergei Nirenburg, David\nFarwell, Steven Helmreich, Eduard Hovy,\nKevin Knight, Stephen Beale, Constantin\nDomashnev, Donna Attardo, Dean\nGrannes, and Ralf Brown. 1994.\nIntegrating translations from multiple\nsources with the Pangloss Mark III\nmachine translation system. In Proceedings\nof the First Conference of the Association for\nMachine Translation in the Americas, pages\n73?80, Columbia, MD.\nFung, Pascale, and Kathleen McKeown.\n1997. Finding terminology translations\nfrom non-parallel corpora. In Proceedings\nof the Fifth Annual Workshop on Very Large\nCorpora, pages 192?202, Hong Kong.\nGough, Nano, Andy Way, and Mary\nHearne. 2002. Example-based machine\ntranslation via the Web. In Stephen\nRichardson, editor, Machine Translation:\nFrom Research to Real Users: Fifth Conference\nof the Association for Machine Translation in\nthe Americas (AMTA-2002) Lecture Notes\nin Artificial Intelligence 2499. Springer\nVerlag, Berlin/Heidelberg, pages 74?83.\nGreen, Thomas. 1979. The necessity of\nsyntax markers: Two experiments with\nartificial languages. Journal of Verbal\nLearning and Behavior, 18:481?496.\nGrefenstette, Gregory. 1999. The World Wide\nWeb as a resource for example-based\nmachine translation tasks. In Proceedings of\nthe ASLIB Conference on Translating and the\nComputer, volume 21, London.\nHogan, Christopher, and Robert E.\nFrederking. 1998. An evaluation of the\nmulti-engine MT architecture. In Machine\nTranslation and the Information Soup:\nProceedings of the Third Conference of the\nAssociation for Machine Translation in the\nAmericas (AMTA ?98), Lecture Notes in\nArtificial Intelligence 1529. Springer\nVerlag, Berlin/Heidelberg, pages 113?123.\nHovy, Edward. 1988. Generating language\nwith a phrasal lexicon. In David\nMcDonald and Leonard Bolc, editors,\nNatural Language Generation Systems.\nSpringer Verlag, New York, pages\n353?384.\nJuola, Patrick. 1994. A psycholinguistic\napproach to corpus-based machine\ntranslation. In CSNLP 1994: Third\nInternational Conference on the Cognitive\nScience of Natural Language Processing,\nDublin.\nJuola, Patrick. 1997. Corpus-based\nacquisition of transfer functions using\npsycholinguistic principles. In Daniel\nJones and Harold Somers, editors, New\nMethods in Language Processing. UCL Press,\nLondon, pages 207?218.\nJuola, Patrick. 1998. On psycholinguistic\ngrammars. Grammars, 1(1):15?31.\nKaji, Hiroyuki, Takuya Kida, and Yuji\nMorimoto. 1992. Learning translation\ntemplates from bilingual text. In\nProceedings of the 15th [sic] International\nConference on Computational Linguistics\n(COLING), pages 672?678, Nantes,\nFrance.\nKay, Martin, and Martin Ro?scheisen. 1993.\nText-translation alignment. Computational\n"},{"#tail":"\n","@confidence":"0.999377514851485","#text":"\nWay and Gough wEBMT\nLinguistics, 19(1):121?142.\nLittlestone, Nick, and Manfred Warmuth.\n1992. The weighted majority algorithm.\nTechnical Report UCSC-CRL-91-28,\nUniversity of California, Santa Cruz.\nMacklovitch, Elliott. 2000. Two types of\ntranslation memory. In Proceedings of the\nASLIB Conference on Translating and the\nComputer, volume 22, London.\nMacklovitch, Elliott, and Graham Russell.\n2000. What?s been forgotten in translation\nmemory. In Envisioning Machine Translation\nin the Information Future: Proceedings of\nFourth Conference of the Association for\nMachine Translation in the Americas\n(AMTA-2000), pages 137?146, Cuernavaca,\nMexico.\nMcTait, Kevin, and Arturo Trujillo. 1999. A\nlanguage-neutral sparse-data algorithm\nfor extracting translation patterns. In\nProceedings of the Eighth International\nConference on Theoretical and Methodological\nIssues in Machine Translation, pages 98?108,\nChester, England.\nMilosavljevic, Maria, Adrian Tulloch, and\nRobert Dale. 1996. Text generation in a\ndynamic hypertext environment. In\nProceedings of the 19th Australasian\nComputer Science Conference, pages\n417?426, Melbourne, Australia.\nMorgan, James, Richard Meier, and Elissa\nNewport. 1989. Facilitating the acquisition\nof syntax with cross-sentential cues to\nphrase structure. Journal of Memory and\nLanguage, 28:360?374.\nMori, Kazuo, and Shannon Moeser. 1983.\nThe role of syntax markers and semantic\nreferents in learning an artificial\nlanguage. Journal of Verbal Learning and\nVerbal Behavior, 22:701?718.\nNagao, Makoto. 1984. A framework of a\nmechanical translation between Japanese\nand English by analogy principle. In\nAlick Elithorn and Ranan Banerji, editors,\nArtificial and Human Intelligence.\nNorth-Holland, Amsterdam, pages\n173?180.\nRayner, Manny, and David Carter. 1997.\nHybrid language processing in the\nspoken language translator. In Proceedings\nof the IEEE International Conference on\nAcoustics, Speech and Signal Processing,\npages 107?110, Munich.\nSato, Satoshi, and Makoto Nagao. 1990.\nToward memory-based translation. In\nCOLING-90: Papers Presented to the 13th\nInternational Conference on Computational\nLinguistics, pages 247?252, Helsinki.\nScha?ler, Reinhard. 1996. Machine translation,\ntranslation memories and the phrasal\nlexicon: The localisation perspective. In\nProceedings of TKE-96: EAMT Workshop on\nMachine Translation, pages 21?33, Vienna.\nScha?ler, Reinhard, Andy Way, and Michael\nCarl. 2003. Example-based machine\ntranslation in a controlled environment.\nIn Michael Carl and Andy Way, editors,\nRecent Advances in Example-Based Machine\nTranslation, Kluwer Academic, Dordrecht,\nthe Netherlands, pages 83?114.\nSimard, Michel, and Philippe Langlais. 2001.\nSubsentential exploitation of translation\nmemories. In Machine Translation Summit\nVIII, pages 335?339, Santiago de\nCompostela, Spain.\nSomers, Harold. 1998. Further experiments\nin bilingual text alignment. International\nJournal of Corpus Linguistics, 3:115?150.\nSomers, Harold, Ian McLean, and Daniel\nJones. 1994. Experiments in multilingual\nexample-based generation. In CSNLP\n1994: Third International Conference on the\nCognitive Science of Natural Language\nProcessing, Dublin.\nVeale, Tony, and Andy Way. 1997. Gaijin: A\nbootstrapping, template-driven approach\nto example-based machine translation. In\nInternational Conference, Recent Advances in\nNatural Language Processing, pages\n239?244, Tzigov Chark, Bulgaria.\nWatanabe, Hideo. 1993. A method for\nextracting translation patterns from\ntranslation examples. In Proceedings of the\nFifth International Conference on Theoretical\nand Methodological Issues in Machine\nTranslation (TMI ?93): MT in the Next\nGeneration, pages 292?301, Kyoto, Japan.\nZernik, Uri, and Michael Dyer. 1987. The\nself-extending phrasal lexicon. Com-\nputational Linguistics, 13(3?4):308?327.\n"}],"#tail":"\n","bodyText":[{"#tail":"\n","@confidence":"0.999050538461538","#text":"\nWe have developed an example-based machine translation (EBMT) system that uses the World\nWide Web for two different purposes: First, we populate the system?s memory with translations\ngathered from rule-based MT systems located on the Web. The source strings input to these\nsystems were extracted automatically from an extremely small subset of the rule types in the Penn-\nII Treebank. In subsequent stages, the ?source, target? translation pairs obtained are automatically\ntransformed into a series of resources that render the translation process more successful. Despite\nthe fact that the output from on-line MT systems is often faulty, we demonstrate in a number\nof experiments that when used to seed the memories of an EBMT system, they can in fact prove\nuseful in generating translations of high quality in a robust fashion. In addition, we demonstrate\nthe relative gain of EBMT in comparison to on-line systems. Second, despite the perception that\nthe documents available on the Web are of questionable quality, we demonstrate in contrast that\nsuch resources are extremely useful in automatically postediting translation candidates proposed\nby our system.\n"},{"#tail":"\n","@confidence":"0.925705764705882","#text":"\nIn quite a short space of time, translation memory (TM) systems have become a very\nuseful tool in the translator?s armory. TM systems store a set of ?source, target? trans-\nlation pairs in their databases. If a new input string cannot be found exactly in the\ntranslation database, a search is conducted for close (or ?fuzzy?) matches of the input\nstring, and these are retrieved together with their translations for the translator to\nmanipulate into the final, output translation. From this description, it should be clear\nthat TM systems do not translate: Indeed, some researchers consider them to be little\nmore than a search-and-replace engine, albeit a rather sophisticated one (Macklovitch\nand Russell 2000).\nWe can illustrate this with respect to the TM entries in (1), taken from the Canadian\nHansards:\n(1) a. While most were critical, some contributions were thoughtful and\nconstructive =? La plupart ont formule? des critiques, mais certains ont\nfait des observations re?fle?chies et constructives.\nb. Others were plain meanspirited and some contained errors of fact =?\nD?autres discours comportaient des propos mesquins et me?me des\nerreurs de fait.\n"},{"#tail":"\n","@confidence":"0.960729444444445","#text":"\nComputational Linguistics Volume 29, Number 3\nConsider the new source string in (2):\n(2) While most were critical, some contributions were plain meanspirited.\nDespite the fact that this new input in (2) is extremely close to the source strings\nin the TM entries in (1), no TM system containing just these translation pairs in its\ndatabase would be able to translate (2); the best they could do would be to identify\none or both of the two source sentences in the TM in (1) as fuzzy matches and display\nthese, together with their French translations. The translator would then manipulate\nthe target strings in the TM into the final translation (3):\n"},{"#tail":"\n","@confidence":"0.998085483870968","#text":"\nAt all stages in the translation process, therefore, the translators themselves are the\nintegral figures: They are free to accept or reject any suggested matches, they construct\nthe translations, and they may or may not use any translations proposed by the TM\nsystem to formulate the translations in the target document. Finally, they are free to\ninsert the translations produced into the TM itself as they see fit: that is, either (3) or\n(4) could be inserted into the TM with the source string (2), or some other translation,\nif that were preferred.\nA prerequisite for TM (and example-based machine translation [EBMT]) applica-\ntions is a parallel corpus aligned at sentential level. Such a corpus may be presented\nto translators en bloc, or translators may help construct it themselves. Here too the\ntranslator maintains a large degree of autonomy: Using a tool such as Trados WinAlign,\nfor example, he or she may manually overwrite some of the aligner?s decisions by\nlinking ?source, target? sentence pairs using the graphical interface provided.\nNevertheless, TM systems are currently falling far short of their potential, given\nthe limitation that the smallest accessible translation units are ?source, target? strings\naligned only at sentential level. Consider the fuzzy matching operation, for instance:\nTranslators are able to set a fuzzy match threshold below which no translation pairs\nare proposed by the TM system. If this threshold is set too low, then potentially useful\ntranslation pairs will be presented along with a lot of noise, thereby risking that this\nuseful translation information will be obscured (high recall, low precision); if it is set\ntoo low, then good matches will be presented, but potentially useful matches will\nnot be (low recall, high precision). We noted above that faced with the new input in\n(2), a TM system might be able to present the translator with the fuzzy matches in\n(1). However, if a translator were to set the level of fuzzy matching at 80% (a not\nunreasonable level), then neither of the translation pairs in (1) would be deemed to\nbe a suitably good fuzzy match, as only 7/9 (77%) of the words in (1a) match those\nin (2) exactly, and only 3/9 (33%) of the words in (1b) match those in (2) exactly.\nIndeed, setting an appropriate fuzzy match level is such a difficult problem that some\ntranslators switch off this option and use the TM only to find exact matches.\nIf subsentential alignment could be integrated into the TM databases, more useful\nfragments could be put at the disposal of the translator. If we could fragment the\n"},{"#tail":"\n","@confidence":"0.971521685714286","#text":"\nWay and Gough wEBMT\nsententially aligned TM examples in (1) so that subsentential chunks were displayed\nto the user, then the chance of finding exact matches or good fuzzy matches would\nincrease considerably. This is currently beyond the scope of TM systems.\nIn contrast, EBMT systems have overcome this constraint by storing subsentential\ntranslational correspondences in addition to the sententially aligned pairs from which\nthey are derived. As a consequence, where a TM system can only propose a number\nof close-scoring matches in its database for the translator to adapt into the final trans-\nlation, an EBMT system can produce translations itself by automatically combining\nchunks from different translation examples stored in its memories.\nIn Section 2, we describe how we automatically obtain a hierarchy of lexical re-\nsources that are used sequentially by our EBMT system, wEBMT, to translate new\ninput. The primary resource gathered is a ?phrasal lexicon,? constructed by extracting\nover 200,000 phrases from the Penn Treebank and having them translated into French\nby three Web-based machine translation (MT) systems.\nEach set of translations is stored separately, and for each set the ?marker hypoth-\nesis? (Green 1979) is used to segment the phrasal lexicon into a ?marker lexicon.? The\nmarker hypothesis is a universal psycholinguistic constraint which states that natural\nlanguages are ?marked? for complex syntactic structure at surface form by a closed\nset of specific lexemes and morphemes. That is, a basic phrase-level segmentation of\nan input sentence can be achieved by exploiting a closed list of known marker words\nto signal the start and end of each segment.\nConsider the following example, selected at random from the Wall Street Journal\nsection of the Penn-II Treebank:\n(5) The Dearborn, Mich., energy company stopped paying a dividend in the\nthird quarter of 1984 because of troubles at its Midland nuclear plant.\nHere we see that three noun phrases start with determiners and one with a possessive\npronoun. The sets of determiners and possessive pronouns are both very small. Fur-\nthermore, there are four prepositional phrases, and the set of prepositions is similarly\nsmall. A further assumption that could be made is that all words that end with -ed are\nverbs, such as stopped in (5). The marker hypothesis is arguably universal in presum-\ning that concepts and structures like these have similar morphological or structural\nmarking in all languages.\nThe marker hypothesis has been used for a number of different language-related\ntasks, including\n"},{"#tail":"\n","@confidence":"0.8894562","#text":"\nand Hearne 2002)\nWith respect to translation, a potential problem in using the marker hypothesis is that\nsome languages do not have marker words such as articles, for instance. Green?s (1979)\nwork showed that artificial languages, both with and without specific marker words,\nmay be learned more accurately and quickly if such psycholinguistic cues exist. The\n"},{"#tail":"\n","@confidence":"0.986655166666667","#text":"\nComputational Linguistics Volume 29, Number 3\nresearch of Mori and Moeser (1983) showed a similar effect due to case marking on\npseudowords in such artificial languages, and Morgan, Meier, and Newport (1989)\ndemonstrated that languages that do not permit pronouns as substitutes for phrases\nalso provide evidence in favor of the marker hypothesis. Juola?s (1994, 1998) work\non grammar optimization and induction shows that context-free grammars can be\nconverted to ?marker-normal form.? However, marker-normal form grammars cannot\ncapture the sorts of regularities demonstrated for languages that do not have a one-\nto-one mapping between a terminal symbol and a word. Nevertheless, Juola (1998,\npage 23) observes that ?a slightly more general mapping, where two adjacent termi-\nnal symbols can be merged into a single lexical item (for example, a word and its\ncase-marking), can capture this sort of result quite handily.? Work using the marker\nhypothesis for MT adapts this monolingual mapping for pairs of languages: It is rea-\nsonably straightforward to map an English determiner-noun sequence onto a Japanese\nnoun?case marker segment, once one has identified the sets of marker tags in the lan-\nguages to be translated.\nFollowing construction of the marker lexicon, the ?source, target? chunks are gen-\neralized further using a methodology based on Block (2000) to permit a limited form\nof insertion in the translation process. As a byproduct of the chosen methodology,\nwe also derive a standard ?word-level? translation lexicon. These various resources\nrender the set of original translation pairs far more useful in deriving translations of\npreviously unseen input.\nIn Section 3, we describe in detail the segmentation process, together with the\nprocedure whereby target chunks are combined to produce candidate translations. In\nSection 4, we report initially on two experiments in which we test different versions\nof our EBMT system against test sets of NPs and sentences. We then conduct a set of\nfurther experiments which show that using the resources developed from more than\none on-line MT system may improve both translation coverage and quality. Further-\nmore, seeding the system databases with more fragments improves translation quality.\nIn addition, we calculate the net gain of our EBMT system by comparing translation\nquality against that of the three on-line MT systems. Finally, we comment on the\nrelative strengths and weaknesses of the three on-line MT systems used.\nLike most EBMT systems, our approach suffers from the problem of ?boundary\nfriction?: where chunks from different translation examples are recombined, the quality\nof the resulting translations may be compromised. Assume that the aligned examples\nin (6) are located in the system database:\n"},{"#tail":"\n","@confidence":"0.906358891304348","#text":"\nWay and Gough wEBMT\nRecombining the French chunks gives us the correct translation in (9):\n(9) Vous pouvez re?lier une souris au connecteur.\nHowever, a number of mistranslations could also ensue, including those in (10):\n(10) a. *Vous pouvez re?lier un souris au connecteur.\nb. *Vous pouvez re?lier un souris au le connecteur.\nThe mistranslation (10a) could be formed via the set of inferences in (11):\n(11) You can attach a =? Vous pouvez re?lier un (from (6a))\nmouse =? souris (from (6b))\nto the connector =? au connecteur (from (6a))\nThe mistranslation (10b) could be formed via the set of inferences in (12):\n(12) You can attach a =? Vous pouvez re?lier un (from (6a))\nmouse =? souris (from (6b))\nto =? au (from (6a))\nthe =? le (from (6b))\nconnector =? connecteur (from (6a))\nIt is clear, therefore, that unless the process by which the original ?source, target?\nsentence pairs are fragmented is well defined and strictly controlled, chunks may\nbe combined from different contexts that result in agreement errors such as those in\n(10).1 Depending on the input string, our wEBMT system may generate thousands\nof candidate translations, including many mistranslations like those in (10). A major\nadvantage of MT systems based on probabilities is that output translations can be\nranked (and pruned, if required): One would hope that such systems would rank\ngood translations such as that in (9) more highly than poor ones such as those in (10).\nWe demonstrate that in almost all experiments, our EBMT system consistently ranks\nthe ?best? translation in the top 10 output translations, and always in the top 1% of\nthe translations generated.\nIn order to minimize errors of boundary friction, in Section 5 we develop a novel,\npost hoc procedure via the World Wide Web to validate and, if necessary, correct\ntranslations prior to their being output to the user.2 Finally we conclude and point to\nareas of future research.\n1 Note also that with respect to the translations given in (3) and (4), the translator interacting with the\nTM has used his or her translation knowledge to avoid a problem of boundary friction: Given the TM\nentries in (1), the translation of plain meanspirited would appear to be mesquins. This is correct in this\ncontext, as it co-occurs with a masculine plural noun propos. In translating (2), however, observations is a\nfeminine plural noun, so the adjective mesquines is inserted to maintain agreement throughout the NP.\nIf the translation pair ?plain meanspirited, mesquines? were not found in the system?s memories, then\nonly the mistranslation observations mesquins could be produced by an EBMT system.\n2 One of the areas of boundary friction that we use our post hoc validation procedure to correct is that of\nsubject-verb agreement. Note that with examples such as (18), this is not usually (such) a problem for\nmarker-based approaches to MT as we face here, as verbs are contained within (part of) the same\nchunk as their subject NPs. However, given that we translate phrases rather than sentences, it is a\nconsiderable problem for our approach, yet one that we overcome satisfactorily. In further work, if we\nwere to store the translations of the VPs with their dummy subject NPs in a sentential lexicon and\nderive all marker lexicons from this database, the problem of subject-verb agreement would be largely\novercome.\n"},{"#tail":"\n","@confidence":"0.968386611111111","#text":"\nderived from the input bitext. There is a wealth of literature on trying to establish sub-\nsentential translations from a bilingual corpus.3 Kay and Ro?scheisen (1993) attempt to\nextract a bilingual dictionary using a hybrid method of sentence and word alignment\non the assumption that the ?source, target? words have a similar distribution. Fung\nand McKeown (1997) attempt to translate technical terms using word relation matrices,\nalthough the resource from which such relations are derived is a pair of nonparallel\ncorpora. Somers (1998) replicates the work of Fung and McKeown with different lan-\nguage pairs using the simpler metric of Levenshtein distance. Boutsis and Piperidis\n(1998) use a tagged parallel corpus to extract translationally equivalent English-Greek\nclauses on the basis of word occurrence and co-occurrence probabilities. The respec-\ntive lengths of the putative alignments in terms of characters is also an important\nfactor. Ahrenberg, Andersson, and Merkel (2002) observe that for less widely spoken\nlanguages, the relative lack of linguistic tools and resources has forced developers of\nword alignment tools for such languages to use shallow processing and basic statis-\ntical approaches to word linking. Accordingly, they generate lexical correspondences\nby means of co-occurrence measures and string similarity metrics.\nMore specifically, the notion of the phrasal lexicon (used first by Becker 1975) has\nbeen used successfully in a number of areas:\n"},{"#tail":"\n","@confidence":"0.991179529411765","#text":"\nMore recently, Simard and Langlais (2001) have proposed the exploitation of TMs at\na subsentential level, while Carl, Way, and Scha?ler (2002) and Scha?ler, Way, and Carl\n(2003, pages 108?109) describe how phrasal lexicons might come to occupy a central\nplace in a future hybrid integrated translation environment. This, they suggest, may\nresult in a paradigm shift from TM to EBMT via the phrasal lexicon: Translators are\non the whole wary of MT technology, but once subsentential alignment is enabled,\ntranslators will become aware of the benefits to be gained from ?source, target? phrasal\nsegments, and from there they suggest that ?it is a reasonably short step to enabling\nan automated solution via the recombination element of EBMT systems such as those\ndescribed in [Carl and Way 2003].?\nIn this section, we describe how the memory of our EBMT system is seeded with\na set of translations obtained from Web-based MT systems. From this initial resource,\nwe subsequently derive a number of different databases that together allow many\nnew input sentences to be translated that it would not be possible to translate in\nother systems. First, the phrasal lexicon is segmented using the marker hypothesis to\nproduce a marker lexicon. This is then generalized, following a methodology based on\nBlock (2000), to generate the ?generalized marker lexicon.? Finally, as a result of the\n"},{"#tail":"\n","@confidence":"0.92818","#text":"\nmethodology chosen, we automatically derive a fourth resource, namely, a ?word-level\nlexicon.?\n"},{"#tail":"\n","@confidence":"0.999415333333333","#text":"\nOur phrasal lexicon was built by selecting a set of 218,697 English noun phrases and\nverb phrases from the Penn Treebank. We identified all rule types occurring 1,000\nor more times and eliminated those that were not relevant (e.g., rules dealing only\nwith numbers). Where rules contained just a single nonterminal on their right-hand\nside, only those rules whose left-hand side was VP were retained in order to ensure\nthat we could handle intransitive verbs. In total, 59 rule types out of a total of over\n29,000 (i.e., just 0.002% of the rules in Penn-II) were used in creating the various lexical\nresources. For each of these 59 rule types, the tokens corresponding to the rule right-\nhand sides were extracted. These extracted English phrases were then translated using\n"},{"#tail":"\n","@confidence":"0.997961833333333","#text":"\nreport in Section 4 on the quality of the French NPs produced, and in Section 5 we\ndiscuss experiments designed to discover whether our EBMT system could improve\non any mistranslations obtained. Translating the VPs involved a little more thought:\nIn the main, on-line MT systems such as these work far better when they translate\nsentences. In order to obtain finite verb forms rather than the default infinitival forms,\nwe provided dummy subjects. Initially these were third-person plural pronouns, which\ncaused similar verb forms to be created. This obviously biases the EBMT system more\nin favor of third-person plural sentences. Nevertheless, using the WWW-based post hoc\nevaluation methodology proposed in Section 5, we were still able to obtain reasonable\ntranslations for non-third-person-plural sentences too. In a subsequent experiment,\nwe seed the databases of wEBMT with third-person singular verb forms by providing\nthird-person singular pronouns as the dummy subjects, and in a final experiment\nwe combine all third-person fragments (both singular and plural) into the system?s\nmemories and compare results on the same test set.\nThe on-line MT systems were selected purely because they enable batch translation\nof large quantities of text. In our experience, the most efficient way to translate large\namounts of data via on-line MT systems is to send each document as an HTML page\nwith the phrases to be translated encoded as an ordered list. We automatically tagged\nthe English phrases with HTML codes and input them into each translation system\nusing the Unix wget function, which takes a URL as input and writes the corresponding\nHTML document to a file. If the URL takes the form of a query, then the document\nretrieved is the result of the query, namely, the translated Web page. Once this is\nobtained, it is a simple process to retrieve the French translations and associate them\nwith their English source equivalents.\n"},{"#tail":"\n","@confidence":"0.995734533333333","#text":"\nGiven that the marker hypothesis is arguably universal, it is clear that benefits may\naccrue by using it to facilitate subsentential alignment of ?source, target? chunks. Juola\n(1994, 1997) conducts some small experiments using his METLA system to show the\nviability of this approach for English ?? French and English ?? Urdu. For the English\n?? French language pair, Juola gives results of 61% correct translation when the\nsystem is tested on the training corpus, and 36% accuracy when it is evaluated with\ntest data. For English ?? Urdu, Juola (1997, page 213) notes that ?the system learned\nthe original training corpus . . . perfectly and could reproduce it without errors?; that\nis, it scored 100% accuracy when tested against the training corpus. On novel test\nsentences, he gives results of 72% correct translation. In their Gaijin system, Veale and\nWay (1997) give a result of 63% accurate translations obtained for English ?? German\non a test set of 791 sentences from CorelDRAW manuals.\nAs in METLA and Gaijin, we exploit lists of known marker words for each language\nto indicate the start and end of segments. For English, our source language, we use\nthe sets of marker words in (13):\n"},{"#tail":"\n","@confidence":"0.984928","#text":"\nIn a preprocessing stage, the aligned ?source, target? pairs in the phrasal lexicon are\ntraversed word by word, and whenever any such marker word is encountered, a new\nchunk is begun, with the first word labeled with its marker category (<DET>, <PREP>,\netc.). The example in (15) illustrates the results of running the marker hypothesis over\nthe source phrase all uses of asbestos:\n"},{"#tail":"\n","@confidence":"0.996352333333333","#text":"\nIn addition, we impose a further constraint that each chunk must also contain at least\none non?marker word, so that the phrase out in the cold will be viewed as one segment\n(labeled with <PREP>), rather than split into still smaller chunks.\nFor each ?English, FrenchX? pair, where X is one of the sets of translations derived\nfrom the three separate MT on-line systems (see above), we derive separate marker\nlexicons for each of the 218,697 source phrases and target translations. This gives\n"},{"#tail":"\n","@confidence":"0.995446857142857","#text":"\nus a total of 656,091 ?source, target? translation pairs (including many repetitions, of\ncourse). Given that English and French have essentially the same word order, these\nmarker lexicons are predicated on the na??ve yet effective assumption that marker-\nheaded chunks in the source S map sequentially to their target equivalents T; that is,\nchunkS1 ?? chunkT1, chunkS2 ?? chunkT2, . . .chunkSn ?? chunkTn, subject to their\nmarker categories matching, where possible. Using the previous example of all uses of\nasbestos, this gives us the marker chunks in (16):\n"},{"#tail":"\n","@confidence":"0.837773142857143","#text":"\nSometimes the number of marker chunks in the two languages differs, with respect to\nboth the marker categories and the number of chunks obtained. Consider the example\nin (17):\n(17) The man looks at the woman =? L?homme regarde la femme.\nOnce the marker hypothesis is applied to (17), it would be marked up as in (18):\n(18) <DET> The man looks <PREP> at <DET> the woman =?\n<DET> L? homme regarde <DET> la femme.\nThat is, the English verb subcategorizes for a PP complement which in this case con-\ntains two marker words, whereas the French verb regarder is a straightforward tran-\nsitive verb. It may appear, therefore, that there are three chunks in the English string\nand only two on the French side, but this is not the case: The restriction that each\nsegment must contain at least one non?marker word ensures that we have just two\nmarker chunks for the English string in (18). However, it remains the case that the\nchunks are tagged differently; we obtain the marker chunks in (19):\n"},{"#tail":"\n","@confidence":"0.99373425","#text":"\nOur alignment method would therefore align the first English chunk with the first\nFrench chunk, as their marker categories match. Note, of course, that this contains a\ntranslation error: regarde translates not as looks but rather as looks at. Errors such as this\nwill adversely affect translation quality, but as we report in Section 4, good-quality\ntranslations are obtainable on the whole. The second pair in (19), however, cannot\nbe mapped straightforwardly onto one another, as the marker categories differ. Nev-\nertheless, our algorithm would align ?<DET> the woman? with ?<DET> la femme,? as\ntheir marker categories match. This ensures that as many potentially useful translation\nfragments are generated as possible.\nThis na??ve alignment procedure works well between (broadly) similar languages\nsuch as English and French, but there are cases even between quite closely related\nlanguages in which the procedure breaks down. In order to increase translation quality\n"},{"#tail":"\n","@confidence":"0.98278775","#text":"\nComputational Linguistics Volume 29, Number 3\nstill further, the mapping function needs to be improved to account for examples such\nas (20):\n(20) The man likes the woman =? La femme pla??t a` l?homme.\nThe like =? plaire case is an argument-switching (or relation-changing) example, in\nthat the subject in English becomes the indirect object in French, and the English object\ntranslates as the French subject. If we were to apply the marker hypothesis to (20), we\nwould derive (21):\n"},{"#tail":"\n","@confidence":"0.99858235","#text":"\nOf course, both alignments are wrong. However, our alignment method correctly aligns\n?source, target? segments in approximately 80% of cases. We calculate this as an ap-\nproximation by testing all translations of marker chunks to see whether these French\nchunks appear anywhere on the Web: If so, we assume that the translations obtained\nby the online MT systems are correct. For 39,895 such translations, 75.2% of those\nproduced by system A appear on the Web, with 81.7% of those generated by system\nB and 81.5% of those produced by system C also appearing on the Web. Note that\nthis gives us only an approximation of the correctness of our alignments, as we are\ntesting whether the French translations are ?good French? rather than whether the\nalignments in which they appear are actually correct.\nCorrecting misalignments such as those in (22) is a topic for further research.\nAdding a bilingual lexicon (our word-level lexicon, for example) and incorporating the\nconstraints contained therein into the marker-based alignment process would prevent\nchunks such as those in (22) from being generated, and we conjecture that translation\nquality would improve accordingly.\nGiven marker chunks such as those in (16), we are able to extract automatically a\nfurther bilingual dictionary, the word-level lexicon. We take advantage of the assump-\ntion that where a chunk contains just one non?marker word in both source and target,\nthese words are translations of each other. Where a marker-headed pair contains just\ntwo words, as in (16), for instance, we can extract the word-level translations in (23):\n"},{"#tail":"\n","@confidence":"0.935088666666667","#text":"\nThat is, using the marker hypothesis method of segmentation, smaller aligned seg-\nments can be extracted from the phrasal lexicon without recourse to any detailed\nparsing techniques or complex co-ocurrence measures.\n"},{"#tail":"\n","@confidence":"0.994444888888889","#text":"\nJuola (1994, 1997) assumes that words ending in -ed are verbs. However, given\nthat verbs are not a closed class, in our approach we do not mark chunks beginning\nwith a verb with any marker category. Instead, we take advantage of the fact that the\ninitial phrasal chunks correspond to rule right-hand sides. That is, for a rule in the\nPenn Treebank VP ?? VBG, NP, PP, we are certain (if the annotators have done their\njob correctly) that the first word in each of the strings corresponding to this right-hand\nside is a VBG, that is, a present participle. Given this information, in such cases we tag\nsuch words with the <LEX> tag. Taking expanding the board to 14 members ?? augmente\nle conseil a` 14 membres as an example, we extract the chunks in (24):\n"},{"#tail":"\n","@confidence":"0.961607","#text":"\nWe ignore here the trivially true lexical chunk ?<QUANT> 14 : 14.?\nIn a final processing stage, we generalize over the marker lexicon following a\nprocess found in Block (2000). In Block?s approach, word alignments are assigned\nprobabilities by means of a statistical word alignment tool. In a subsequent stage,\nchunk pairs are extracted, which are then generalized to produce a set of translation\ntemplates for each ?source, target? segment.\nBlock distinguishes chunks from ?patterns,? as we do: His chunks are similar to\nour marker chunks, and his patterns are similar to our generalized marker chunks.\nOnce chunks are derived from ?source, target? alignments, patterns are computed from\nthe derived chunks by means of the following algorithm: ?for each pair of chunk pairs\n??CS1, CT1?, ?CS2, CT2??, if CS1 is a substring in CS2 and CT1 is a substring in CT2, then\n?PS, PT? is a pattern pair where PS equals CS2 with CS1 replaced by a variable V and\nPT equals CT2 with CT1 replaced by V? (Block 2000, pages 414?415). Block then gives\nan example that shows how patterns are derived. Assume the chunk pairs in (25):\n"},{"#tail":"\n","@confidence":"0.815249117647059","#text":"\nComputational Linguistics Volume 29, Number 3\nUsing the algorithm described above, the patterns in (26) are derived from the chunks\nin (25):\n(26) ? [V ist], [V is] ?\n? [das V], [which V] ?\n? [das V was], [which V what] ?\n...\n? [V ist was Sie], [V is what you] ?\n...\n? [das ist was V wollten], [which is what V wanted] ?\n...\nOf course, many other researchers also try to extract generalized templates. Kaji,\nKida, and Morimoto (1992) identify translationally equivalent phrasal segments and\nreplace such equivalents with variables to generate a set of translation patterns. Watan-\nabe (1993) combines lexical and dependency mappings to form his generalizations.\nOther similar approaches include those of Cicekli and Gu?venir (1996), McTait and\nTrujillo (1999), Carl (1999), and Brown (2000), inter alia.\nIn our system, in some cases the smallest chunk obtainable via the marker-based\nsegmentation process may be something like (27):\n(27) <DET> the good man : le bon homme\nIn such cases, if our system were confronted with a good man, it would not be able\nto translate such a phrase, assuming this to be missing from the marker lexicon. Ac-\ncordingly, we convert examples such as (27) into their generalized equivalents, as in\n(28):\n(28) <DET> good man : bon homme\nThat is, where Block (2000) substitutes variables for various words in his templates,\nwe replace certain lexical items with their marker tag. Given that examples such as\n??<DET> a : un? are likely to exist in the word-level lexicon, they may be inserted at\nthe point indicated by the marker tag to form the correct translation un bon homme. We\nthus cluster on marker words to improve the coverage of our system (see Section 5\nfor results that show exactly how clustering on marker words helps); others (notably\nBrown [2000, 2003]) use clustering techniques to determine equivalence classes of\nindividual words that can occur in the same context, and in so doing derive translation\ntemplates from individual translation examples.\n"},{"#tail":"\n","@confidence":"0.7331916","#text":"\nIn sum, we automatically create four knowledge sources:\n? the original ?source,target? phrasal translation pairs\n? the marker lexicon (cf. (16))\n? the generalized marker lexicon (cf. (28))\n? the word-level lexicon (cf. (24))\n"},{"#tail":"\n","@confidence":"0.913400916666667","#text":"\nWay and Gough wEBMT\nWhen matching the input to the corpus, we search for chunks in the order given\nhere, that is, from specific examples (those containing more context) to generic (those\ncontaining less context). We give in (29) an example of how a particular sentence from\nour test set is translated via these different knowledge sources:\n(29) Input:\nA major concern for the parent company is what advertisers are paying\nper page.\nChunks found in marker lexicon:\nfor the parent company : pour la socie?te? me`re\nwhat advertisers are paying per page : quels annonceurs paient per page\nChunk found in generalized marker lexicon:\n"},{"#tail":"\n","@confidence":"0.949994333333333","#text":"\nGiven the fragments shown in (29), a translation can now be derived. First, the\nword pair ?<DET> a : une? is inserted into the generalized template ?<DET> major\nconcern: inquie?tude majeure? to begin the translation process; the next chunk, ?for\nthe parent company : pour la socie?te? me`re,? is retrieved from the marker lexicon; the\nmissing word pair ?<LEX> is : est? is retrieved from the word-level lexicon; and finally,\nthe marker chunk ?what advertisers are paying per page : quels annonceurs paient\nper page? is appended to produce the translation in (30):\n(30) Une inquie?tude majeure pour la socie?te? me`re est quels annonceurs\npaient per page.\nOf course, this ?translation? is not without problems: There is a poor (in this instance)\ntranslation of what as quels, and a nontranslation of per. There is little our system can\ndo about errors such as these made by the on-line MT systems. Nevertheless, (29)\nillustrates how the various knowledge sources play a part in determining the final\ntranslation in our system.\nNote that none of these aligned resources would be possible in a TM system. The\nproblem of segmentation is not an inconsiderable one in all EBMT systems, but we\n(and others) have found that using the marker hypothesis can greatly facilitate such a\nprocess. We shall show in subsequent sections that because such knowledge sources\nare derived automatically from the original translations obtained via Web-based MT\nsystems, the translations obtained in our EBMT process are largely of high quality, are\nranked highly in the set of output translation candidates, and may be generated in\nalmost all cases?all this despite the fact that the original translations obtained via the\nWeb contain many errors, and that the source phrases to be translated were selected\nfrom a mere fraction of the rule types in the Penn-II Treebank.\n3. Retrieving Chunks and Producing Translations\nIn Section 4, we report on a number of experiments using the resources obtained in\nthe previous section to translate two test sets of data, one a set of NPs and the other\n"},{"#tail":"\n","@confidence":"0.979310428571429","#text":"\nComputational Linguistics Volume 29, Number 3\na set of sentences. Although we are primarily interested in translating sentences, we\ntranslate NPs for two reasons: (1) to assure ourselves that we are in fact translating\nnominal chunks correctly, and (2) to see whether our methodology can actually correct\nany NPs mistranslated by the three on-line MT systems. In this section, we describe\nthe processes involved in retrieving appropriate chunks and forming translations for\nNPs only (these being fewer in number than for sentences, of course).\n"},{"#tail":"\n","@confidence":"0.999690555555556","#text":"\nIn many cases, a 100% match for a given NP cannot be found in the phrasal lexicon.\nIn order to try and process the NP in a compositional manner, it is segmented into\nsmaller chunks, and the system then attempts to locate these chunks individually and\nto retrieve their relevant translation(s) from the various lexicons described above. We\nuse an n-gram-based segmentation method. Initially, we located all possible bigrams,\ntrigrams and so on within the input string and then searched for these within the\nrelevant knowledge sources.\nHowever, many of these n-grams cannot be found by our system, given that new\nchunks are placed in the marker lexicon when a marker word is found in a sentence.\nTaking the NP the total at risk a year as an example, chunks such as the total at risk a\nor at risk a cannot be located, as new chunks would be formed at each marker word\n(assuming the adjacent word is a non?marker word), so the best that could be expected\nhere might be to find the chunks in (31):\n(31) <DET> the total, <PREP> at risk, <DET> a year\nThe respective translations of these chunks would then be recombined to form the\ntarget string. In a recent addition to our work, we have eliminated certain n-grams\n(such as those that end in a marker word, for instance) from the search process, as\nthese would never be found given our chosen method of segmentation.\n"},{"#tail":"\n","@confidence":"0.986478411764706","#text":"\nWe use translations retrieved from the three different on-line MT systems specified\nabove (see Section 2.1). These translations are further broken down using the marker\nhypothesis to provide us with an additional three knowledge sources A?, B?, and\nC?, a marker lexicon, generalized marker lexicon and word-level lexicon derived from\nchunks produced by each system. These knowledge sources can be combined in several\ndifferent ways. We have produced translations using\n? information from a single source: A/A?, B/B?, or C/C?, that is, a phrasal\nlexicon and set of marker lexicons derived from translations produced\nby each on-line system\n? information from pairs of sources: A/A? and B/B?, A/A? and C/C? or\nB/B? and C/C?, that is, phrasal and marker lexicons derived from\ntranslations produced by two different on-line systems\n? information from all available knowledge sources: A/A? and B/B? and\nC/C?, that is, phrasal and marker lexicons derived from translations\nproduced by all three on-line systems\nThe objective here is to see how much translation coverage and quality are improved\nby using chunks derived from multiple sources. Assuming that the English strings are\n"},{"#tail":"\n","@confidence":"0.9017618","#text":"\nWay and Gough wEBMT\nnot translated in exactly the same manner by the three on-line MT systems means that\nmore knowledge sources could be combined in attempting to translate the new input\ncontained in the test sets of noun phrases and sentences. Results from experiments\nconducted using multiple knowledge sources are given in Section 4.2.\n"},{"#tail":"\n","@confidence":"0.993983837837838","#text":"\nEach time a source language (SL) chunk is submitted for translation, the appropriate\ntarget language (TL) chunks are retrieved and returned with a weight attached. We\nuse a maximum of six knowledge sources:\n? Stage 1: Three sets of translations (A, B, and C) are retrieved using each\nof the three on-line MT systems.\n? Stage 2: Three sets of translations (A?, B?, and C?) acquired by breaking\ndown the translations retrieved in Stage 1 using the marker hypothesis\nto form the marker lexicon, the generalized marker lexicon, and the\nword-level lexicon.\nWithin each knowledge source, each translation is weighted according to the formula\nin (32):\n(32) weight = number of occurrences of the proposed translationtotal number of translations produced for SL phrase\nFor the SL phrase the house, assuming that la maison is found eight times and le\ndomicile is found twice, then P(la maison  |the house) = 8/10 and P(le domicile  |the\nhouse) = 2/10. Note that since each SL phrase will only have one proposed translation\nwithin each of the knowledge sources acquired at Stage 1, these translations will\nalways have a weight of 1.\nIf we wish to consider only those translations produced using a single MT system\n(e.g., A and A?), we add the weights of translations found in both knowledge sources\nand divide the weights of all proposed translations by two. For the SL phrase the\nhouse, assuming P(la maison  |the house) = 5/10 in knowledge source A and P(la\nmaison  |the house) = 8/10 in A?, then P(la maison  |the house) = 13/20 over both\nknowledge sources. Similarly, if we wish to consider translations produced by all three\nMT systems, then we add the weights of common translations and divide the weights\nof all proposed translations by six.\nWhen translated phrases have been retrieved for each chunk of the input string,\nthey must then be combined to produce an output string. In order to calculate a\nranking for each TL sentence produced, we multiply the weights of each chunk used\nin its construction. Note that this ensures that greater importance is attributed to longer\nchunks, as is usual in most EBMT systems (cf. Sato and Nagao 1990; Veale and Way\n1997; Carl 1999).7\nAs an example, consider the translation into French of the house collapsed. Assume\nthe conditional probabilities in (33):\n7 Note that approaches that prefer the greatest context to be taken into account are not limited to EBMT.\nResearch in the area of data-oriented parsing (cf. Bod, Scha, and Sima?an, 2003) also shows that unless\nthe corpus is inherently biased, derivations constructed using the smallest number of subtrees have a\nhigher probability than those built with a larger number of smaller subtrees.\n"},{"#tail":"\n","@confidence":"0.913676","#text":"\nGiven the weights in (33), the four translations in (34) can be produced, each with\nan associated probability:\n"},{"#tail":"\n","@confidence":"0.99941375","#text":"\nWhere different derivations result in the same TL string, their weights are summed\nand the duplicate strings are removed.\nThe examples in (33) and (34) are reasonably straightforward if we assume, as\nhere, that the chunks in (35) exist in the system databases shown:\n"},{"#tail":"\n","@confidence":"0.9904563","#text":"\nThese mistranslations are all caused by boundary friction.\nEach of the translations in (37) and (38) would be output with an associated weight\nand ranked by the system. We would like to incorporate into our model a procedure\nwhereby translation chunks extracted from the phrasal and marker lexicons are more\nhighly regarded than those constructed by inserting words from the word-level lexicon\ninto generalized marker chunks. That is, we want to allocate a larger portion of the\nprobability space to the phrasal and marker lexicons than to the generalized or word-\nlevel lexicons. We have yet to import such a constraint into our model, but we plan\nto do so in the near future using the weighted majority algorithm (Littlestone and\nWarmuth 1992).\n"},{"#tail":"\n","@confidence":"0.64997","#text":"\nWe report here on a number of experiments using test sets of 200 sentences and 500\nnoun phrases. Some typical examples from the two test sets are given in (39):\n"},{"#tail":"\n","@confidence":"0.926960545454545","#text":"\na chaotic sex life.\nThe test sets were created automatically from words contained in at least one of the\nsystems? knowledge bases, with the proviso that the strings corresponding to the 59\nrule types we extracted from the Penn Treebank reflected the frequency bias of these\nrule types, as far as possible. That is, we wanted to ensure that strings corresponding\nto a rule type that was (approximately) twice as frequent as some other rule type\noccurred (approximately) twice as often in the test sets. Finally, we ensured that strings\ncorresponding to all 59 rule types were present in the sentence test set.\nThe experiments were designed to evaluate the coverage and translation quality\nof different versions of our EBMT system. We contrast the results obtained when the\nmemories of our system are seeded with source strings and their translations derived\n"},{"#tail":"\n","@confidence":"0.8978391","#text":"\nComputational Linguistics Volume 29, Number 3\nWe also compare and contrast the results obtained when the memories of our sys-\ntem are seeded with source strings and their translations derived using third-person\nsingular, third-person plural, and both third-person singular and third-person plural\ndummy subjects.\nBoth sets of experiments are designed to test whether coverage and translation\nquality improve when more ?source, target? fragments are taken into account. With\nrespect to quality, the translations output (for sentences, using chunks derived with\nthird-person plural dummy subjects) were scored according to the following scale by\ntwo native speakers of French with excellent English:\n"},{"#tail":"\n","@confidence":"0.988139095238095","#text":"\nThis scale is used to measure the impact on translation quality, both for sentences\nand NPs, of using multiple knowledge sources. Although we are primarily interested\nin the translation of sentences, we use the NP test set to see whether we are in fact\ntranslating nominal chunks correctly, and also to investigate whether our methodology\ncan actually correct any NPs mistranslated by the three on-line MT systems. We discuss\nthis further in Section 5.\nWe also measure the ability of our system to rank the ?best? translation (as deter-\nmined by our human experts) highly in the set of output translations. Statistical MT\nsystems such as wEBMT may derive many different translations for a particular input,\neach of which is output with a confidence weighting. We are keen to ensure that if\nour system is able to produce high-quality translations, these are ranked as highly\nas possible: We do not consider it feasible for a human to have to sift through many\nhundreds or thousands of translations in order to determine the ?correct? one.\nIn a further experiment, we translate the test set of sentences via the three on-\nline MT systems and test to see whether our system wEBMT can improve on these\ntranslations. In so doing we calculate the ?net gain? of performing example-based MT\ncompared to using on-line MT systems.\nFinally, we offer some thoughts on the relative merits of the three on-line MT\nsystems used in our research. Although this was not the primary focus of our research,\nit turned out that we were able, as a direct consequence of our methodology, to evaluate\nthe on-line MT systems chosen.\n"},{"#tail":"\n","@confidence":"0.937694333333333","#text":"\nHere we report on experiments in which the two test sets are tackled by our system\nwhen its memory is seeded with translations obtained by the individual on-line MT\nsystems specified in Section 2.1. A parameter that is altered in the experiment on\nthe sentential test set is the nature of the dummy subjects used to gather the initial\ntranslation fragments: third-person singular, third-person plural, and both third-person\nsingular and third-person plural.\n"},{"#tail":"\n","@confidence":"0.9101065","#text":"\nof 8.5 words (minimum 3 words, maximum 18). The input strings were segmented by\napplying the n-gram segmentation approach outlined in Section 3.\n"},{"#tail":"\n","@confidence":"0.954759777777778","#text":"\nAs far as coverage is concerned, our system wEBMT translated 184 (92%) of the sen-\ntences using chunks derived from Systems A and C, and using chunks from system B,\nour system managed to translate 180 sentences (90%). The same 16 sentences were not\ntranslated by any of the systems owing to their failure to locate one or more words in\nthe sentence within the word-level lexicon. Recall that despite the fact that all words\nin the test set were seen by the system in the training phase, only those content (i.e.,\nnon-marker) words that occur in bigram marker chunks are inserted into the word-\nlevel lexicon (cf. (23)). In cases such as these, in which one or more words cannot be\ntranslated by our system, partial translations such as those in (40) are output:\n"},{"#tail":"\n","@confidence":"0.997533111111111","#text":"\nThe form required in (40) is a simple past-tense verb, but misplaced appears in (41) only\nas a passive participle. The word were in (41) is not a marker word, so this fragment\ncannot be broken down any further by our segmentation method.8 In such cases we\noutput the partial translation with source equivalents for any untranslated words, as\nshown in (40).\nNinety-six (48%) of the sentences were translated by combining fragments con-\ntained in the original phrasal lexicon or the marker lexicon, 56 (28%) of the translations\nwere obtained by locating single content (i.e., non-marker) words in the word-level\nlexicon and inserting these into the translation at the appropriate position, and 32\n(16%) were produced by inserting marker words into generalized templates.\nTable 1 shows the results obtained from our human evaluators? ratings of the\ntranslations produced by our system when it was populated with fragments derived\nfrom one of the individual on-line MT systems. Evaluators rated more than one-third\nof translations as intelligible and without syntactic errors (score 3), with over 85% of\ntranslations deemed intelligible (scores 2 and 3) for all systems. Unintelligble transla-\ntions (score 1) ranged from 14% for chunks derived from SDL to just 4.4% for trans-\nlations formed from knowledge sources created from Logomedia. These initial results\nprovide some evidence in favor of the hypothesis that Logomedia might be the best\nsystem. Although such evaluation is not a primary focus of our work at the outset,\nour methodology provides as a spin-off an evaluation of the three MT systems. We\ndiscuss this further in Section 4.5.\nWhen the system cannot produce a translation for a particular input, the main\nreason is an absent word in the word-level lexicon. Adding more lexical entries would\nimprove translation coverage and would also affect translation quality (possibly ad-\nversely, in some cases). We plan to measure the impact of a larger lexicon in future\nwork. Low-quality translations are almost invariably caused by inappropriate verb\nforms in the word-level dictionary: For the experiments carried out in which all verbs\n"},{"#tail":"\n","@confidence":"0.627146","#text":"\nune pleine page, assuming there to be no other relevant fragments in the system?s databases.\n"},{"#tail":"\n","@confidence":"0.990406181818182","#text":"\nwere third-person plural, any NP with a third-person singular subject in the test set\nwould be accompanied by a third-person plural verb in the translation. A similar effect\nis seen where the databases of wEBMT were seeded with third-person singular verbs,\nof course. However, we should expect an improvement in translation quality when\nboth sets of verb forms are included in the memories of the system (see Experiment\n2).\nTable 2 shows where the ?best? translation, as defined by a human expert, was\nranked among the of translations output by our system. In over 65% of cases, the\nsystem itself had ranked the ?best? translation first, and the ?best? translation was\nnever located outside the top five ranked translations. This is remarkable given that\nover 2,000 translations are output for certain source sentences.\n"},{"#tail":"\n","@confidence":"0.928786055555556","#text":"\nThe results for the previous experiment were obtained when the databases were seeded\nwith third-person plural dummy subjects. We ran two variations on this experiment:\n(1) we tested the system by seeding its memories with third-person singular dummy\nsubjects, and (2) We tested the system by seeding its memories with both third-person\nsingular and third-person plural dummy subjects.\nFigure 1 shows that translation quality improves when the system databases are\nseeded with more translation pairs. We can see that the system does slightly better\nwhen it uses third-person plural chunks compared to when it uses their singular coun-\nterparts. When third-person singular dummy subjects are inserted in order to derive\nthe initial translation fragments inserted into our system?s memories, the number of\ntranslations rated 3 for quality deteriorates by about 5% for systems B and C and by\nabout 3% for system A. Given a larger number of third-person plural NP subjects in\nour test set, this was to be expected.\nHowever, a considerable improvement in quality can be seen when fragments from\nTable 2\nRanking of ?best? translation for sentences:\nChunks derived from individual on-line MT\nsystems, third-person plural dummy subjects.\n"},{"#tail":"\n","@confidence":"0.966687384615385","#text":"\nboth singular and plural forms are inserted into the system?s memories. Translations\nproduced from chunks derived from system A are rated 3 in 66.1% of cases, and this\nrises to 67.9% for system B and 68% for system C. Regarding intelligibility (scores 2\nand 3 for quality), system A scores 85.8%, system B scores 91.1%, and system C scores\n95.6%. We consider these to be very reasonable results.\nTable 3 summarizes the relative ranking of the ?best? translation when more trans-\nlation pairs are used to seed the system?s memories. Now that both third-person sin-\ngular and third-person plural dummy subjects are provided, we see that the number\nof ?best? translations ranked first deteriorates, by about 6% for systems A and C and\nby 4.5% for system B. In Table 2, we saw that the ?best? translation was in no case\nranked lower than fifth, but now that many more translations are output per test set\nsentence, we sometimes have to search as low as 20th in order to find the ?best?\ntranslation.\n"},{"#tail":"\n","@confidence":"0.812206","#text":"\naverage NP length of 6.14 words (minimum 3 words, maximum 12). The noun phrases\nin the test set alo need to be fragmented using our n-gram segmentation method, as\n"},{"#tail":"\n","@confidence":"0.909755333333333","#text":"\nComputational Linguistics Volume 29, Number 3\nit is highly probable that they do not exist en bloc in the phrasal lexicon and therefore\nneed to be analyzed using smaller fragments in the system?s databases.\nWe give results for coverage and translation quality in Table 4. These results are\nfor NPs translated via chunks derived from the three individual on-line MT systems.\nAs with the sentence test set, fragments derived from systems A and C achieve the\nbroadest coverage, producing translations for 474 out of the 500 NPs; those obtained\nfrom system B enable 463 of the 500 NPs to be translated.\nAs for quality, wEBMT clearly performs best when using translation fragments\nderived from system C: 47.3% of these translations were awarded a quality score of 3,\nmore than 10% better than for chunks derived from system B. For system C, a total of\n452 (96%) of the generated translations were deemed intelligible (scores 2 and 3), that\nis, 31 (6.6%) more translations than with system B.\nOn average, about 54% of translations are formed by combining chunks from\nthe phrasal lexicon with those from the marker lexicon, about 9% are produced by\ninserting marker words into the generalized templates, and about 37% are generated\nby inserting single non?marker words from the word-level lexicon at the appropriate\nlocations in phrasal chunks. The major reason that translations fail to be produced in\n6% of cases is the absence of a relevant generalized template. For example, the unseen\ninput her negative TV ads is generalized to (42):\n(42) <POSS> negative TV ads\nHowever, the nearest relevant generalized template found in the system?s memory is\n(43):\n(43) <DET> negative TV ads\nThat is, the template in (43) allows the insertion of any determiner, but no other\nmarker word. Deriving translation fragments from more examples would lead to an\nimprovement in coverage. Alternatively, for marker words that appear in the same\nrelative position, such as determiners and possessive pronouns, we could ?back off?\nto a more general marker tag to allow mutual substitution of such words in a subse-\nquent operation to enable translation of examples like these. This remains an area of\ninvestigation in future work.\nThe results in Table 4 further substantiate our findings on the sentence test set,\nnamely, that system C may be the best of the three on-line MT systems used to populate\nthe memories of our EBMT system. We comment further on this in Section 4.5. In\naddition, these figures provide strong evidence that our system can indeed translate\nmost noun phrases with which it is confronted and with more than reasonable quality.\n"},{"#tail":"\n","@confidence":"0.989368111111111","#text":"\nIf the three on-line MT systems translate the phrases extracted from the Penn-II Tree-\nbank in different ways, then combining systems to obtain results for AB, AC, BC,\nand ABC always involves an increase in the number of translations produced, both\nfor sentences and noun phrases. That is, if an input string receives a translation via\nchunks derived from the individual on-line systems, when chunks are combined from\ndifferent systems, more translations will be output for that input string.\nAs an example, the number of translations produced by each system for the NP\na plan for reducing debt over 20 years is shown in Table 6. Whereas the greatest num-\nber of translations for this NP produced from chunks from any individual on-line\n"},{"#tail":"\n","@confidence":"0.956655181818182","#text":"\nand when more knowledge sources are used: Measuring % translation quality using fragments\nderived from combinations of on-line MT systems.\nevaluated: Of course, if we consider (say) three-chunk combinations from either system\nA or B, the only possibilities are AAA or BBB, respectively.\nHowever, the number of translations produced by the system is less significant\nthan their quality. The ranking process outlined in Section 3 classifies the translations\nproduced with regard to their position as the ?best? translation. In the sections below,\nwe also discuss the issue of quality and show that it improves when more translation\nfragments are taken into account. Furthermore, we show below that despite generating\nmore translations per input string, wEBMT still ranks the ?best? translation in the top\n1% of all output translation candidates.\n"},{"#tail":"\n","@confidence":"0.981539230769231","#text":"\nSystems. We saw in Experiment 1 that 16 strings in the test set were left untranslated\nby systems A, B, and C individually. When knowledge sources are combined, these 16\nstrings remain untranslated. However, as Figure 2 shows, the translation quality im-\nproves significantly. The best individual system performance was 36.5% scoring 3. This\nrises to a best performance of 48.9% among pairs of systems combined and improves\nstill further to 50% when chunks from all three knowledge sources are combined.\nTable 7 provides results regarding the relative location of the ?best? translation for\nsentences. For all system combinations, the ?best? translation is to be found among\nthe top 10 ranked translations in all permutations of combinations of chunks, with\nat least 54% ranked first. Despite a corresponding rise in the number of translations\nproduced per input sentence when all three knowledge sources are combined (ABC),\nin over 97% of cases, the ?best? translation continues to be found in the top five output\ncandidates.\n"},{"#tail":"\n","@confidence":"0.864605074074074","#text":"\nDatabases with More Examples. Figure 2 demonstrates that considerable improve-\nments in translation quality are achieved when the memory of wEBMT is seeded with\nboth third-person singular and third-person plural fragments. For the pairwise com-\nbinations, 78.7% of the translations derived from AB are rated 3 for quality, compared\nto 80.4% of those derived from AC and BC. The results for ABC improve again, to\n81.5%. Regarding intelligibility (scores 2 and 3 for quality), we can see from Figure 2\nthat near perfect results are obtained: AB scores 95.6%, and all other combinations\nscore 96.7%.\nTable 8 shows the ranking of the ?best? translation when multiple knowledge\nsources are employed and both third-person singular and third-person plural dummy\nsubjects are used to populate the system?s memories. The number of instances in which\nthe ?best? translation is ranked first by wEBMT deteriorates: by 24% for AB, by 15% for\nAC, by 20% for BC, and by 27% for ABC. For all system combinations, Table 7 shows\nthat the ?best? translation was ranked no lower than 10th; for the system combinations\nin Table 8, sometimes the ?correct? translation is ranked as low as 36th. As expected,\nthe worst ranking results are for system combination ABC, in which all system chunks\nare combined for both third-person singular and third-person plural dummy subjects.\nHowever, even here the ?best? translation is ranked in the top five in over 63% of\ncases, and 72.6% of the time it is located among the top 10 ranked translations. For\nthis system configuration, the lowest we have to look to find the ?best? translation\nis 36th. For that particular sentence (i.e., the one for which the ?best? translation is\nranked 36), over 4,000 possible translations are generated, so even here the ?best?\ntranslation remains in the top 1% of translation candidates.\nTable 8\nRanking of ?best? translation for sentences: Chunks derived from combinations of\non-line MT systems, third-person singular and third-person plural dummy\nsubjects.\n"},{"#tail":"\n","@confidence":"0.911020708333333","#text":"\nferent Systems.\nAs we did with sentences, we seeded our EBMT system with fragments derived from\nthe three different on-line MT systems and confronted it with the NP test set. Table 9\nclearly shows that as more knowledge sources are added, translation quality improves\nconsiderably. The worst-performing individual system scores 3 for quality in just over\na third of cases, but when all system chunks are combined, this rises to 77.8%. Note\nalso that, unlike with sentences, we see an increase in coverage when more knowledge\nsources are used, from a low of 92.6% for system B to a high of 96% when all chunks\nare combined. Many more improvements are seen when our post hoc validation and\ncorrection methodology, described in Section 5, is used, but the merging of fragments\nderived from different on-line systems also leads to an improvement in translation\nquality. Consider the examples in (45):\n(45) Input: an old story in common\nSystem B: une vieille histoire dans commun\nSystem Combination BC: une vieille histoire en commun\nThat is, the optional PP in common was mistranslated by system B as dans commun, but\nwhen knowledge from system C is added to that of system B, the improved translation\nen commun is generated.\nWe saw in Section 4.1.2 that when translating the NP test set, the ?best? transla-\ntion, as adjudged by our human evaluators, was to be found no lower than tenth of\nall translations output by our system. When knowledge sources are combined, it is\nTable 10\nRanking of ?best? translation for NPs: Chunks derived from\nmore that one on-line MT system.\n"},{"#tail":"\n","@confidence":"0.999709588235294","#text":"\nimportant to measure whether the ?best? translation is still highly ranked. The results\nof such an assessment are summarized in Table 10. When the ?best? translation is\nranked first by the system, we see that the optimal combination of knowledge sources\nis the pair BC, with 66.4%. This is an interesting result given that in Table 5, only 57.7%\nof the NPs translated by system B were ranked first, with 60% of those produced by\nsystem C ranked in first place. That is, we see a 6.4% improvement (31 NPs) when\nfragments from systems B and C are combined. All other combinations cause the num-\nber of ?best? translations ranked first to deteriorate, as may be expected. When the\n?best? translation is ranked either first or second by the system, the best combination\nof fragments is that from system ABC, with 79.5% (376 NPs).\nImportantly, for all combinations, the ?best? translation remains among the top 10\nranked translations. This is encouraging, as any translator using our system needs only\nto examine a small subset of the translations produced to find the ?best? one. Indeed,\ngiven the various results shown, we are confident that we could prune the number of\ntranslations generated for presentation to the translator for selection of the ?best? one:\nFor the most part, this is the top ten translations for both NPs and sentences, but in\nthe worst case, we need present no more than the top 1% of the candidate translations.\n"},{"#tail":"\n","@confidence":"0.999566352941176","#text":"\nThe results presented in this section show that seeding the wEBMT system?s databases\nwith more fragments improves both coverage and translation quality. We do this addi-\ntional seeding in two ways: (1) by combining fragments derived from different on-line\nMT systems, and (2) by obtaining translations using both third-person singular and\nthird-person plural dummy subjects. The best combination of these parameters is to\nuse chunks derived from Logomedia with third-person plural dummy subjects pro-\nvided. Nevertheless, despite the fact that Logomedia appears to be the best on-line MT\nsystem, adding chunks from the other two on-line MT systems improves coverage\nand translation quality. In sum, therefore, the best results are obtained when chunks\nfrom all three on-line systems (combination ABC) are used and the wEBMT system?s\ndatabases are seeded with translations from these systems for both third-person sin-\ngular and third-person plural versions of sentences.\nThe disadvantage of using more knowledge sources, of course, is that many more\ncandidate translations are generated, which sometimes causes the ?best? translation\nto appear lower in the ranked order of output translations. Nevertheless, the ?best?\ntranslation is almost always to be found in the top 10 translations produced by wEBMT\nand always in the top 1% of the candidate translations.\n"},{"#tail":"\n","@confidence":"0.999816","#text":"\nIn order to try to calculate the relative gain of EBMT, we translated all 200 strings in the\nsentence test set via the three on-line MT systems used elsewhere in our experiments.\nOf course, the main advantage of using such Web-based systems is that they are\nextremely robust: no matter what they are confronted with, they will always produce\nsome translation. With respect to coverage, therefore, the on-line systems currently\nwin out over wEBMT: the size of the lexicons available to the on-line systems means\nthat they will generate translations with all source words translated more often than\nour system will. Nevertheless, the fact that our system outputs partial translations in\nsituations in which it encounters a word that it cannot translate demonstrates a certain\nlevel of robustness in our system.\nWhere quality is concerned, however, wEBMT can improve on the translations\nproduced by the three on-line MT systems. We provided our human evaluators with\nthe source sentences from the test set, together with the translation generated by our\n"},{"#tail":"\n","@confidence":"0.980825846153846","#text":"\nComputational Linguistics Volume 29, Number 3\nwEBMT system using combinations of chunks derived from all three on-line systems\n(ABC), and the translation obtained directly from the on-line systems themselves. The\npairs of translations (wEBMT and on-line MT system) were presented in a random\norder. The evaluators were simply asked to state, for all three on-line MT systems,\nwhich of the pair of translations they preferred: that from the on-line MT system or\nthat from wEBMT.\nTranslations produced by wEBMT using chunks derived from all three systems\nwere preferred to those from system A in 30/184 cases (16.3%) (we ignored the 16\ncases for which our system could produce only partial translations); for system B,\nour system?s translations were preferred in 8/180 cases (4.4%); and for system C,\nour system was judged as producing better translations in 6/184 cases (3.3%). Some\nexamples in which our system offered improvements over the translations provided\n"},{"#tail":"\n","@confidence":"0.981624935483871","#text":"\nInput: The researchers air the shows.\nSystem B: L?air de chercheurs les expositions.\nwEBMT ABC: Les chercheurs ae?rent les expositions.\nInput: A group hire lawyers to provide information about clients.\nSystem C: Un avocats de la location du groupe fournir de l?informations\nau sujet de clients.\nwEBMT ABC: Un groupe embauche des avocats a` fournir de\nl?informations au sujet de clients.\nRegarding the first two translation pairs in (46), wEBMT has provided a finite verb\nwhere the on-line MT systems have none. In addition, the translation of the subject\nNPs is much improved. As for the final translation pair in (46), whereas Logomedia\nmanaged to retrieve the correct translation of provide, this was not the main verb in\nthe English input string. wEBMT, on the other hand, does translate hire correctly as a\nverb rather than a noun.\nWe consider three ways in which the net gain of EBMT may be calculated. First,\nwe assume it is equal to the number of translations produced by wEBMT that are\npreferred by the human evaluator, minus those derived by the on-line MT systems\nthat are preferred, divided by the total number of translations. In fact, where both\nwEBMT and the on-line systems produce a translation, those derived via wEBMT are\nalways preferred. Those translations produced by the on-line systems that are preferred\nare those in which wEBMT was unable to generate a complete translation. This is quite\na harsh measure: As can be seen from the translations in (46), although the words in\nthe translations produced by the on-line systems are all French (but recall (29)?(30),\nin which this was not the case), the translations themselves are poor. In some cases,\ndespite the fact that the translations derived via wEBMT may contain an untranslated\nEnglish word, the accompanying partial translations may in fact be deemed superior\nto the ?complete? translations derived via the on-line systems.\nNevertheless, assuming that the on-line systems win out in these situations, the\nnet gain compared to system A is 14/200 (7%), whereas for systems B and C, we see\nin effect a net loss: ?12/200 (?6%) for system B, and ?10/200 (?5%) for system C. If\nwe can obtain complete translations in those cases in which we currently encounter\n"},{"#tail":"\n","@confidence":"0.970166666666667","#text":"\nan untranslatable word, we are confident that we can convert these net losses into\nnet gains. With respect to system A, we can assume that our net gain would increase\nfurther.\nHowever, we provide two other interpretations of the net gain of EBMT, calculated\nusing the formula in (47):\n(47) Net Gain = Coverage Percentage + K(Translation Quality)\nThe term Translation Quality in (47) refers to the number of translations preferred by\nthe human evaluator, excluding cases in which one system failed to produce a trans-\nlation, which is already factored into the equation under the term Coverage Percentage.\nWhere K=1, we view coverage and translation quality as equally important. If we\nconsider quality to be more important, we can increase K. We provide results for K=1\nand K=2 in (48):\n"},{"#tail":"\n","@confidence":"0.9947104","#text":"\nwith respect to Reverso, and a slight loss compared to Logomedia. However, wEBMT\noutperforms all three on-line systems when translation quality is viewed as twice as\nimportant as coverage. This is a reasonable view, we feel, and our system shows a net\ngain against all three on-line systems in this context. Although the coverage obtained\nwith the on-line systems is better, the improved translation quality obtained with\nwEBMT ensures a net gain.\nWe expect to obtain more insightful results regarding the relative gain of EBMT\nover on-line MT systems when automatic evaluation metrics (such as IBM?s Bleu, or\ndynamic programming, or sentence- and word-error rates) have been obtained. This\nis a priority in future work.\n"},{"#tail":"\n","@confidence":"0.998926857142857","#text":"\nThe previous sections detail the results obtained when translation fragments derived\nfrom the three individual on-line MT systems are used, together with various combi-\nnations of knowledge sources. We provided results both for coverage and translation\nquality. As we noted above, we were able, as a consequence of our chosen methodol-\nogy, to evaluate the on-line MT systems used.\nWhere sentences are concerned, we saw that coverage was approximately the same\nfor each individual system, and that combinations of multiple knowledge sources did\n"},{"#tail":"\n","@confidence":"0.978789608695652","#text":"\nComputational Linguistics Volume 29, Number 3\nnot improve coverage. For NPs, however, coverage improved when more fragments\nwere considered: Whereas 474 NPs could be translated by both systems A (SDL) and C\n(Logomedia), this number rose to 480 when all three knowledge sources were combined.\nWith respect to translation quality, whereas Logomedia and Reverso could hardly\nbe distinguished when it came to numbers of translations of sentences adjudged as\nintelligible and syntactically correct, if we consider those translations considered un-\nintelligible by our human evaluators, about twice as many translations produced by\nchunks derived from Reverso were unintelligible compared to those produced by Lo-\ngomedia. This would indicate that Logomedia may be better.\nWhen fragments from combinations of systems are considered, we note that for\nsentences, no improvement in coverage results, but quite significant improvements in\nquality are seen. System C slightly outperformed system B in the individual face-off,\nand we see that combinations that utilize chunks from system C outperform those\nthat do not: AC and BC both score 3 for quality in 80.4% of cases, compared to AB?s\n78.7%, and ABC improves still further, to 81.5%. When the databases of wEBMT are\nseeded with more chunks (using both singular and plural dummy subjects), system C\ncontinues to outperform the other two systems.\nWhen NPs are considered, system C considerably outperforms the other two sys-\ntems, obtaining a score of 3 for quality in 10.2% more cases than its nearest challenger,\nsystem B. When chunks from different systems are combined, again we see that com-\nbinations with chunks derived from system C outperform those that omit them: BC\nand AC improve over AB by 10% and 18%, respectively, and ABC shows a further\nincrease.\nFinally, in Section 4.4, we discussed the relative gain of using wEBMT over the\nthree on-line MT systems. Further evidence that Logomedia may be the best of the three\nsystems is provided by the fact that the relative gain compared to Logomedia was much\nlower than with the other two systems.\nIt is worth considering why some combinations seem to work better than others.\nFor NPs, in cases where system A fails to produce the ?best? translation, this is often\ndue to incorrect word order. For example, in the NP cellular mobile lines for the workmen,\nsystem A produces the translation cellulaire mobile lignes pour les ouvriers.9 It is also the\ncase that when system A fails to retrieve a translation for a particular chunk, it simply\nproposes the English for that chunk as its translation. This is useful to some extent,\nin that a default translation is produced (cf. the similar approach that we have taken\nwith respect to (40), for instance). However, in all of these cases this utility is lessened\nconsiderably given that either system B or system C produces a better translation.\nSystem B has the added advantage that it sometimes provides an alternative translation\nin brackets. If no translation is available, the English is output. System C often produces\na correct translation of a verb where the other systems are lacking. It is probably\nbecause of this aspect of translation that system C?s translations are preferred over\nthose of the other two systems.\n5. Validation and Correction of Translations via the Web\nA translation can be formed in our system only when the recombination of chunks\ncauses the input string to be matched exactly. Therefore, if all chunks cannot be re-\ntrieved, then no complete translation can be produced (cf. (40) and resultant discus-\n"},{"#tail":"\n","@confidence":"0.996132113636363","#text":"\nsion). We have shown that when a translation cannot be produced by combining\nphrasal chunks, translations can be formed by the insertion of single marker words\ninto generalized templates. This can be compared to the idea of ?hooks? (Somers,\nMcLean, and Jones 1994), where some context in which fragments have occurred is\nmaintained in the translation templates. The hooks indicate which words and POS\ntags can occur in the immediate left and right context of a fragment, together with a\nweight that reflects how often this context is found in a corpus. The ?best? translation,\ntherefore, is simply that which is output by the system with the highest score.\nConsider the translation of the NP the personal computers. There are three possible\nways in which this may be segmented using the marker hypothesis, namely, the chunks\nin (49):\n(49) Phrasal lexicon: the personal computers\nMarker lexicon: <DET> the personal computers\nGeneralized lexicon: <DET> personal computers\nIn our system, the only chunk retrieved is the generalized chunk in (49). The system\nstores a list of marker words and their translations in the word-level lexicon. A weight\nderived via the method in (32) is attached to each translation. The system searches\nfor marker words within the string and retrieves their translations.10 In this case, the\nmarker word in the string is the and its translation can be one of le, la, l?, or les,\ndepending on the context. The system simply attaches the translation with the highest\nweight to the existing chunk ordinateurs personnels to produce the mistranslation in\n(50):\n(50) *la ordinateurs personnels\nThe problem of boundary friction is clearly visible here: We have inserted a feminine\nsingular determiner into a chunk that was generalized from a masculine plural NP.\nHowever, rather than output this wrong translation directly, we use a post hoc val-\nidation and (if required) correction process based on Grefenstette (1999). Grefenstette\nshows that the Web can be used as a filter on translation quality simply by searching\nfor competing translation candidates and selecting the one that is found most often.\nRather than search for competing candidates, we select the ?best? translation and have\nits morphological variants searched for on-line. In the example above, namely, the per-\nsonal computers, we search for les ordinateurs personnels versus the wrong alternatives\nle/la/l?ordinateurs personnels. Interestingly, using Lycos, and setting the search language\nto French, the correct form les ordinateurs personnels is uniquely preferred over the other\nalternatives, as it is found 2,454 times, whereas the others are not found at all. In this\ncase, this translation overrides the highest-ranked translation (50) and is output as the\nfinal translation. In fact, in checking the translations obtained for NPs using system\ncombination ABC, we noted that 251 NPs out of the test set of 500 could be improved.\nOf these 251, 207 (82.5%) were improved post hoc via the Web, with no improvement\nfor the remaining 43 cases. We consider this to be quite a significant result.\nIn addition to determiner-noun agreement, we use this methodology to check for\nagreement between the head noun in the subject NP with the head verb in the main\n10 Although this is not relevant for the example discussed here, if non?marker words remain untranslated\nyet exist in the word-level marker lexicon, these too would be inserted at this stage.\n"},{"#tail":"\n","@confidence":"0.986815111111111","#text":"\nclause VP. We extracted a list of all verbs in the Penn-II Treebank and obtained trans-\nlations for all verb forms using the three on-line MT systems by inserting appropriate\nthird-person dummy subjects. We use the list of translated verbs to attempt to find the\nmain verb and identify the head noun as the rightmost non?marker word or the right-\nmost word before any other marker word in a nominal chunk. Having extracted the\nnoun and the verb from the mistranslation in this way, we then search for this bigram\non the Web and correct the verb if its morphological variant (third-person singular or\nthird-person plural form) is found more often than in the translation obtained by our\nsystem.\nTo exemplify this procedure with a sentence from the test set, his empire is beyond\nthe reach of the president, system A produces the translations in (51):\n(51) a. *son empire sont au dela` de la porte?e du pre?sident (ranked first, with\nprobability 0.614)\nb. son empire est au dela` de la porte?e du pre?sident (ranked fifth, with\nprobability 0.028)\nThis shows that a correct translation such as (51b) may be ranked lower than an incor-\nrect variant (51a) with considerably less probability. The higher ranking is accounted\nfor because the pair ?is beyond the reach of the president, sont au dela` de la porte?e du pre?sident?\nis contained in the phrasal lexicon, whereas the pair ?is beyond the reach of the president,\nest au dela` de la porte?e du pre?sident? does not appear.\nPrior to outputting translations such as (51a), we search for the relevant n-grams\nvia the Web. For this example, using AltaVista, we obtained the results in Table 11.\nWith the counts for all other bigrams for the two translation candidates in (51) being\nexactly the same, in order to evaluate which of these proposed target strings is the\n?better? translation, one can simply add the occurrences found on the Web for all four\ndifferent bigrams and report their relative probabilities. This gives us the probabilities\nin (52):\n(52) a. #empire sont + #sont au = 91,550/311,179 = 0.294\nb. #empire est + #est au = 219,629/311,179 = 0.706\nThat is, the string empire est au is about 2.4 times more likely than the string empire\nsont au. However, the count for the second bigram in each example in (52) can of\ncourse be discounted, as the juxtaposition of sont or est with au bears no relevance to\nthe correctness or otherwise of the translations in (51). The amended probabilities are,\ntherefore, those in (53):\n(53) a. #empire sont = 353/2,162 = 0.163\nb. #empire est = 1,809/2,162 = 0.837\n"},{"#tail":"\n","@confidence":"0.988469736842105","#text":"\nThese figures accurately reflect the likelihood of the translations in (51). Given that\nP(empire est) is about five times higher than P(empire sont), translation (51a) is rejected\nin favor of (51b).\nHaving given examples of how post hoc validation works within both NPs and\nsentences, we summarize in Table 12 the results obtained when we tested the 58 sen-\ntences whose translations contained subject-verb agreement errors owing to boundary\nfriction. Improvements were seen for translations derived from each of the on-line MT\nsystems: from a minimum of 58.6% (34 translations) for system A to a maximum of\n76% (44 translations) for system C. For each system, no improvement was found for\ntwo translations, and for 10 translations, our methodology could not tell definitively\nwhether the word to be corrected was a noun or a verb, so no change was made.\nFinally, in a small number of cases (between 2 and 12 translations), the target string\nwas not found on the Web, so again, no change was made.\nIn order to be as accurate and relevant as possible, statistical language (and trans-\nlation) models should be derived from corpora that are as large as possible, represen-\ntative, and of high quality. Although the Web is large, this post hoc validation process\nshows that despite the inherent noise contained on the Web because of the heteroge-\nneous nature of the documents contained therein, it remains a resource that is of great\nuse in evaluating translation candidates.\n"},{"#tail":"\n","@confidence":"0.9990387","#text":"\nWe have presented an EBMT system based on the marker hypothesis that uses post\nhoc validation and correction via the Web.11 Over 218,000 NPs and VPs were extracted\nautomatically from the Penn-II Treebank using just 59 of its 29,000 rule types. These\nphrases were then translated automatically by three on-line MT systems. These trans-\nlations gave rise to a number of automatically constructed linguistic resources: (1) the\noriginal ?source,target? phrasal translation pairs, (2) the marker lexicon, (3) the gen-\n11 Thanks are due to one of the anonymous reviewers for pointing out that our wEBMT system, seeded\nwith input from multiple translation systems, with a postvalidation process via the Web (amounting to\nan n-gram target language model), in effect forms a multiengine MT system as described by Frederking\nand Nirenburg (1994), Frederking et al (1994), and Hogan and Frederking (1998).\n"},{"#tail":"\n","@confidence":"0.997642769230769","#text":"\nComputational Linguistics Volume 29, Number 3\neralized lexicon, and (4) the word-level lexicon. When the system is confronted with\nnew input, these knowledge sources are searched in turn for matching chunks, and\nthe target language chunks are combined to create translation candidates.\nWe presented a number of experiments that showed how the system fared when\nconfronted with NPs and sentences. For the test set of 500 NPs, we obtained trans-\nlations in 96% of cases, with 77.8% of the 500 NPs being translated correctly. For\nsentences, we obtained translations in 92% of cases, with a completely correct transla-\ntion obtained 81.5% of the time. Translation quality improved both when chunks from\ndifferent on-line systems were used and when the system?s memories were seeded\nwith both third-person singular and third-person plural forms. For both NPs and sen-\ntences, we obtained intelligible translations in over 96% of cases. In most cases, the\n?best? translation was ranked in the top 10 translations output by the system and was\nalways ranked in the top 1% of translation candidates. This facilitates the task of any\ntranslator interacting with our system who needs to search for the ?best? translation\namong the alternatives provided.\nWe calculated the net gain of using wEBMT compared to the three on-line MT\nsystems. In some cases, an improvement of 50% was seen when EBMT was used.\nAs a consequence of the methodology chosen, we were able to perform a detailed\nevaluation of the strengths and weaknesses of the three Web-based systems used in\nour research, with Logomedia clearly outranking the other systems used. Neverthe-\nless, adding chunks from the other two on-line MT systems improves both coverage\nand translation quality. In sum, therefore, the best results are obtained when chunks\nfrom all three on-line systems are used, and the system?s databases are seeded with\ntranslations from these systems for both third-person singular and third-person plural\nversions of sentences.\nIn addition, prior to the system?s outputting the best-ranked translation candidate,\nmorphological variants of certain components in the translation are searched for via\nthe Web in order to confirm it as the final output translation or to propose a corrected\nalternative. Currently we validate our translations only with regard to subject head\nnoun?head verb agreement and determiner-noun agreement, but we plan to extend\nthis validation to cover more cases of boundary friction. We demonstrated that con-\nsiderable improvements can be made to the translations derived by the system by\nsubmitting them to the Web for validation and correction.\nA number of issues for further work present themselves. The decision to take only\nthose Penn-II rules occurring 1,000 or more times was completely arbitrary, and it\nmight be useful to include some strings corresponding to the less frequently occurring\nstructures in our database. Similarly, it would be a good idea to extend our word-level\nlexicon by including more entries using rules in which the right-hand side contains a\nsingle non-terminal.\nFurthermore, the quality of the output was not taken into consideration when\nselecting the on-line MT systems from which all our system resources are derived, so\nthat any results obtained may be further improved by selecting a ?better? MT system\nthat permits batch processing.\nWe could expect a significant improvement in the results obtained if we were to im-\nport the original sentences and their translations into a sentential database. Although\nwe insert dummy subject pronouns to derive appropriate finite verb forms, we do not\nmaintain these translation pairs as a resource for subsequent consultation and retrieval.\nAlthough the chance of finding an exact match at sentential level is very low, it will\nincrease as more sentence pairs are added to the database, especially if we restrict the\ndomain of applicability of (a version of) our system to a particular sublanguage area.\nHowever, the major improvement that can be expected is in the segmentation process:\n"},{"#tail":"\n","@confidence":"0.990396216216216","#text":"\nWay and Gough wEBMT\nGiven that verbs are not a closed class, any verb will be contained within (part of) a\nchunk pertaining to its subject NP. That is, although subject-verb agreement poses a\nconsiderable problem to our system given the choice of original input material, this\nparticular instance of boundary friction will disappear if we segment our translation\npairs at the sentential rather than at the phrasal level.\nIn addition, we want to evaluate our system further with respect to larger data sets.\nManual evaluation is costly, both in terms of time and effort required. Accordingly,\nin future work we plan to use automatic evaluation methodologies such as sentence\nerror rate or word error rate. These are very harsh metrics: Consider the example in\n(54), extracted from the Canadian Hansards:\n(54) Again this was voted down by the Liberal majority =?\nMalheureusement, encore une fois, la majorite? libe?rale l?a rejete?.\nAutomatic evaluation measures presuppose the existence of an ?oracle? (i.e., ?cor-\nrect?) translation produced by a human, such as here. Translations derived by the\nMT system to be evaluated are then compared against the human translation. In the\nexample in (54), the human has inserted malheureusement although there is no sign of\nunfortunately in the English source. If the perfect translation Encore une fois, la majorite?\nlibe?rale l?a rejete? were produced by an MT system, therefore, it would be penalized, as\nthe human translation is always considered to be the ?correct? translation. We have\nobtained a number of translation memories from two major computer companies, as\nwell as a large amount of monolingual data from the same domain, with which we\nplan to test our system using automatic evaluation metrics in future work. This will\nalso enable us to test our EBMT methodology against other language pairs, which\nmay present the segmentation method employed with new challenges to overcome.\nFinally, we plan to prioritize the lexical resources produced so that more weight-\ning would be given to translations derived from the phrasal and marker lexicons as\nopposed to those derived via word insertion from the word level lexicon and the\ngeneralized templates.\nIn sum, we have demonstrated that using a ?linguistics-lite? approach based on\nthe marker hypothesis, with a large number of phrases extracted automatically from\na very small number of the rules in the Penn Treebank, many new reusable linguistic\nresources can be derived automatically that can be utilized in an EBMT system capable\nof translating new input with quite reasonable rates of success. We have demonstrated\nthat a net gain may be achieved by using EBMT over on-line MT systems. We have\nalso shown that the Web can be used to validate and correct candidate translations\nprior to their being output.\n"},{"#tail":"\n","@confidence":"0.999891","#text":"\nThe authors wish to thank Mary Hearne for\nhelpful input in the initial stages of this\nproject. In addition, the insightful comments\nprovided by four anonymous reviewers\nhelped improve this article considerably. All\nremaining errors are our own.\n"}],"#text":"\n","affiliation":{"#tail":"\n","@confidence":"0.9892","#text":"\nDublin City University Dublin City University\n"},"sectionHeader":[{"#tail":"\n","@confidence":"0.994048","@genericHeader":"abstract","#text":"\n1. Introduction\n"},{"#tail":"\n","@confidence":"0.824305","@genericHeader":"categories and subject descriptors","#text":"\n4. Experiments and System Evaluation\n"},{"#tail":"\n","@confidence":"0.358874","@genericHeader":"general terms","#text":"\n8 Of course, even if it could be, we would be able to derive only the mistranslation Une petite fille e?gare?s\n"},{"#tail":"\n","@confidence":"0.95782","@genericHeader":"conclusions","#text":"\n6. Conclusions and Further Work\n"},{"#tail":"\n","@confidence":"0.966929","@genericHeader":"acknowledgments","#text":"\nAcknowledgments\n"},{"#tail":"\n","@confidence":"0.986592","@genericHeader":"references","#text":"\nReferences\n"}],"tableCaption":[{"#tail":"\n","@confidence":"0.714127","#text":"\nTable 4\n"},{"#tail":"\n","@confidence":"0.8779455","#text":"\nTable 5. Our system ranks the ?best? translation first over 57% of the time, and in\nover 96% of cases, it ranks it in the top five, and at worst in the top ten.\n"},{"#tail":"\n","@confidence":"0.566802","#text":"\nWay and Gough wEBMT\nTable 12\n"}],"page":[{"#tail":"\n","@confidence":"0.998889","#text":"\n422\n"},{"#tail":"\n","@confidence":"0.997768","#text":"\n423\n"},{"#tail":"\n","@confidence":"0.998977","#text":"\n424\n"},{"#tail":"\n","@confidence":"0.983873","#text":"\n425\n"},{"#tail":"\n","@confidence":"0.999578","#text":"\n426\n"},{"#tail":"\n","@confidence":"0.998963","#text":"\n427\n"},{"#tail":"\n","@confidence":"0.999252","#text":"\n428\n"},{"#tail":"\n","@confidence":"0.997818","#text":"\n429\n"},{"#tail":"\n","@confidence":"0.99329","#text":"\n430\n"},{"#tail":"\n","@confidence":"0.997523","#text":"\n431\n"},{"#tail":"\n","@confidence":"0.998547","#text":"\n432\n"},{"#tail":"\n","@confidence":"0.998841","#text":"\n433\n"},{"#tail":"\n","@confidence":"0.999391","#text":"\n434\n"},{"#tail":"\n","@confidence":"0.998282","#text":"\n435\n"},{"#tail":"\n","@confidence":"0.999684","#text":"\n436\n"},{"#tail":"\n","@confidence":"0.919835","#text":"\n70\n"},{"#tail":"\n","@confidence":"0.820491","#text":"\n437\n"},{"#tail":"\n","@confidence":"0.998107","#text":"\n438\n"},{"#tail":"\n","@confidence":"0.99654","#text":"\n439\n"},{"#tail":"\n","@confidence":"0.977896","#text":"\n440\n"},{"#tail":"\n","@confidence":"0.94963","#text":"\n441\n"},{"#tail":"\n","@confidence":"0.995209","#text":"\n442\n"},{"#tail":"\n","@confidence":"0.774436","#text":"\n443\n"},{"#tail":"\n","@confidence":"0.9964","#text":"\n444\n"},{"#tail":"\n","@confidence":"0.996805","#text":"\n445\n"},{"#tail":"\n","@confidence":"0.784301","#text":"\n446\n"},{"#tail":"\n","@confidence":"0.992548","#text":"\n447\n"},{"#tail":"\n","@confidence":"0.993613","#text":"\n448\n"},{"#tail":"\n","@confidence":"0.993479","#text":"\n449\n"},{"#tail":"\n","@confidence":"0.964917","#text":"\n450\n"},{"#tail":"\n","@confidence":"0.991613","#text":"\n451\n"},{"#tail":"\n","@confidence":"0.987143","#text":"\n452\n"},{"#tail":"\n","@confidence":"0.99741","#text":"\n453\n"},{"#tail":"\n","@confidence":"0.994151","#text":"\n454\n"},{"#tail":"\n","@confidence":"0.987298","#text":"\n455\n"},{"#tail":"\n","@confidence":"0.980193","#text":"\n456\n"},{"#tail":"\n","@confidence":"0.961538","#text":"\n457\n"}],"table":[{"#tail":"\n","@confidence":"0.6770298","#text":"\nthree on-line MT systems:\n? SDL International?s Enterprise Translation Server4 (system A)\n? Reverso by Softissimo5 (system B)\n? Logomedia6 (system C)\nTranslating the NPs via these MT systems was reasonably straightforward. We\n"},{"#tail":"\n","@confidence":"0.8370604","#text":"\nComputational Linguistics Volume 29, Number 3\nTable 1\nTranslation quality for sentences: Chunks\nderived from individual on-line MT\nsystems, third-person plural dummy\nsubjects.\nSystem Score 1 Score 2 Score 3\nA 14.2% 51.2% 34.6%\nB 8.9% 54.7% 36.4%\nC 4.4% 59.1% 36.5%\n"},{"#tail":"\n","@confidence":"0.997948","#text":"\nSystem Ranked 1 Ranked 2?5\nA 71.6% 28.4%\nB 65.3% 34.7%\nC 70.3% 29.7%\n"},{"#tail":"\n","@confidence":"0.914608833333333","#text":"\np.p/s:3+2\nFigure 1\nTranslation quality improves when system databases are seeded with more translation pairs:\nMeasuring % translation quality using fragments derived from single on-line MT systems.\nTable 3\nRanking of ?best? translation for sentences: Chunks derived from\nindividual on-line MT systems, third-person singular and third-person\nplural dummy subjects.\nSystem Ranked 1 Ranked 2?5 Ranked 6?10 Ranked 10?20\nA 65.2% 30.5% 0.0% 4.3%\nB 60.8% 34.9% 0.0% 4.3%\nC 64.1% 31.6% 0.0% 4.3%\n"},{"#tail":"\n","@confidence":"0.883452","#text":"\nTranslation coverage and quality for NPs: Chunks\nderived from individual on-line MT systems.\nSystem Coverage Quality\nScore 1 Score 2 Score 3\nA 94.8% 13.7% 52.5% 33.8%\nB 92.6% 10.6% 52.3% 37.1%\nC 94.8% 4.0% 48.7% 47.3%\n"},{"#tail":"\n","@confidence":"0.933057625","#text":"\nWay and Gough wEBMT\nTable 5\nRanking of ?best? translation for NPs: Chunks derived from\nindividual on-line MT systems.\nSystem Ranked 1 Ranked 2 Ranked 3?5 Ranked 6?10\nA 64.6% 9.1% 23.6% 2.7%\nB 57.7% 15.6% 24.8% 1.9%\nC 60.0% 7.6% 29.3% 3.1%\n"},{"#tail":"\n","@confidence":"0.7111082","#text":"\nWay and Gough wEBMT\nTable 7\nRanking of ?best? translation for sentences: Chunks\nderived from combinations of on-line MT systems,\nthird-person plural dummy subjects.\nSystem Ranked 1 Ranked 2?5 Ranked 6?10\nAB 67.6% 31.1% 1.3%\nAC 54.0% 46.0% 0.0%\nBC 63.6% 35.1% 1.3%\nABC 62.2% 35.1% 2.7%\n"},{"#tail":"\n","@confidence":"0.998735","#text":"\nSystem Ranked 1 Ranked 2?5 Ranked 6?10 Ranked 10?20 Ranked 20?40\nAB 43.4% 32.6% 2.3% 13.0% 8.7%\nAC 39.1% 34.8% 5.4% 12.0% 8.7%\nBC 43.4% 31.7% 2.7% 13.5% 8.7%\nABC 35.2% 28.0% 9.4% 18.3% 9.1%\n"},{"#tail":"\n","@confidence":"0.936963307692308","#text":"\nComputational Linguistics Volume 29, Number 3\nTable 9\nNPs: Coverage and quality improve when\nfragments from different sources are included.\nKnowledge Source Coverage Quality\nCombination Percentage Score 3\nA 94.8 33.8\nB 92.6 37.1\nC 94.8 47.3\nAB 95.4 54.1\nBC 95.6 64.0\nAC 94.8 72.0\nABC 96.0 77.8\n"},{"#tail":"\n","@confidence":"0.9966176","#text":"\nSystem Ranked 1 Ranked 2 Ranked 3?5 Ranked 6?10\nAB 42.2% 13.8% 41.3% 2.7%\nAC 62.1% 14.1% 21.3% 2.5%\nBC 66.4% 11.4% 19.8% 2.4%\nABC 62.0% 17.5% 13.5% 7.0%\n"},{"#tail":"\n","@confidence":"0.910145","#text":"\n(48) Where K=1:\nNet GainMT = 100\nNet GainEBMT = 92 + 30 = 122 (compared to system A)\nNet GainEBMT = 92 + 8 = 100 (compared to system B)\nNet GainEBMT = 92 + 6 = 98 (compared to system C)\nWhere K=2:\nNet GainMT = 100\nNet GainEBMT = 92 + 60 = 152 (compared to system A)\nNet GainEBMT = 92 + 16 = 108 (compared to system B)\nNet GainEBMT = 92 + 12 = 104 (compared to system C)\nThat is, where K=1, wEBMT outperforms SDL by a factor of 22, whereas there is no gain\n"},{"#tail":"\n","@confidence":"0.74623275","#text":"\nComputational Linguistics Volume 29, Number 3\nTable 11\nValidating translations using AltaVista\nn-Gram Searched For Number of Web Occurrences\nempire sont 353\nsont au 91,197\nempire est 1,809\nest au 217,820\n"},{"#tail":"\n","@confidence":"0.9797735","#text":"\nUsing the Web to improve noun-verb agreement\nImprovement No Improvement N-V Confusion Not on Web\nSystem A: Enterprise Translation Server\n58.6% 3.4% 17.3% 20.7%\nSystem B: Reverso\n62% 3.4% 17.3% 20.7%\nSystem C: Logomedia\n76% 3.4% 17.2% 3.4%\n"}]}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.436330","#tail":"\n","@no":"0","note":{"#tail":"\n","@confidence":"0.568736","#text":"c? 2003 Association for Computational Linguistics"},"#text":"\n","affiliation":{"#tail":"\n","@confidence":"0.998958","#text":"Dublin City University Dublin City University"},"author":{"#tail":"\n","@confidence":"0.999632","#text":"Andy Way Nano Gough"},"abstract":{"#tail":"\n","@confidence":"0.980806923076923","#text":"We have developed an example-based machine translation (EBMT) system that uses the World Wide Web for two different purposes: First, we populate the system?s memory with translations gathered from rule-based MT systems located on the Web. The source strings input to these systems were extracted automatically from an extremely small subset of the rule types in the Penn- II Treebank. In subsequent stages, the ?source, target? translation pairs obtained are automatically transformed into a series of resources that render the translation process more successful. Despite the fact that the output from on-line MT systems is often faulty, we demonstrate in a number of experiments that when used to seed the memories of an EBMT system, they can in fact prove useful in generating translations of high quality in a robust fashion. In addition, we demonstrate the relative gain of EBMT in comparison to on-line systems. Second, despite the perception that the documents available on the Web are of questionable quality, we demonstrate in contrast that such resources are extremely useful in automatically postediting translation candidates proposed by our system."},"title":{"#tail":"\n","@confidence":"0.981508333333333","#text":"wEBMT: Developing and Validating an Example-Based Machine Translation System Using the World Wide Web"}}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Ahrenberg, Lars, Mikael Andersson, and Magnus Merkel. 2002. A system for incremental and interactive word linking. In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC), pages 485?490, Las Palmas, Canary Islands, Spain."},"#text":"\n","pages":{"#tail":"\n","#text":"485--490"},"marker":{"#tail":"\n","#text":"Ahrenberg, Andersson, Merkel, 2002"},"location":{"#tail":"\n","#text":"Las Palmas, Canary Islands,"},"title":{"#tail":"\n","#text":"A system for incremental and interactive word linking."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Lars Ahrenberg"},{"#tail":"\n","#text":"Mikael Andersson"},{"#tail":"\n","#text":"Magnus Merkel"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1975"},"rawString":{"#tail":"\n","#text":"Becker, Joseph. 1975. The phrasal lexicon. In Proceedings of the International Workshop on Theoretical Issues in Natural Language Processing, pages 70?73, Cambridge, MA."},"#text":"\n","pages":{"#tail":"\n","#text":"70--73"},"marker":{"#tail":"\n","#text":"Becker, 1975"},"location":{"#tail":"\n","#text":"Cambridge, MA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"and co-occurrence probabilities. The respective lengths of the putative alignments in terms of characters is also an important factor. Ahrenberg, Andersson, and Merkel (2002) observe that for less widely spoken languages, the relative lack of linguistic tools and resources has forced developers of word alignment tools for such languages to use shallow processing and basic statistical approaches to word linking. Accordingly, they generate lexical correspondences by means of co-occurrence measures and string similarity metrics. More specifically, the notion of the phrasal lexicon (used first by Becker 1975) has been used successfully in a number of areas: ? Learnability (Zernik and Dyer 1987) ? Text generation (Hovy 1988; Milosavljevic, Tulloch, and Dale 1996) ? Speech generation (Rayner and Carter 1997) ? Localization (Scha?ler 1996) More recently, Simard and Langlais (2001) have proposed the exploitation of TMs at a subsentential level, while Carl, Way, and Scha?ler (2002) and Scha?ler, Way, and Carl (2003, pages 108?109) describe how phrasal lexicons might come to occupy a central place in a future hybrid integrated translation environment. This, they suggest, may result in a paradigm shift f","@endWordPosition":"2849","@position":"17822","annotationId":"T1","@startWordPosition":"2848","@citStr":"Becker 1975"}},"title":{"#tail":"\n","#text":"The phrasal lexicon."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the International Workshop on Theoretical Issues in Natural Language Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Joseph Becker"}}},{"date":{"#tail":"\n","#text":"2000"},"editor":{"#tail":"\n","#text":"In Wolfgang Wahlster, editor,"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"pping, where two adjacent terminal symbols can be merged into a single lexical item (for example, a word and its case-marking), can capture this sort of result quite handily.? Work using the marker hypothesis for MT adapts this monolingual mapping for pairs of languages: It is reasonably straightforward to map an English determiner-noun sequence onto a Japanese noun?case marker segment, once one has identified the sets of marker tags in the languages to be translated. Following construction of the marker lexicon, the ?source, target? chunks are generalized further using a methodology based on Block (2000) to permit a limited form of insertion in the translation process. As a byproduct of the chosen methodology, we also derive a standard ?word-level? translation lexicon. These various resources render the set of original translation pairs far more useful in deriving translations of previously unseen input. In Section 3, we describe in detail the segmentation process, together with the procedure whereby target chunks are combined to produce candidate translations. In Section 4, we report initially on two experiments in which we test different versions of our EBMT system against test sets of NPs ","@endWordPosition":"1715","@position":"10798","annotationId":"T2","@startWordPosition":"1714","@citStr":"Block (2000)"},{"#tail":"\n","#text":"lution via the recombination element of EBMT systems such as those described in [Carl and Way 2003].? In this section, we describe how the memory of our EBMT system is seeded with a set of translations obtained from Web-based MT systems. From this initial resource, we subsequently derive a number of different databases that together allow many new input sentences to be translated that it would not be possible to translate in other systems. First, the phrasal lexicon is segmented using the marker hypothesis to produce a marker lexicon. This is then generalized, following a methodology based on Block (2000), to generate the ?generalized marker lexicon.? Finally, as a result of the 3 We refer the interested reader to the excellent and comprehensive bibliography on parallel text processing available at http://www.up.univ-mrs.fr/?veronis/biblios/ptp.htm. 427 Way and Gough wEBMT methodology chosen, we automatically derive a fourth resource, namely, a ?word-level lexicon.? 2.1 The Phrasal Lexicon Our phrasal lexicon was built by selecting a set of 218,697 English noun phrases and verb phrases from the Penn Treebank. We identified all rule types occurring 1,000 or more times and eliminated those that ","@endWordPosition":"3096","@position":"19361","annotationId":"T3","@startWordPosition":"3095","@citStr":"Block (2000)"},{"#tail":"\n","#text":" a present participle. Given this information, in such cases we tag such words with the <LEX> tag. Taking expanding the board to 14 members ?? augmente le conseil a` 14 membres as an example, we extract the chunks in (24): (24) <DET> the board : le conseil <DET> the : le <PREP> to <QUANT> 14 members : a` 14 membres <QUANT> 14 members : 14 membres <LEX> expanding : augmente <LEX> board : conseil <PREP> to : a` <LEX> members : membres We ignore here the trivially true lexical chunk ?<QUANT> 14 : 14.? In a final processing stage, we generalize over the marker lexicon following a process found in Block (2000). In Block?s approach, word alignments are assigned probabilities by means of a statistical word alignment tool. In a subsequent stage, chunk pairs are extracted, which are then generalized to produce a set of translation templates for each ?source, target? segment. Block distinguishes chunks from ?patterns,? as we do: His chunks are similar to our marker chunks, and his patterns are similar to our generalized marker chunks. Once chunks are derived from ?source, target? alignments, patterns are computed from the derived chunks by means of the following algorithm: ?for each pair of chunk pairs ","@endWordPosition":"5239","@position":"32158","annotationId":"T4","@startWordPosition":"5238","@citStr":"Block (2000)"},{"#tail":"\n","#text":"pproaches include those of Cicekli and Gu?venir (1996), McTait and Trujillo (1999), Carl (1999), and Brown (2000), inter alia. In our system, in some cases the smallest chunk obtainable via the marker-based segmentation process may be something like (27): (27) <DET> the good man : le bon homme In such cases, if our system were confronted with a good man, it would not be able to translate such a phrase, assuming this to be missing from the marker lexicon. Accordingly, we convert examples such as (27) into their generalized equivalents, as in (28): (28) <DET> good man : bon homme That is, where Block (2000) substitutes variables for various words in his templates, we replace certain lexical items with their marker tag. Given that examples such as ??<DET> a : un? are likely to exist in the word-level lexicon, they may be inserted at the point indicated by the marker tag to form the correct translation un bon homme. We thus cluster on marker words to improve the coverage of our system (see Section 5 for results that show exactly how clustering on marker words helps); others (notably Brown [2000, 2003]) use clustering techniques to determine equivalence classes of individual words that can occur in","@endWordPosition":"5678","@position":"34649","annotationId":"T5","@startWordPosition":"5677","@citStr":"Block (2000)"}]},"title":{"#tail":"\n","#text":"Example-based incremental synchronous interpretation."},"volume":{"#tail":"\n","#text":"3"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Block, Hans-Ulrich. 2000. Example-based incremental synchronous interpretation. In Wolfgang Wahlster, editor, Verbmobil: Foundations of Speech-to-Speech Translation, Springer Verlag, Berlin/Heidelberg/New Computational Linguistics Volume 29, Number 3 York, pages 411?417."},"#text":"\n","pages":{"#tail":"\n","#text":"411--417"},"marker":{"#tail":"\n","#text":"Block, 2000"},"publisher":{"#tail":"\n","#text":"Springer Verlag,"},"location":{"#tail":"\n","#text":"York,"},"booktitle":{"#tail":"\n","#text":"Berlin/Heidelberg/New Computational Linguistics Volume 29, Number"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Hans-Ulrich Block"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"editor":{"#tail":"\n","#text":"Bod, Rens, Remko Scha, and Khalil Sima?an, editors."},"rawString":{"#tail":"\n","#text":"Bod, Rens, Remko Scha, and Khalil Sima?an, editors. 2003. Data-Oriented Parsing. CSLI Publications, Stanford, CA."},"#text":"\n","marker":{"#tail":"\n","#text":"2003"},"publisher":{"#tail":"\n","#text":"CSLI Publications,"},"location":{"#tail":"\n","#text":"Stanford, CA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"7) into their generalized equivalents, as in (28): (28) <DET> good man : bon homme That is, where Block (2000) substitutes variables for various words in his templates, we replace certain lexical items with their marker tag. Given that examples such as ??<DET> a : un? are likely to exist in the word-level lexicon, they may be inserted at the point indicated by the marker tag to form the correct translation un bon homme. We thus cluster on marker words to improve the coverage of our system (see Section 5 for results that show exactly how clustering on marker words helps); others (notably Brown [2000, 2003]) use clustering techniques to determine equivalence classes of individual words that can occur in the same context, and in so doing derive translation templates from individual translation examples. 2.3 Summary In sum, we automatically create four knowledge sources: ? the original ?source,target? phrasal translation pairs ? the marker lexicon (cf. (16)) ? the generalized marker lexicon (cf. (28)) ? the word-level lexicon (cf. (24)) 433 Way and Gough wEBMT When matching the input to the corpus, we search for chunks in the order given here, that is, from specific examples (those containing more","@endWordPosition":"5764","@position":"35151","annotationId":"T6","@startWordPosition":"5763","@citStr":"[2000, 2003]"}},"title":{"#tail":"\n","#text":"Data-Oriented Parsing."},"@valid":"true"},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Boutsis, Sotiris, and Stelios Piperidis. 1998. Aligning clauses in parallel texts. In Proceedings of the Third Conference on Empirical Methods in Natural Language Processing, pages 17?26, Granada, Spain."},"#text":"\n","pages":{"#tail":"\n","#text":"17--26"},"marker":{"#tail":"\n","#text":"Boutsis, Piperidis, 1998"},"location":{"#tail":"\n","#text":"Granada,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ure on trying to establish subsentential translations from a bilingual corpus.3 Kay and Ro?scheisen (1993) attempt to extract a bilingual dictionary using a hybrid method of sentence and word alignment on the assumption that the ?source, target? words have a similar distribution. Fung and McKeown (1997) attempt to translate technical terms using word relation matrices, although the resource from which such relations are derived is a pair of nonparallel corpora. Somers (1998) replicates the work of Fung and McKeown with different language pairs using the simpler metric of Levenshtein distance. Boutsis and Piperidis (1998) use a tagged parallel corpus to extract translationally equivalent English-Greek clauses on the basis of word occurrence and co-occurrence probabilities. The respective lengths of the putative alignments in terms of characters is also an important factor. Ahrenberg, Andersson, and Merkel (2002) observe that for less widely spoken languages, the relative lack of linguistic tools and resources has forced developers of word alignment tools for such languages to use shallow processing and basic statistical approaches to word linking. Accordingly, they generate lexical correspondences by means of ","@endWordPosition":"2743","@position":"17088","annotationId":"T7","@startWordPosition":"2740","@citStr":"Boutsis and Piperidis (1998)"}},"title":{"#tail":"\n","#text":"Aligning clauses in parallel texts."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Third Conference on Empirical Methods in Natural Language Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Sotiris Boutsis"},{"#tail":"\n","#text":"Stelios Piperidis"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Brown, Ralf. 2000. Automated generalization of translation examples. In Eighteenth International Conference on Computational Linguistics: COLING 2000 in Europe, pages 125?131, Saarbru?cken, Germany."},"#text":"\n","pages":{"#tail":"\n","#text":"125--131"},"marker":{"#tail":"\n","#text":"Brown, 2000"},"location":{"#tail":"\n","#text":"Saarbru?cken, Germany."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":", [which V] ? ? [das V was], [which V what] ? ... ? [V ist was Sie], [V is what you] ? ... ? [das ist was V wollten], [which is what V wanted] ? ... Of course, many other researchers also try to extract generalized templates. Kaji, Kida, and Morimoto (1992) identify translationally equivalent phrasal segments and replace such equivalents with variables to generate a set of translation patterns. Watanabe (1993) combines lexical and dependency mappings to form his generalizations. Other similar approaches include those of Cicekli and Gu?venir (1996), McTait and Trujillo (1999), Carl (1999), and Brown (2000), inter alia. In our system, in some cases the smallest chunk obtainable via the marker-based segmentation process may be something like (27): (27) <DET> the good man : le bon homme In such cases, if our system were confronted with a good man, it would not be able to translate such a phrase, assuming this to be missing from the marker lexicon. Accordingly, we convert examples such as (27) into their generalized equivalents, as in (28): (28) <DET> good man : bon homme That is, where Block (2000) substitutes variables for various words in his templates, we replace certain lexical items with thei","@endWordPosition":"5589","@position":"34150","annotationId":"T8","@startWordPosition":"5588","@citStr":"Brown (2000)"}},"title":{"#tail":"\n","#text":"Automated generalization of translation examples."},"booktitle":{"#tail":"\n","#text":"In Eighteenth International Conference on Computational Linguistics: COLING 2000 in Europe,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Ralf Brown"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"editor":{"#tail":"\n","#text":"In Michael Carl and Andy Way, editors,"},"rawString":{"#tail":"\n","#text":"Brown, Ralf. 2003. Clustered transfer-rule induction for example-based translation. In Michael Carl and Andy Way, editors, Recent Advances in Example-Based Machine Translation. Kluwer Academic, Dordrecht, the Netherlands, pages 287?305."},"#text":"\n","pages":{"#tail":"\n","#text":"287--305"},"marker":{"#tail":"\n","#text":"Brown, 2003"},"title":{"#tail":"\n","#text":"Clustered transfer-rule induction for example-based translation."},"booktitle":{"#tail":"\n","#text":"Recent Advances in Example-Based Machine Translation. Kluwer Academic, Dordrecht, the Netherlands,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Ralf Brown"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"Carl, Michael. 1999. Inducing translation templates for example-based machine translation. In Machine Translation Summit VII, pages 250?258, Singapore."},"#text":"\n","pages":{"#tail":"\n","#text":"250--258"},"marker":{"#tail":"\n","#text":"Carl, 1999"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"V is] ? ? [das V], [which V] ? ? [das V was], [which V what] ? ... ? [V ist was Sie], [V is what you] ? ... ? [das ist was V wollten], [which is what V wanted] ? ... Of course, many other researchers also try to extract generalized templates. Kaji, Kida, and Morimoto (1992) identify translationally equivalent phrasal segments and replace such equivalents with variables to generate a set of translation patterns. Watanabe (1993) combines lexical and dependency mappings to form his generalizations. Other similar approaches include those of Cicekli and Gu?venir (1996), McTait and Trujillo (1999), Carl (1999), and Brown (2000), inter alia. In our system, in some cases the smallest chunk obtainable via the marker-based segmentation process may be something like (27): (27) <DET> the good man : le bon homme In such cases, if our system were confronted with a good man, it would not be able to translate such a phrase, assuming this to be missing from the marker lexicon. Accordingly, we convert examples such as (27) into their generalized equivalents, as in (28): (28) <DET> good man : bon homme That is, where Block (2000) substitutes variables for various words in his templates, we replace certain lexic","@endWordPosition":"5586","@position":"34132","annotationId":"T9","@startWordPosition":"5585","@citStr":"Carl (1999)"},{"#tail":"\n","#text":", if we wish to consider translations produced by all three MT systems, then we add the weights of common translations and divide the weights of all proposed translations by six. When translated phrases have been retrieved for each chunk of the input string, they must then be combined to produce an output string. In order to calculate a ranking for each TL sentence produced, we multiply the weights of each chunk used in its construction. Note that this ensures that greater importance is attributed to longer chunks, as is usual in most EBMT systems (cf. Sato and Nagao 1990; Veale and Way 1997; Carl 1999).7 As an example, consider the translation into French of the house collapsed. Assume the conditional probabilities in (33): 7 Note that approaches that prefer the greatest context to be taken into account are not limited to EBMT. Research in the area of data-oriented parsing (cf. Bod, Scha, and Sima?an, 2003) also shows that unless the corpus is inherently biased, derivations constructed using the smallest number of subtrees have a higher probability than those built with a larger number of smaller subtrees. 436 Computational Linguistics Volume 29, Number 3 (33) a. P(la maison | the house) = ","@endWordPosition":"7249","@position":"44079","annotationId":"T10","@startWordPosition":"7248","@citStr":"Carl 1999"}]},"title":{"#tail":"\n","#text":"Inducing translation templates for example-based machine translation."},"booktitle":{"#tail":"\n","#text":"In Machine Translation Summit VII,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Michael Carl"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Carl, Michael, and Andy Way, editors. 2003. Recent Advances in Example-Based Machine Translation. Kluwer Academic, Dordrecht, the Netherlands."},"#text":"\n","marker":{"#tail":"\n","#text":"Carl, Way, editors, 2003"},"publisher":{"#tail":"\n","#text":"Kluwer Academic,"},"location":{"#tail":"\n","#text":"Dordrecht, the Netherlands."},"booktitle":{"#tail":"\n","#text":"Recent Advances in Example-Based Machine Translation."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Michael Carl"},{"#tail":"\n","#text":"Andy Way"},{"#tail":"\n","#text":"editors"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"editor":{"#tail":"\n","#text":"In Stephen Richardson, editor,"},"rawString":{"#tail":"\n","#text":"Carl, Michael, Andy Way, and Reinhard Scha?ler. 2002. Toward a hybrid integrated translation environment. In Stephen Richardson, editor, Machine Translation: From Research to Real Users: Fifth Conference of the Association for Machine Translation in the Americas (AMTA-2002). Lecture Notes in Artificial Intelligence 2499. Springer Verlag, Berlin/Heidelberg, pages 11?20."},"#text":"\n","pages":{"#tail":"\n","#text":"2499"},"marker":{"#tail":"\n","#text":"Carl, Way, Schaler, 2002"},"publisher":{"#tail":"\n","#text":"Springer Verlag, Berlin/Heidelberg,"},"title":{"#tail":"\n","#text":"Toward a hybrid integrated translation environment."},"booktitle":{"#tail":"\n","#text":"Machine Translation: From Research to Real Users: Fifth Conference of the Association for Machine Translation in the Americas (AMTA-2002). Lecture Notes in Artificial Intelligence"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Michael Carl"},{"#tail":"\n","#text":"Andy Way"},{"#tail":"\n","#text":"Reinhard Schaler"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"Cicekli, Ilyas, and Altay Gu?venir. 1996. Learning translation rules from a bilingual corpus. In Proceedings of the Second International Conference on New Methods in Language Processing, pages 90?97, Ankara, Turkey."},"#text":"\n","pages":{"#tail":"\n","#text":"90--97"},"marker":{"#tail":"\n","#text":"Cicekli, Guvenir, 1996"},"location":{"#tail":"\n","#text":"Ankara, Turkey."},"title":{"#tail":"\n","#text":"Learning translation rules from a bilingual corpus."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Second International Conference on New Methods in Language Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Ilyas Cicekli"},{"#tail":"\n","#text":"Altay Guvenir"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Frederking, Robert, and Sergei Nirenburg. 1994. Three heads are better than one. In Proceedings of the Fourth Conference on Applied Natural Language Processing (ANLP-94), pages 95?100, Stuttgart, Germany."},"#text":"\n","pages":{"#tail":"\n","#text":"95--100"},"marker":{"#tail":"\n","#text":"Frederking, Nirenburg, 1994"},"location":{"#tail":"\n","#text":"Stuttgart, Germany."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ank using just 59 of its 29,000 rule types. These phrases were then translated automatically by three on-line MT systems. These translations gave rise to a number of automatically constructed linguistic resources: (1) the original ?source,target? phrasal translation pairs, (2) the marker lexicon, (3) the gen11 Thanks are due to one of the anonymous reviewers for pointing out that our wEBMT system, seeded with input from multiple translation systems, with a postvalidation process via the Web (amounting to an n-gram target language model), in effect forms a multiengine MT system as described by Frederking and Nirenburg (1994), Frederking et al (1994), and Hogan and Frederking (1998). 454 Computational Linguistics Volume 29, Number 3 eralized lexicon, and (4) the word-level lexicon. When the system is confronted with new input, these knowledge sources are searched in turn for matching chunks, and the target language chunks are combined to create translation candidates. We presented a number of experiments that showed how the system fared when confronted with NPs and sentences. For the test set of 500 NPs, we obtained translations in 96% of cases, with 77.8% of the 500 NPs being translated correctly. For sentences, ","@endWordPosition":"15579","@position":"94328","annotationId":"T11","@startWordPosition":"15576","@citStr":"Frederking and Nirenburg (1994)"}},"title":{"#tail":"\n","#text":"Three heads are better than one."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Fourth Conference on Applied Natural Language Processing (ANLP-94),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Robert Frederking"},{"#tail":"\n","#text":"Sergei Nirenburg"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Frederking, Robert, Sergei Nirenburg, David Farwell, Steven Helmreich, Eduard Hovy, Kevin Knight, Stephen Beale, Constantin Domashnev, Donna Attardo, Dean Grannes, and Ralf Brown. 1994. Integrating translations from multiple sources with the Pangloss Mark III machine translation system. In Proceedings of the First Conference of the Association for Machine Translation in the Americas, pages 73?80, Columbia, MD."},"#text":"\n","pages":{"#tail":"\n","#text":"73--80"},"marker":{"#tail":"\n","#text":"Frederking, Nirenburg, Farwell, Helmreich, Hovy, Knight, Beale, Domashnev, Attardo, Grannes, Brown, 1994"},"location":{"#tail":"\n","#text":"Columbia, MD."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ule types. These phrases were then translated automatically by three on-line MT systems. These translations gave rise to a number of automatically constructed linguistic resources: (1) the original ?source,target? phrasal translation pairs, (2) the marker lexicon, (3) the gen11 Thanks are due to one of the anonymous reviewers for pointing out that our wEBMT system, seeded with input from multiple translation systems, with a postvalidation process via the Web (amounting to an n-gram target language model), in effect forms a multiengine MT system as described by Frederking and Nirenburg (1994), Frederking et al (1994), and Hogan and Frederking (1998). 454 Computational Linguistics Volume 29, Number 3 eralized lexicon, and (4) the word-level lexicon. When the system is confronted with new input, these knowledge sources are searched in turn for matching chunks, and the target language chunks are combined to create translation candidates. We presented a number of experiments that showed how the system fared when confronted with NPs and sentences. For the test set of 500 NPs, we obtained translations in 96% of cases, with 77.8% of the 500 NPs being translated correctly. For sentences, we obtained translations ","@endWordPosition":"15583","@position":"94353","annotationId":"T12","@startWordPosition":"15580","@citStr":"Frederking et al (1994)"}},"title":{"#tail":"\n","#text":"Integrating translations from multiple sources with the Pangloss Mark III machine translation system."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the First Conference of the Association for Machine Translation in the Americas,"},"@valid":"false","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Robert Frederking"},{"#tail":"\n","#text":"Sergei Nirenburg"},{"#tail":"\n","#text":"David Farwell"},{"#tail":"\n","#text":"Steven Helmreich"},{"#tail":"\n","#text":"Eduard Hovy"},{"#tail":"\n","#text":"Kevin Knight"},{"#tail":"\n","#text":"Stephen Beale"},{"#tail":"\n","#text":"Constantin Domashnev"},{"#tail":"\n","#text":"Donna Attardo"},{"#tail":"\n","#text":"Dean Grannes"},{"#tail":"\n","#text":"Ralf Brown"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Fung, Pascale, and Kathleen McKeown. 1997. Finding terminology translations from non-parallel corpora. In Proceedings of the Fifth Annual Workshop on Very Large Corpora, pages 192?202, Hong Kong."},"#text":"\n","pages":{"#tail":"\n","#text":"192--202"},"marker":{"#tail":"\n","#text":"Fung, McKeown, 1997"},"location":{"#tail":"\n","#text":"Hong Kong."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"nguistics Volume 29, Number 3 2. Deriving Translation Resources from Web-Based MT Systems All EBMT systems, from the initial proposal by Nagao (1984) to the recent collection of Carl and Way (2003), are premised on the availability of subsentential alignments derived from the input bitext. There is a wealth of literature on trying to establish subsentential translations from a bilingual corpus.3 Kay and Ro?scheisen (1993) attempt to extract a bilingual dictionary using a hybrid method of sentence and word alignment on the assumption that the ?source, target? words have a similar distribution. Fung and McKeown (1997) attempt to translate technical terms using word relation matrices, although the resource from which such relations are derived is a pair of nonparallel corpora. Somers (1998) replicates the work of Fung and McKeown with different language pairs using the simpler metric of Levenshtein distance. Boutsis and Piperidis (1998) use a tagged parallel corpus to extract translationally equivalent English-Greek clauses on the basis of word occurrence and co-occurrence probabilities. The respective lengths of the putative alignments in terms of characters is also an important factor. Ahrenberg, Andersso","@endWordPosition":"2694","@position":"16764","annotationId":"T13","@startWordPosition":"2691","@citStr":"Fung and McKeown (1997)"}},"title":{"#tail":"\n","#text":"Finding terminology translations from non-parallel corpora."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Fifth Annual Workshop on Very Large Corpora,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Pascale Fung"},{"#tail":"\n","#text":"Kathleen McKeown"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"editor":{"#tail":"\n","#text":"Stephen Richardson, editor,"},"rawString":{"#tail":"\n","#text":"Gough, Nano, Andy Way, and Mary Hearne. 2002. Example-based machine translation via the Web. In Stephen Richardson, editor, Machine Translation: From Research to Real Users: Fifth Conference of the Association for Machine Translation in the Americas (AMTA-2002) Lecture Notes in Artificial Intelligence 2499. Springer Verlag, Berlin/Heidelberg, pages 74?83."},"#text":"\n","pages":{"#tail":"\n","#text":"2499"},"marker":{"#tail":"\n","#text":"Gough, Way, Hearne, 2002"},"publisher":{"#tail":"\n","#text":"Springer Verlag, Berlin/Heidelberg,"},"title":{"#tail":"\n","#text":"Example-based machine translation via the Web. In"},"booktitle":{"#tail":"\n","#text":"Machine Translation: From Research to Real Users: Fifth Conference of the Association for Machine Translation in the Americas (AMTA-2002) Lecture Notes in Artificial Intelligence"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Nano Gough"},{"#tail":"\n","#text":"Andy Way"},{"#tail":"\n","#text":"Mary Hearne"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1979"},"rawString":{"#tail":"\n","#text":"Green, Thomas. 1979. The necessity of syntax markers: Two experiments with artificial languages. Journal of Verbal Learning and Behavior, 18:481?496."},"journal":{"#tail":"\n","#text":"Journal of Verbal Learning and Behavior,"},"#text":"\n","pages":{"#tail":"\n","#text":"18--481"},"marker":{"#tail":"\n","#text":"Green, 1979"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"tem can produce translations itself by automatically combining chunks from different translation examples stored in its memories. In Section 2, we describe how we automatically obtain a hierarchy of lexical resources that are used sequentially by our EBMT system, wEBMT, to translate new input. The primary resource gathered is a ?phrasal lexicon,? constructed by extracting over 200,000 phrases from the Penn Treebank and having them translated into French by three Web-based machine translation (MT) systems. Each set of translations is stored separately, and for each set the ?marker hypothesis? (Green 1979) is used to segment the phrasal lexicon into a ?marker lexicon.? The marker hypothesis is a universal psycholinguistic constraint which states that natural languages are ?marked? for complex syntactic structure at surface form by a closed set of specific lexemes and morphemes. That is, a basic phrase-level segmentation of an input sentence can be achieved by exploiting a closed list of known marker words to signal the start and end of each segment. Consider the following example, selected at random from the Wall Street Journal section of the Penn-II Treebank: (5) The Dearborn, Mich., energy co","@endWordPosition":"1188","@position":"7445","annotationId":"T14","@startWordPosition":"1187","@citStr":"Green 1979"},{"#tail":"\n","#text":"ners and one with a possessive pronoun. The sets of determiners and possessive pronouns are both very small. Furthermore, there are four prepositional phrases, and the set of prepositions is similarly small. A further assumption that could be made is that all words that end with -ed are verbs, such as stopped in (5). The marker hypothesis is arguably universal in presuming that concepts and structures like these have similar morphological or structural marking in all languages. The marker hypothesis has been used for a number of different language-related tasks, including ? language learning (Green 1979; Mori and Moeser 1983; Morgan, Meier, and Newport 1989) ? monolingual grammar induction (Juola 1998) ? grammar optimization (Juola 1994) ? insights into universal grammar (Juola 1998) ? machine translation (Juola 1994, 1997; Veale and Way 1997; Gough, Way, and Hearne 2002) With respect to translation, a potential problem in using the marker hypothesis is that some languages do not have marker words such as articles, for instance. Green?s (1979) work showed that artificial languages, both with and without specific marker words, may be learned more accurately and quickly if such psycholinguisti","@endWordPosition":"1409","@position":"8820","annotationId":"T15","@startWordPosition":"1408","@citStr":"Green 1979"}]},"title":{"#tail":"\n","#text":"The necessity of syntax markers: Two experiments with artificial languages."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Thomas Green"}}},{"volume":{"#tail":"\n","#text":"21"},"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"Grefenstette, Gregory. 1999. The World Wide Web as a resource for example-based machine translation tasks. In Proceedings of the ASLIB Conference on Translating and the Computer, volume 21, London. Hogan, Christopher, and Robert E."},"#text":"\n","marker":{"#tail":"\n","#text":"Grefenstette, 1999"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"marker word in the string is the and its translation can be one of le, la, l?, or les, depending on the context. The system simply attaches the translation with the highest weight to the existing chunk ordinateurs personnels to produce the mistranslation in (50): (50) *la ordinateurs personnels The problem of boundary friction is clearly visible here: We have inserted a feminine singular determiner into a chunk that was generalized from a masculine plural NP. However, rather than output this wrong translation directly, we use a post hoc validation and (if required) correction process based on Grefenstette (1999). Grefenstette shows that the Web can be used as a filter on translation quality simply by searching for competing translation candidates and selecting the one that is found most often. Rather than search for competing candidates, we select the ?best? translation and have its morphological variants searched for on-line. In the example above, namely, the personal computers, we search for les ordinateurs personnels versus the wrong alternatives le/la/l?ordinateurs personnels. Interestingly, using Lycos, and setting the search language to French, the correct form les ordinateurs personnels is uni","@endWordPosition":"14440","@position":"87469","annotationId":"T16","@startWordPosition":"14439","@citStr":"Grefenstette (1999)"}},"title":{"#tail":"\n","#text":"The World Wide Web as a resource for example-based machine translation tasks."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the ASLIB Conference on Translating and the Computer,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Gregory Grefenstette"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Frederking. 1998. An evaluation of the multi-engine MT architecture. In Machine Translation and the Information Soup: Proceedings of the Third Conference of the Association for Machine Translation in the Americas (AMTA ?98), Lecture Notes in Artificial Intelligence 1529. Springer Verlag, Berlin/Heidelberg, pages 113?123."},"#text":"\n","pages":{"#tail":"\n","#text":"113--123"},"marker":{"#tail":"\n","#text":"Frederking, 1998"},"publisher":{"#tail":"\n","#text":"Springer Verlag, Berlin/Heidelberg,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"slated automatically by three on-line MT systems. These translations gave rise to a number of automatically constructed linguistic resources: (1) the original ?source,target? phrasal translation pairs, (2) the marker lexicon, (3) the gen11 Thanks are due to one of the anonymous reviewers for pointing out that our wEBMT system, seeded with input from multiple translation systems, with a postvalidation process via the Web (amounting to an n-gram target language model), in effect forms a multiengine MT system as described by Frederking and Nirenburg (1994), Frederking et al (1994), and Hogan and Frederking (1998). 454 Computational Linguistics Volume 29, Number 3 eralized lexicon, and (4) the word-level lexicon. When the system is confronted with new input, these knowledge sources are searched in turn for matching chunks, and the target language chunks are combined to create translation candidates. We presented a number of experiments that showed how the system fared when confronted with NPs and sentences. For the test set of 500 NPs, we obtained translations in 96% of cases, with 77.8% of the 500 NPs being translated correctly. For sentences, we obtained translations in 92% of cases, with a completel","@endWordPosition":"15588","@position":"94386","annotationId":"T17","@startWordPosition":"15587","@citStr":"Frederking (1998)"}},"title":{"#tail":"\n","#text":"An evaluation of the multi-engine MT architecture."},"booktitle":{"#tail":"\n","#text":"In Machine Translation and the Information Soup: Proceedings of the Third Conference of the Association for Machine Translation in the Americas (AMTA ?98), Lecture Notes in Artificial Intelligence 1529."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Frederking"}}},{"date":{"#tail":"\n","#text":"1988"},"editor":{"#tail":"\n","#text":"In David McDonald and Leonard Bolc, editors,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"portant factor. Ahrenberg, Andersson, and Merkel (2002) observe that for less widely spoken languages, the relative lack of linguistic tools and resources has forced developers of word alignment tools for such languages to use shallow processing and basic statistical approaches to word linking. Accordingly, they generate lexical correspondences by means of co-occurrence measures and string similarity metrics. More specifically, the notion of the phrasal lexicon (used first by Becker 1975) has been used successfully in a number of areas: ? Learnability (Zernik and Dyer 1987) ? Text generation (Hovy 1988; Milosavljevic, Tulloch, and Dale 1996) ? Speech generation (Rayner and Carter 1997) ? Localization (Scha?ler 1996) More recently, Simard and Langlais (2001) have proposed the exploitation of TMs at a subsentential level, while Carl, Way, and Scha?ler (2002) and Scha?ler, Way, and Carl (2003, pages 108?109) describe how phrasal lexicons might come to occupy a central place in a future hybrid integrated translation environment. This, they suggest, may result in a paradigm shift from TM to EBMT via the phrasal lexicon: Translators are on the whole wary of MT technology, but once subsentential a","@endWordPosition":"2869","@position":"17938","annotationId":"T18","@startWordPosition":"2868","@citStr":"Hovy 1988"}},"title":{"#tail":"\n","#text":"Generating language with a phrasal lexicon."},"#tail":"\n","rawString":{"#tail":"\n","#text":"Hovy, Edward. 1988. Generating language with a phrasal lexicon. In David McDonald and Leonard Bolc, editors, Natural Language Generation Systems. Springer Verlag, New York, pages 353?384."},"#text":"\n","pages":{"#tail":"\n","#text":"353--384"},"marker":{"#tail":"\n","#text":"Hovy, 1988"},"publisher":{"#tail":"\n","#text":"Springer Verlag,"},"location":{"#tail":"\n","#text":"New York,"},"booktitle":{"#tail":"\n","#text":"Natural Language Generation Systems."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Edward Hovy"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Juola, Patrick. 1994. A psycholinguistic approach to corpus-based machine translation. In CSNLP 1994: Third International Conference on the Cognitive Science of Natural Language Processing, Dublin."},"#text":"\n","marker":{"#tail":"\n","#text":"Juola, 1994"},"location":{"#tail":"\n","#text":"Dublin."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" prepositional phrases, and the set of prepositions is similarly small. A further assumption that could be made is that all words that end with -ed are verbs, such as stopped in (5). The marker hypothesis is arguably universal in presuming that concepts and structures like these have similar morphological or structural marking in all languages. The marker hypothesis has been used for a number of different language-related tasks, including ? language learning (Green 1979; Mori and Moeser 1983; Morgan, Meier, and Newport 1989) ? monolingual grammar induction (Juola 1998) ? grammar optimization (Juola 1994) ? insights into universal grammar (Juola 1998) ? machine translation (Juola 1994, 1997; Veale and Way 1997; Gough, Way, and Hearne 2002) With respect to translation, a potential problem in using the marker hypothesis is that some languages do not have marker words such as articles, for instance. Green?s (1979) work showed that artificial languages, both with and without specific marker words, may be learned more accurately and quickly if such psycholinguistic cues exist. The 424 Computational Linguistics Volume 29, Number 3 research of Mori and Moeser (1983) showed a similar effect due to cas","@endWordPosition":"1429","@position":"8957","annotationId":"T19","@startWordPosition":"1428","@citStr":"Juola 1994"},{"#tail":"\n","#text":"le. If the URL takes the form of a query, then the document retrieved is the result of the query, namely, the translated Web page. Once this is obtained, it is a simple process to retrieve the French translations and associate them with their English source equivalents. 4 http://www.freetranslation.com 5 http://trans.voila.fr 6 http://www.logomedia.net 428 Computational Linguistics Volume 29, Number 3 2.2 The Marker Lexicons Given that the marker hypothesis is arguably universal, it is clear that benefits may accrue by using it to facilitate subsentential alignment of ?source, target? chunks. Juola (1994, 1997) conducts some small experiments using his METLA system to show the viability of this approach for English ?? French and English ?? Urdu. For the English ?? French language pair, Juola gives results of 61% correct translation when the system is tested on the training corpus, and 36% accuracy when it is evaluated with test data. For English ?? Urdu, Juola (1997, page 213) notes that ?the system learned the original training corpus . . . perfectly and could reproduce it without errors?; that is, it scored 100% accuracy when tested against the training corpus. On novel test sentences, he g","@endWordPosition":"3665","@position":"23028","annotationId":"T20","@startWordPosition":"3664","@citStr":"Juola (1994"},{"#tail":"\n","#text":"ntage of the assumption that where a chunk contains just one non?marker word in both source and target, these words are translations of each other. Where a marker-headed pair contains just two words, as in (16), for instance, we can extract the word-level translations in (23): (23) <QUANT> all : tous <PREP> of : d? <LEX> uses : usages <LEX> asbestos : asbeste That is, using the marker hypothesis method of segmentation, smaller aligned segments can be extracted from the phrasal lexicon without recourse to any detailed parsing techniques or complex co-ocurrence measures. 431 Way and Gough wEBMT Juola (1994, 1997) assumes that words ending in -ed are verbs. However, given that verbs are not a closed class, in our approach we do not mark chunks beginning with a verb with any marker category. Instead, we take advantage of the fact that the initial phrasal chunks correspond to rule right-hand sides. That is, for a rule in the Penn Treebank VP ?? VBG, NP, PP, we are certain (if the annotators have done their job correctly) that the first word in each of the strings corresponding to this right-hand side is a VBG, that is, a present participle. Given this information, in such cases we tag such words w","@endWordPosition":"5032","@position":"31026","annotationId":"T21","@startWordPosition":"5031","@citStr":"Juola (1994"}]},"title":{"#tail":"\n","#text":"A psycholinguistic approach to corpus-based machine translation."},"booktitle":{"#tail":"\n","#text":"In CSNLP 1994: Third International Conference on the Cognitive Science of Natural Language Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Patrick Juola"}}},{"date":{"#tail":"\n","#text":"1997"},"editor":{"#tail":"\n","#text":"In Daniel Jones and Harold Somers, editors,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"nal Linguistics Volume 29, Number 3 2.2 The Marker Lexicons Given that the marker hypothesis is arguably universal, it is clear that benefits may accrue by using it to facilitate subsentential alignment of ?source, target? chunks. Juola (1994, 1997) conducts some small experiments using his METLA system to show the viability of this approach for English ?? French and English ?? Urdu. For the English ?? French language pair, Juola gives results of 61% correct translation when the system is tested on the training corpus, and 36% accuracy when it is evaluated with test data. For English ?? Urdu, Juola (1997, page 213) notes that ?the system learned the original training corpus . . . perfectly and could reproduce it without errors?; that is, it scored 100% accuracy when tested against the training corpus. On novel test sentences, he gives results of 72% correct translation. In their Gaijin system, Veale and Way (1997) give a result of 63% accurate translations obtained for English ?? German on a test set of 791 sentences from CorelDRAW manuals. As in METLA and Gaijin, we exploit lists of known marker words for each language to indicate the start and end of segments. For English, our source langua","@endWordPosition":"3728","@position":"23397","annotationId":"T22","@startWordPosition":"3727","@citStr":"Juola (1997"}},"title":{"#tail":"\n","#text":"Corpus-based acquisition of transfer functions using psycholinguistic principles."},"#tail":"\n","rawString":{"#tail":"\n","#text":"Juola, Patrick. 1997. Corpus-based acquisition of transfer functions using psycholinguistic principles. In Daniel Jones and Harold Somers, editors, New Methods in Language Processing. UCL Press, London, pages 207?218."},"#text":"\n","pages":{"#tail":"\n","#text":"207--218"},"marker":{"#tail":"\n","#text":"Juola, 1997"},"publisher":{"#tail":"\n","#text":"UCL Press,"},"location":{"#tail":"\n","#text":"London,"},"booktitle":{"#tail":"\n","#text":"New Methods in Language Processing."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Patrick Juola"}}},{"volume":{"#tail":"\n","#text":"1"},"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Juola, Patrick. 1998. On psycholinguistic grammars. Grammars, 1(1):15?31."},"journal":{"#tail":"\n","#text":"Grammars,"},"#text":"\n","issue":{"#tail":"\n","#text":"1"},"marker":{"#tail":"\n","#text":"Juola, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"y small. Furthermore, there are four prepositional phrases, and the set of prepositions is similarly small. A further assumption that could be made is that all words that end with -ed are verbs, such as stopped in (5). The marker hypothesis is arguably universal in presuming that concepts and structures like these have similar morphological or structural marking in all languages. The marker hypothesis has been used for a number of different language-related tasks, including ? language learning (Green 1979; Mori and Moeser 1983; Morgan, Meier, and Newport 1989) ? monolingual grammar induction (Juola 1998) ? grammar optimization (Juola 1994) ? insights into universal grammar (Juola 1998) ? machine translation (Juola 1994, 1997; Veale and Way 1997; Gough, Way, and Hearne 2002) With respect to translation, a potential problem in using the marker hypothesis is that some languages do not have marker words such as articles, for instance. Green?s (1979) work showed that artificial languages, both with and without specific marker words, may be learned more accurately and quickly if such psycholinguistic cues exist. The 424 Computational Linguistics Volume 29, Number 3 research of Mori and Moeser (1983","@endWordPosition":"1424","@position":"8921","annotationId":"T23","@startWordPosition":"1423","@citStr":"Juola 1998"},{"#tail":"\n","#text":"showed a similar effect due to case marking on pseudowords in such artificial languages, and Morgan, Meier, and Newport (1989) demonstrated that languages that do not permit pronouns as substitutes for phrases also provide evidence in favor of the marker hypothesis. Juola?s (1994, 1998) work on grammar optimization and induction shows that context-free grammars can be converted to ?marker-normal form.? However, marker-normal form grammars cannot capture the sorts of regularities demonstrated for languages that do not have a oneto-one mapping between a terminal symbol and a word. Nevertheless, Juola (1998, page 23) observes that ?a slightly more general mapping, where two adjacent terminal symbols can be merged into a single lexical item (for example, a word and its case-marking), can capture this sort of result quite handily.? Work using the marker hypothesis for MT adapts this monolingual mapping for pairs of languages: It is reasonably straightforward to map an English determiner-noun sequence onto a Japanese noun?case marker segment, once one has identified the sets of marker tags in the languages to be translated. Following construction of the marker lexicon, the ?source, target? chunks a","@endWordPosition":"1608","@position":"10134","annotationId":"T24","@startWordPosition":"1607","@citStr":"Juola (1998"}]},"title":{"#tail":"\n","#text":"On psycholinguistic grammars."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Patrick Juola"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1992"},"rawString":{"#tail":"\n","#text":"Kaji, Hiroyuki, Takuya Kida, and Yuji Morimoto. 1992. Learning translation templates from bilingual text. In Proceedings of the 15th [sic] International Conference on Computational Linguistics (COLING), pages 672?678, Nantes, France."},"#text":"\n","pages":{"#tail":"\n","#text":"672--678"},"marker":{"#tail":"\n","#text":"Kaji, Kida, Morimoto, 1992"},"location":{"#tail":"\n","#text":"Nantes, France."},"title":{"#tail":"\n","#text":"Learning translation templates from bilingual text."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 15th [sic] International Conference on Computational Linguistics (COLING),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Hiroyuki Kaji"},{"#tail":"\n","#text":"Takuya Kida"},{"#tail":"\n","#text":"Yuji Morimoto"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"Kay, Martin, and Martin Ro?scheisen. 1993. Text-translation alignment. Computational Way and Gough wEBMT Linguistics, 19(1):121?142."},"#text":"\n","marker":{"#tail":"\n","#text":"Kay, Roscheisen, 1993"},"booktitle":{"#tail":"\n","#text":"Text-translation alignment. Computational Way and Gough wEBMT Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Martin Kay"},{"#tail":"\n","#text":"Martin Roscheisen"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Technical Report UCSC-CRL-91-28,"},"date":{"#tail":"\n","#text":"1992"},"institution":{"#tail":"\n","#text":"University of California, Santa Cruz."},"rawString":{"#tail":"\n","#text":"Littlestone, Nick, and Manfred Warmuth. 1992. The weighted majority algorithm. Technical Report UCSC-CRL-91-28, University of California, Santa Cruz."},"#text":"\n","marker":{"#tail":"\n","#text":"Littlestone, Warmuth, 1992"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ut with an associated weight and ranked by the system. We would like to incorporate into our model a procedure whereby translation chunks extracted from the phrasal and marker lexicons are more highly regarded than those constructed by inserting words from the word-level lexicon into generalized marker chunks. That is, we want to allocate a larger portion of the probability space to the phrasal and marker lexicons than to the generalized or wordlevel lexicons. We have yet to import such a constraint into our model, but we plan to do so in the near future using the weighted majority algorithm (Littlestone and Warmuth 1992). 4. Experiments and System Evaluation We report here on a number of experiments using test sets of 200 sentences and 500 noun phrases. Some typical examples from the two test sets are given in (39): (39) Noun phrases: ? the heavy use of management fees last year ? an increase through issues of new shares and convertible bonds ? a space-based defense shield for official acts by the congressman Sentences: ? The bright red one interferes with the genes that are responsible for collecting pollen. ? A more recent novel permitted the new basket product. ? The area with the museums and the charities","@endWordPosition":"7764","@position":"47105","annotationId":"T25","@startWordPosition":"7761","@citStr":"Littlestone and Warmuth 1992"}},"title":{"#tail":"\n","#text":"The weighted majority algorithm."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Nick Littlestone"},{"#tail":"\n","#text":"Manfred Warmuth"}]}},{"volume":{"#tail":"\n","#text":"22"},"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Macklovitch, Elliott. 2000. Two types of translation memory. In Proceedings of the ASLIB Conference on Translating and the Computer, volume 22, London."},"#text":"\n","marker":{"#tail":"\n","#text":"Macklovitch, 2000"},"location":{"#tail":"\n","#text":"London."},"title":{"#tail":"\n","#text":"Two types of translation memory."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the ASLIB Conference on Translating and the Computer,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Elliott Macklovitch"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Macklovitch, Elliott, and Graham Russell. 2000. What?s been forgotten in translation memory. In Envisioning Machine Translation in the Information Future: Proceedings of Fourth Conference of the Association for Machine Translation in the Americas (AMTA-2000), pages 137?146, Cuernavaca, Mexico."},"#text":"\n","pages":{"#tail":"\n","#text":"137--146"},"marker":{"#tail":"\n","#text":"Macklovitch, Russell, 2000"},"location":{"#tail":"\n","#text":"Cuernavaca, Mexico."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"y useful tool in the translator?s armory. TM systems store a set of ?source, target? translation pairs in their databases. If a new input string cannot be found exactly in the translation database, a search is conducted for close (or ?fuzzy?) matches of the input string, and these are retrieved together with their translations for the translator to manipulate into the final, output translation. From this description, it should be clear that TM systems do not translate: Indeed, some researchers consider them to be little more than a search-and-replace engine, albeit a rather sophisticated one (Macklovitch and Russell 2000). We can illustrate this with respect to the TM entries in (1), taken from the Canadian Hansards: (1) a. While most were critical, some contributions were thoughtful and constructive =? La plupart ont formule? des critiques, mais certains ont fait des observations re?fle?chies et constructives. b. Others were plain meanspirited and some contained errors of fact =? D?autres discours comportaient des propos mesquins et me?me des erreurs de fait. ? School of Computing, Dublin 9, Ireland. E-mail: away@computing.dcu.ie ? School of Computing, Dublin 9, Ireland. E-mail: ngough@computing.dcu.ie 422 Co","@endWordPosition":"324","@position":"2106","annotationId":"T26","@startWordPosition":"321","@citStr":"Macklovitch and Russell 2000"}},"title":{"#tail":"\n","#text":"What?s been forgotten in translation memory. In Envisioning Machine Translation in the Information Future:"},"booktitle":{"#tail":"\n","#text":"Proceedings of Fourth Conference of the Association for Machine Translation in the Americas (AMTA-2000),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Elliott Macklovitch"},{"#tail":"\n","#text":"Graham Russell"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"McTait, Kevin, and Arturo Trujillo. 1999. A language-neutral sparse-data algorithm for extracting translation patterns. In Proceedings of the Eighth International Conference on Theoretical and Methodological Issues in Machine Translation, pages 98?108, Chester, England."},"#text":"\n","pages":{"#tail":"\n","#text":"98--108"},"marker":{"#tail":"\n","#text":"McTait, Trujillo, 1999"},"location":{"#tail":"\n","#text":"Chester, England."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"s in (25): (26) ? [V ist], [V is] ? ? [das V], [which V] ? ? [das V was], [which V what] ? ... ? [V ist was Sie], [V is what you] ? ... ? [das ist was V wollten], [which is what V wanted] ? ... Of course, many other researchers also try to extract generalized templates. Kaji, Kida, and Morimoto (1992) identify translationally equivalent phrasal segments and replace such equivalents with variables to generate a set of translation patterns. Watanabe (1993) combines lexical and dependency mappings to form his generalizations. Other similar approaches include those of Cicekli and Gu?venir (1996), McTait and Trujillo (1999), Carl (1999), and Brown (2000), inter alia. In our system, in some cases the smallest chunk obtainable via the marker-based segmentation process may be something like (27): (27) <DET> the good man : le bon homme In such cases, if our system were confronted with a good man, it would not be able to translate such a phrase, assuming this to be missing from the marker lexicon. Accordingly, we convert examples such as (27) into their generalized equivalents, as in (28): (28) <DET> good man : bon homme That is, where Block (2000) substitutes variables for various words in his templates, we replace ","@endWordPosition":"5584","@position":"34119","annotationId":"T27","@startWordPosition":"5581","@citStr":"McTait and Trujillo (1999)"}},"title":{"#tail":"\n","#text":"A language-neutral sparse-data algorithm for extracting translation patterns."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Eighth International Conference on Theoretical and Methodological Issues in Machine Translation,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kevin McTait"},{"#tail":"\n","#text":"Arturo Trujillo"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"Milosavljevic, Maria, Adrian Tulloch, and Robert Dale. 1996. Text generation in a dynamic hypertext environment. In Proceedings of the 19th Australasian Computer Science Conference, pages 417?426, Melbourne, Australia."},"#text":"\n","pages":{"#tail":"\n","#text":"417--426"},"marker":{"#tail":"\n","#text":"Milosavljevic, Tulloch, Dale, 1996"},"location":{"#tail":"\n","#text":"Melbourne, Australia."},"title":{"#tail":"\n","#text":"Text generation in a dynamic hypertext environment."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 19th Australasian Computer Science Conference,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Maria Milosavljevic"},{"#tail":"\n","#text":"Adrian Tulloch"},{"#tail":"\n","#text":"Robert Dale"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1989"},"rawString":{"#tail":"\n","#text":"Morgan, James, Richard Meier, and Elissa Newport. 1989. Facilitating the acquisition of syntax with cross-sentential cues to phrase structure. Journal of Memory and Language, 28:360?374."},"journal":{"#tail":"\n","#text":"Journal of Memory and Language,"},"#text":"\n","pages":{"#tail":"\n","#text":"28--360"},"marker":{"#tail":"\n","#text":"Morgan, Meier, Newport, 1989"},"title":{"#tail":"\n","#text":"Facilitating the acquisition of syntax with cross-sentential cues to phrase structure."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"James Morgan"},{"#tail":"\n","#text":"Richard Meier"},{"#tail":"\n","#text":"Elissa Newport"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1983"},"rawString":{"#tail":"\n","#text":"Mori, Kazuo, and Shannon Moeser. 1983. The role of syntax markers and semantic referents in learning an artificial language. Journal of Verbal Learning and Verbal Behavior, 22:701?718."},"journal":{"#tail":"\n","#text":"Journal of Verbal Learning and Verbal Behavior,"},"#text":"\n","pages":{"#tail":"\n","#text":"22--701"},"marker":{"#tail":"\n","#text":"Mori, Moeser, 1983"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" with a possessive pronoun. The sets of determiners and possessive pronouns are both very small. Furthermore, there are four prepositional phrases, and the set of prepositions is similarly small. A further assumption that could be made is that all words that end with -ed are verbs, such as stopped in (5). The marker hypothesis is arguably universal in presuming that concepts and structures like these have similar morphological or structural marking in all languages. The marker hypothesis has been used for a number of different language-related tasks, including ? language learning (Green 1979; Mori and Moeser 1983; Morgan, Meier, and Newport 1989) ? monolingual grammar induction (Juola 1998) ? grammar optimization (Juola 1994) ? insights into universal grammar (Juola 1998) ? machine translation (Juola 1994, 1997; Veale and Way 1997; Gough, Way, and Hearne 2002) With respect to translation, a potential problem in using the marker hypothesis is that some languages do not have marker words such as articles, for instance. Green?s (1979) work showed that artificial languages, both with and without specific marker words, may be learned more accurately and quickly if such psycholinguistic cues exist. The 424 ","@endWordPosition":"1413","@position":"8842","annotationId":"T28","@startWordPosition":"1410","@citStr":"Mori and Moeser 1983"}},"title":{"#tail":"\n","#text":"The role of syntax markers and semantic referents in learning an artificial language."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kazuo Mori"},{"#tail":"\n","#text":"Shannon Moeser"}]}},{"date":{"#tail":"\n","#text":"1984"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ed within (part of) the same chunk as their subject NPs. However, given that we translate phrases rather than sentences, it is a considerable problem for our approach, yet one that we overcome satisfactorily. In further work, if we were to store the translations of the VPs with their dummy subject NPs in a sentential lexicon and derive all marker lexicons from this database, the problem of subject-verb agreement would be largely overcome. 426 Computational Linguistics Volume 29, Number 3 2. Deriving Translation Resources from Web-Based MT Systems All EBMT systems, from the initial proposal by Nagao (1984) to the recent collection of Carl and Way (2003), are premised on the availability of subsentential alignments derived from the input bitext. There is a wealth of literature on trying to establish subsentential translations from a bilingual corpus.3 Kay and Ro?scheisen (1993) attempt to extract a bilingual dictionary using a hybrid method of sentence and word alignment on the assumption that the ?source, target? words have a similar distribution. Fung and McKeown (1997) attempt to translate technical terms using word relation matrices, although the resource from which such relations are derive","@endWordPosition":"2620","@position":"16290","annotationId":"T29","@startWordPosition":"2619","@citStr":"Nagao (1984)"}},"title":{"#tail":"\n","#text":"A framework of a mechanical translation between Japanese and English by analogy principle."},"#tail":"\n","rawString":{"#tail":"\n","#text":"Nagao, Makoto. 1984. A framework of a mechanical translation between Japanese and English by analogy principle. In Alick Elithorn and Ranan Banerji, editors, Artificial and Human Intelligence. North-Holland, Amsterdam, pages 173?180."},"#text":"\n","pages":{"#tail":"\n","#text":"173--180"},"marker":{"#tail":"\n","#text":"Nagao, 1984"},"publisher":{"#tail":"\n","#text":"North-Holland,"},"location":{"#tail":"\n","#text":"Amsterdam,"},"booktitle":{"#tail":"\n","#text":"In Alick Elithorn and Ranan Banerji, editors, Artificial and Human Intelligence."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Makoto Nagao"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Rayner, Manny, and David Carter. 1997. Hybrid language processing in the spoken language translator. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, pages 107?110, Munich."},"#text":"\n","pages":{"#tail":"\n","#text":"107--110"},"marker":{"#tail":"\n","#text":"Rayner, Carter, 1997"},"location":{"#tail":"\n","#text":"Munich."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"r less widely spoken languages, the relative lack of linguistic tools and resources has forced developers of word alignment tools for such languages to use shallow processing and basic statistical approaches to word linking. Accordingly, they generate lexical correspondences by means of co-occurrence measures and string similarity metrics. More specifically, the notion of the phrasal lexicon (used first by Becker 1975) has been used successfully in a number of areas: ? Learnability (Zernik and Dyer 1987) ? Text generation (Hovy 1988; Milosavljevic, Tulloch, and Dale 1996) ? Speech generation (Rayner and Carter 1997) ? Localization (Scha?ler 1996) More recently, Simard and Langlais (2001) have proposed the exploitation of TMs at a subsentential level, while Carl, Way, and Scha?ler (2002) and Scha?ler, Way, and Carl (2003, pages 108?109) describe how phrasal lexicons might come to occupy a central place in a future hybrid integrated translation environment. This, they suggest, may result in a paradigm shift from TM to EBMT via the phrasal lexicon: Translators are on the whole wary of MT technology, but once subsentential alignment is enabled, translators will become aware of the benefits to be gained from ","@endWordPosition":"2881","@position":"18023","annotationId":"T30","@startWordPosition":"2878","@citStr":"Rayner and Carter 1997"}},"title":{"#tail":"\n","#text":"Hybrid language processing in the spoken language translator."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Manny Rayner"},{"#tail":"\n","#text":"David Carter"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1990"},"rawString":{"#tail":"\n","#text":"Sato, Satoshi, and Makoto Nagao. 1990. Toward memory-based translation. In COLING-90: Papers Presented to the 13th International Conference on Computational Linguistics, pages 247?252, Helsinki."},"#text":"\n","pages":{"#tail":"\n","#text":"247--252"},"marker":{"#tail":"\n","#text":"Sato, Nagao, 1990"},"location":{"#tail":"\n","#text":"Helsinki."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"20 over both knowledge sources. Similarly, if we wish to consider translations produced by all three MT systems, then we add the weights of common translations and divide the weights of all proposed translations by six. When translated phrases have been retrieved for each chunk of the input string, they must then be combined to produce an output string. In order to calculate a ranking for each TL sentence produced, we multiply the weights of each chunk used in its construction. Note that this ensures that greater importance is attributed to longer chunks, as is usual in most EBMT systems (cf. Sato and Nagao 1990; Veale and Way 1997; Carl 1999).7 As an example, consider the translation into French of the house collapsed. Assume the conditional probabilities in (33): 7 Note that approaches that prefer the greatest context to be taken into account are not limited to EBMT. Research in the area of data-oriented parsing (cf. Bod, Scha, and Sima?an, 2003) also shows that unless the corpus is inherently biased, derivations constructed using the smallest number of subtrees have a higher probability than those built with a larger number of smaller subtrees. 436 Computational Linguistics Volume 29, Number 3 (33","@endWordPosition":"7243","@position":"44047","annotationId":"T31","@startWordPosition":"7240","@citStr":"Sato and Nagao 1990"}},"title":{"#tail":"\n","#text":"Toward memory-based translation."},"booktitle":{"#tail":"\n","#text":"In COLING-90: Papers Presented to the 13th International Conference on Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Satoshi Sato"},{"#tail":"\n","#text":"Makoto Nagao"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"Scha?ler, Reinhard. 1996. Machine translation, translation memories and the phrasal lexicon: The localisation perspective. In Proceedings of TKE-96: EAMT Workshop on Machine Translation, pages 21?33, Vienna."},"#text":"\n","pages":{"#tail":"\n","#text":"21--33"},"marker":{"#tail":"\n","#text":"Schaler, 1996"},"location":{"#tail":"\n","#text":"Vienna."},"title":{"#tail":"\n","#text":"Machine translation, translation memories and the phrasal lexicon: The localisation perspective."},"booktitle":{"#tail":"\n","#text":"In Proceedings of TKE-96: EAMT Workshop on Machine Translation,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Reinhard Schaler"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"editor":{"#tail":"\n","#text":"In Michael Carl and Andy Way, editors,"},"rawString":{"#tail":"\n","#text":"Scha?ler, Reinhard, Andy Way, and Michael Carl. 2003. Example-based machine translation in a controlled environment. In Michael Carl and Andy Way, editors, Recent Advances in Example-Based Machine Translation, Kluwer Academic, Dordrecht, the Netherlands, pages 83?114."},"#text":"\n","pages":{"#tail":"\n","#text":"83--114"},"marker":{"#tail":"\n","#text":"Schaler, Way, Carl, 2003"},"title":{"#tail":"\n","#text":"Example-based machine translation in a controlled environment."},"booktitle":{"#tail":"\n","#text":"Recent Advances in Example-Based Machine Translation, Kluwer Academic, Dordrecht, the Netherlands,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Reinhard Schaler"},{"#tail":"\n","#text":"Andy Way"},{"#tail":"\n","#text":"Michael Carl"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Simard, Michel, and Philippe Langlais. 2001. Subsentential exploitation of translation memories. In Machine Translation Summit VIII, pages 335?339, Santiago de Compostela, Spain."},"#text":"\n","pages":{"#tail":"\n","#text":"335--339"},"marker":{"#tail":"\n","#text":"Simard, Langlais, 2001"},"location":{"#tail":"\n","#text":"Santiago de Compostela,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"and resources has forced developers of word alignment tools for such languages to use shallow processing and basic statistical approaches to word linking. Accordingly, they generate lexical correspondences by means of co-occurrence measures and string similarity metrics. More specifically, the notion of the phrasal lexicon (used first by Becker 1975) has been used successfully in a number of areas: ? Learnability (Zernik and Dyer 1987) ? Text generation (Hovy 1988; Milosavljevic, Tulloch, and Dale 1996) ? Speech generation (Rayner and Carter 1997) ? Localization (Scha?ler 1996) More recently, Simard and Langlais (2001) have proposed the exploitation of TMs at a subsentential level, while Carl, Way, and Scha?ler (2002) and Scha?ler, Way, and Carl (2003, pages 108?109) describe how phrasal lexicons might come to occupy a central place in a future hybrid integrated translation environment. This, they suggest, may result in a paradigm shift from TM to EBMT via the phrasal lexicon: Translators are on the whole wary of MT technology, but once subsentential alignment is enabled, translators will become aware of the benefits to be gained from ?source, target? phrasal segments, and from there they suggest that ?it i","@endWordPosition":"2891","@position":"18096","annotationId":"T32","@startWordPosition":"2888","@citStr":"Simard and Langlais (2001)"}},"title":{"#tail":"\n","#text":"Subsentential exploitation of translation memories."},"booktitle":{"#tail":"\n","#text":"In Machine Translation Summit VIII,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Michel Simard"},{"#tail":"\n","#text":"Philippe Langlais"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Somers, Harold. 1998. Further experiments in bilingual text alignment. International Journal of Corpus Linguistics, 3:115?150."},"journal":{"#tail":"\n","#text":"International Journal of Corpus Linguistics,"},"#text":"\n","pages":{"#tail":"\n","#text":"3--115"},"marker":{"#tail":"\n","#text":"Somers, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"d Way (2003), are premised on the availability of subsentential alignments derived from the input bitext. There is a wealth of literature on trying to establish subsentential translations from a bilingual corpus.3 Kay and Ro?scheisen (1993) attempt to extract a bilingual dictionary using a hybrid method of sentence and word alignment on the assumption that the ?source, target? words have a similar distribution. Fung and McKeown (1997) attempt to translate technical terms using word relation matrices, although the resource from which such relations are derived is a pair of nonparallel corpora. Somers (1998) replicates the work of Fung and McKeown with different language pairs using the simpler metric of Levenshtein distance. Boutsis and Piperidis (1998) use a tagged parallel corpus to extract translationally equivalent English-Greek clauses on the basis of word occurrence and co-occurrence probabilities. The respective lengths of the putative alignments in terms of characters is also an important factor. Ahrenberg, Andersson, and Merkel (2002) observe that for less widely spoken languages, the relative lack of linguistic tools and resources has forced developers of word alignment tools for such ","@endWordPosition":"2720","@position":"16939","annotationId":"T33","@startWordPosition":"2719","@citStr":"Somers (1998)"}},"title":{"#tail":"\n","#text":"Further experiments in bilingual text alignment."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Harold Somers"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Somers, Harold, Ian McLean, and Daniel Jones. 1994. Experiments in multilingual example-based generation. In CSNLP 1994: Third International Conference on the Cognitive Science of Natural Language Processing, Dublin."},"#text":"\n","marker":{"#tail":"\n","#text":"Somers, McLean, Jones, 1994"},"location":{"#tail":"\n","#text":"Dublin."},"title":{"#tail":"\n","#text":"Experiments in multilingual example-based generation."},"booktitle":{"#tail":"\n","#text":"In CSNLP 1994: Third International Conference on the Cognitive Science of Natural Language Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Harold Somers"},{"#tail":"\n","#text":"Ian McLean"},{"#tail":"\n","#text":"Daniel Jones"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Veale, Tony, and Andy Way. 1997. Gaijin: A bootstrapping, template-driven approach to example-based machine translation. In International Conference, Recent Advances in Natural Language Processing, pages 239?244, Tzigov Chark, Bulgaria."},"#text":"\n","pages":{"#tail":"\n","#text":"239--244"},"marker":{"#tail":"\n","#text":"Veale, Way, 1997"},"location":{"#tail":"\n","#text":"Tzigov Chark, Bulgaria."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"uld be made is that all words that end with -ed are verbs, such as stopped in (5). The marker hypothesis is arguably universal in presuming that concepts and structures like these have similar morphological or structural marking in all languages. The marker hypothesis has been used for a number of different language-related tasks, including ? language learning (Green 1979; Mori and Moeser 1983; Morgan, Meier, and Newport 1989) ? monolingual grammar induction (Juola 1998) ? grammar optimization (Juola 1994) ? insights into universal grammar (Juola 1998) ? machine translation (Juola 1994, 1997; Veale and Way 1997; Gough, Way, and Hearne 2002) With respect to translation, a potential problem in using the marker hypothesis is that some languages do not have marker words such as articles, for instance. Green?s (1979) work showed that artificial languages, both with and without specific marker words, may be learned more accurately and quickly if such psycholinguistic cues exist. The 424 Computational Linguistics Volume 29, Number 3 research of Mori and Moeser (1983) showed a similar effect due to case marking on pseudowords in such artificial languages, and Morgan, Meier, and Newport (1989) demonstrated t","@endWordPosition":"1446","@position":"9064","annotationId":"T34","@startWordPosition":"1443","@citStr":"Veale and Way 1997"},{"#tail":"\n","#text":" show the viability of this approach for English ?? French and English ?? Urdu. For the English ?? French language pair, Juola gives results of 61% correct translation when the system is tested on the training corpus, and 36% accuracy when it is evaluated with test data. For English ?? Urdu, Juola (1997, page 213) notes that ?the system learned the original training corpus . . . perfectly and could reproduce it without errors?; that is, it scored 100% accuracy when tested against the training corpus. On novel test sentences, he gives results of 72% correct translation. In their Gaijin system, Veale and Way (1997) give a result of 63% accurate translations obtained for English ?? German on a test set of 791 sentences from CorelDRAW manuals. As in METLA and Gaijin, we exploit lists of known marker words for each language to indicate the start and end of segments. For English, our source language, we use the sets of marker words in (13): (13) <DET> {the, a, an, those, these, . . . } <PREP> {in, on, out, with, from, to, under, . . . } <QUANT> {all, some, few, many, . . . } <CONJ> {and, or, . . . } <POSS> {my, your, our,. . . } <PRON> {I, you, he, she, it,. . . } A similar set (14) was produced for French,","@endWordPosition":"3780","@position":"23713","annotationId":"T35","@startWordPosition":"3777","@citStr":"Veale and Way (1997)"},{"#tail":"\n","#text":"e sources. Similarly, if we wish to consider translations produced by all three MT systems, then we add the weights of common translations and divide the weights of all proposed translations by six. When translated phrases have been retrieved for each chunk of the input string, they must then be combined to produce an output string. In order to calculate a ranking for each TL sentence produced, we multiply the weights of each chunk used in its construction. Note that this ensures that greater importance is attributed to longer chunks, as is usual in most EBMT systems (cf. Sato and Nagao 1990; Veale and Way 1997; Carl 1999).7 As an example, consider the translation into French of the house collapsed. Assume the conditional probabilities in (33): 7 Note that approaches that prefer the greatest context to be taken into account are not limited to EBMT. Research in the area of data-oriented parsing (cf. Bod, Scha, and Sima?an, 2003) also shows that unless the corpus is inherently biased, derivations constructed using the smallest number of subtrees have a higher probability than those built with a larger number of smaller subtrees. 436 Computational Linguistics Volume 29, Number 3 (33) a. P(la maison | t","@endWordPosition":"7247","@position":"44067","annotationId":"T36","@startWordPosition":"7244","@citStr":"Veale and Way 1997"}]},"title":{"#tail":"\n","#text":"Gaijin: A bootstrapping, template-driven approach to example-based machine translation."},"booktitle":{"#tail":"\n","#text":"In International Conference, Recent Advances in Natural Language Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Tony Veale"},{"#tail":"\n","#text":"Andy Way"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"Watanabe, Hideo. 1993. A method for extracting translation patterns from translation examples. In Proceedings of the Fifth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI ?93): MT in the Next Generation, pages 292?301, Kyoto, Japan."},"#text":"\n","pages":{"#tail":"\n","#text":"292--301"},"marker":{"#tail":"\n","#text":"Watanabe, 1993"},"location":{"#tail":"\n","#text":"Kyoto, Japan."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" is what you wanted] ? 432 Computational Linguistics Volume 29, Number 3 Using the algorithm described above, the patterns in (26) are derived from the chunks in (25): (26) ? [V ist], [V is] ? ? [das V], [which V] ? ? [das V was], [which V what] ? ... ? [V ist was Sie], [V is what you] ? ... ? [das ist was V wollten], [which is what V wanted] ? ... Of course, many other researchers also try to extract generalized templates. Kaji, Kida, and Morimoto (1992) identify translationally equivalent phrasal segments and replace such equivalents with variables to generate a set of translation patterns. Watanabe (1993) combines lexical and dependency mappings to form his generalizations. Other similar approaches include those of Cicekli and Gu?venir (1996), McTait and Trujillo (1999), Carl (1999), and Brown (2000), inter alia. In our system, in some cases the smallest chunk obtainable via the marker-based segmentation process may be something like (27): (27) <DET> the good man : le bon homme In such cases, if our system were confronted with a good man, it would not be able to translate such a phrase, assuming this to be missing from the marker lexicon. Accordingly, we convert examples such as (27) into thei","@endWordPosition":"5561","@position":"33951","annotationId":"T37","@startWordPosition":"5559","@citStr":"Watanabe (1993)"}},"title":{"#tail":"\n","#text":"A method for extracting translation patterns from translation examples."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Fifth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI ?93): MT in the Next Generation,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Hideo Watanabe"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1987"},"rawString":{"#tail":"\n","#text":"Zernik, Uri, and Michael Dyer. 1987. The self-extending phrasal lexicon. Computational Linguistics, 13(3?4):308?327."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","pages":{"#tail":"\n","#text":"13--3"},"marker":{"#tail":"\n","#text":"Zernik, Dyer, 1987"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ents in terms of characters is also an important factor. Ahrenberg, Andersson, and Merkel (2002) observe that for less widely spoken languages, the relative lack of linguistic tools and resources has forced developers of word alignment tools for such languages to use shallow processing and basic statistical approaches to word linking. Accordingly, they generate lexical correspondences by means of co-occurrence measures and string similarity metrics. More specifically, the notion of the phrasal lexicon (used first by Becker 1975) has been used successfully in a number of areas: ? Learnability (Zernik and Dyer 1987) ? Text generation (Hovy 1988; Milosavljevic, Tulloch, and Dale 1996) ? Speech generation (Rayner and Carter 1997) ? Localization (Scha?ler 1996) More recently, Simard and Langlais (2001) have proposed the exploitation of TMs at a subsentential level, while Carl, Way, and Scha?ler (2002) and Scha?ler, Way, and Carl (2003, pages 108?109) describe how phrasal lexicons might come to occupy a central place in a future hybrid integrated translation environment. This, they suggest, may result in a paradigm shift from TM to EBMT via the phrasal lexicon: Translators are on the whole wary of MT technol","@endWordPosition":"2864","@position":"17909","annotationId":"T38","@startWordPosition":"2861","@citStr":"Zernik and Dyer 1987"}},"title":{"#tail":"\n","#text":"The self-extending phrasal lexicon."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Uri Zernik"},{"#tail":"\n","#text":"Michael Dyer"}]}}]}}]}}
