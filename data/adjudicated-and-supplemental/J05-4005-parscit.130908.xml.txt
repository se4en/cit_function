on is considered a separate process from segmentation (e.g., Chen 2003; Wu and Jiang 2000; Chen and Bai 1998). For instance, Chen (2003) assumes that OOV words are usually two or more characters long and are often segmented into single characters. He then uses different components to detect OOV words of different types in a cascaded manner after the basic word segmentation. We believe that the identification of OOV words should not be treated as a problem separate from word segmentation. We propose a unified approach that solves both problems simultaneously. A previous work along this line is Sproat et al. (1996), which is based on weighted finite-state transducers (FSTs). Our approach is similarly motivated but is based on a different mechanism: linear mixture models. As we shall see, the models provide a more flexible framework for incorporating various kinds of lexical and statistical information. Many types of OOV words that are not covered in Sproat’s system can be dealt with in our system. The linear models we used are originally derived from linear discriminant functions widely used for pattern classification (Duda, Hart, and Stork 2001) and have been recently introduced into NLP tasks by Colli
These methods use metrics that are based on statistical features such as mutual information, term frequency, and their variants. They require a reasonably large training corpus. The new words detected are mostly proper nouns and other relatively frequent words. Unfortunately, new words, under our definition of the term, may not be detected. 534 Gao et al. Chinese Word Segmentation: A Pragmatic Approach Fewer methods have been proposed for an on-line approach, and that is the focus of this article. Some recent advances in on-line NWI explore the use of machine learning approaches. For example, Li et al. (2003) define NWI as a binary classification problem and use support vector machines (SVM) to combine various linguistically motivated features to determine whether a Chinese character sequence is a word. Our method is an extension of that of Li et al. in that NWI is not a stand-alone process in our system but an integral part of word segmentation. We shall show experimentally the benefit of the integration in Section 5.5. 2.3 Standards Adaptation As described earlier, while Chinese words are supposed to be well-defined, unambiguous, and static linguistic entities, we are more concerned with segment
tions. This inspires the development of an adaptive Chinese word segmenter. However, most of the previous segmenters have been developed according to a standard that assumes a single correct segmentation. The only adaptive system, to the best of our knowledge, is the customizable segmenter described in Wu (2003), in which the display of the segmentation output can be customized by users.3 The adaptation method we will describe in Section 6 can be viewed as an improved version in that the adaptation rules (or transformations) are acquired automatically from application data via the TBL method (Gao et al. 2004). Though the use of TBL for Chinese word segmentation is not new (see Palmer [1997]; Hockenmaier and Brew [1998]), none of the previous work is aimed at standards adaptation. 2.4 Evaluation The performance of Chinese word segmenters is generally reported in terms of precision and recall. However, a comparison across systems could be very difficult for two reasons. First, the “correct” segmentation is not clearly defined. It is common that for a given sentence there are multiple plausible word segmentations. As shown in Sproat et al. (1996), the rate of agreement between two human judges is les
ed automatically from application data via the TBL method (Gao et al. 2004). Though the use of TBL for Chinese word segmentation is not new (see Palmer [1997]; Hockenmaier and Brew [1998]), none of the previous work is aimed at standards adaptation. 2.4 Evaluation The performance of Chinese word segmenters is generally reported in terms of precision and recall. However, a comparison across systems could be very difficult for two reasons. First, the “correct” segmentation is not clearly defined. It is common that for a given sentence there are multiple plausible word segmentations. As shown in Sproat et al. (1996), the rate of agreement between two human judges is less than 80%. To deal with this problem, Fung and Wu (1994) suggest a procedure called nk-blind that uses n blind judges’ standards. If we set k = 1, it is sufficient for a segmentation to be considered correct if it agrees with at least one of the n judges. If k = n, all judges must agree. Therefore, nk-blind gives a more representative performance measure by taking into account multiple judges. Similarly, Sproat et al. (1996) also uses multiple human judges. In Section 8.2, we will present our method for cross-system comparison. We do not 
input string in two steps: First, for each type, we use a set of constraints (which are compiled by linguists and are represented as FSAs) to generate only those “most likely” candidates. Second, each of the generated candidates is assigned a class model probability. Class models are defined as generative models that are estimated on their corresponding named entity lists using MLE, together with a backoff smoothing schema, as described in Section 4.1.1. We will describe briefly the constraints and the class models here. The Chinese person-name model is a modified version of that described in Sproat et al. (1996). Other NE models are novel, though they share some similarities with the Chinese person-name model. 5.3.1 Chinese Person Names. There are two main constraints. (1) PN patterns: We assume that a Chinese PN consists of a family name F and a given name G, and is of the pattern F+G. Both F and G are one or two characters long. (2) Family name list: We only consider PN candidates that begin with an F stored in the family name list (which contains 373 entries in our system). Given a PN candidate, which is a character string s, the class model probability P(s|PN) is computed by a character bigram mo
 w*, but the source–channel models are estimated on the ON list. Consider the earlier example. Assuming that w* = LN/ýFj,/Az/lø, where -ý is tagged as an LN, the probability P(s |ON) would be estimated using a word class bigram model as: P(- ý ý Fj, M z l ø |ON) ≈ P(LN/ý Fj,/MA z/l ø |ON) P(-ý |LN) = P(LN |<ON>) P(ýFj, |LN) P(�, j%z |ýFj,) P(lø |�z) P(</ON> |lø) P(-ý |LN), where P(-ý |LN) is the class model probability of -ý given that it is an LN, and <ON> and </ON> are symbols denoting the beginning and the end of an ON, respectively. 5.3.4 Transliterations of Foreign Names. As described in Sproat et al. (1996), FNs are usually transliterated using Chinese character strings whose sequential pronunciation mimics the source language pronunciation of the name. Since FNs can be of any length and their original pronunciation is effectively unlimited, the recognition of such names can be tricky. Fortunately, there are only a few hundred Chinese characters that are particularly common in transliterations. Therefore, an FN candidate would be generated given s if it contains only characters stored in a transliterated name character list (which contains 618 Chinese characters). The probability P(s|FN) is esti
tstrapping Approach and Beyond Our basic solution is the bootstrapping approach described in Gao et al. (2002). It consists of three steps: (1) Initially, we use a greedy word segmenter to annotate the corpus and obtain an initial context model based on the initial annotated corpus; (2) we reannotate the corpus using the obtained models; and (3) we retrain the context 562 Gao et al. Chinese Word Segmentation: A Pragmatic Approach Figure 7 (a) A Chinese OAS -j�-0;h. (b) Two sentences in the training set, which contain the OAS and (c) whose OASs have been replaced with the single tokens <OAS>. (Li et al. 2003). Table 16 Methods of resolving OAs in word segmentation, on the MSR test set. Methods Accuracy FMM 73.1% BMM 71.5% Rule + FMM 90.7% Rule + BMM 91.3% Ours 94.3% model using the reannotated corpus.12 Steps 2 and 3 are iterated until the performance of the system converges. This approach is also named Viterbi iterative training, an approximation of EM training. In the above approach, the quality of the context model depends to a large degree upon the quality of the initial annotated corpus, which is, however, not satisfied due to two problems. First, the greedy segmenter cannot deal with the seg
uent case of a given CAS. ‘ME’ indicates the accuracy of the maximum-entropy classifier. ‘VSM’ indicates the accuracy of the method of using VSM for disambiguation. simply by rules. We reimplemented their method in our experiments and found that 90.7% (or 91.3%) of the OAs in the MSR test set can be resolved. The result is similar to Sun and Zou’s but still not as good as ours. Therefore, we conclude that our method significantly outperforms the rule-based approaches. Another advantage of our method is that it is an unsupervised approach that requires no human annotation. Readers can refer to Li et al. (2003) for more details. To resolve CA, we select 70 high-frequency two-character CASs (e.g., :k fi'L ‘talent’ and :k/fi'L ‘just able’), as shown in Figure 8. For each CAS, we train a binary classifier using sentences that contain the CAS and that have been segmented using the greedy segmenter. Then, for each occurrence of a CAS in the initial segmented training data, the corresponding classifier is used to determine whether the CAS should be segmented. Our experiments show that 95.7% of the CAs can be resolved. Detailed results are shown in Figure 8, where ‘Voting’ indicates the accuracy of the bas
