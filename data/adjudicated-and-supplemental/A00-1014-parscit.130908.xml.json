{"algorithms":{"#text":"\n","@version":"110505","algorithm":{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"note":{"#tail":"\n","#text":"To appear."},"rawString":{"#tail":"\n","#text":"Jennifer Chu-Carroll and Jill S. Nickerson. 2000. Evaluating automatic dialogue strategy adaptation for a spoken dialogue system. In Proceedings of the 1st Conference of the North American Chapter of the Association for Computational Linguistics. To appear."},"#text":"\n","marker":{"#tail":"\n","#text":"Chu-Carroll, Nickerson, 2000"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ys take over task initiative and suggest an alternative item. 5 System Evaluation We conducted two experiments to evaluate MIMIC's automatic adaptation capabilities. We compared MIMIC with two control systems: MIMIC-SI, a system-initiative version of MIMIC in which the system retains both initiatives throughout the dialogue, and MIMIC-MI, a nonadaptive mixed-initiative version of MIMIC that resembles the behavior of many existing dialogue systems. In this section we summarize these experiments and their results. A companion paper describes the evaluation process and results in further detail (Chu-Carroll and Nickerson, 2000). Each experiment involved eight users interacting with MIMIC and MIMIC-SI or MIMIC-MI to perform a set of tasks, each requiring the user to obtain specific movie information. User satisfaction was assessed by asking the subjects to fill out a questionnaire after interacting with each version of the system. Furthermore, a number of performance features, largely based on the PARADISE dialogue evaluation scheme (Walker et al., 1997), were automatically logged, derived, or manually annotated. In addition, we logged the cues automatically detected in each user utterance, as well as the initiative ","@endWordPosition":"4457","@position":"29319","annotationId":"T1","@startWordPosition":"4453","@citStr":"Chu-Carroll and Nickerson, 2000"}},"title":{"#tail":"\n","#text":"Evaluating automatic dialogue strategy adaptation for a spoken dialogue system."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 1st Conference of the North American Chapter of the Association for Computational Linguistics."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Jennifer Chu-Carroll"},{"#tail":"\n","#text":"Jill S Nickerson"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Diane J. Litman, Shimei Pan, and Marilyn A. Walker. 1998. Evaluating response strategies in a web-based spoken dialogue agent. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics, pages 780-786."},"#text":"\n","pages":{"#tail":"\n","#text":"780--786"},"marker":{"#tail":"\n","#text":"Litman, Pan, Walker, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ps 9-11). 3.2.3 Strategy Selection Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction (Whittaker and Stenton, 1988; Walker and Whittaker, 1990; Chu-Carroll and Brown, 1998). Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution. Since task initiative models contribution to domain/problemsolving goals, while dialogue initiative affects the cur5An alternative strategy to step (4) is to perform a database lookup based on the ambiguous query and summarize the results (Litman et al., 1998), which we leave for future work. rent discourse goal, we developed alternative strategies for achieving the goals in Figure 4 based on initiative distribution, as shown in Table 1. The strategies employed when MIMIC has only dialogue initiative are similar to the mixed initiative dialogue strategies employed by many existing spoken dialogue systems (e.g., (Bennacef et at., 1996; Stent et al., 1999)). To instantiate an attribute, MIMIC adopts the InfoSeek dialogue act to solicit the missing information. In contrast, when MIMIC has both initiatives, it plays a more active role by presenting the","@endWordPosition":"3221","@position":"21499","annotationId":"T2","@startWordPosition":"3218","@citStr":"Litman et al., 1998"}},"title":{"#tail":"\n","#text":"Evaluating response strategies in a web-based spoken dialogue agent."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Diane J Litman"},{"#tail":"\n","#text":"Shimei Pan"},{"#tail":"\n","#text":"Marilyn A Walker"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Christine H. Nakatani and Jennifer Chu-Carroll. 2000. Using dialogue representations for concept-to-speech generation. In Proceedings of the ANLP-NAACL Workshop on Conversational Systems."},"#text":"\n","marker":{"#tail":"\n","#text":"Nakatani, Chu-Carroll, 2000"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"r output over the telephone. We used the Bell Labs TTS system (Sproat, 1998), which in addition to converting plain text into speech, accepts text strings annotated to override default pitch height, accent placement, speaking rate, etc.2 3.1 Semantic Interpretation MIMIC utilizes a non-recursive frame-based semantic representation commonly used in spoken dialogue systems (e.g. (Seneff et al., 1991; Lamel, 1998)), which represents an utterance as a set of attribute-value pairs. Figure 2(a) shows the frame-based semantic representation for the utterance &quot;What time is Analyze This playing 2 See (Nakatani and Chu-Carroll, 2000) for how MIMIC's dialoguelevel knowledge is used to override default prosodic assignments for concept-to-speech generation. Question-Type: When Movie: Analyze This Theater: null Town: Montclair (a) Semantic Representation Question-Type: When Movie: mandatory Theater: mandatory Town: optional (b) Task Specification Figure 2: Semantic Representation and Task Specification in Montclair?&quot; MIMIC's semantic representation is constructed by first extracting, for each attribute, a set of keywords from the user utterance. Using a vector-based topic identification process (Salton, 1971; Chu-Carroll and ","@endWordPosition":"1958","@position":"12930","annotationId":"T3","@startWordPosition":"1955","@citStr":"Nakatani and Chu-Carroll, 2000"}},"title":{"#tail":"\n","#text":"Using dialogue representations for concept-to-speech generation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the ANLP-NAACL Workshop on Conversational Systems."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Christine H Nakatani"},{"#tail":"\n","#text":"Jennifer Chu-Carroll"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"Amanda Stent, John Dowding, Jean Mark Gawron, Elizabeth Owen Bratt, and Robert Moore. 1999. The CommandTalk spoken dialogue system. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 183-190."},"#text":"\n","pages":{"#tail":"\n","#text":"183--190"},"marker":{"#tail":"\n","#text":"Stent, Dowding, Gawron, Bratt, Moore, 1999"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"o domain/problemsolving goals, while dialogue initiative affects the cur5An alternative strategy to step (4) is to perform a database lookup based on the ambiguous query and summarize the results (Litman et al., 1998), which we leave for future work. rent discourse goal, we developed alternative strategies for achieving the goals in Figure 4 based on initiative distribution, as shown in Table 1. The strategies employed when MIMIC has only dialogue initiative are similar to the mixed initiative dialogue strategies employed by many existing spoken dialogue systems (e.g., (Bennacef et at., 1996; Stent et al., 1999)). To instantiate an attribute, MIMIC adopts the InfoSeek dialogue act to solicit the missing information. In contrast, when MIMIC has both initiatives, it plays a more active role by presenting the user with additional information comprising valid instantiations of the attribute (GiveOptions). Given an invalid query, MIMIC notifies the user of the failed query and provides an openended prompt when it only has dialogue initiative. When MIMIC has both initiatives, however, in addition to NotifyFailure, it suggests an alternative close to the user's original query and provides a limited prompt. ","@endWordPosition":"3286","@position":"21901","annotationId":"T4","@startWordPosition":"3283","@citStr":"Stent et al., 1999"}},"title":{"#tail":"\n","#text":"The CommandTalk spoken dialogue system."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Amanda Stent"},{"#tail":"\n","#text":"John Dowding"},{"#tail":"\n","#text":"Jean Mark Gawron"},{"#tail":"\n","#text":"Elizabeth Owen Bratt"},{"#tail":"\n","#text":"Robert Moore"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1990"},"rawString":{"#tail":"\n","#text":"Marilyn Walker and Steve Whittaker. 1990. Mixed initiative in dialogue: An investigation into discourse segmentation. In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics, pages 70-78."},"#text":"\n","pages":{"#tail":"\n","#text":"70--78"},"marker":{"#tail":"\n","#text":"Walker, Whittaker, 1990"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"stantiate(ambiguous-attr) Else /* more than one value specified Constrain(ambiguous-attr) Else if InvalidAction detected ProvideNegativeAnswer(SemRep) Else 1* well-formed query */ answer 4-- database-query(SemRep) ProvideAnswer(answer) Figure 4: Goal Selection Algorithm user queries (steps 1-8)5 (van Beek et al., 1993; Raskutti and Zukerman, 1993; Qu and Beale, 1999), and 2) providing answers to well-formed queries (steps 9-11). 3.2.3 Strategy Selection Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction (Whittaker and Stenton, 1988; Walker and Whittaker, 1990; Chu-Carroll and Brown, 1998). Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution. Since task initiative models contribution to domain/problemsolving goals, while dialogue initiative affects the cur5An alternative strategy to step (4) is to perform a database lookup based on the ambiguous query and summarize the results (Litman et al., 1998), which we leave for future work. rent discourse goal, we developed alternative strategies for achieving the goals in Figure 4 based on initiative distribution, as shown in Table 1. T","@endWordPosition":"3158","@position":"21082","annotationId":"T5","@startWordPosition":"3155","@citStr":"Walker and Whittaker, 1990"}},"title":{"#tail":"\n","#text":"Mixed initiative in dialogue: An investigation into discourse segmentation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Marilyn Walker"},{"#tail":"\n","#text":"Steve Whittaker"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Marilyn A. Walker, Diane J. Litman, Candance A. Kamm, and Alicia Abella. 1997. PARADISE: A framework for evaluating spoken dialogue agents. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics, pages 271-280."},"#text":"\n","pages":{"#tail":"\n","#text":"271--280"},"marker":{"#tail":"\n","#text":"Walker, Litman, Kamm, Abella, 1997"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"tems. In this section we summarize these experiments and their results. A companion paper describes the evaluation process and results in further detail (Chu-Carroll and Nickerson, 2000). Each experiment involved eight users interacting with MIMIC and MIMIC-SI or MIMIC-MI to perform a set of tasks, each requiring the user to obtain specific movie information. User satisfaction was assessed by asking the subjects to fill out a questionnaire after interacting with each version of the system. Furthermore, a number of performance features, largely based on the PARADISE dialogue evaluation scheme (Walker et al., 1997), were automatically logged, derived, or manually annotated. In addition, we logged the cues automatically detected in each user utterance, as well as the initiative distribution for each turn and the dialogue acts selected to generate each system response. The features gathered from the dialogue interactions were analyzed along three dimensions: system performance, discourse features (in terms of characteristics of the resulting dialogues, such as the cues detected in user utterances), and initiative distribution. Our results show that MIMIC's adaptation capabilities 1) led to better system p","@endWordPosition":"4524","@position":"29753","annotationId":"T6","@startWordPosition":"4521","@citStr":"Walker et al., 1997"}},"title":{"#tail":"\n","#text":"PARADISE: A framework for evaluating spoken dialogue agents."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Marilyn A Walker"},{"#tail":"\n","#text":"Diane J Litman"},{"#tail":"\n","#text":"Candance A Kamm"},{"#tail":"\n","#text":"Alicia Abella"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1988"},"rawString":{"#tail":"\n","#text":"Steve Whittaker and Phil Stenton. 1988. Cues and control in expert-client dialogues. In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics, pages 123-130."},"#text":"\n","pages":{"#tail":"\n","#text":"123--130"},"marker":{"#tail":"\n","#text":"Whittaker, Stenton, 1988"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"* attribute unspecified */ Instantiate(ambiguous-attr) Else /* more than one value specified Constrain(ambiguous-attr) Else if InvalidAction detected ProvideNegativeAnswer(SemRep) Else 1* well-formed query */ answer 4-- database-query(SemRep) ProvideAnswer(answer) Figure 4: Goal Selection Algorithm user queries (steps 1-8)5 (van Beek et al., 1993; Raskutti and Zukerman, 1993; Qu and Beale, 1999), and 2) providing answers to well-formed queries (steps 9-11). 3.2.3 Strategy Selection Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction (Whittaker and Stenton, 1988; Walker and Whittaker, 1990; Chu-Carroll and Brown, 1998). Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution. Since task initiative models contribution to domain/problemsolving goals, while dialogue initiative affects the cur5An alternative strategy to step (4) is to perform a database lookup based on the ambiguous query and summarize the results (Litman et al., 1998), which we leave for future work. rent discourse goal, we developed alternative strategies for achieving the goals in Figure 4 based on initiative distribu","@endWordPosition":"3154","@position":"21054","annotationId":"T7","@startWordPosition":"3151","@citStr":"Whittaker and Stenton, 1988"}},"title":{"#tail":"\n","#text":"Cues and control in expert-client dialogues."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Steve Whittaker"},{"#tail":"\n","#text":"Phil Stenton"}]}}]}}}}
