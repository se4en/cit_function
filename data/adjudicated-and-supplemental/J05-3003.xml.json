{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","listItem":{"#tail":"\n","@confidence":"0.405069333333333","#text":"\nfrom Penn-II and 221 from Penn-III. Briscoe and Carroll (1997), by comparison, employ\n163 distinct predefined frames.\n6. Evaluation\n"},"figure":[{"#tail":"\n","@confidence":"0.949227272727273","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\nTable 4\nConflation of Penn Treebank tags.\nConflated Category Penn Treebank Category\nJJ JJ\nJJR\nJJS\nN NN\nNNS\nNNP\nNNPS\nPRP\nRB RB\nRBR\nRBS\nV VB\nVBD\nVBG\nVBN\nVBP\nVBZ\nMD\n"},{"#tail":"\n","@confidence":"0.25667975","#text":"\nComputational Linguistics Volume 31, Number 3\nTable 6\nSemantic forms for the verb accept marked with p for passive use.\nSemantic form Occurrences Conditional probability\n"},{"#tail":"\n","@confidence":"0.5864245","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\nTable 8\nNumber of semantic form types for Penn-III.\nWithout prepositions and particles With prepositions and particles\nSemantic form types 15,166 21,005\nActive 11,038 16,000\nPassive 4,128 5,005\nTable 9\nNumber of frame types for verbs for Penn-II.\nWithout prepositions With prepositions\nand particles and particles\nNumber of frame types 38 577\nNumber of singletons 1 243\nNumber occurring twice 1 84\nNumber occurring five or fewer times 7 415\nNumber occurring more than five times 31 162\n"},{"#tail":"\n","@confidence":"0.752105","#text":"\nTable 10\nNumber of frame types for verbs for Penn-III.\nWithout prepositions With prepositions\nand particles and particles\nNumber of frame types 50 1,084\nNumber of singletons 6 544\nNumber occurring twice 2 147\nNumber occurring five or fewer times 12 863\nNumber occurring more than five times 38 221\n"}],"author":[{"#tail":"\n","@confidence":"0.802834","#text":"\nRuth O?Donovan?\n"},{"#tail":"\n","@confidence":"0.875263","#text":"\nMichael Burke??\n"},{"#tail":"\n","@confidence":"0.845169","#text":"\nAoife Cahill?\n"},{"#tail":"\n","@confidence":"0.533455","#text":"\nJosef van Genabith??\n"},{"#tail":"\n","@confidence":"0.968596","#text":"\nAndy Way??\n"}],"equation":[{"#tail":"\n","@confidence":"0.999452","#text":"\nP (ArgList|?) = count(??ArgList?)?n\ni=1 count(??ArgListi?)\n"},{"#tail":"\n","@confidence":"0.99896","#text":"\nP (ArgList|?, v) = count(??ArgList, v?)?n\ni=1 count(??ArgListi, v?)\n"},{"#tail":"\n","@confidence":"0.997326375","#text":"\nrecall =\ntp\ntp + fn\nprecision =\ntp\ntp + fp\nf-score =\n2 ? recall ? precision\n"}],"subsectionHeader":[{"#tail":"\n","@confidence":"0.247274","#text":"\nFeature Precision Recall F-score\n"},{"#tail":"\n","@confidence":"0.965088","#text":"\n6.1 COMLEX\n"},{"#tail":"\n","@confidence":"0.941899","#text":"\n6.2 COMLEX-LFG Mapping I and Penn-II\n"},{"#tail":"\n","@confidence":"0.992581","#text":"\n6.3 COMLEX-LFG Mapping II and Penn-II\n"},{"#tail":"\n","@confidence":"0.975301","#text":"\n6.4 Penn-III (Mapping-II)\n"},{"#tail":"\n","@confidence":"0.978653","#text":"\n6.5 Error Analysis and Discussion\n"}],"subsubsectionHeader":[{"#tail":"\n","@confidence":"0.5155","#text":"\n6.3.1 Directional Prepositions. The recall figures for Experiments 3 and 3a in Table 17\n"},{"#tail":"\n","@confidence":"0.50334","#text":"\n6.3.2 Passive Evaluation. Table 20 presents the results of evaluating the extracted pas-\n"}],"footnote":{"#tail":"\n","@confidence":"0.933273","#text":"\n3 We do not associate syntactic categories with OBLs as they are always PPs.\n"},"construct":[{"#tail":"\n","@confidence":"0.992397307692308","#text":"\nADJUNCT 892/968 = 92 892/950 = 94 93\nCOMP 88/92 = 96 88/102 = 86 91\nCOORD 153/184 = 83 153/167 = 92 87\nDET 265/267 = 99 265/269 = 99 99\nOBJ 442/459 = 96 442/461 = 96 96\nOBL 50/52 = 96 50/61 = 82 88\nOBLAG 12/12 = 100 12/12 = 100 100\nPASSIVE 76/79 = 96 76/80 = 95 96\nRELMOD 46/48 = 96 46/50 = 92 94\nSUBJ 396/412 = 96 396/414 = 96 96\nTOPIC 13/13 = 100 13/13 = 100 100\nTOPICREL 46/49 = 94 46/52 = 88 91\nXCOMP 145/153 = 95 145/146 = 99 97\n"},{"#tail":"\n","@confidence":"0.648707684210526","#text":"\naccept([subj, obj]) 122 0.813\naccept ([subj],p) 9 0.060\naccept([subj, comp]) 5 0.033\naccept([subj, obl:as],p) 3 0.020\naccept([subj, obj, obl:as]) 3 0.020\naccept([subj, obj, obl:from]) 3 0.020\naccept ([subj]) 2 0.013\naccept([subj, obj, obl:at]) 1 0.007\naccept([subj, obj, obl:for]) 1 0.007\naccept([subj, obj, xcomp]) 1 0.007\nTable 7\nSemantic forms for the verb accept including syntactic category for each grammatical function.\nSemantic form Occurrences Conditional probability\naccept([subj(n), obj(n)]) 116 0.773\naccept([subj(n)]) 11 0.073\naccept([subj(n), comp(that)]) 4 0.027\naccept([subj(n), obj(n), obl:from]) 3 0.020\naccept([subj(n), obl:as]) 3 0.020\nOther 13 0.087\n"}],"title":{"#tail":"\n","@confidence":"0.388984333333333","#text":"\nLarge-Scale Induction and Evaluation of\nLexical Resources from the Penn-II and\nPenn-III Treebanks\n"},"@confidence":"0.000000","#tail":"\n","reference":[{"#tail":"\n","@confidence":"0.998080195876288","#text":"\nAdes, Anthony and Mark Steedman. 1982.\nOn the order of words. Linguistics and\nPhilosophy, 4(4):517? 558.\nBoguraev, Branimir, Edward Briscoe,\nJohn Carroll, David Carter, and\nClaire Grover. 1987. The derivation of\na grammatically indexed lexicon from\nthe Longman Dictionary of Contemporary\nEnglish. In Proceedings of the 25th\nAnnual Meeting of the Association of\nComputational Linguistics, pages 193?200,\nStanford, CA.\nBrants, Sabine, Stefanie Dipper, Silvia\nHansen, Wolfgang Lezius, and George\nSmith. 2002. The TIGER Treebank. In\nProceedings of the Workshop on Treebanks\nand Linguistic Theories, Sozopol, Bulgaria.\nBrent, Michael. 1993. From grammar to\nlexicon: Unsupervised learning of lexical\nsyntax. Computational Linguistics,\n19(2):203?222.\nBresnan, Joan. 2001. Lexical-Functional Syntax.\nBlackwell, Oxford.\nBriscoe, Edward. 2001. From dictionary to\ncorpus to self-organizing dictionary:\nLearning valency associations in the face\nof variation and change. In Proceedings of\nCorpus Linguistics 2001, Lancaster, UK.\nBriscoe, Edward and John Carroll. 1997.\nAutomatic extraction of subcategorization\nfrom corpora. In Proceedings of the Fifth\nACL Conference on Applied Natural\nLanguage Processing, pages 356?363,\nWashington, DC.\nBurke, Michael, Aoife Cahill, Ruth\nO?Donovan, Josef van Genabith, and\nAndy Way. 2004a. Evaluation of an\nautomatic annotation algorithm against\nthe PARC 700 Dependency Bank. In\nProceedings of the Ninth International\nConference on LFG, pages 101?121,\nChristchurch, New Zealand.\nBurke, Michael, Aoife Cahill, Ruth\nO?Donovan, Josef van Genabith, and\nAndy Way. 2004b. Treebank-based\nacquisition of wide-coverage, probabilistic\nLFG resources: Project overview, results\nand evaluation. In Proceedings of the\nWorkshop ?Beyond Shallow Analyses?\nFormalisms and Statistical Modelling\nfor Deep Analyses? at the First International\nJoint Conference on Natural Language\nProcessing (IJCNLP-04), Hainan\nIsland, China.\nBurke, Michael, Olivia Lam, Rowena\nChan, Aoife Cahill, Ruth O?Donovan,\nAdams Bodomo, Josef van Genabith,\nand Andy Way. 2004. Treebank-based\nacquisition of a Chinese lexical-functional\ngrammar. In Proceedings of the 18th\nPacific Asia Conference on Language,\nInformation and Computation,\npages 161?172, Tokyo.\nCahill, Aoife, Michael Burke, Ruth\nO?Donovan, Josef van Genabith, and Andy\nWay. 2004. Long-distance dependency\nresolution in automatically acquired\nwide-coverage PCFG-based LFG\napproximations. In Proceedings\nof the 42nd Annual Meeting of the\nAssociation of Computational Linguistics,\npages 320?327, Barcelona.\nCahill, Aoife, Martin Forst, Mairead\nMcCarthy, Ruth O?Donovan, Christian\nRohrer, Josef van Genabith, and Andy\nWay. 2003. Treebank-based multilingual\nunification-grammar development. In\nProceedings of the Workshop on Ideas and\nStrategies for Multilingual Grammar\nDevelopment at the 15th ESS-LLI,\npages 17?24, Vienna.\nCahill, Aoife, Mairead McCarthy,\nMichael Burke, Ruth O?Donovan,\nJosef van Genabith, and Andy Way.\n2004. Evaluating automatic F-structure\nannotation for the Penn-II Treebank.\nJournal of Research on Language and\nComputation, 2(4):523?547.\nCahill, Aoife, Mairead McCarthy, Josef van\nGenabith, and Andy Way. 2002. Parsing\ntext with a PCFG derived from Penn-II\nwith an automatic F-structure annotation\nprocedure. In Proceedings of the Seventh\nInternational Conference on LFG, edited by\nMiriam Butt and Tracy Holloway King.\nCSLI Publications, Stanford, CA,\npages 76?95.\n"},{"#tail":"\n","@confidence":"0.995951420168068","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\nCarroll, Glenn and Mats Rooth. 1998. Valence\ninduction with a head-lexicalised PCFG. In\nProceedings of the Third Conference on\nEmpirical Methods in Natural Language\nProcessing, pages 36?45,\nGranada, Spain.\nCharniak, Eugene. 1996. Tree-bank\ngrammars. In AAAI-96: Proceedings of the\nThirteenth National Conference on Artificial\nIntelligence. MIT Press, Cambridge, MA,\npages 1031?1036.\nChen, John and K. Vijay-Shanker. 2000.\nAutomated extraction of TAGs from the\nPenn Treebank. In Proceedings of the 38th\nAnnual Meeting of the Association of\nComputational Linguistics, pages 65?76,\nHong Kong.\nCollins, Michael. 1997. Three generative\nlexicalised models for statistical parsing. In\nProceedings of the 35th Annual Meeting of the\nAssociation for Computational Linguistics,\npages 16?23, Madrid.\nCrouch, Richard, Ron Kaplan, Tracy King,\nand Stefan Riezler. 2002. A comparison\nof evaluation metrics for a broad coverage\nparser. In Proceedings of Workshop\n?Beyond PARSEVAL? at Third International\nConference on Language Resources and\nEvaluation, Las Palmas, Spain.\nDalrymple, Mary. 2001. Lexical Functional\nGrammar. Volume 34 of Syntax and\nSemantics. Academic Press, New York.\nDowty, David. 1982. Grammatical relations\nand Montague grammar. In Pauline\nJacobson and Geoffrey Pullum, editors,\nThe Nature of Syntactic Representation.\nReidel, Dordrecht, The Netherlands,\npages 79?130.\nDudenredaktion, editor. 2001. DUDEN?Das\nStilworterbuch. [DUDEN?The Style\nDictionary]. Number 2 in Duden in zwo?lf\nBanden [Duden in Twelve Volumes].\nDudenverlag, Mannheim, Germany.\nEckle, Judith. 1999. Linguistic Knowledge for\nAutomatic Lexicon Acquisition from German\nText Corpora. Ph.D. thesis, University of\nStuttgart, Germany.\nFrank, Anette. 2000. Automatic F-structure\nannotation of treebank trees. In Proceedings\nof the Fifth International Conference on LFG,\nBerkeley, CA, edited by Miriam Butt\nand Tracy Holloway King. CSLI,\npages 139?160.\nGrishman, Ralph, Catherine MacLeod, and\nAdam Meyers. 1994. COMLEX syntax:\nBuilding a computational lexicon. In\nProceedings of the 15th International\nConference on Computational Linguistics,\npages 268?272, Kyoto.\nHajic, Jan. 1998. Building a syntactically\nannotated corpus: The Prague\nDependency Treebank. In Issues in Valency\nand Meaning, edited by Eva Hajicova.\nKarolinum, Prague, Czech Republic,\npages 106?132.\nHindle, Donald and Mats Rooth. 1993.\nAmbiguity and lexical relations.\nComputational Linguistics, 19(1):103?120.\nHockenmaier, Julia, Gann Bierner, and Jason\nBaldridge. 2004. Extending the coverage of\na CCG system. Journal of Language and\nComputation, 2(2):165?208.\nHornby, Albert, editor. 1980. Oxford Advanced\nLearner?s Dictionary of Current English.\nOxford University Press, Oxford, UK.\nJoshi, Aravind. 1988. Tree adjoining\ngrammars. In David Dowty, Lauri\nKarttunen, and Arnold Zwicky, editors,\nNatural Language Parsing. Cambridge\nUniversity Press, Cambridge,\npages 206?250.\nKaplan, Ronald and Joan Bresnan. 1982.\nLexical functional grammar: A formal\nsystem for grammatical representation. In\nJoan Bresnan, editor, The Mental\nRepresentation of Grammatical Relations. MIT\nPress, Cambridge, MA, pages 173?281.\nKing, Tracy Holloway, Richard Crouch,\nStefan Riezler, Mary Dalrymple, and\nRonald Kaplan. 2003. The PARC 700\nDependency Bank. In Proceedings of the\nFourth International Workshop on\nLinguistically Interpreted Corpora, Budapest.\nKingsbury, Paul and Martha Palmer. 2002.\nFrom Treebank to PropBank. In Proceedings\nof the Third International Conference on\nLanguage Resources and Evaluation\n(LREC-2002), Las Palmas, Spain.\nKinyon, Alexandra and Carlos Prolo. 2002.\nIdentifying verb arguments and their\nsyntactic function in the Penn Treebank. In\nProceedings of the Third LREC Conference,\npages 1982?1987, Las Palmas, Spain.\nKorhonen, Anna. 2002. Subcategorization\nacquisition. As Technical Report\nUCAM-CL-TR-530, Computer Laboratory,\nUniversity of Cambridge, UK.\nKrotov, Alexander, Mark Hepple, Robert\nGaizauskas, and Yorick Wilks. 1998.\nCompacting the Penn Treebank grammar.\nIn Proceedings of the 36th Annual Meeting of\nthe Association for Computational Linguistics\nand 17th International Conference on\nComputational Linguistics, pages 669?703,\nMontreal.\nLevin, Beth. 1993. English Verb Classes and\nAlternations. University of Chicago Press,\nChicago.\n"},{"#tail":"\n","@confidence":"0.997739495798319","#text":"\nComputational Linguistics Volume 31, Number 3\nMacLeod, Catherine, Ralph Grishman, and\nAdam Meyers. 1994. The Comlex Syntax\nProject: The first year. In Proceedings of the\nARPA Workshop on Human Language\nTechnology, pages 669?703, Princeton.\nMagerman, David. 1994. Natural Language\nParsing as Statistical Pattern Recognition.\nPh.D. thesis, Stanford University,\nStanford, CA.\nMagerman, David. 1995. Statistical decision\ntree models for parsing. In Proceedings of\nthe 33rd Annual Meeting for the Association\nof Computational Linguistics, pages 276?283,\nCambridge, MA.\nManning, Christopher. 1993. Automatic\nacquisition of a large subcategorisation\ndictionary from corpora. In Proceedings of\nthe 31st Annual Meeting of the Association for\nComputational Linguistics, pages 235?242,\nColumbus, OH.\nMarcus, Mitchell, Grace Kim, Mary Ann\nMarcinkiewicz, Robert MacIntyre, Mark\nFerguson, Karen Katz, and Britta\nSchasberger. 1994. The Penn Treebank:\nAnnotating predicate argument structure.\nIn Proceedings of the ARPA Human Language\nTechnology Workshop, Princeton.\nMarinov, Svetoslav and Cecilia Hemming.\n2004. Automatic Extraction of\nSubcategorization Frames from the\nBulgarian Tree Bank. Unpublished\nmanuscript, Graduate School of Language\nTechnology, Go?teborg, Sweden.\nMeyers, Adam, Catherine MacLeod, and\nRalph Grishman. 1996. Standardization of\nthe complement/adjunct distinction.\nIn Proceedings of the Seventh\nEURALEX International Conference,\nGo?teborg, Sweden.\nMiyao, Yusuke, Takashi Ninomiya, and\nJun?ichi Tsujii. 2004. Corpus-oriented\ngrammar development for acquiring a\nhead-driven phrase structure grammar\nfrom the Penn Treebank. In Proceedings of\nthe First International Joint Conference on\nNatural Language Processing (IJCNLP-04),\npages 390?398, Hainan Island, China.\nNakanishi, Hiroko, Yusuke Miyao, and\nJun?ichi Tsujii. 2004. Using inverse\nlexical rules to acquire a wide-coverage\nlexicalized grammar. In Proceedings\nof the Workshop ?Beyond Shallow\nAnalyses?Formalisms and Statistical\nModelling for Deep Analyses? at the First\nInternational Joint Conference on Natural\nLanguage Processing (IJCNLP-04), Hainan\nIsland, China.\nO?Donovan, Ruth, Michael Burke,\nAoife Cahill, Josef van Genabith, and\nAndy Way. 2004. Large-scale induction\nand evaluation of lexical resources from\nthe Penn-II Treebank. In Proceedings\nof the 42nd Annual Meeting of the\nAssociation of Computational Linguistics,\npages 368?375, Barcelona.\nPollard, Carl and Ivan Sag. 1994.\nHead-Driven Phrase Structure Grammar.\nUniversity of Chicago Press, Chicago.\nProctor, Paul, editor. 1978. Longman\nDictionary of Contemporary English.\nLongman, London.\nRoland, Douglas and Daniel Jurafsky.\n1998. How verb subcategorization\nfrequencies are affected by corpus\nchoice. In Proceedings of the 36th\nAnnual Meeting of the Association\nfor Computational Linguistics and\n17th International Conference on\nComputational Linguistics,\npages 1117?1121, Montreal.\nSadler, Louisa, Josef van Genabith,\nand Andy Way. 2000. Automatic\nF-structure annotation from the\nAP Treebank. In Proceedings of the\nFifth International Conference on LFG,\nBerkeley, CA, edited by Miriam\nButt and Tracy Holloway King. CSLI,\npages 226?243.\nSarkar, Anoop and Daniel Zeman. 2000.\nAutomatic extraction of subcategorization\nframes for Czech. In Proceedings of the 19th\nInternational Conference on Computational\nLinguistics, pages 691?697, Saarbru?cken,\nGermany.\nSchulte im Walde, Sabine. 2002a. A\nsubcategorisation lexicon for German\nverbs induced from a lexicalised PCFG. In\nProceedings of the Third LREC Conference,\npages 1351?1357, Las Palmas, Spain.\nSchulte im Walde, Sabine. 2002b. Evaluating\nverb subcategorisation frames learned by a\nGerman statistical grammar against\nmanual definitions in the Duden\nDictionary. In Proceedings of the 10th\nEURALEX International Congress,\npages 187?197, Copenhagen.\nSimov, Kiril, Gergana Popova, and Petya\nOsenova. 2002. HPSG-based syntactic\ntreebank of Bulgarian (BulTreeBank). In\nAndrew Wilson, Paul Rayson, and Tony\nMcEnery, editors, A Rainbow of Corpora:\nCorpus Linguistics and the Languages of the\nWorld. Lincon-Europa, Munich,\npages 135?142.\nUshioda, Akira, David Evans, Ted Gibson,\nand Alex Waibel. 1993. The Automatic\nacquisition of frequencies of verb\nsubcategorization frames from tagged\n"},{"#tail":"\n","@confidence":"0.998661151515151","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\ncorpora. In SIGLEX ACL Workshop on the\nAcquisition of Lexical Knowledge from Text,\npages 95?106, Columbus, OH.\nvan Genabith, Josef, Louisa Sadler, and\nAndy Way. 1999. Data-driven compilation\nof LFG semantic forms. In EACL-99\nWorkshop on Linguistically Interpreted\nCorpora (LINC-99), pages 69?76, Bergen,\nNorway.\nvan Genabith, Josef, Andy Way, and Louisa\nSadler. 1999. Semi-automatic generation of\nF-structures from Treebanks. In\nProceedings of the Fourth International\nConference on Lexical-Functional Grammar,\nManchester, UK. Available at\nhttp://cslipublications.stanford.edu/.\nWauschkuhn, Oliver. 1999. Automatische\nExtraktion von Verbvalenzen aus deutschen\nTextkorpora [Automatic Extraction of Verb\nValence from German Text Corpora]. PhD\nthesis, University of Stuttgart, Germany.\nXia, Fei. 1999. Extracting tree adjoining\ngrammars from bracketed corpora.\nIn Fifth Natural Language Processing\nPacific Rim Symposium (NLPRS-99),\nBeijing, China.\nXue, Nianwen, Fu-Dong Chiou, and Martha\nPalmer. 2002. Building a large-scale\nannotated Chinese corpus. In Proceedings\nof the 19th International Conference on\nComputational Linguistics (COLING 2002),\nTaipei, Taiwan.\n"}],"bodyText":[{"#tail":"\n","@confidence":"0.9981822","#text":"\nWe present a methodology for extracting subcategorization frames based on an automatic\nlexical-functional grammar (LFG) f-structure annotation algorithm for the Penn-II and\nPenn-III Treebanks. We extract syntactic-function-based subcategorization frames (LFG\nsemantic forms) and traditional CFG category-based subcategorization frames as well as\nmixed function/category-based frames, with or without preposition information for obliques\nand particle information for particle verbs. Our approach associates probabilities with frames\nconditional on the lemma, distinguishes between active and passive frames, and fully\nreflects the effects of long-distance dependencies in the source data structures. In contrast\nto many other approaches, ours does not predefine the subcategorization frame types extracted,\nlearning them instead from the source data. Including particles and prepositions, we extract\n21,005 lemma frame types for 4,362 verb lemmas, with a total of 577 frame types and an\naverage of 4.8 frame types per verb. We present a large-scale evaluation of the complete\nset of forms extracted against the full COMLEX resource. To our knowledge, this is\nthe largest and most complete evaluation of subcategorization frames acquired automatically\nfor English.\n"},{"#tail":"\n","@confidence":"0.995253433333333","#text":"\nIn modern syntactic theories (e.g., lexical-functional grammar [LFG] [Kaplan and\nBresnan 1982; Bresnan 2001; Dalrymple 2001], head-driven phrase structure gram-\nmar [HPSG] [Pollard and Sag 1994], tree-adjoining grammar [TAG] [Joshi 1988], and\ncombinatory categorial grammar [CCG] [Ades and Steedman 1982]), the lexicon is\nthe central repository for much morphological, syntactic, and semantic information.\n? National Centre for Language Technology, School of Computing, Dublin City University, Glasnevin,\nDublin 9, Ireland. E-mail: {rodonovan,mburke,acahill,josef,away}@computing.dcu.ie.\n? Centre for Advanced Studies, IBM, Dublin, Ireland.\nSubmission received: 19 March 2004; revised submission received: 18 December 2004; accepted for\npublication: 2 March 2005.\n? 2005 Association for Computational Linguistics\nComputational Linguistics Volume 31, Number 3\nExtensive lexical resources, therefore, are crucial in the construction of wide-coverage\ncomputational systems based on such theories.\nOne important type of lexical information is the subcategorization requirements\nof an entry (i.e., the arguments a predicate must take in order to form a grammatical\nconstruction). Lexicons, including subcategorization details, were traditionally pro-\nduced by hand. However, as the manual construction of lexical resources is time con-\nsuming, error prone, expensive, and rarely ever complete, it is often the case that the\nlimitations of NLP systems based on lexicalized approaches are due to bottlenecks in\nthe lexicon component. In addition, subcategorization requirements may vary across\nlinguistic domain or genre (Carroll and Rooth 1998). Manning (1993) argues that, aside\nfrom missing domain-specific complementation trends, dictionaries produced by hand\nwill tend to lag behind real language use because of their static nature. Given these\nfacts, research on automating acquisition of dictionaries for lexically based NLP sys-\ntems is a particularly important issue.\nAside from the extraction of theory-neutral subcategorization lexicons, there has\nalso been work in the automatic construction of lexical resources which comply\nwith the principles of particular linguistic theories such as LTAG, CCG, and HPSG\n(Chen and Vijay-Shanker 2000; Xia 1999; Hockenmaier, Bierner, and Baldridge 2004;\nNakanishi, Miyao, and Tsujii 2004). In this article we present an approach to auto-\nmating the process of lexical acquisition for LFG (i.e., grammatical-function-based sys-\ntems). However, our approach also generalizes to CFG category-based approaches. In\nLFG, subcategorization requirements are enforced through semantic forms specifying\nwhich grammatical functions are required by a particular predicate. Our approach is\nbased on earlier work on LFG semantic form extraction (van Genabith, Sadler, and\nWay 1999) and recent progress in automatically annotating the Penn-II and Penn-III\nTreebanks with LFG f-structures (Cahill et al 2002; Cahill, McCarthy, et al 2004). Our\ntechnique requires a treebank annotated with LFG functional schemata. In the early\napproach of van Genabith, Sadler, and Way (1999), this was provided by manually\nannotating the rules extracted from the publicly available subset of the AP Treebank to\nautomatically produce corresponding f-structures. If the f-structures are of high qual-\nity, reliable LFG semantic forms can be generated quite simply by recursively reading\noff the subcategorizable grammatical functions for each local PRED value at each level of\nembedding in the f-structures. The work reported in van Genabith, Sadler, and Way\n(1999) was small scale (100 trees) and proof of concept and required considerable\nmanual annotation work. It did not associate frames with probabilities, discriminate\nbetween frames for active and passive constructions, properly reflect the effects of\nlong-distance dependencies (LDDs), or include CFG category information. In this\narticle we show how the extraction process can be scaled to the complete Wall\nStreet Journal (WSJ) section of the Penn-II Treebank, with about one million words\nin 50,000 sentences, based on the automatic LFG f-structure annotation algorithm\ndescribed in Cahill et al (2002) and Cahill, McCarthy, et al (2004). More recently\nwe have extended the extraction approach to the larger, domain-diverse Penn-III\nTreebank. Aside from the parsed WSJ section, this version of the treebank contains\nparses for a subsection of the Brown corpus (almost 385,000 words in 24,000 trees)\ntaken from a variety of text genres.1 In addition to extracting grammatical-function-\n1 For the remainder of this work, when we refer to the Penn-II Treebank, we mean the parse-annotated WSJ,\nand when we refer to the Penn-III Treebank, we mean the parse-annotated WSJ and Brown corpus\ncombined.\n"},{"#tail":"\n","@confidence":"0.996992833333333","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\nbased subcategorization frames, we also include the syntactic categories of the predicate\nand its subcategorized arguments, as well as additional details such as the prepositions\nrequired by obliques and particles accompanying particle verbs. Our method discrim-\ninates between active and passive frames, properly reflects LDDs in the source data\nstructures, assigns conditional probabilities to the semantic forms associated with each\npredicate, and does not predefine the subcategorization frames extracted.\nIn Section 2 of this article, we briefly outline LFG, presenting typical lexical entries\nand the encoding of subcategorization information. Section 3 reviews related work in\nthe area of automatic subcategorization frame extraction. Our methodology and its\nimplementation are presented in Section 4. In Section 5 we present results from the\nextraction process. We evaluate the complete induced lexicon against the COMLEX\nresource (Grishman, MacLeod, and Meyers 1994) and present the results in Section 6.\nTo our knowledge, this is by far the largest and most complete evaluation of subcat-\negorization frames automatically acquired for English. In Section 7, we examine the\ncoverage of our lexicon in regard to unseen data and the rate at which new lexical\nentries are learned. Finally, in Section 8 we conclude and give suggestions for future\nwork.\n"},{"#tail":"\n","@confidence":"0.970022153846154","#text":"\nLexical functional grammar (Kaplan and Bresnan 1982; Bresnan 2001; Dalrymple\n2001) is a member of the family of constraint-based grammars. It posits minimally\ntwo levels of syntactic representation:2 c(onstituent)-structure encodes details of sur-\nface syntactic constituency, whereas f(unctional)-structure expresses abstract syntactic\ninformation about predicate?argument?modifier relations and certain morphosyntactic\nproperties such as tense, aspect, and case. C-structure takes the form of phrase structure\ntrees and is defined in terms of CFG rules and lexical entries. F-structure is pro-\nduced from functional annotations on the nodes of the c-structure and implemented\nin terms of recursive feature structures (attribute?value matrices). This is exemplified\nby the analysis of the string The inquiry soon focused on the judge (wsj 0267 72) using\nthe grammar in Figure 1, which results in the annotated c-structure and f-structure in\nFigure 2.\nThe value of the PRED attribute in an f-structure is a semantic form ??gf1, gf2, . . . ,\ngfn?, where ? is a lemma and gf a grammatical function. The semantic form provides\nan argument list ?gf1,gf2, . . . ,gfn? specifying the governable grammatical functions (or\narguments) required by the predicate to form a grammatical construction. In Figure 1\nthe verb FOCUS requires a subject and an oblique object introduced by the preposition\non: FOCUS?(? SUBJ)(? OBLon)?. The argument list can be empty, as in the PRED value\nfor judge in Figure 1. According to Dalrymple (2001), LFG assumes the following uni-\nversally available inventory of grammatical functions: SUBJ(ect), OBJ(ect), OBJ?, COMP,\nXCOMP, OBL(ique)?, ADJ(unct), XADJ. OBJ? and OBL? represent families of grammatical\nfunctions indexed by their semantic role, represented by the theta subscript. This list\nof grammatical functions is divided into governable (subcategorizable) grammatical\nfunctions (arguments) and nongovernable (nonsubcategorizable) grammatical func-\ntions (modifiers/adjuncts), as summarized in Table 1.\n2 LFGs may also involve morphological and semantic levels of representation.\n"},{"#tail":"\n","@confidence":"0.950264052631579","#text":"\nComputational Linguistics Volume 31, Number 3\nFigure 1\nSample LFG rules and lexical entries.\nA number of languages allow the possibility of object functions in addition to the\nprimary OBJ, such as the second or indirect object in English. Oblique arguments are\nrealized as prepositional phrases in English. COMP, XCOMP, and XADJ are all clausal\nfunctions which differ in the way in which they are controlled. A COMP is a closed\nfunction which contains its own internal SUBJ:\nThe judge thinks [COMP that it will resume].\nXCOMP and XADJ are open functions not requiring an internal SUBJ. The subject is\ninstead specified externally in the matrix phrase:\nThe judge wants [XCOMP to open an inquiry].\nWhile many linguistic theories state subcategorization requirements in terms\nof phrase structure (CFG categories), Dalrymple (2001) questions the viability and\nuniversality of such an approach because of the variety of ways in which grammatical\nfunctions may be realized at the language-specific constituent structure level. LFG\nargues that subcategorization requirements are best stated at the f-structure level,\nin functional rather than phrasal terms. This is because of the assumption that\nabstract grammatical functions are primitive concepts as opposed to derivatives\n"},{"#tail":"\n","@confidence":"0.8184604","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\nFigure 2\nC- and f-structures for Penn Treebank sentence wsj 0267 72, The inquiry soon focused on the judge.\nof phrase structural position. In LFG, the subcategorization requirements of a\nparticular predicate are expressed by its semantic form: FOCUS?(? SUBJ)(? OBLon)? in\n"},{"#tail":"\n","@confidence":"0.990855133333333","#text":"\nThe subcategorization requirements expressed by semantic forms are enforced at\nf-structure level through completeness and coherence well-formedness conditions on\nf-structure (Kaplan and Bresnan 1982):\nAn f-structure is locally complete iff it contains all the governable grammatical\nfunctions that its predicate governs. An f-structure is complete iff it and all its\nsubsidiary f-structures are locally complete. An f-structure is locally coherent iff\nall the governable grammatical functions that it contains are governed by a\nlocal predicate. An f-structure is coherent iff it and all its subsidiary f-structures\nare locally coherent. (page 211)\nConsider again the f-structure in Figure 2. The semantic form associated with\nthe verb focus is FOCUS?(? SUBJ)(? OBLon)?. The f-structure is locally complete, as it\ncontains the SUBJ and an OBL with the preposition on specified by the semantic\nform. The f-structure also satisfies the coherence condition, as it does not contain\nany governable grammatical functions other than the SUBJ and OBL required by the\nlocal PRED.\n"},{"#tail":"\n","@confidence":"0.992441333333333","#text":"\nBecause of the specific form of the LFG lexicon, our extraction approach differs in\ninteresting ways from that of previous lexical extraction experiments. This contrast is\nmade evident in Sections 3 and 4.\n"},{"#tail":"\n","@confidence":"0.999662064516129","#text":"\nThe encoding of verb subcategorization properties is an essential step in the\nconstruction of computational lexicons for tasks such as parsing, generation, and\nmachine translation. Creating such a resource by hand is time consuming and error\nprone, requires considerable linguistic expertise, and is rarely if ever complete. In\naddition, a hand-crafted lexicon cannot be easily adapted to specific domains or\naccount for linguistic change. Accordingly, many researchers have attempted to\nconstruct lexicons automatically, especially for English. In this section, we discuss\napproaches to CFG-based subcategorization frame extraction as well as attempts to\ninduce lexical resources which comply with specific linguistic theories or express\ninformation in terms of more abstract predicate-argument relations. The evaluation of\nthese approaches is discussed in greater detail in Section 6, in which we compare our\nresults with those reported elsewhere in the literature.\nWe will divide more-general approaches to subcategorization frame acquisition\ninto two groups: those which extract information from raw text and those which\nuse preparsed and hand-corrected treebank data as their input. Typically in the\napproaches based on raw text, a number of subcategorization patterns are predefined,\na set of verb subcategorization frame associations are hypothesized from the data,\nand statistical methods are applied to reliably select hypotheses for the final lexicon.\nBrent (1993) relies on morphosyntactic cues in the untagged Brown corpus as indicators\nof six predefined subcategorization frames. The frames do not include details of specific\nprepositions. Brent used hypothesis testing on binomial frequency data to statistically\nfilter the induced frames. Ushioda et al (1993) run a finite-state NP parser on a\nPOS-tagged corpus to calculate the relative frequency of the same six subcategoriza-\ntion verb classes. The experiment is limited by the fact that all prepositional phrases\nare treated as adjuncts. Ushioda et al (1993) employ an additional statistical method\nbased on log-linear models and Bayes? theorem to filter the extra noise introduced by\nthe parser and were the first to induce relative frequencies for the extracted frames.\nManning (1993) attempts to improve on the approach of Brent (1993) by passing raw\ntext through a stochastic tagger and a finite-state parser (which includes a set of\nsimple rules for subcategorization frame recognition) in order to extract verbs and\nthe constituents with which they co-occur. He assumes 19 different subcategorization\n"},{"#tail":"\n","@confidence":"0.999617235294118","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\nframe definitions, and the extracted frames include details of specific prepositions.\nThe extracted frames are noisy as a result of parser errors and so are filtered using\nthe binomial hypothesis theory (BHT), following Brent (1993). Applying his technique\nto approximately four million words of New York Times newswire, Manning acquired\n4,900 verb-subcategorization frame pairs for 3,104 verbs, an average of 1.6 frames\nper verb. Briscoe and Carroll (1997) predefine 163 verbal subcategorization frames,\nobtained by manually merging the classes exemplified in the COMLEX (MacLeod,\nGrishman, and Meyers 1994) and ANLT (Boguraev et al 1987) dictionaries and adding\naround 30 frames found by manual inspection. The frames incorporate control informa-\ntion and details of specific prepositions. Briscoe and Carroll (1997) refine the BHT with a\npriori information about the probabilities of subcategorization frame membership and\nuse it to filter the induced frames. Recent work by Korhonen (2002) on the filtering\nphase of this approach uses linguistic verb classes (based on Levin [1993]) for obtaining\nmore accurate back-off estimates for hypothesis selection. Carroll and Rooth (1998)\nuse a handwritten head-lexicalized, context-free grammar and a text corpus to\ncompute the probability of particular subcategorization patterns. The approach is\niterative with the aim of estimating the distribution of subcategorization frames\nassociated with a particular predicate. They perform a mapping between their frames\nand those of the OALD, resulting in 15 frame types. These do not contain details of\nspecific prepositions.\nMore recently, a number of researchers have applied similar techniques to auto-\nmatically derive lexical resources for languages other than English. Schulte im Walde\n(2002a, 2002b) uses a head-lexicalized probabilistic context-free grammar similar to\nthat of Caroll and Rooth (1998) to extract subcategorization frames from a large\nGerman newspaper corpus from the 1990s. She predefines 38 distinct frame types,\nwhich contain maximally three arguments each and are made up of a combination\nof the following: nominative, dative, and accusative noun phrases; reflexive pro-\nnouns; prepositional phrases; expletive es; subordinated nonfinite clauses; subordinated\nfinite clauses; and copula constructions. The frames may optionally contain details of\nparticular prepositional use. Unsupervised training is performed on a large German\nnewspaper corpus, and the resulting probabilistic grammar establishes the relevance of\ndifferent frame types to a specific lexical head. Because of computing time constraints,\nSchulte im Walde limits sentence length for grammar training and parsing. Sentences\nof length between 5 and 10 words were used to bootstrap the lexicalized grammar\nmodel. For lexicalized training, sentences of length between 5 and 13 words were\nused. The result is a subcategorization lexicon for over 14,000 German verbs. The\nextensive evaluation carried out by Schulte im Walde will be discussed in greater detail\nin Section 6.\nApproaches using treebank-based data as a source for subcategorization infor-\nmation, such as ours, do not predefine the frames to be extracted but rather learn them\nfrom the data. Kinyon and Prolo (2002) describe a simple tool which uses fine-grained\nrules to identify the arguments of verb occurrences in the Penn-II Treebank. This is\nmade possible by manual examination of more than 150 different sequences of syntactic\nand functional tags in the treebank. Each of these sequences was categorized as a\nmodifier or argument. Arguments were then mapped to traditional syntactic functions.\nFor example, the tag sequence NP-SBJ denotes a mandatory argument, and its syntactic\nfunction is subject. In general, argumenthood was preferred over adjuncthoood. As\nKinyon and Prolo (2002) does not include an evaluation, currently it is impossible to\nsay how effective their technique is. Sarkar and Zeman (2000) present an approach to\nlearn previously unknown frames for Czech from the Prague Dependency Bank (Hajic\n"},{"#tail":"\n","@confidence":"0.996905058823529","#text":"\nComputational Linguistics Volume 31, Number 3\n1998). Czech is a language with a freer word order than English and so configurational\ninformation cannot be relied upon. In a dependency tree, the set of all dependents\nof the verb make up a so-called observed frame, whereas a subcategorization frame\ncontains a subset of the dependents in the observed frame. Finding subcategorization\nframes involves filtering adjuncts from the observed frame. This is achieved using three\ndifferent hypothesis tests: BHT, log-likelihood ratio, and t-score. The system learns 137\nsubcategorization frames from 19,126 sentences for 914 verbs (those which occurred\nfive times or more). Marinov and Hemming (2004) present preliminary work on the\nautomatic extraction of subcategorization frames for Bulgarian from the BulTreeBank\n(Simov, Popova, and Osenova 2002). In a similar way to that of Sarkar and Zeman\n(2000), Marinov and Hemming?s system collects both arguments and adjuncts. It then\nuses the binomial log-likelihood ratio to filter incorrect frames. The BulTreebank trees\nare annotated with HPSG-typed feature structure information and thus contain more\ndetail than the dependency trees. The work done for Bulgarian is small-scale, however,\nas Marinov and Hemming are working with a preliminary version of the treebank with\n580 sentences.\nWork has been carried out on the extraction of formalism-specific lexical resources\nfrom the Penn-II Treebank, in particular TAG, CCG, and HPSG. As these formalisms are\nfully lexicalized with an invariant (LTAG and CCG) or limited (HPSG) rule component,\nthe extraction of a lexicon essentially amounts to the creation of a grammar. Chen and\nVijay-Shanker (2000) explore a number of related approaches to the extraction of a\nlexicalized TAG from the Penn-II Treebank with the aim of constructing a statistical\nmodel for parsing. The extraction procedure utilizes a head percolation table as intro-\nduced by Magerman (1995) in combination with a variation of Collins?s (1997) approach\nto the differentiation between complement and adjunct. This results in the construction\nof a set of lexically anchored elementary trees which make up the TAG in question.\nThe number of frame types extracted (i.e., an elementary tree without a specific lexical\nanchor) ranged from 2,366 to 8,996. Xia (1999) also presents a similar method for\nthe extraction of a TAG from the Penn Treebank. The extraction procedure consists\nof three steps: First, the bracketing of the trees in the Penn Treebank is corrected and\nextended based on the approaches of Magerman (1994) and Collins (1997). Then the\nelementary trees are read off in a quite straightforward manner. Finally any invalid\nelementary trees produced as a result of annotation errors in the treebank are filtered out\nusing linguistic heuristics. The number of frame types extracted by Xia (1999) ranged\nfrom 3,014 to 6,099.\nHockenmaier, Bierner, and Baldridge (2004) outline a method for the automatic\nextraction of a large syntactic CCG lexicon from the Penn-II Treebank. For each tree, the\nalgorithm annotates the nodes with CCG categories in a top-down recursive manner.\nThe first step is to label each node as either a head, complement, or adjunct based\non the approaches of Magerman (1994) and Collins (1997). Each node is subsequently\nassigned the relevant category based on its constituent type and surface configuration.\nThe algorithm handles ?like? coordination and exploits the traces used in the treebank\nin order to interpret LDDs. Unlike our approach, those of Xia (1999) and Hockenmaier,\nBierner, and Baldridge (2004) include a substantial initial correction and clean-up of the\nPenn-II trees.\nMiyao, Ninomiya, and Tsujii (2004) and Nakanishi, Miyao, and Tsujii (2004)\ndescribe a methodology for acquiring an English HPSG from the Penn-II Treebank.\nManually defined heuristics are used to automatically annotate each tree in the treebank\nwith partially specified HPSG derivation trees: Head/argument/modifier distinctions\nare made for each node in the tree based on Magerman (1994) and Collins (1997);\n"},{"#tail":"\n","@confidence":"0.994422142857143","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\nthe whole tree is then converted to a binary tree; heuristics are applied to deal with\nphenomena such as LDDs and coordination and to correct some errors in the tree-\nbank, and finally an HPSG category is assigned to each node in the tree in accordance\nwith its CFG category. In the next phase of the process (externalization), HPSG lexical\nentries are automatically extracted from the annotated trees through the application of\n?inverse schemata.?\n"},{"#tail":"\n","@confidence":"0.999353463414634","#text":"\nThe first step in the application of our methodology is the production of a tree-\nbank annotated with LFG f-structure information. F-structures are attribute?value\nstructures which represent abstract syntactic information, approximating to ba-\nsic predicate?argument?modifier structures. Most of the early work on automatic\nf-structure annotation (e.g., van Genabith, Way, and Sadler 1999; Frank 2000; Sadler,\nvan Genabith, and Way 2000) was applied only to small data sets (fewer than 200\nsentences) and was largely proof of concept. However, more recent work (Cahill et al\n2002; Cahill, McCarthy, et al 2004) has presented efforts in evolving and scaling up\nannotation techniques to the Penn-II Treebank (Marcus et al 1994), containing more\nthan 1,000,000 words and 49,000 sentences.\nWe utilize the automatic annotation algorithm of Cahill et al (2002) and Cahill,\nMcCarthy, et al (2004) to derive a version of Penn-II in which each node in each\ntree is annotated with LFG functional annotations in the form of attribute-value struc-\nture equations. The algorithm uses categorial, configurational, local head, and Penn-II\nfunctional and trace information. The annotation procedure is dependent on locating\nthe head daughter, for which an amended version of Magerman (1994) is used. The\nhead is annotated with the LFG equation ?=?. Linguistic generalizations are provided\nover the left (the prefix) and the right (suffix) context of the head for each syntactic\ncategory occurring as the mother nodes of such heads. To give a simple example, the\nrightmost NP to the left of a VP head under an S is likely to be the subject of the sen-\ntence (? SUBJ =?), while the leftmost NP to the right of the V head of a VP is most\nprobably the verb?s object (? OBJ =?). Cahill, McCarthy, et al (2004) provide four\nclasses of annotation principles: one for noncoordinate configurations, one for coor-\ndinate configurations, one for traces (long-distance dependencies), and a final ?catch\nall and clean up? phase.\nThe satisfactory treatment of long-distance dependencies by the annotation algo-\nrithm is imperative for the extraction of accurate semantic forms. The Penn Treebank\nemploys a rich arsenal of traces and empty productions (nodes which do not realize\nany lexical material) to coindex displaced material with the position where it should\nbe interpreted semantically. The algorithm of Cahill, McCarthy, et al (2004) translates\nthe traces into corresponding reentrancies in the f-structure representation by treating\nnull constituents as full nodes and recording the traces in terms of index=i f-structure\nannotations (Figure 3). Passive movement is captured and expressed at f-structure level\nusing a passive:+ annotation. Once a treebank tree is annotated with feature structure\nequations by the annotation algorithm, the equations are collected, and a constraint\nsolver produces an f-structure.\nIn order to ensure the quality of the semantic forms extracted by our method, we\nmust first ensure the quality of the f-structure annotations. The results of two different\nevaluations of the automatically generated f-structures are presented in Table 2. Both\nuse the evaluation software and triple encoding presented in Crouch et al (2002). The\nfirst of these is against the DCU 105, a gold-standard set of 105 hand-coded f-structures\n"},{"#tail":"\n","@confidence":"0.921657733333333","#text":"\nComputational Linguistics Volume 31, Number 3\nFigure 3\nUse of reentrancy between TOPIC and COMP to capture long-distance dependency in Penn\nTreebank sentence wsj 0008 2, Until Congress acts, the government hasn?t any authority to issue new\ndebt obligations of any kind, the Treasury said.\nfrom Section 23 of the Penn Treebank as described in Cahill, McCarthy, et al (2004). For\nthe full set of annotations they achieve precision of over 96.5% and recall of over 96.6%.\nThere is, however, a risk of overfitting when evaluation is limited to a gold standard\nof this size. More recently, Burke, Cahill, et al (2004a) carried out an evaluation of the\nautomatic annotation algorithm against the publicly available PARC 700 Dependency\nBank (King et al 2003), a set of 700 randomly selected sentences from Section 23\nwhich have been parsed, converted to dependency format, and manually corrected\nand extended by human validators. They report precision of over 88.5% and recall of\nover 86% (Table 2). The PARC 700 Dependency Bank differs substantially from both\nthe DCU 105 f-structure bank and the automatically generated f-structures in regard to\n"},{"#tail":"\n","@confidence":"0.9317197","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\nthe style of linguistic analysis, feature nomenclature, and feature geometry. Some, but\nnot all, of these differences are captured by automatic conversion software. A detailed\ndiscussion of the issues inherent in this process and a full analysis of results is presented\nin Burke, Cahill, et al (2004a). Results broken down by grammatical function for the\nDCU 105 evaluation are presented in Table 3. OBL (prepositional phrase) arguments are\ntraditionally difficult to annotate reliably. The results show, however, that with respect\nto obliques, the annotation algorithm, while slightly conservative (recall of 82%), is very\naccurate: 96% of the time it annotates an oblique, the annotation is correct.\nA high-quality set of f-structures having been produced, the semantic form ex-\ntraction methodology is applied. This is based on and substantially extends both the\ngranularity and coverage of an idea in van Genabith, Sadler, and Way (1999):\nFor each f-structure generated, for each level of embedding we determine the local\nPRED value and collect the subcategorisable grammatical functions present at that level\nof embedding. (page 72)\nConsider the automatically generated f-structure in Figure 4 for tree wsj 0003 22\nin the Penn-II and Penn-III Treebanks. It is crucial to note that in the automatically\ngenerated f-structures the value of the PRED feature is a lemma and not a semantic\nform. Exploiting the information contained in the f-structure and applying the\nmethod described above, we recursively extract the following nonempty semantic\nforms: impose([subj, obj, obl:on]), in([obj]), of([obj]), and on([obj]). In effect,\nin both the approach of van Genabith, Sadler, and Way (1999) and our approach,\nsemantic forms are reverse-engineered from automatically generated f-structures\nfor treebank trees. The automatically induced semantic forms contain the following\nsubcategorizable syntactic functions:\nSUBJ OBJ OBJ2 OBLprep OBL2 COMP XCOMP PART\nPART is not a syntactic function in the strict sense, but we decided to capture the\nrelevant co-occurrence patterns of verbs and particles in the semantic forms. Just as\nTable 3\nPrecision and recall on automatically generated f-structures by feature against the DCU 105.\n"},{"#tail":"\n","@confidence":"0.912481888888889","#text":"\nComputational Linguistics Volume 31, Number 3\nFigure 4\nAutomatically generated f-structure and extracted semantic forms for the Penn-II Treebank\nstring wsj 0003 22, In July, the Environmental Protection Agency imposed a gradual ban on virtually\nall uses of asbestos.\nOBLprep includes the prepositional head of the PP, PART includes the actual particle\nwhich occurs, for example, add([subj, obj, part:up]).\nIn the work presented here, we substantially extend and scale the approach of\nvan Genabith, Sadler, and Way (1999) in regard to coverage, granularity, and eval-\nuation. First, we scale the approach to the full WSJ section of the Penn-II Treebank\nand the parsed Brown corpus section of Penn-III, with a combined total of approx-\nimately 75,000 trees. Van Genabith, Sadler, and Way (1999) was proof of concept on\n100 trees. Second, in contrast to the approach of van Genabith, Sadler, and Way (1999)\n(and many other approaches), our approach fully reflects long-distance dependencies,\nindicated in terms of traces in the Penn-II and Penn-III Treebanks and correspond-\ning reentrancies at f-structure. Third, in addition to abstract syntactic-function-\nbased subcategorization frames, we also compute frames for syntactic function?CFG\ncategory pairs, for both the verbal heads and their arguments, and also generate\n"},{"#tail":"\n","@confidence":"0.99386504","#text":"\npure CFG-based subcategorization frames. Fourth, in contrast to the approach of\nvan Genabith, Sadler, and Way (1999) (and many other approaches), our method differ-\nentiates between frames for active and passive constructions. Fifth, in contrast to that of\nvan Genabith, Sadler, and Way (1999), our method associates conditional probabilities\nwith frames. Sixth, we evaluate the complete set of semantic forms extracted (not\njust a selection) against the manually constructed COMLEX (MacLeod, Grishman, and\nMeyers 1994) resource.\nIn order to capture CFG-based categorial information, we add a CAT feature to\nthe f-structures automatically generated from the Penn-II and Penn-III Treebanks. Its\nvalue is the syntactic category of the lexical item whose lemma gives rise to the PRED\nvalue at that particular level of embedding. This makes it possible to classify words\nand their semantic forms based on their syntactic category and reduces the risk of\ninaccurate assignment of subcategorization frame frequencies due to POS ambiguity,\ndistinguishing, for example, between the nominal and verbal occurrences of the lemma\nfight. With this, the output for the verb impose in Figure 4 is impose(v,[subj, obj,\nobl:on]). For some of our experiments, we conflate the different verbal (and other)\ntags used in the Penn Treebanks to a single verbal marker (Table 4). As a further\nextension, the extraction procedure reads off the syntactic category of the head of\neach of the subcategorized syntactic functions: impose(v,[subj(n),obj(n),obl:on]).3\nIn this way, our methodology is able to produce surface syntactic as well as abstract\nfunctional subcategorization details. Dalrymple (2001) argues that there are cases,\nalbeit exceptional ones, in which constraints on syntactic category are an issue in\nsubcategorization. In contrast to much of the work reviewed in Section 3, which limits\nitself to the extraction of surface syntactic subcategorization details, our system can\nprovide this information as well as details of grammatical function.\n"},{"#tail":"\n","@confidence":"0.926437583333333","#text":"\nComputational Linguistics Volume 31, Number 3\nAnother way in which we develop and extend the basic extraction algorithm\nis to deal with passive voice and its effect on subcategorization behavior. Consider\nFigure 5: Not taking into account that the example sentence is a passive construction,\nthe extraction algorithm extracts outlaw([subj]). This is incorrect, as outlaw is a tran-\nsitive verb and therefore requires both a subject and an object to form a gram-\nmatical sentence in the active voice. To cope with this problem, the extraction al-\ngorithm uses the feature-value pair passive:+, which appears in the f-structure at\nthe level of embedding of the verb in question, to mark that predicate as occurring\nin the passive: outlaw([subj],p). The annotation algorithm?s accuracy in recognizing\npassive constructions is reflected by the f-score of 96% reported in Table 3 for the\nPASSIVE feature.\nThe syntactic functions COMP and XCOMP refer to clausal complements with\ndifferent predicate control patterns as described in Section 2. However, as it stands,\nneither of these functions betrays anything about the syntactic nature of the constructs\nin question. Many lexicons, both automatically acquired and manually created, are\nmore fine grained in their approaches to subcategorized clausal arguments, differ-\nentiating, for example, between a that-clause and a to + infinitive clause (Ushioda\net al 1993). With only a slight modification, our system, along with the details\nprovided by the automatically generated f-structures, allows us to extract frames\nwith an equivalent level of detail. For example, to identify a that-clause, we use\nFigure 5\nAutomatically generated f-structure for the Penn-II Treebank string wsj 0003 23. By 1997, almost\nall remaining uses of cancer-causing asbestos will be outlawed.\n"},{"#tail":"\n","@confidence":"0.948474434782609","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\nTable 5\nSemantic forms for the verb accept.\nSemantic form Occurrences Conditional probability\naccept([subj, obj]) 122 0.813\naccept ([subj]) 11 0.073\naccept([subj, comp]) 5 0.033\naccept([subj, obl:as]) 3 0.020\naccept([subj, obj, obl:as]) 3 0.020\naccept([subj, obj, obl:from]) 3 0.020\naccept([subj, obj, obl:at]) 1 0.007\naccept([subj, obj, obl:for]) 1 0.007\naccept([subj, obj, xcomp]) 1 0.007\nthe feature-value pair that:+ at f-structure level to read off the following subcate-\ngorization frame for the verb add: add([subj,comp(that)]). Using the feature-value pair\nto inf:+, we can identify to + infinitive clauses, resulting in the following frame for\nthe verb want: want([subj,xcomp(to inf)]). We can also derive control information about\nopen complements. In Figure 5, the reentrant XCOMP subject is identical to the subject\nof will in the matrix clause, which allows us to induce information about the nature\nof the external control of the XCOMP (i.e., whether it is subject or object control).\nIn order to estimate the likelihood of the co-occurrence of a predicate with a partic-\nular argument list, we compute conditional probabilities for subcategorization frames\nbased on the number of token occurrences in the corpus:\n"},{"#tail":"\n","@confidence":"0.9987633","#text":"\nwhere ArgList1... ArgListn are the possible argument lists which can occur for ?. Be-\ncause of variations in verbal subcategorization across domains, probabilities are also\nuseful for predicting the way in which verbs behave in certain contexts. In Section 6,\nwe use the conditional probabilities to filter possible error judgments by our system.\nTables 5?7 show, with varying levels of analysis, the attested semantic forms for the\nverb accept with their associated conditional probabilities. The effect of differentiating\nbetween the active and passive occurrences of verbs can be seen in the different con-\nditional probabilities associated with the intransitive frame ([subj]) of the verb accept\n(shown in boldface type) in Tables 5 and 6.4 Table 7 shows the joint grammatical-\nfunction/syntactic-category-based subcategorization frames.\n"},{"#tail":"\n","@confidence":"0.851675666666667","#text":"\nWe extract semantic forms for 4,362 verb lemmas from Penn-III. Table 8 shows the\nnumber of distinct semantic form types (i.e., lemma and argument list combination)\n4 Given these, it is possible to condition frames on both lemma (?) and voice (v: active/passive):\n"},{"#tail":"\n","@confidence":"0.998759555555556","#text":"\nextracted. Discriminating obliques by associated preposition and recording particle\ninformation, the algorithm finds a total of 21,005 semantic form types, 16,000 occurring\nin active voice and 5,005 in passive voice. When the obliques are parameterized for\nprepositions and particles are included for particle verbs, we find an average of 4.82\nsemantic form types per verb. Without the inclusion of details for individual preposi-\ntions or particles, there was an average of 3.45 semantic form types per verb. Unlike\nmany of the researchers whose work is reviewed in Section 3, we do not predefine the\nframes extracted by our system. Table 9 shows the numbers of distinct frame types\nextracted from Penn-II, ignoring PRED values.5 We provide two columns of statistics,\none in which all oblique (PP) arguments are condensed into one OBL function and\nall particle arguments are condensed into part, and the other in which we differen-\ntiate among obl:to (e.g., give), obl:on (e.g., rely), obl:for (e.g., compensate), etc., and\nlikewise for particles. Collapsing obliques and particles into simple functions, we extract\n38 frame types. Discriminating particles and obliques by preposition, we extract 577\nframe types. Table 10 shows the same results for Penn-III, with 50 simple frame types\nand 1,084 types when parameterized for prepositions and particles. We also show the\nresult of applying absolute thresholding techniques to the semantic forms induced.\nApplying an absolute threshold of five occurrences, we still generate 162 frame types\n"},{"#tail":"\n","@confidence":"0.817303","#text":"\nsend([subj, obj, obj2])), then that frame [subj, obj, obj2] is counted only once.\n"},{"#tail":"\n","@confidence":"0.9938992","#text":"\nMost of the previous approaches discussed in Section 3 have been evaluated to\ndifferent degrees. In general, a small number of frequently occurring verbs is selected,\nand the subcategorization frames extracted for these verbs (from some quantity of\nunseen test data) are compared to a gold standard. The gold standard is either manually\ncustom-made based on the test data or adapted from an existing external resource\nsuch as the OALD (Hornby 1980) or COMLEX (MacLeod, Grishman, and Meyers\n1994). There are advantages and disadvantages to both types of gold standard. While\nit is time-consuming to manually construct a custom-made standard, the resulting\nstandard has the advantage of containing only the subcategorization frames exhibited\nin the test data. Using an existing externally produced resource is quicker, but the gold\n"},{"#tail":"\n","@confidence":"0.991347595238095","#text":"\nComputational Linguistics Volume 31, Number 3\nstandard may contain many more frames than those which occur in the data from which\nthe test lexicon is induced or, indeed, may omit relevant correct frames contained in\nthe data. As a result, systems generally score better against custom-made, manually\nestablished gold standards.\nCarroll and Rooth (1998) achieve an F-score of 77% against the OALD when they\nevaluate a selection of 100 verbs with absolute frequency of greater than 500 each.\nTheir system recognizes 15 frames, and these do not contain details of subcategorized-\nfor prepositions. Still, to date this is the largest number of verbs used in any of the\nevaluations of the systems for English described in Section 3. Sarkar and Zeman (2000)\nevaluate 914 Czech verbs against a custom-made gold standard and record a token\nrecall of 88%. However, their evaluation does not examine the extracted subcatego-\nrization frames but rather the argument?adjunct distinctions posited by their sys-\ntem. The largest lexical evaluation we know of is that of Schulte im Walde (2002b)\nfor German. She evaluates 3,000 German verbs with a token frequency between\n10 and 2,000 against the Duden (Dudenredaktion 2001). We will refer to this work\nand the methods and results presented by Schulte im Walde again in Sections 6.2\nand 6.3.\nWe carried out a large-scale evaluation of our automatically induced lexicon (2,993\nactive verb lemmas for Penn-II and 3,529 for Penn-III, as well as 1,422 passive verb\nlemmas from Penn-II) against the COMLEX resource. To our knowledge this is the most\nextensive evaluation ever carried out for English lexical extraction. We conducted a\nnumber of experiments on the subcategorization frames extracted from Penn-II and\nPenn-III which are described and discussed in Sections 6.2, 6.3, and 6.4. Finding a\ncommon format for the gold standard and induced lexical entries is a nontrivial task.\nTo ensure that we did not bias the evaluation in favor of either resource, we carried\nout two different mappings for the frames from Penn-II and Penn-III: COMLEX-LFG\nMapping I and COMLEX-LFG Mapping II. For each mapping we carried out six basic\nexperiments (and two additional ones for COMLEX-LFG Mapping II) for the active\nsubcategorization frames extracted. Within each experiment, the following factors were\nvaried: level of prepositional phrase detail, level of particle detail, relative threshold\n(1% or 5%), and incorporation of an expanded set of directional prepositions. Using\nthe second mapping we also evaluated the automatically extracted passive frames and\nexperimented with absolute thresholds. Direct comparison of subcategorization frame\nacquisition systems is difficult because of variations in the number of frames extracted,\nthe number of test verbs, the gold standards used, the size of the test data, and the\nlevel of detail in the subcategorization frames (e.g., whether they are parameterized\nfor specific prepositions). Therefore, in order to establish a baseline against which to\ncompare our results, following Schulte in Walde (2002b), we assigned the two most\nfrequent frame types (transitive and intransitive) by default to each verb and compared\nthis ?artificial? lexicon to the gold standard. The section concludes with a full discussion\nof the reported results.\n"},{"#tail":"\n","@confidence":"0.9980214","#text":"\nWe evaluate our induced semantic forms against COMLEX (MacLeod, Grishman, and\nMeyers 1994), a computational machine-readable lexicon containing syntactic infor-\nmation for approximately 38,000 English headwords. Its creators paid particular\nattention to the encoding of more detailed subcategorization information than is avail-\nable in either the OALD or the LDOCE (Proctor 1978), both for verbs and for nouns\n"},{"#tail":"\n","@confidence":"0.978140142857143","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\nFigure 6\nIntersection between active-verb lemma types in COMLEX and the Penn-II-induced lexicon.\nand adjectives which take complements (Grishman, MacLeod, and Meyers 1994). By\nchoosing to evaluate against COMLEX, we set our sights high: Our extracted semantic\nforms are fine-grained, and COMLEX is considerably more detailed than the OALD\nor LDOCE used for earlier evaluations. While our system can generate semantic forms\nfor any lemma (regardless of part of speech) which induces a PRED value, we have\nthus far evaluated the automatic generation of subcategorization frames for verbs\nonly. COMLEX defines 138 distinct verb frame types without the inclusion of specific\nprepositions or particles.\nAs COMLEX contains information other than subcategorization details, it was\nnecessary for us to extract the subcategorization frames associated with each verbal\nlexicon entry. The following is a sample entry for the verb reimburse:\n"},{"#tail":"\n","@confidence":"0.977676052631579","#text":"\nEach entry is organized as a nested set of typed feature-value lists. The first symbol\n(i.e., VERB) gives the part of speech. The value of the :ORTH feature is the base form\nof the verb. Any entry with irregular morphological behavior will also include the\nfeatures :PLURAL, :PAST, and so on, with the relevant values. All verbs have a :SUBC\nfeature, and for our purposes, this is the most interesting feature. In the case of the\nexample above, the subcategorization values specify that reimburse can occur with two\nobject noun phrases (NP-NP), an object noun phrase followed by a prepositional phrase\nheaded by for (NP-PP :PVAL (?for?)) or just an object noun phrase (NP). (Note that the\ndetails of the subject are not included in COMLEX frames.) What makes the COMLEX\nresource particularly suitable for our evaluation is that each of the complement types\n(NP-NP, NP-PP, and NP) which make up the value of the :SUBC feature is associated with\na formal frame definition which looks like the following:\n(vp-frame np-np :cs ((np 2)(np 3))\n:gs (:subject 1 :obj 2 :obj2 3)\n:ex ?she asked him his name?)\nThe value of the :cs feature is the constituent structure of the subcategorization\nframe, which lists the syntactic CF-PSG constituents in sequence (omitting the sub-\nject, again). The value of the :gs feature is the grammatical structure which indicates\nthe functional role played by each of the CF-PSG constituents. The elements of the\n"},{"#tail":"\n","@confidence":"0.980647333333333","#text":"\nIntersection between active-verb lemma types in COMLEX and the Penn-III-induced lexicon.\nconstituent structure are indexed, and these indices are referenced in the :gs field.\nThe index 1 always refers to the surface subject of the verb. This mapping between\nconstituent structure and functional structure makes the information contained in\nCOMLEX particularly suitable as an evaluation standard for the LFG semantic forms\nwhich we induce.\nWe present the evaluation for the verbs which occur in an active context in the\ntreebank. COMLEX does not provide passive frames. For Penn-II, there are 2,993\nverb lemmas (used actively) that both resources have in common. 2,669 verb lemmas\nappear in COMLEX but not in the induced lexicon, and 416 verb lemmas (used actively)\nappear in the induced lexicon but not in COMLEX (Figure 6). For Penn-III, COMLEX\nand the induced lexicon share 3,529 verb lemmas (used actively). This is shown in\n"},{"#tail":"\n","@confidence":"0.966832052631579","#text":"\nIn order to carry out the evaluation, we have to find a common format for the expression\nof subcategorization information between our induced LFG-style subcategorization\nframes and those contained in COMLEX. The following are the common syntactic\nfunctions: SUBJ, OBJ, OBJi, COMP, and PART. Unlike our system, COMLEX does not\ndistinguish an OBL from an OBJi, so we converted all the obliques in the induced frames\nto OBJi. As in COMLEX, the value of i depends on the number of objects/obliques\nalready present in the semantic form. COMLEX does not differentiate between COMPs\nand XCOMPs as our system does (control information is expressed in a different way:\nsee Section 6.3), so we conflate our two LFG categories to that of COMP. The process is\nsummarized in Table 11.\nThe manually constructed COMLEX entries provide a gold standard against which\nwe evaluate the automatically induced frames. We calculate the number of true pos-\nitives (tps) (where our semantic forms and those from COMLEX are the same), the\nnumber of false negatives ( fns) (those frames which appeared in COMLEX but were not\nproduced by our system), and the number of false positives ( fps) (those frames\n6 Given these figures, one might begin to wonder about the value of automatic induction. First, COMLEX\ndoes not rank frames by probabilities, which are essential in disambiguation. Second, the coverage of\nCOMLEX is not complete: 518 lemmas ?discovered? by the induction experiment are not listed in\nCOMLEX; see the error analysis in Section 6.5.\n"},{"#tail":"\n","@confidence":"0.8078585","#text":"\nproduced by our system which do not appear in COMLEX). We calculate precision,\nrecall, and F-score using the following standard equations:\n"},{"#tail":"\n","@confidence":"0.960038","#text":"\nrecall + precision\nWe use the frequencies associated with each of our semantic forms in order to set\na relative threshold to filter the selection of semantic forms. For a threshold of 1% we\ndisregard any semantic forms with a conditional probability (i.e., given a lemma) of\nless than or equal to 0.01. As some verbs occur less frequently than others, we think it\nis important to use a relative rather than absolute threshold (as in Carroll and Rooth\n[1998], for instance) in this way. We carried out the evaluation in a similar way to\nSchulte im Walde?s (2002b) for German, the only experiment comparable in scale to\nours. Despite the obvious differences in approach and language, this allows us to make\nsome tentative comparisons between our respective results. The statistics shown in\nTable 12 give the results of three different experiments with the relative threshold set\nto 1%. As for all the results tables, the baseline statistics (simply assigning the most\nfrequent frames, in this case transitive and intransitive, to each lemma by default) are\nin each case shown in the left column, and the results achieved by our induced lexicon\nare presented in the right column. Distinguishing between complement and adjunct\nprepositional phrases is a notoriously difficult aspect of automatic subcategorization\nframe acquisition. For this reason, following the evaluation setup in Schulte im Walde\n(2002b), the three experiments vary with respect to the amount of prepositional infor-\nmation contained in the subcategorization frames.\nExperiment 1. Here we excluded subcategorized prepositional-phrase arguments en-\ntirely from the comparison. In a manner similar to that of Schulte im Walde (2002b), any\n"},{"#tail":"\n","@confidence":"0.983692111111111","#text":"\nframes containing an OBL were mapped to the same frame type minus that argument.\nFor example, the frame [subj,obl:for] becomes [subj]. Using a relative threshold of\n1% (Table 12), our results (precision of 75.2%, recall of 69.1%, and F-score of 72.0%)\nare remarkably similar to those of Schulte im Walde (2002b), who reports precision of\n74.53%, recall of 69.74%, and an f-score of 72.05%.\nExperiment 2. Here we include subcategorized prepositional phrase arguments but\nonly in their simplest form; that is, they were not parameterized for particular prepo-\nsitions. For example, the frame [subj,obl:for] is rewritten as [subj,obl]. Using a\nrelative threshold of 1% (Table 12), our results (precision of 65.5%, recall of 63.1%, and\nF-score of 64.3%) compare favorably to those of Schulte im Walde (2002b), who recorded\nprecision of 60.76%, recall of 63.91%, and an F-score of 62.30%.\nExperiment 3. Here we used semantic forms which contain details of specific prepo-\nsitions for any subcategorized prepositional phrase (e.g., [subj,obl:for]). Using a rela-\ntive threshold of 1% (Table 12), our precision figure (71.8%) is quite high (in comparison\nto 65.52% as recorded by Schulte im Walde [2002b]). However our recall (16.8%) is very\nlow (compared to the 50.83% that Schulte im Walde [2002b] reports). Consequently our\nF-score (27.3%) is also low (Schulte im Walde [2002b] records an F-score of 57.24%). The\nreason for this is discussed in Section 6.2.1.\nThe statistics in Table 13 are the result of the second experiment, in which the\nrelative threshold was increased to 5%. The effect of such an increase is obvious in\nthat precision goes up (by as much as 5%) for each of the three evaluations while\nrecall goes down (by as much as 5.5%). This is to be expected, as a greater threshold\nmeans that there are fewer semantic forms associated with each verb in the induced\nlexicon, but they are more likely to be correct because of their greater frequency of\noccurrence. The conditional probabilities we associate with each semantic form together\nwith thresholding can be used to customize the induced lexicon to the task for which\nit is required, that is, whether a very precise lexicon is preferred to one with broader\n"},{"#tail":"\n","@confidence":"0.98733437037037","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\ncoverage. In Tables 12 and 13, the baseline is exceeded in all experiments with the\nexception of Experiment 2. This can be attributed to Mapping I, in which OBLi becomes\nOBJi (Table 11). Experiment 2 includes obliques without the specific preposition, mean-\ning that in this mapping, the frame [subj,obj:with] becomes [subj,obj]. Therefore,\nthe transitive baseline frame scores better than it should against the gold standard. A\nmore fine-grained LFG-COMLEX mapping in which this effect disappears is presented\nin Section 6.3.\n6.2.1 Directional Prepositions. Our recall statistic was particularly low in the case of\nevaluation using details of prepositions (Experiment 3, Tables 12 and 13). This can be\naccounted for by the fact that the creators of COMLEX have chosen to err on the side\nof overgeneration in regard to the list of prepositions which may occur with a verb and\na subcategorization frame containing a prepositional phrase. This is particularly true\nof directional prepositions. For COMLEX, a list of 31 directional prepositions (Table 14)\nwas prepared and assigned in its entirety by default to any verb which can potentially\nappear with any directional preposition in order to save time and avoid the risk of\nmissing prepositions. Grishman, MacLeod, and Meyers (1994) acknowledge that this\ncan lead to a preposition list which is ?a little rich? for a particular verb, but this is\nthe approach they have chosen to take. In a subsequent experiment, we incorporated\nthis list of directional prepositions by default into our semantic form induction process\nin the same way as the creators of COMLEX have done. Table 15 shows that doing\nso results in a significant improvement in the recall statistic (45.1%), as would be\nexpected, with the new statistic being almost three times as good as the result re-\nported in Table 12 for Experiment 3 (16.8%). There is also an improvement in the\nprecision figure (from 71.8% to 86.9%). This is due to a substantial increase in the\nnumber of true positives (from 5,612 to 14,675) compared with a stationary false pos-\nitive figure (2,205 in both cases). The f-score increases from 27.3% to 59.4%.\n"},{"#tail":"\n","@confidence":"0.722536235294118","#text":"\nThe COMLEX-LFG Mapping I presented above establishes a ?least common denomi-\nnator? for the COMLEX and our LFG-inspired resources. More-fine-grained mappings\nare possible: in order to ensure that the mapping from our semantic forms to the\nCOMLEX frames did not oversimplify the information in the automatically extracted\nsubcategorization frames, we conducted a further set of experiments in which we\nconverted the information in the COMLEX entries to the format of our extracted\nsemantic forms. We explicitly differentiated between OBLs and OBJs by automatically\nTable 14\nCOMLEX directional prepositions.\nabout across along around\nbehind below beneath between\nbeyond by down from\nin inside into off\non onto out out of\noutside over past through\nthroughout to toward toward\nup up to via\n"},{"#tail":"\n","@confidence":"0.870263588235294","#text":"\ndeducing whether a COMLEX OBJi was coindexed with an NP or a PP. Furthermore, as\ncan be seen in the following example, COMLEX frame definitions contain details of the\ncontrol patterns of sentential complements, encoded using the :features attribute. This\nallows for automatic discrimination between COMPs and XCOMPs.\n(vp-frame to-inf-sc :cs (vp 2 :mood to-infinitive :subject 1)\n:features (:control subject)\n:gs (:subject 1 :comp 2)\n:ex ?I wanted to come?)\nThe mapping is summarized in Table 16. The results of the subsequent evaluation are\npresented in Tables 17 and 18. We have added Experiments 2a and 3a. These are the\nsame as Experiments 2 and 3, except that they additionally include the specific particle\nwith each PART function. While the recall figures in Tables 17 and 18 are slightly lower\nthan those in Tables 12 and 13, changing the mapping in this way results in an increase\nin precision in each case (by as much as 11.6%). The results of the lexical evaluation\nare consistently better than the baseline, in some cases by almost 16% (Experiment 2,\nthreshold 5%). Notice that in contrast to Tables 12 and 13, in the more-fine-grained\nCOMLEX-LFG Mapping II presented here, all experiments exceed the baseline.\n"},{"#tail":"\n","@confidence":"0.979783833333333","#text":"\n(24.0% and 21.5%) and Table 18 (19.7% and 17.4%) drop in a similar fashion to the results\nseen in Tables 12 and 13. For this reason, we again incorporated the list of 31 directional\nprepositions (Table 14) by default and reran Experiments 3 and 3a for a threshold of\n1%. The results are presented in Table 19. The effect was as expected: The recall scores\nfor the two experiments increased to 40.8% and 35.4% (from 24.0% and 22.5%), and the\nF-scores increased to 54.4% and 49.7% (from 35.9% and 33.0%).\n"},{"#tail":"\n","@confidence":"0.687089","#text":"\nsive semantic forms for 1,422 verb lemmas shared by the induced lexicon and COMLEX.\n"},{"#tail":"\n","@confidence":"0.8903698","#text":"\nWe applied lexical-redundancy rules (Kaplan and Bresnan 1982) to automatically con-\nvert the active COMLEX frames to their passive counterparts: For example, subjects are\ndemoted to optional by oblique agents, and direct objects become subjects. The resulting\nprecision was very high (from 72.3% to 80.2%), and there was the expected drop in recall\nwhen prepositional details were included (from 54.7% to 29.3%).\n"},{"#tail":"\n","@confidence":"0.860433571428571","#text":"\na limited number of verbs for evaluation, based on the verbs? absolute frequency in the\ncorpus. We carried out a similar experiment. Table 21 shows the results of Experiment\n2 for all verbs, for the verb lemmas with an absolute frequency greater than 100, and\nfor verbs with a frequency greater than 200. The use of an absolute threshold results\nin an increase in precision (from 77.1% to 82.3% and 81.7%), an increase in recall (from\n50.4% to 60.8% to 58.7%), and an overall increase in F-score (from 61.0% to 69.9%\nand 68.4%).\n"},{"#tail":"\n","@confidence":"0.995918535714286","#text":"\nRecently we have applied our methodology to the Penn-III Treebank, a more balanced\ncorpus resource with a number of text genres. Penn-III consists of the WSJ section from\nPenn-II as well as a parse-annotated subset of the Brown corpus. The Brown corpus\ncomprises 24,242 trees compiled from a variety of text genres including popular lore,\ngeneral fiction, science fiction, mystery and detective fiction, and humor. It has been\nshown (Roland and Jurafsky 1998) that the subcategorization tendencies of verbs vary\nacross linguistic domains. Our aim, therefore, is to increase the scope of the induced\nlexicon not only in terms of the verb lemmas for which there are entries, but also in\nterms of the frames with which they co-occur. The f-structure annotation algorithm was\nextended with only minor amendments to cover the parsed Brown corpus. The most\nimportant of these was the way in which we distinguish between oblique and adjunct.\nWe noted in Section 4 that our method of assigning an oblique annotation in Penn-II\nwas precise, albeit conservative. Because of a change of annotation policy in Penn-III,\nthe -CLR tag (indicating a close relationship between a PP and the local syntactic head),\ninformation which we had previously exploited, is no longer used. For Penn-III the\nalgorithm annotates all PPs which do not carry a Penn adverbial functional tag (such\nas -TMP or -LOC) and occur as the sisters of the verbal head of a VP as obliques.\nIn addition, the algorithm annotates as obliques PPs associated with -PUT (locative\ncomplements of the verb put) or -DTV (second object in ditransitives) tags.\nWhen evaluating the application of the lexical extraction system on Penn-III, we\ncarried out two sets of experiments, identical in each case to those described for Penn-II\nin Section 6.3, including the use of relative (1% and 5%) rather than absolute thresholds.\nFor the first set of experiments we evaluated the lexicon induced from the parse-\nannotated Brown corpus only. This evaluation was performed for 2,713 active-verb\nlemmas using the more fine-grained Mapping-II. Tables 22 and 23 show that the results\ngenerally exceed the baseline, in some cases by almost 10%, similar to those recorded\nfor Penn-II (Tables 17 and 18). While the precision is slightly lower than that re-\nported for the experiments in Tables 17 and 18, in particular for Experiments 2, 2a, 3,\n"},{"#tail":"\n","@confidence":"0.98956875","#text":"\nand 3a, in which details of obliques are included, the recall in each of these experi-\nments is slightly higher than that recorded for Penn-II. We conjecture that the main\nreason for this is that the amended approach to the annotation of obliques is slightly\nless precise and conservative than the largely -CLR-tag-driven approach taken for\nPenn-II. Consequently we record an increase in recall and a drop in precision. This\ntrend is repeated in the second set of experiments. In this instance, we combined the\nlexicon extracted from the WSJ with that extracted from the parse-annotated Brown\ncorpus, and evaluated the resulting resource for 3,529 active-verb lemmas. The results\nare shown in Tables 24 and 25. The results compare very positively against the baseline.\nThe precision scores are lower (by between 1.5% and 9.7%) than those reported for\nPenn-II (Tables 17 and 18). There has however been a significant increase in recall (up to\n8.7%) and an overall increase in F-score (by up to 4.4%).\n"},{"#tail":"\n","@confidence":"0.9841315","#text":"\nThe work presented in this section highlights a number of issues associated with the\nevaluation of automatically induced subcategorization frames against an existing exter-\nnal gold standard, in this case COMLEX. While this evaluation approach is arguably\nless labor-intensive than the manual construction of a custom-made gold standard,\nit does introduce a number of difficulties into the evaluation procedure. It is a\nnontrivial task to convert both the gold standard and the induced resource to a common\n"},{"#tail":"\n","@confidence":"0.998690181818182","#text":"\nformat in order to facilitate evaluation. In addition, as our results show, the choice\nof common format and mapping to it can affect the results. In COMLEX-LFG Map-\nping I (Section 6.2), we found that mapping from the induced lexicon to COMLEX\nresulted in higher recall scores than those achieved when we (effectively) reversed the\nmapping (COMLEX-LFG Mapping II [Section 6.3]). The first mapping is essentially a\nconflation of our more fine-grained LFG grammatical functions with the more generic\nCOMLEX functions, while the second mapping tries to maintain as many distinctions\nas possible.\nAnother drawback to using an existing external gold standard such as COMLEX\nto evaluate an automatically induced subcategorization lexicon is that the resources\nare not necessarily constructed from the same source data. As noted above, it is well doc-\numented (Roland and Jurafsky 1998) that subcategorization frames (and their frequen-\ncies) vary across domains. We have extracted frames from two sources (the WSJ and the\nBrown corpus), whereas COMLEX was built using examples from the San Jose Mercury\nNews, the Brown corpus, several literary works from the Library of America, scientific\nabstracts from the U.S. Department of Energy, and the WSJ. For this reason, it is likely\nto contain a greater variety of subcategorization frames than our induced lexicon. It is\nalso possible that because of human error, COMLEX contains subcategorization frames\nthe validity of which are in doubt, for example, the overgeneration of subcategorized-for\ndirectional prepositional phrases. This is because the aim of the COMLEX project was to\nconstruct as complete a set of subcategorization frames as possible, even for infrequent\nverbs. Lexicographers were allowed to extrapolate from the citations found, a procedure\n"},{"#tail":"\n","@confidence":"0.983165088235295","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\nwhich is bound to be less certain than the assignment of frames based entirely on exist-\ning examples. As a generalization, Briscoe (2001) notes that lexicons such as COMLEX\ntend to demonstrate high precision but low recall. Briscoe and Carroll (1997) report\non manually analyzing an open-class vocabulary of 35,000 head words for predicate\nsubcategorization information and comparing the results against the subcategorization\ndetails in COMLEX. Precision was quite high (95%), but recall was low (84%). This has\nan effect on both the precision and recall scores of our system against COMLEX. In order\nto ascertain the effect of using COMLEX as a gold standard for our induced lexicon,\nwe carried out some more-detailed error analysis, the results of which are summarized\nin Table 26. We randomly selected 80 false negatives (fn) and 80 false positives (fp)\nacross a range of active frame types containing prepositional and particle detail taken\nfrom Penn-III and manually examined them in order to classify them as ?correct? or\n?incorrect.? Of the 80 fps, 33 were manually judged to be legitimate subcategorization\nframes. For example, as Table 26 shows, there are a number of correct transitive verbs\n([subj,obj]) in our automatically induced lexicon which are not included in COMLEX.\nThis examination was also useful in highlighting to us the frame types on which\nthe lexical extraction procedure was performing poorly, in our case, those containing\nXCOMPs and those containing OBJ2S. Out of 80 fns, 14 were judged to be incorrect when\nmanually examined. These can be broken down as follows: one intransitive frame, three\nditransitive frames, three frames containing a COMP, and seven frames containing an\noblique were found to be invalid.\n7. Lexical Accession Rates\nIn addition to evaluating the quality of our extracted semantic forms, we also examined\nthe rate at which they are induced. This can be expressed as a measure of the coverage\nof the induced lexicon on new data. Following Hockenmaier, Bierner, and Baldridge\n(2002), Xia (1999), and Miyao, Ninomiya, and Tsujii (2004), we extract a reference\nlexicon from Sections 02?21 of the WSJ. We then compare this to a test lexicon from\nSection 23. Table 27 shows the results of the evaluation of the coverage of an induced\nlexicon for verbs only. There is a corresponding semantic form in the reference lexicon\nfor 89.89% of the verbs in Section 23. 10.11% of the entries in the test lexicon did not\nappear in the reference lexicon. Within this group, we can distinguish between known\nwords, which have an entry in the reference lexicon, and unknown words, which do\nnot exist at all in the reference lexicon. In the same way we make the distinction\n"},{"#tail":"\n","@confidence":"0.9857736","#text":"\nbetween known frames and unknown frames. There are, therefore, four different cases\nin which an entry may not appear in the reference lexicon. Table 27 shows that the\nmost common case is that of known verbs occurring with a different, although known,\nsubcategorization frame (7.85%).\nThe rate of accession may also be represented graphically. In Charniak (1996) and\nKrotov et al (1998), it was observed that treebank grammars (CFGs extracted from\ntreebanks) are very large and grow with the size of the treebank. We were interested in\ndiscovering whether the acquisition of lexical material from the same data displayed a\nsimilar propensity. Figure 8 graphs the rate of induction of semantic form and CFG rule\ntypes from Penn-III (the WSJ and parse-annotated Brown corpus combined). Because\nof the variation in the size of sections between the Brown and the WSJ, we plotted\naccession against word count. The first part of the graph (up to 1,004,414 words)\nFigure 8\nComparison of accession rates for semantic form and CFG rule types for Penn-III (nonempty\nframes) (WSJ followed by Brown).\n"},{"#tail":"\n","@confidence":"0.992572178571429","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\nrepresents the rate of accession from the WSJ, and the final 384,646 words are those\nof the Brown corpus. The seven curves represent the following: The acquisition of\nsemantic form types (nonempty) for all syntactic categories with and without specific\npreposition and particle information, the acquisition of semantic form types (non-\nempty) for all verbs with and without specific preposition and particle information,\nthe number of lemmas associated with the extract semantic forms, and the acqui-\nsition of CFG rule types. The curve representing the growth in the overall size of\nthe lexicon is similar in shape to that of the PCFG, while the rate of increase in\nthe number of verbal semantic forms (particularly when obliques and particles are\nexcluded) appears to slow more quickly. Figure 8 shows the effect of domain di-\nversity from the Brown section in terms of increased growth rates for 1e+06 words\nupward. Figure 9 depicts the same information, this time extracted from the Brown\nsection first followed by the WSJ. The curves are different, but similar trends are\nrepresented. This time the effects of domain diversity for the Brown section are\ndiscernible by comparing the absolute accession rate for the 0.4e+06 mark between\nFigures 8 and 9.\nFigure 10 shows the result when we abstract away from semantic forms (verb\nframe combinations) to subcategorization frames and plot their rate of acces-\nsion. The graph represents the growth rate of frame types for Penn-III (WSJ fol-\nlowed by Brown and Brown followed by WSJ). The curve rises sharply initially\nbut gradually levels, practically flattening out, despite the increase in the number\nof words. This reflects the information about Section 23 in Table 27, where we demon-\nstrate that although new verb frame combinations occur, all of the frame types in\nSection 23 have been seen by the lexical extraction program in previous sections.\nFigure 9\nComparison of accession rates for semantic form and CFG rule types for Penn-III (nonempty\nframes) (Brown followed by WSJ).\n"},{"#tail":"\n","@confidence":"0.7356905","#text":"\nComputational Linguistics Volume 31, Number 3\nFigure 10\nAccession rates for frame types (without prepositions and particles) for Penn-III.\nFigure 11 shows that including information about prepositions and particles in the\nframes results in an accession rate which continues to grow, albeit ever more slowly,\nwith the increase in size of the extraction data. This emphasizes the advantage of our\napproach, which extracts frames containing such information without the limitation\nof predefinition.\nFigure 11\nAccession rates for frame types for Penn-III.\n"},{"#tail":"\n","@confidence":"0.99480864","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\n8. Conclusions and Further Work\nWe have presented an algorithm for the extraction of semantic forms (or subcatego-\nrization frames) from the Penn-II and Penn-III Treebanks, automatically annotated with\nLFG f-structures. In contrast to many other approaches, ours does not predefine the sub-\ncategorization frames we extract. We have applied the algorithm to the WSJ sections of\nPenn-II (50,000 trees) (O?Donovan et al 2004) and to the parse-annotated Brown corpus\nof Penn-III (almost 25,000 additional trees). We extract syntactic-function-based subcat-\negorization frames (LFG semantic forms) and traditional CFG category-based frames, as\nwell as mixed-function-category-based frames. Unlike many other approaches to sub-\ncategorization frame extraction, our system properly reflects the effects of long-distance\ndependencies. Also unlike many approaches, our method distinguishes between active\nand passive frames. Finally, our system associates conditional probabilities with the\nframes we extract. Making the distinction between the behavior of verbs in active and\npassive contexts is particularly important for the accurate assignment of probabilities\nto semantic forms. We carried out an extensive evaluation of the complete induced\nlexicon against the full COMLEX resource. To our knowledge, this is the most extensive\nqualitative evaluation of subcategorization extraction in English. The only evaluation of\na similar scale is that carried out by Schulte im Walde (2002b) for German. The results\nreported here for Penn-II compare favorably against the baseline and, in fact, are an\nimprovement on those reported in O?Donovan et al (2004). The results for the larger,\nmore domain-diverse Penn-III lexicon are very encouraging, in some cases almost 15%\nabove the baseline. We believe our semantic forms are fine-grained, and by choosing\nto evaluate against COMLEX, we set our sights high: COMLEX is considerably more\ndetailed than the OALD or LDOCE used for other earlier evaluations. Our error analysis\nalso revealed some interesting issues associated with using an external standard such as\nCOMLEX. In the future, we hope to evaluate the automatic annotations and extracted\nlexicon against Propbank (Kingsbury and Palmer 2002).\nApart from the related approach of Miyao, Ninomiya, and Tsujii (2004), which\ndoes not distinguish between argument and adjunct prepositional phrases, our\ntreebank and automatic f-structure annotation-based architecture for the automatic\nacquisition of detailed subcategorization frames is quite unlike any of the architec-\ntures presented in the literature. Subcategorization frames are reverse-engineered and\nalmost a byproduct of the automatic f-structure annotation algorithm. It is important\nto realize that the induction of lexical resources is part of a larger project on the\nacquisition of wide-coverage, robust, probabilistic, deep unification grammar resources\nfrom treebanks Burke, Cahill, et al (2004b). We are already using the extracted seman-\ntic forms in parsing new text with robust, wide-coverage probabilistic LFG grammar\napproximations automatically acquired from the f-structure-annotated Penn-II tree-\nbank, specifically in the resolution of LDDs, as described in Cahill, Burke, et al (2004).\nWe hope to be able to apply our lexical acquisition methodology beyond existing\nparse-annotated corpora (Penn-II and Penn-III): New text is parsed by our probabilistic\nLFG approximations into f-structures from which we can then extract further seman-\ntic forms. The work reported here is part of the core components for bootstrapping\nthis approach.\nIn the shorter term, we intend to make the extracted subcategorization lexicons from\nPenn-II and Penn-III available as a downloadable public-domain research resource.\nWe have also applied our more general unification grammar acquisition meth-\nodology to the TIGER Treebank (Brants et al 2002) and Penn Chinese Treebank\n(Xue, Chiou, and Palmer 2002), extracting wide-coverage, probabilistic LFG grammar\n"},{"#tail":"\n","@confidence":"0.97733275","#text":"\nComputational Linguistics Volume 31, Number 3\napproximations and lexical resources for German (Cahill et al 2003) and Chinese\n(Burke, Lam, et al 2004). The lexical resources, however, have not yet been evaluated.\nThis, and much else, has to await further research.\n"},{"#tail":"\n","@confidence":"0.99522025","#text":"\nThe research reported here is partially\nsupported by Enterprise Ireland Basic\nResearch Grant SC/2001/186, an IRCSET\nPhD fellowship award, and an IBM PhD\nfellowship award. We are particularly\ngrateful to our anonymous reviewers, whose\ninsightful comments have helped to improve\nthis article considerably.\n"}],"#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.931302","#text":"\nDublin City University\n"},{"#tail":"\n","@confidence":"0.959814","#text":"\nDublin City University\n"},{"#tail":"\n","@confidence":"0.958798","#text":"\nDublin City University\n"},{"#tail":"\n","@confidence":"0.894377","#text":"\nDublin City University\n"},{"#tail":"\n","@confidence":"0.971124","#text":"\nDublin City University\n"},{"#tail":"\n","@confidence":"0.191801","#text":"\nComputational Linguistics Volume 31, Number 3\n"}],"sectionHeader":[{"#tail":"\n","@confidence":"0.992046","@genericHeader":"abstract","#text":"\n1. Introduction\n"},{"#tail":"\n","@confidence":"0.710486","@genericHeader":"keywords","#text":"\n2. Subcategorization in LFG\n"},{"#tail":"\n","@confidence":"0.869654166666667","@genericHeader":"introduction","#text":"\nSUBJ ADJ\nOBJ XADJ\nXCOMP\nCOMP\nOBJ?\nOBL?\n"},{"#tail":"\n","@confidence":"0.997352","@genericHeader":"method","#text":"\n3. Related Work\n"},{"#tail":"\n","@confidence":"0.992147","@genericHeader":"method","#text":"\n4. Methodology\n"},{"#tail":"\n","@confidence":"0.998818","@genericHeader":"method","#text":"\n5. Results\n"},{"#tail":"\n","@confidence":"0.464627","@genericHeader":"method","#text":"\n5 To recap, if two verbs have the same subcategorization requirements (e.g., give([subj, obj, obj2]),\n"},{"#tail":"\n","@confidence":"0.464754666666667","@genericHeader":"method","#text":"\n(VERB :ORTH ?reimburse? :SUBC ((NP-NP)\n(NP-PP :PVAL (?for?))\n(NP)))\n"},{"#tail":"\n","@confidence":"0.966947","@genericHeader":"acknowledgments","#text":"\nAcknowledgments\n"},{"#tail":"\n","@confidence":"0.985598","@genericHeader":"references","#text":"\nReferences\n"}],"tableCaption":[{"#tail":"\n","@confidence":"0.864786","#text":"\nTable 1\nGovernable and nongovernable grammatical functions in LFG.\nGovernable GFs Nongovernable GFs\n"},{"#tail":"\n","@confidence":"0.775543","#text":"\nTable 13\n"},{"#tail":"\n","@confidence":"0.662434","#text":"\nTable 16\n"},{"#tail":"\n","@confidence":"0.4192805","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\nTable 17\n"},{"#tail":"\n","@confidence":"0.746913","#text":"\nTable 19\n"},{"#tail":"\n","@confidence":"0.697354","#text":"\nTable 21\n"},{"#tail":"\n","@confidence":"0.730995","#text":"\nTable 23\n"},{"#tail":"\n","@confidence":"0.597732","#text":"\nTable 25\n"},{"#tail":"\n","@confidence":"0.664909","#text":"\nTable 26\n"}],"page":[{"#tail":"\n","@confidence":"0.989962","#text":"\n330\n"},{"#tail":"\n","@confidence":"0.997528","#text":"\n331\n"},{"#tail":"\n","@confidence":"0.997609","#text":"\n332\n"},{"#tail":"\n","@confidence":"0.999469","#text":"\n333\n"},{"#tail":"\n","@confidence":"0.999107","#text":"\n334\n"},{"#tail":"\n","@confidence":"0.99821","#text":"\n335\n"},{"#tail":"\n","@confidence":"0.998874","#text":"\n336\n"},{"#tail":"\n","@confidence":"0.998112","#text":"\n337\n"},{"#tail":"\n","@confidence":"0.999713","#text":"\n338\n"},{"#tail":"\n","@confidence":"0.995271","#text":"\n339\n"},{"#tail":"\n","@confidence":"0.941225","#text":"\n340\n"},{"#tail":"\n","@confidence":"0.992885","#text":"\n341\n"},{"#tail":"\n","@confidence":"0.995786","#text":"\n342\n"},{"#tail":"\n","@confidence":"0.996473","#text":"\n343\n"},{"#tail":"\n","@confidence":"0.99847","#text":"\n344\n"},{"#tail":"\n","@confidence":"0.985254","#text":"\n345\n"},{"#tail":"\n","@confidence":"0.995651","#text":"\n346\n"},{"#tail":"\n","@confidence":"0.992443","#text":"\n347\n"},{"#tail":"\n","@confidence":"0.995926","#text":"\n348\n"},{"#tail":"\n","@confidence":"0.996841","#text":"\n349\n"},{"#tail":"\n","@confidence":"0.980575","#text":"\n350\n"},{"#tail":"\n","@confidence":"0.974505","#text":"\n351\n"},{"#tail":"\n","@confidence":"0.757396","#text":"\n352\n"},{"#tail":"\n","@confidence":"0.836937","#text":"\n353\n"},{"#tail":"\n","@confidence":"0.844936","#text":"\n354\n"},{"#tail":"\n","@confidence":"0.623096","#text":"\n355\n"},{"#tail":"\n","@confidence":"0.999275","#text":"\n356\n"},{"#tail":"\n","@confidence":"0.628177","#text":"\n357\n"},{"#tail":"\n","@confidence":"0.989708","#text":"\n358\n"},{"#tail":"\n","@confidence":"0.992658","#text":"\n359\n"},{"#tail":"\n","@confidence":"0.981952","#text":"\n360\n"},{"#tail":"\n","@confidence":"0.981169","#text":"\n361\n"},{"#tail":"\n","@confidence":"0.982543","#text":"\n362\n"},{"#tail":"\n","@confidence":"0.980845","#text":"\n363\n"},{"#tail":"\n","@confidence":"0.988354","#text":"\n364\n"},{"#tail":"\n","@confidence":"0.999187","#text":"\n365\n"}],"figureCaption":[{"#tail":"\n","@confidence":"0.545918","#text":"\nFigure 1.\n"},{"#tail":"\n","@confidence":"0.988879","#text":"\nFigure 7\n"},{"#tail":"\n","@confidence":"0.7033","#text":"\nFigure 7. 6\n"}],"table":[{"#tail":"\n","@confidence":"0.913610333333333","#text":"\nTable 2\nResults of f-structure evaluation.\nDCU 105 PARC 700\nPrecision 96.52% 88.57%\nRecall 96.62% 86.10%\nF-score 96.57% 87.32%\n"},{"#tail":"\n","@confidence":"0.262535","#text":"\nComputational Linguistics Volume 31, Number 3\n"},{"#tail":"\n","@confidence":"0.806862","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\nTable 11\nMapping I: Merging of COMLEX and LFG syntactic functions.\nOur syntactic functions COMLEX syntactic functions Merged function\nSUBJ Subject SUBJ\nOBJ Object OBJ\nOBJ2 Obj2 OBJi\nOBL Obj3\nOBL2 Obj4\nCOMP Comp COMP\nXCOMP\nPART Part PART\n"},{"#tail":"\n","@confidence":"0.9770875","#text":"\nComputational Linguistics Volume 31, Number 3\nTable 12\nResults of Penn-II evaluation of active frames against COMLEX (relative threshold of 1%).\nPrecision Recall F-score\nMapping I Baseline Induced Baseline Induced Baseline Induced\nExperiment 1 66.1% 75.2% 65.8% 69.1% 66.0% 72.0%\nExperiment 2 71.5% 65.5% 64.3% 63.1% 67.7% 64.3%\nExperiment 3 64.7% 71.8% 11.9% 16.8% 20.1% 27.3%\n"},{"#tail":"\n","@confidence":"0.991076","#text":"\nResults of Penn-II evaluation of active frames against COMLEX (relative threshold of 5%).\nPrecision Recall F-score\nMapping I Baseline Induced Baseline Induced Baseline Induced\nExperiment 1 66.1% 80.2% 65.8% 63.6% 66.0% 70.9%\nExperiment 2 71.5% 69.6% 64.3% 56.9% 67.7% 62.7%\nExperiment 3 64.7% 76.7% 11.9% 13.9% 20.1% 23.5%\n"},{"#tail":"\n","@confidence":"0.9374332","#text":"\nComputational Linguistics Volume 31, Number 3\nTable 15\nPenn-II evaluation of active frames against COMLEX using p-dir list (relative threshold of 1%).\nMapping I Precision Recall F-score\nExperiment 3 86.9% 45.1% 59.4%\n"},{"#tail":"\n","@confidence":"0.8810608","#text":"\nMapping II: Merging of COMLEX and LFG syntactic functions.\nOur syntactic functions COMLEX syntactic functions Merged function\nSUBJ Subject SUBJ\nOBJ Object OBJ\nOBJ2 Obj2 OBJ2\nOBL Obj3 OBL\nOBL2 Obj4 OBL2\nCOMP Comp COMP\nXCOMP Comp XCOMP\nPART Part PART\n"},{"#tail":"\n","@confidence":"0.993045647058823","#text":"\nResults of Penn-II evaluation of active frames against COMLEX (relative threshold of 1%).\nPrecision Recall F-score\nMapping II Baseline Induced Baseline Induced Baseline Induced\nExperiment 1 72.1% 79.0% 58.5% 59.6% 64.6% 68.0%\nExperiment 2 65.2% 77.1% 37.4% 50.4% 47.5% 61.0%\nExperiment 2a 65.2% 76.4% 32.7% 44.5% 43.6% 56.3%\nExperiment 3 65.2% 75.9% 15.2% 24.0% 24.7% 35.9%\nExperiment 3a 65.2% 71.0% 13.6% 21.5% 22.5% 33.0%\nTable 18\nResults of Penn-II evaluation of active frames against COMLEX (relative threshold of 5%).\nPrecision Recall F-score\nMapping II Baseline Induced Baseline Induced Baseline Induced\nExperiment 1 72.1% 83.5% 58.5% 54.7% 64.6% 66.1%\nExperiment 2 65.2% 81.4% 37.4% 44.8% 47.5% 57.8%\nExperiment 2a 65.2% 80.9% 32.7% 39.0% 43.6% 52.6%\nExperiment 3 65.2% 75.9% 15.2% 19.7% 24.7% 31.3%\nExperiment 3a 65.2% 75.5% 13.6% 17.4% 22.5% 28.3%\n"},{"#tail":"\n","@confidence":"0.989536727272727","#text":"\nPenn-II evaluation of active frames against COMLEX using p-dir list (relative threshold of 1%).\nMapping II Precision Recall F-score\nExperiment 3 81.7% 40.8% 54.4%\nExperiment 3a 83.1% 35.4% 49.7%\nTable 20\nResults of Penn-II evaluation of passive frames (relative threshold of 1%).\nPassive Precision Recall F-score\nExperiment 2 80.2% 54.7% 65.1%\nExperiment 2a 79.7% 46.2% 58.5%\nExperiment 3 72.6% 33.4% 45.8%\nExperiment 3a 72.3% 29.3% 41.7%\n"},{"#tail":"\n","@confidence":"0.3928295","#text":"\nComputational Linguistics Volume 31, Number 3\n6.3.3 Absolute Thresholds. Many of the previous approaches discussed in Section 3 use\n"},{"#tail":"\n","@confidence":"0.9888802","#text":"\nPenn-II evaluation of active frames against COMLEX using absolute thresholds (Experiment 2).\nThreshold Precision Recall F-score\nAll 77.1% 50.4% 61.0%\nThreshold 100 82.3% 60.8% 69.9%\nThreshold 200 81.7% 58.7% 68.4%\n"},{"#tail":"\n","@confidence":"0.924548454545455","#text":"\nO?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources\nTable 22\nResults of Penn-III active frames (Brown Corpus only) COMLEX comparison (relative threshold\nof 1%).\nPrecision Recall F-Score\nMapping II Baseline Induced Baseline Induced Baseline Induced\nExperiment 1 73.2% 79.2% 60.1% 60.0% 66.0% 68.2%\nExperiment 2 66.0% 70.5% 37.5% 50.5% 47.8% 58.9%\nExperiment 2a 66.0% 71.3% 32.7% 44.5% 43.7% 54.8%\nExperiment 3 66.0% 64.3% 15.2% 23.1% 24.8% 34.0%\nExperiment 3a 66.0% 64.1% 13.5% 20.7% 22.4% 31.3%\n"},{"#tail":"\n","@confidence":"0.991813555555556","#text":"\nResults of Penn-III active frames (Brown corpus only) COMLEX comparison (relative threshold\nof 5%).\nPrecision Recall F-score\nMapping II Baseline Induced Baseline Induced Baseline Induced\nExperiment 1 73.2% 82.7% 60.1% 56.4% 66.0% 67.0%\nExperiment 2 66.0% 74.6% 37.5% 46.1% 47.8% 57.0%\nExperiment 2a 66.0% 76.0% 32.7% 40.0% 43.7% 52.4%\nExperiment 3 66.0% 69.2% 15.2% 18.7% 24.8% 29.5%\nExperiment 3a 66.0% 69.0% 13.5% 16.6% 22.4% 26.7%\n"},{"#tail":"\n","@confidence":"0.965969909090909","#text":"\nComputational Linguistics Volume 31, Number 3\nTable 24\nResults of Penn-III active frames (Brown and WSJ) COMLEX comparison (relative threshold of\n1%).\nPrecision Recall F-score\nMapping II Baseline Induced Baseline Induced Baseline Induced\nExperiment 1 71.2% 77.4% 62.9% 66.2% 66.8% 71.4%\nExperiment 2 64.5% 70.4% 40.0% 58.0% 49.3% 63.6%\nExperiment 2a 64.5% 71.5% 35.1% 51.9% 45.5% 60.2%\nExperiment 3 64.5% 66.2% 17.0% 27.4% 26.8% 38.8%\nExperiment 3a 64.5% 66.0% 15.1% 24.8% 24.5% 36.0%\n"},{"#tail":"\n","@confidence":"0.930510333333333","#text":"\nResults of Penn-III active frames (Brown and WSJ) COMLEX comparison (relative threshold of\n5%).\nPrecision Recall F-score\nMapping II Baseline Induced Baseline Induced Baseline Induced\nExperiment 1 71.2% 82.0% 62.9% 61.0% 66.8% 69.9%\nExperiment 2 64.5% 74.3% 40.0% 53.5% 49.3% 62.2%\nExperiment 2a 64.5% 76.4% 35.1% 45.1% 45.5% 56.7%\nExperiment 3 64.5% 71.1% 17.0% 21.5% 26.8% 33.0%\nExperiment 3a 64.5% 70.8% 15.1% 19.2% 24.5% 30.2%\n"},{"#tail":"\n","@confidence":"0.841500111111111","#text":"\nError analysis.\nFrame type COMLEX: False negatives Induced: False positives\nCorrect Incorrect Correct Incorrect\n[subj] 9 1 4 6\n[subj, obj] 10 0 9 1\n[subj, obj, obj2] 7 3 1 9\n[.., xcomp, ..] 10 0 1 10\n[.., comp, ..] 7 3 4 5\n[.., obl, ..] 23 7 14 16\n"},{"#tail":"\n","@confidence":"0.957968909090909","#text":"\nComputational Linguistics Volume 31, Number 3\nTable 27\nCoverage of induced lexicon (WSJ 02?21) on unseen data (WSJ 23) (verbs only).\nEntries also in reference lexicon 89.89%\nEntries not in reference lexicon 10.11%\nKnown words 7.85%\nKnown words, known frames 7.85%\nKnown words, unknown frames 0\nUnknown words 2.32%\nUnknown words, known frames 2.32%\nUnknown words, unknown frames 0\n"}]}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.293097","#tail":"\n","@no":"0","#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.997576","#text":"Dublin City University"},{"#tail":"\n","@confidence":"0.850657333333333","#text":"Dublin City University Aoife Cahill? Dublin City University"},{"#tail":"\n","@confidence":"0.988001","#text":"Dublin City University"},{"#tail":"\n","@confidence":"0.998634","#text":"Dublin City University"}],"author":[{"#tail":"\n","@confidence":"0.99929","#text":"Ruth ODonovan"},{"#tail":"\n","@confidence":"0.945761","#text":"Michael Burke"},{"#tail":"\n","@confidence":"0.921308","#text":"Josef van_Genabith"},{"#tail":"\n","@confidence":"0.992032","#text":"Andy Way"}],"abstract":{"#tail":"\n","@confidence":"0.973689133333333","#text":"We present a methodology for extracting subcategorization frames based on an automatic lexical-functional grammar (LFG) f-structure annotation algorithm for the Penn-II and Penn-III Treebanks. We extract syntactic-function-based subcategorization frames (LFG semantic forms) and traditional CFG category-based subcategorization frames as well as mixed function/category-based frames, with or without preposition information for obliques and particle information for particle verbs. Our approach associates probabilities with frames conditional on the lemma, distinguishes between active and passive frames, and fully reflects the effects of long-distance dependencies in the source data structures. In contrast to many other approaches, ours does not predefine the subcategorization frame types extracted, learning them instead from the source data. Including particles and prepositions, we extract 21,005 lemma frame types for 4,362 verb lemmas, with a total of 577 frame types and an average of 4.8 frame types per verb. We present a large-scale evaluation of the complete set of forms extracted against the full COMLEX resource. To our knowledge, this is the largest and most complete evaluation of subcategorization frames acquired automatically for English."},"title":{"#tail":"\n","@confidence":"0.997319","#text":"Large-Scale Induction and Evaluation of Lexical Resources from the Penn-II and Penn-III Treebanks"}}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"date":{"#tail":"\n","#text":"1982"},"issue":{"#tail":"\n","#text":"4"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"l of 577 frame types and an average of 4.8 frame types per verb. We present a large-scale evaluation of the complete set of forms extracted against the full COMLEX resource. To our knowledge, this is the largest and most complete evaluation of subcategorization frames acquired automatically for English. 1. Introduction In modern syntactic theories (e.g., lexical-functional grammar [LFG] [Kaplan and Bresnan 1982; Bresnan 2001; Dalrymple 2001], head-driven phrase structure grammar [HPSG] [Pollard and Sag 1994], tree-adjoining grammar [TAG] [Joshi 1988], and combinatory categorial grammar [CCG] [Ades and Steedman 1982]), the lexicon is the central repository for much morphological, syntactic, and semantic information. ? National Centre for Language Technology, School of Computing, Dublin City University, Glasnevin, Dublin 9, Ireland. E-mail: {rodonovan,mburke,acahill,josef,away}@computing.dcu.ie. ? Centre for Advanced Studies, IBM, Dublin, Ireland. Submission received: 19 March 2004; revised submission received: 18 December 2004; accepted for publication: 2 March 2005. ? 2005 Association for Computational Linguistics Computational Linguistics Volume 31, Number 3 Extensive lexical resources, therefore, are ","@endWordPosition":"253","@position":"1871","annotationId":"T1","@startWordPosition":"250","@citStr":"Ades and Steedman 1982"}},"title":{"#tail":"\n","#text":"On the order of words."},"volume":{"#tail":"\n","#text":"4"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Ades, Anthony and Mark Steedman. 1982. On the order of words. Linguistics and Philosophy, 4(4):517? 558."},"journal":{"#tail":"\n","#text":"Linguistics and Philosophy,"},"#text":"\n","pages":{"#tail":"\n","#text":"558"},"marker":{"#tail":"\n","#text":"Ades, Steedman, 1982"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Anthony Ades"},{"#tail":"\n","#text":"Mark Steedman"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1987"},"rawString":{"#tail":"\n","#text":"Boguraev, Branimir, Edward Briscoe, John Carroll, David Carter, and Claire Grover. 1987. The derivation of a grammatically indexed lexicon from the Longman Dictionary of Contemporary English. In Proceedings of the 25th Annual Meeting of the Association of Computational Linguistics, pages 193?200, Stanford, CA."},"#text":"\n","pages":{"#tail":"\n","#text":"193--200"},"marker":{"#tail":"\n","#text":"Boguraev, Briscoe, Carroll, Carter, Grover, 1987"},"location":{"#tail":"\n","#text":"Stanford, CA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"and the extracted frames include details of specific prepositions. The extracted frames are noisy as a result of parser errors and so are filtered using the binomial hypothesis theory (BHT), following Brent (1993). Applying his technique to approximately four million words of New York Times newswire, Manning acquired 4,900 verb-subcategorization frame pairs for 3,104 verbs, an average of 1.6 frames per verb. Briscoe and Carroll (1997) predefine 163 verbal subcategorization frames, obtained by manually merging the classes exemplified in the COMLEX (MacLeod, Grishman, and Meyers 1994) and ANLT (Boguraev et al 1987) dictionaries and adding around 30 frames found by manual inspection. The frames incorporate control information and details of specific prepositions. Briscoe and Carroll (1997) refine the BHT with a priori information about the probabilities of subcategorization frame membership and use it to filter the induced frames. Recent work by Korhonen (2002) on the filtering phase of this approach uses linguistic verb classes (based on Levin [1993]) for obtaining more accurate back-off estimates for hypothesis selection. Carroll and Rooth (1998) use a handwritten head-lexicalized, context-free grammar","@endWordPosition":"2373","@position":"16285","annotationId":"T2","@startWordPosition":"2370","@citStr":"Boguraev et al 1987"}},"title":{"#tail":"\n","#text":"The derivation of a grammatically indexed lexicon from the Longman Dictionary of Contemporary English."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 25th Annual Meeting of the Association of Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Branimir Boguraev"},{"#tail":"\n","#text":"Edward Briscoe"},{"#tail":"\n","#text":"John Carroll"},{"#tail":"\n","#text":"David Carter"},{"#tail":"\n","#text":"Claire Grover"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Brants, Sabine, Stefanie Dipper, Silvia Hansen, Wolfgang Lezius, and George Smith. 2002. The TIGER Treebank. In Proceedings of the Workshop on Treebanks and Linguistic Theories, Sozopol, Bulgaria."},"#text":"\n","marker":{"#tail":"\n","#text":"Brants, Dipper, Hansen, Lezius, Smith, 2002"},"location":{"#tail":"\n","#text":"Sozopol, Bulgaria."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"to apply our lexical acquisition methodology beyond existing parse-annotated corpora (Penn-II and Penn-III): New text is parsed by our probabilistic LFG approximations into f-structures from which we can then extract further semantic forms. The work reported here is part of the core components for bootstrapping this approach. In the shorter term, we intend to make the extracted subcategorization lexicons from Penn-II and Penn-III available as a downloadable public-domain research resource. We have also applied our more general unification grammar acquisition methodology to the TIGER Treebank (Brants et al 2002) and Penn Chinese Treebank (Xue, Chiou, and Palmer 2002), extracting wide-coverage, probabilistic LFG grammar 361 Computational Linguistics Volume 31, Number 3 approximations and lexical resources for German (Cahill et al 2003) and Chinese (Burke, Lam, et al 2004). The lexical resources, however, have not yet been evaluated. This, and much else, has to await further research. Acknowledgments The research reported here is partially supported by Enterprise Ireland Basic Research Grant SC/2001/186, an IRCSET PhD fellowship award, and an IBM PhD fellowship award. We are particularly grateful to ou","@endWordPosition":"13132","@position":"84978","annotationId":"T3","@startWordPosition":"13129","@citStr":"Brants et al 2002"}},"title":{"#tail":"\n","#text":"The TIGER Treebank."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Workshop on Treebanks and Linguistic Theories,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Sabine Brants"},{"#tail":"\n","#text":"Stefanie Dipper"},{"#tail":"\n","#text":"Silvia Hansen"},{"#tail":"\n","#text":"Wolfgang Lezius"},{"#tail":"\n","#text":"George Smith"}]}},{"volume":{"#tail":"\n","#text":"19"},"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"Brent, Michael. 1993. From grammar to lexicon: Unsupervised learning of lexical syntax. Computational Linguistics, 19(2):203?222."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"2"},"marker":{"#tail":"\n","#text":"Brent, 1993"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ter detail in Section 6, in which we compare our results with those reported elsewhere in the literature. We will divide more-general approaches to subcategorization frame acquisition into two groups: those which extract information from raw text and those which use preparsed and hand-corrected treebank data as their input. Typically in the approaches based on raw text, a number of subcategorization patterns are predefined, a set of verb subcategorization frame associations are hypothesized from the data, and statistical methods are applied to reliably select hypotheses for the final lexicon. Brent (1993) relies on morphosyntactic cues in the untagged Brown corpus as indicators of six predefined subcategorization frames. The frames do not include details of specific prepositions. Brent used hypothesis testing on binomial frequency data to statistically filter the induced frames. Ushioda et al (1993) run a finite-state NP parser on a POS-tagged corpus to calculate the relative frequency of the same six subcategorization verb classes. The experiment is limited by the fact that all prepositional phrases are treated as adjuncts. Ushioda et al (1993) employ an additional statistical method based on","@endWordPosition":"2100","@position":"14468","annotationId":"T4","@startWordPosition":"2099","@citStr":"Brent (1993)"},{"#tail":"\n","#text":"e on the approach of Brent (1993) by passing raw text through a stochastic tagger and a finite-state parser (which includes a set of simple rules for subcategorization frame recognition) in order to extract verbs and the constituents with which they co-occur. He assumes 19 different subcategorization 334 O?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources frame definitions, and the extracted frames include details of specific prepositions. The extracted frames are noisy as a result of parser errors and so are filtered using the binomial hypothesis theory (BHT), following Brent (1993). Applying his technique to approximately four million words of New York Times newswire, Manning acquired 4,900 verb-subcategorization frame pairs for 3,104 verbs, an average of 1.6 frames per verb. Briscoe and Carroll (1997) predefine 163 verbal subcategorization frames, obtained by manually merging the classes exemplified in the COMLEX (MacLeod, Grishman, and Meyers 1994) and ANLT (Boguraev et al 1987) dictionaries and adding around 30 frames found by manual inspection. The frames incorporate control information and details of specific prepositions. Briscoe and Carroll (1997) refine the BHT ","@endWordPosition":"2314","@position":"15878","annotationId":"T5","@startWordPosition":"2313","@citStr":"Brent (1993)"}]},"title":{"#tail":"\n","#text":"From grammar to lexicon: Unsupervised learning of lexical syntax."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Michael Brent"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Bresnan, Joan. 2001. Lexical-Functional Syntax. Blackwell, Oxford."},"#text":"\n","marker":{"#tail":"\n","#text":"Bresnan, 2001"},"publisher":{"#tail":"\n","#text":"Blackwell,"},"location":{"#tail":"\n","#text":"Oxford."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"rization frame types extracted, learning them instead from the source data. Including particles and prepositions, we extract 21,005 lemma frame types for 4,362 verb lemmas, with a total of 577 frame types and an average of 4.8 frame types per verb. We present a large-scale evaluation of the complete set of forms extracted against the full COMLEX resource. To our knowledge, this is the largest and most complete evaluation of subcategorization frames acquired automatically for English. 1. Introduction In modern syntactic theories (e.g., lexical-functional grammar [LFG] [Kaplan and Bresnan 1982; Bresnan 2001; Dalrymple 2001], head-driven phrase structure grammar [HPSG] [Pollard and Sag 1994], tree-adjoining grammar [TAG] [Joshi 1988], and combinatory categorial grammar [CCG] [Ades and Steedman 1982]), the lexicon is the central repository for much morphological, syntactic, and semantic information. ? National Centre for Language Technology, School of Computing, Dublin City University, Glasnevin, Dublin 9, Ireland. E-mail: {rodonovan,mburke,acahill,josef,away}@computing.dcu.ie. ? Centre for Advanced Studies, IBM, Dublin, Ireland. Submission received: 19 March 2004; revised submission received: 18 ","@endWordPosition":"227","@position":"1677","annotationId":"T6","@startWordPosition":"226","@citStr":"Bresnan 2001"},{"#tail":"\n","#text":"ts from the extraction process. We evaluate the complete induced lexicon against the COMLEX resource (Grishman, MacLeod, and Meyers 1994) and present the results in Section 6. To our knowledge, this is by far the largest and most complete evaluation of subcategorization frames automatically acquired for English. In Section 7, we examine the coverage of our lexicon in regard to unseen data and the rate at which new lexical entries are learned. Finally, in Section 8 we conclude and give suggestions for future work. 2. Subcategorization in LFG Lexical functional grammar (Kaplan and Bresnan 1982; Bresnan 2001; Dalrymple 2001) is a member of the family of constraint-based grammars. It posits minimally two levels of syntactic representation:2 c(onstituent)-structure encodes details of surface syntactic constituency, whereas f(unctional)-structure expresses abstract syntactic information about predicate?argument?modifier relations and certain morphosyntactic properties such as tense, aspect, and case. C-structure takes the form of phrase structure trees and is defined in terms of CFG rules and lexical entries. F-structure is produced from functional annotations on the nodes of the c-structure and imp","@endWordPosition":"1121","@position":"7844","annotationId":"T7","@startWordPosition":"1120","@citStr":"Bresnan 2001"}]},"title":{"#tail":"\n","#text":"Lexical-Functional Syntax."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Joan Bresnan"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Briscoe, Edward. 2001. From dictionary to corpus to self-organizing dictionary: Learning valency associations in the face of variation and change. In Proceedings of Corpus Linguistics 2001, Lancaster, UK."},"#text":"\n","marker":{"#tail":"\n","#text":"Briscoe, 2001"},"location":{"#tail":"\n","#text":"Lancaster, UK."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"mes (Brown and WSJ) COMLEX comparison (relative threshold of 5%). Precision Recall F-score Mapping II Baseline Induced Baseline Induced Baseline Induced Experiment 1 71.2% 82.0% 62.9% 61.0% 66.8% 69.9% Experiment 2 64.5% 74.3% 40.0% 53.5% 49.3% 62.2% Experiment 2a 64.5% 76.4% 35.1% 45.1% 45.5% 56.7% Experiment 3 64.5% 71.1% 17.0% 21.5% 26.8% 33.0% Experiment 3a 64.5% 70.8% 15.1% 19.2% 24.5% 30.2% 356 O?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources which is bound to be less certain than the assignment of frames based entirely on existing examples. As a generalization, Briscoe (2001) notes that lexicons such as COMLEX tend to demonstrate high precision but low recall. Briscoe and Carroll (1997) report on manually analyzing an open-class vocabulary of 35,000 head words for predicate subcategorization information and comparing the results against the subcategorization details in COMLEX. Precision was quite high (95%), but recall was low (84%). This has an effect on both the precision and recall scores of our system against COMLEX. In order to ascertain the effect of using COMLEX as a gold standard for our induced lexicon, we carried out some more-detailed error analysis, th","@endWordPosition":"11425","@position":"74072","annotationId":"T8","@startWordPosition":"11424","@citStr":"Briscoe (2001)"}},"title":{"#tail":"\n","#text":"From dictionary to corpus to self-organizing dictionary: Learning valency associations in the face of variation and change."},"booktitle":{"#tail":"\n","#text":"In Proceedings of Corpus Linguistics"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Edward Briscoe"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Briscoe, Edward and John Carroll. 1997. Automatic extraction of subcategorization from corpora. In Proceedings of the Fifth ACL Conference on Applied Natural Language Processing, pages 356?363, Washington, DC."},"#text":"\n","pages":{"#tail":"\n","#text":"356--363"},"marker":{"#tail":"\n","#text":"Briscoe, Carroll, 1997"},"location":{"#tail":"\n","#text":"Washington, DC."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"s and the constituents with which they co-occur. He assumes 19 different subcategorization 334 O?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources frame definitions, and the extracted frames include details of specific prepositions. The extracted frames are noisy as a result of parser errors and so are filtered using the binomial hypothesis theory (BHT), following Brent (1993). Applying his technique to approximately four million words of New York Times newswire, Manning acquired 4,900 verb-subcategorization frame pairs for 3,104 verbs, an average of 1.6 frames per verb. Briscoe and Carroll (1997) predefine 163 verbal subcategorization frames, obtained by manually merging the classes exemplified in the COMLEX (MacLeod, Grishman, and Meyers 1994) and ANLT (Boguraev et al 1987) dictionaries and adding around 30 frames found by manual inspection. The frames incorporate control information and details of specific prepositions. Briscoe and Carroll (1997) refine the BHT with a priori information about the probabilities of subcategorization frame membership and use it to filter the induced frames. Recent work by Korhonen (2002) on the filtering phase of this approach uses linguistic verb clas","@endWordPosition":"2347","@position":"16103","annotationId":"T9","@startWordPosition":"2344","@citStr":"Briscoe and Carroll (1997)"},{"#tail":"\n","#text":"344 O?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources Table 8 Number of semantic form types for Penn-III. Without prepositions and particles With prepositions and particles Semantic form types 15,166 21,005 Active 11,038 16,000 Passive 4,128 5,005 Table 9 Number of frame types for verbs for Penn-II. Without prepositions With prepositions and particles and particles Number of frame types 38 577 Number of singletons 1 243 Number occurring twice 1 84 Number occurring five or fewer times 7 415 Number occurring more than five times 31 162 from Penn-II and 221 from Penn-III. Briscoe and Carroll (1997), by comparison, employ 163 distinct predefined frames. 6. Evaluation Most of the previous approaches discussed in Section 3 have been evaluated to different degrees. In general, a small number of frequently occurring verbs is selected, and the subcategorization frames extracted for these verbs (from some quantity of unseen test data) are compared to a gold standard. The gold standard is either manually custom-made based on the test data or adapted from an existing external resource such as the OALD (Hornby 1980) or COMLEX (MacLeod, Grishman, and Meyers 1994). There are advantages and disadvan","@endWordPosition":"6465","@position":"42888","annotationId":"T10","@startWordPosition":"6462","@citStr":"Briscoe and Carroll (1997)"},{"#tail":"\n","#text":" Baseline Induced Baseline Induced Baseline Induced Experiment 1 71.2% 82.0% 62.9% 61.0% 66.8% 69.9% Experiment 2 64.5% 74.3% 40.0% 53.5% 49.3% 62.2% Experiment 2a 64.5% 76.4% 35.1% 45.1% 45.5% 56.7% Experiment 3 64.5% 71.1% 17.0% 21.5% 26.8% 33.0% Experiment 3a 64.5% 70.8% 15.1% 19.2% 24.5% 30.2% 356 O?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources which is bound to be less certain than the assignment of frames based entirely on existing examples. As a generalization, Briscoe (2001) notes that lexicons such as COMLEX tend to demonstrate high precision but low recall. Briscoe and Carroll (1997) report on manually analyzing an open-class vocabulary of 35,000 head words for predicate subcategorization information and comparing the results against the subcategorization details in COMLEX. Precision was quite high (95%), but recall was low (84%). This has an effect on both the precision and recall scores of our system against COMLEX. In order to ascertain the effect of using COMLEX as a gold standard for our induced lexicon, we carried out some more-detailed error analysis, the results of which are summarized in Table 26. We randomly selected 80 false negatives (fn) and 80 false positive","@endWordPosition":"11443","@position":"74185","annotationId":"T11","@startWordPosition":"11440","@citStr":"Briscoe and Carroll (1997)"}]},"title":{"#tail":"\n","#text":"Automatic extraction of subcategorization from corpora."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Fifth ACL Conference on Applied Natural Language Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Edward Briscoe"},{"#tail":"\n","#text":"John Carroll"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Burke, Michael, Aoife Cahill, Ruth O?Donovan, Josef van Genabith, and Andy Way. 2004a. Evaluation of an automatic annotation algorithm against the PARC 700 Dependency Bank. In Proceedings of the Ninth International Conference on LFG, pages 101?121, Christchurch, New Zealand."},"#text":"\n","pages":{"#tail":"\n","#text":"101--121"},"marker":{"#tail":"\n","#text":"Burke, Cahill, ODonovan, van Genabith, Way, 2004"},"location":{"#tail":"\n","#text":"Christchurch, New Zealand."},"title":{"#tail":"\n","#text":"Evaluation of an automatic annotation algorithm against the PARC 700 Dependency Bank."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Ninth International Conference on LFG,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Michael Burke"},{"#tail":"\n","#text":"Aoife Cahill"},{"#tail":"\n","#text":"Ruth ODonovan"},{"#tail":"\n","#text":"Josef van Genabith"},{"#tail":"\n","#text":"Andy Way"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Burke, Michael, Aoife Cahill, Ruth O?Donovan, Josef van Genabith, and Andy Way. 2004b. Treebank-based acquisition of wide-coverage, probabilistic LFG resources: Project overview, results and evaluation. In Proceedings of the Workshop ?Beyond Shallow Analyses? Formalisms and Statistical Modelling for Deep Analyses? at the First International Joint Conference on Natural Language Processing (IJCNLP-04), Hainan Island, China."},"#text":"\n","marker":{"#tail":"\n","#text":"Burke, Cahill, ODonovan, van Genabith, Way, 2004"},"location":{"#tail":"\n","#text":"Hainan Island, China."},"title":{"#tail":"\n","#text":"Treebank-based acquisition of wide-coverage, probabilistic LFG resources: Project overview, results and evaluation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Workshop ?Beyond Shallow Analyses? Formalisms and Statistical Modelling for Deep Analyses? at the First International Joint Conference on Natural Language Processing (IJCNLP-04),"},"@valid":"false","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Michael Burke"},{"#tail":"\n","#text":"Aoife Cahill"},{"#tail":"\n","#text":"Ruth ODonovan"},{"#tail":"\n","#text":"Josef van Genabith"},{"#tail":"\n","#text":"Andy Way"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Burke, Michael, Olivia Lam, Rowena Chan, Aoife Cahill, Ruth O?Donovan, Adams Bodomo, Josef van Genabith, and Andy Way. 2004. Treebank-based acquisition of a Chinese lexical-functional grammar. In Proceedings of the 18th Pacific Asia Conference on Language, Information and Computation, pages 161?172, Tokyo."},"#text":"\n","pages":{"#tail":"\n","#text":"161--172"},"marker":{"#tail":"\n","#text":"Burke, Lam, Chan, Cahill, ODonovan, Bodomo, van Genabith, Way, 2004"},"location":{"#tail":"\n","#text":"Tokyo."},"title":{"#tail":"\n","#text":"Treebank-based acquisition of a Chinese lexical-functional grammar."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 18th Pacific Asia Conference on Language, Information and Computation,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Michael Burke"},{"#tail":"\n","#text":"Olivia Lam"},{"#tail":"\n","#text":"Rowena Chan"},{"#tail":"\n","#text":"Aoife Cahill"},{"#tail":"\n","#text":"Ruth ODonovan"},{"#tail":"\n","#text":"Adams Bodomo"},{"#tail":"\n","#text":"Josef van Genabith"},{"#tail":"\n","#text":"Andy Way"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Cahill, Aoife, Michael Burke, Ruth O?Donovan, Josef van Genabith, and Andy Way. 2004. Long-distance dependency resolution in automatically acquired wide-coverage PCFG-based LFG approximations. In Proceedings of the 42nd Annual Meeting of the Association of Computational Linguistics, pages 320?327, Barcelona."},"#text":"\n","pages":{"#tail":"\n","#text":"320--327"},"marker":{"#tail":"\n","#text":"Cahill, Burke, ODonovan, van Genabith, Way, 2004"},"location":{"#tail":"\n","#text":"Barcelona."},"title":{"#tail":"\n","#text":"Long-distance dependency resolution in automatically acquired wide-coverage PCFG-based LFG approximations."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 42nd Annual Meeting of the Association of Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Aoife Cahill"},{"#tail":"\n","#text":"Michael Burke"},{"#tail":"\n","#text":"Ruth ODonovan"},{"#tail":"\n","#text":"Josef van Genabith"},{"#tail":"\n","#text":"Andy Way"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Cahill, Aoife, Martin Forst, Mairead McCarthy, Ruth O?Donovan, Christian Rohrer, Josef van Genabith, and Andy Way. 2003. Treebank-based multilingual unification-grammar development. In Proceedings of the Workshop on Ideas and Strategies for Multilingual Grammar Development at the 15th ESS-LLI, pages 17?24, Vienna."},"#text":"\n","pages":{"#tail":"\n","#text":"17--24"},"marker":{"#tail":"\n","#text":"Cahill, Forst, McCarthy, ODonovan, Rohrer, van Genabith, Way, 2003"},"location":{"#tail":"\n","#text":"Vienna."},"title":{"#tail":"\n","#text":"Treebank-based multilingual unification-grammar development."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Workshop on Ideas and Strategies for Multilingual Grammar Development at the 15th ESS-LLI,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Aoife Cahill"},{"#tail":"\n","#text":"Martin Forst"},{"#tail":"\n","#text":"Mairead McCarthy"},{"#tail":"\n","#text":"Ruth ODonovan"},{"#tail":"\n","#text":"Christian Rohrer"},{"#tail":"\n","#text":"Josef van Genabith"},{"#tail":"\n","#text":"Andy Way"}]}},{"volume":{"#tail":"\n","#text":"2"},"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Cahill, Aoife, Mairead McCarthy, Michael Burke, Ruth O?Donovan, Josef van Genabith, and Andy Way. 2004. Evaluating automatic F-structure annotation for the Penn-II Treebank. Journal of Research on Language and Computation, 2(4):523?547."},"journal":{"#tail":"\n","#text":"Journal of Research on Language and Computation,"},"#text":"\n","issue":{"#tail":"\n","#text":"4"},"marker":{"#tail":"\n","#text":"Cahill, McCarthy, Burke, ODonovan, van Genabith, Way, 2004"},"title":{"#tail":"\n","#text":"Evaluating automatic F-structure annotation for the Penn-II Treebank."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Aoife Cahill"},{"#tail":"\n","#text":"Mairead McCarthy"},{"#tail":"\n","#text":"Michael Burke"},{"#tail":"\n","#text":"Ruth ODonovan"},{"#tail":"\n","#text":"Josef van Genabith"},{"#tail":"\n","#text":"Andy Way"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Cahill, Aoife, Mairead McCarthy, Josef van Genabith, and Andy Way. 2002. Parsing text with a PCFG derived from Penn-II with an automatic F-structure annotation procedure. In Proceedings of the Seventh International Conference on LFG, edited by Miriam Butt and Tracy Holloway King. CSLI Publications, Stanford, CA, pages 76?95."},"#text":"\n","pages":{"#tail":"\n","#text":"76--95"},"marker":{"#tail":"\n","#text":"Cahill, McCarthy, van Genabith, Way, 2002"},"publisher":{"#tail":"\n","#text":"CSLI Publications,"},"location":{"#tail":"\n","#text":"Stanford, CA,"},"title":{"#tail":"\n","#text":"Parsing text with a PCFG derived from Penn-II with an automatic F-structure annotation procedure."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Seventh International Conference on LFG, edited by Miriam Butt and"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Aoife Cahill"},{"#tail":"\n","#text":"Mairead McCarthy"},{"#tail":"\n","#text":"Josef van Genabith"},{"#tail":"\n","#text":"Andy Way"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"O?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources Carroll, Glenn and Mats Rooth. 1998. Valence induction with a head-lexicalised PCFG. In Proceedings of the Third Conference on Empirical Methods in Natural Language Processing, pages 36?45, Granada, Spain."},"#text":"\n","pages":{"#tail":"\n","#text":"36--45"},"marker":{"#tail":"\n","#text":"et, 1998"},"location":{"#tail":"\n","#text":"Granada,"},"title":{"#tail":"\n","#text":"al Large-Scale Induction and Evaluation of Lexical Resources"},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Third Conference on Empirical Methods in Natural Language Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"ODonovan et"}}},{"date":{"#tail":"\n","#text":"1996"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"only). Entries also in reference lexicon 89.89% Entries not in reference lexicon 10.11% Known words 7.85% Known words, known frames 7.85% Known words, unknown frames 0 Unknown words 2.32% Unknown words, known frames 2.32% Unknown words, unknown frames 0 between known frames and unknown frames. There are, therefore, four different cases in which an entry may not appear in the reference lexicon. Table 27 shows that the most common case is that of known verbs occurring with a different, although known, subcategorization frame (7.85%). The rate of accession may also be represented graphically. In Charniak (1996) and Krotov et al (1998), it was observed that treebank grammars (CFGs extracted from treebanks) are very large and grow with the size of the treebank. We were interested in discovering whether the acquisition of lexical material from the same data displayed a similar propensity. Figure 8 graphs the rate of induction of semantic form and CFG rule types from Penn-III (the WSJ and parse-annotated Brown corpus combined). Because of the variation in the size of sections between the Brown and the WSJ, we plotted accession against word count. The first part of the graph (up to 1,004,414 words) Figur","@endWordPosition":"12018","@position":"77643","annotationId":"T12","@startWordPosition":"12017","@citStr":"Charniak (1996)"}},"title":{"#tail":"\n","#text":"Tree-bank grammars. In"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Charniak, Eugene. 1996. Tree-bank grammars. In AAAI-96: Proceedings of the Thirteenth National Conference on Artificial Intelligence. MIT Press, Cambridge, MA, pages 1031?1036."},"#text":"\n","pages":{"#tail":"\n","#text":"1031--1036"},"marker":{"#tail":"\n","#text":"Charniak, 1996"},"publisher":{"#tail":"\n","#text":"MIT Press,"},"location":{"#tail":"\n","#text":"Cambridge, MA,"},"booktitle":{"#tail":"\n","#text":"AAAI-96: Proceedings of the Thirteenth National Conference on Artificial Intelligence."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Eugene Charniak"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Chen, John and K. Vijay-Shanker. 2000. Automated extraction of TAGs from the Penn Treebank. In Proceedings of the 38th Annual Meeting of the Association of Computational Linguistics, pages 65?76, Hong Kong."},"#text":"\n","pages":{"#tail":"\n","#text":"65--76"},"marker":{"#tail":"\n","#text":"Chen, Vijay-Shanker, 2000"},"location":{"#tail":"\n","#text":"Hong Kong."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"e (Carroll and Rooth 1998). Manning (1993) argues that, aside from missing domain-specific complementation trends, dictionaries produced by hand will tend to lag behind real language use because of their static nature. Given these facts, research on automating acquisition of dictionaries for lexically based NLP systems is a particularly important issue. Aside from the extraction of theory-neutral subcategorization lexicons, there has also been work in the automatic construction of lexical resources which comply with the principles of particular linguistic theories such as LTAG, CCG, and HPSG (Chen and Vijay-Shanker 2000; Xia 1999; Hockenmaier, Bierner, and Baldridge 2004; Nakanishi, Miyao, and Tsujii 2004). In this article we present an approach to automating the process of lexical acquisition for LFG (i.e., grammatical-function-based systems). However, our approach also generalizes to CFG category-based approaches. In LFG, subcategorization requirements are enforced through semantic forms specifying which grammatical functions are required by a particular predicate. Our approach is based on earlier work on LFG semantic form extraction (van Genabith, Sadler, and Way 1999) and recent progress in automatically","@endWordPosition":"518","@position":"3803","annotationId":"T13","@startWordPosition":"515","@citStr":"Chen and Vijay-Shanker 2000"},{"#tail":"\n","#text":" are annotated with HPSG-typed feature structure information and thus contain more detail than the dependency trees. The work done for Bulgarian is small-scale, however, as Marinov and Hemming are working with a preliminary version of the treebank with 580 sentences. Work has been carried out on the extraction of formalism-specific lexical resources from the Penn-II Treebank, in particular TAG, CCG, and HPSG. As these formalisms are fully lexicalized with an invariant (LTAG and CCG) or limited (HPSG) rule component, the extraction of a lexicon essentially amounts to the creation of a grammar. Chen and Vijay-Shanker (2000) explore a number of related approaches to the extraction of a lexicalized TAG from the Penn-II Treebank with the aim of constructing a statistical model for parsing. The extraction procedure utilizes a head percolation table as introduced by Magerman (1995) in combination with a variation of Collins?s (1997) approach to the differentiation between complement and adjunct. This results in the construction of a set of lexically anchored elementary trees which make up the TAG in question. The number of frame types extracted (i.e., an elementary tree without a specific lexical anchor) ranged from ","@endWordPosition":"3134","@position":"21395","annotationId":"T14","@startWordPosition":"3131","@citStr":"Chen and Vijay-Shanker (2000)"}]},"title":{"#tail":"\n","#text":"Automated extraction of TAGs from the Penn Treebank."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 38th Annual Meeting of the Association of Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"John Chen"},{"#tail":"\n","#text":"K Vijay-Shanker"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Collins, Michael. 1997. Three generative lexicalised models for statistical parsing. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics, pages 16?23, Madrid."},"#text":"\n","pages":{"#tail":"\n","#text":"16--23"},"marker":{"#tail":"\n","#text":"Collins, 1997"},"location":{"#tail":"\n","#text":"Madrid."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"n of Collins?s (1997) approach to the differentiation between complement and adjunct. This results in the construction of a set of lexically anchored elementary trees which make up the TAG in question. The number of frame types extracted (i.e., an elementary tree without a specific lexical anchor) ranged from 2,366 to 8,996. Xia (1999) also presents a similar method for the extraction of a TAG from the Penn Treebank. The extraction procedure consists of three steps: First, the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of Magerman (1994) and Collins (1997). Then the elementary trees are read off in a quite straightforward manner. Finally any invalid elementary trees produced as a result of annotation errors in the treebank are filtered out using linguistic heuristics. The number of frame types extracted by Xia (1999) ranged from 3,014 to 6,099. Hockenmaier, Bierner, and Baldridge (2004) outline a method for the automatic extraction of a large syntactic CCG lexicon from the Penn-II Treebank. For each tree, the algorithm annotates the nodes with CCG categories in a top-down recursive manner. The first step is to label each node as either a head, ","@endWordPosition":"3279","@position":"22298","annotationId":"T15","@startWordPosition":"3278","@citStr":"Collins (1997)"},{"#tail":"\n","#text":"in the treebank in order to interpret LDDs. Unlike our approach, those of Xia (1999) and Hockenmaier, Bierner, and Baldridge (2004) include a substantial initial correction and clean-up of the Penn-II trees. Miyao, Ninomiya, and Tsujii (2004) and Nakanishi, Miyao, and Tsujii (2004) describe a methodology for acquiring an English HPSG from the Penn-II Treebank. Manually defined heuristics are used to automatically annotate each tree in the treebank with partially specified HPSG derivation trees: Head/argument/modifier distinctions are made for each node in the tree based on Magerman (1994) and Collins (1997); 336 O?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources the whole tree is then converted to a binary tree; heuristics are applied to deal with phenomena such as LDDs and coordination and to correct some errors in the treebank, and finally an HPSG category is assigned to each node in the tree in accordance with its CFG category. In the next phase of the process (externalization), HPSG lexical entries are automatically extracted from the annotated trees through the application of ?inverse schemata.? 4. Methodology The first step in the application of our methodology is th","@endWordPosition":"3506","@position":"23783","annotationId":"T16","@startWordPosition":"3505","@citStr":"Collins (1997)"}]},"title":{"#tail":"\n","#text":"Three generative lexicalised models for statistical parsing."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Michael Collins"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Crouch, Richard, Ron Kaplan, Tracy King, and Stefan Riezler. 2002. A comparison of evaluation metrics for a broad coverage parser. In Proceedings of Workshop ?Beyond PARSEVAL? at Third International Conference on Language Resources and Evaluation, Las Palmas, Spain."},"#text":"\n","marker":{"#tail":"\n","#text":"Crouch, Kaplan, King, Riezler, 2002"},"location":{"#tail":"\n","#text":"Las Palmas,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"(Figure 3). Passive movement is captured and expressed at f-structure level using a passive:+ annotation. Once a treebank tree is annotated with feature structure equations by the annotation algorithm, the equations are collected, and a constraint solver produces an f-structure. In order to ensure the quality of the semantic forms extracted by our method, we must first ensure the quality of the f-structure annotations. The results of two different evaluations of the automatically generated f-structures are presented in Table 2. Both use the evaluation software and triple encoding presented in Crouch et al (2002). The first of these is against the DCU 105, a gold-standard set of 105 hand-coded f-structures 337 Computational Linguistics Volume 31, Number 3 Figure 3 Use of reentrancy between TOPIC and COMP to capture long-distance dependency in Penn Treebank sentence wsj 0008 2, Until Congress acts, the government hasn?t any authority to issue new debt obligations of any kind, the Treasury said. from Section 23 of the Penn Treebank as described in Cahill, McCarthy, et al (2004). For the full set of annotations they achieve precision of over 96.5% and recall of over 96.6%. There is, however, a risk of ov","@endWordPosition":"4094","@position":"27545","annotationId":"T17","@startWordPosition":"4091","@citStr":"Crouch et al (2002)"}},"title":{"#tail":"\n","#text":"A comparison of evaluation metrics for a broad coverage parser."},"booktitle":{"#tail":"\n","#text":"In Proceedings of Workshop ?Beyond PARSEVAL? at Third International Conference on Language Resources and Evaluation,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Richard Crouch"},{"#tail":"\n","#text":"Ron Kaplan"},{"#tail":"\n","#text":"Tracy King"},{"#tail":"\n","#text":"Stefan Riezler"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Dalrymple, Mary. 2001. Lexical Functional Grammar. Volume 34 of Syntax and Semantics. Academic Press, New York."},"#text":"\n","marker":{"#tail":"\n","#text":"Dalrymple, 2001"},"publisher":{"#tail":"\n","#text":"Academic Press,"},"location":{"#tail":"\n","#text":"New York."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" types extracted, learning them instead from the source data. Including particles and prepositions, we extract 21,005 lemma frame types for 4,362 verb lemmas, with a total of 577 frame types and an average of 4.8 frame types per verb. We present a large-scale evaluation of the complete set of forms extracted against the full COMLEX resource. To our knowledge, this is the largest and most complete evaluation of subcategorization frames acquired automatically for English. 1. Introduction In modern syntactic theories (e.g., lexical-functional grammar [LFG] [Kaplan and Bresnan 1982; Bresnan 2001; Dalrymple 2001], head-driven phrase structure grammar [HPSG] [Pollard and Sag 1994], tree-adjoining grammar [TAG] [Joshi 1988], and combinatory categorial grammar [CCG] [Ades and Steedman 1982]), the lexicon is the central repository for much morphological, syntactic, and semantic information. ? National Centre for Language Technology, School of Computing, Dublin City University, Glasnevin, Dublin 9, Ireland. E-mail: {rodonovan,mburke,acahill,josef,away}@computing.dcu.ie. ? Centre for Advanced Studies, IBM, Dublin, Ireland. Submission received: 19 March 2004; revised submission received: 18 December 2004; a","@endWordPosition":"229","@position":"1693","annotationId":"T18","@startWordPosition":"228","@citStr":"Dalrymple 2001"},{"#tail":"\n","#text":"traction process. We evaluate the complete induced lexicon against the COMLEX resource (Grishman, MacLeod, and Meyers 1994) and present the results in Section 6. To our knowledge, this is by far the largest and most complete evaluation of subcategorization frames automatically acquired for English. In Section 7, we examine the coverage of our lexicon in regard to unseen data and the rate at which new lexical entries are learned. Finally, in Section 8 we conclude and give suggestions for future work. 2. Subcategorization in LFG Lexical functional grammar (Kaplan and Bresnan 1982; Bresnan 2001; Dalrymple 2001) is a member of the family of constraint-based grammars. It posits minimally two levels of syntactic representation:2 c(onstituent)-structure encodes details of surface syntactic constituency, whereas f(unctional)-structure expresses abstract syntactic information about predicate?argument?modifier relations and certain morphosyntactic properties such as tense, aspect, and case. C-structure takes the form of phrase structure trees and is defined in terms of CFG rules and lexical entries. F-structure is produced from functional annotations on the nodes of the c-structure and implemented in terms","@endWordPosition":"1123","@position":"7861","annotationId":"T19","@startWordPosition":"1122","@citStr":"Dalrymple 2001"},{"#tail":"\n","#text":"tated c-structure and f-structure in Figure 2. The value of the PRED attribute in an f-structure is a semantic form ??gf1, gf2, . . . , gfn?, where ? is a lemma and gf a grammatical function. The semantic form provides an argument list ?gf1,gf2, . . . ,gfn? specifying the governable grammatical functions (or arguments) required by the predicate to form a grammatical construction. In Figure 1 the verb FOCUS requires a subject and an oblique object introduced by the preposition on: FOCUS?(? SUBJ)(? OBLon)?. The argument list can be empty, as in the PRED value for judge in Figure 1. According to Dalrymple (2001), LFG assumes the following universally available inventory of grammatical functions: SUBJ(ect), OBJ(ect), OBJ?, COMP, XCOMP, OBL(ique)?, ADJ(unct), XADJ. OBJ? and OBL? represent families of grammatical functions indexed by their semantic role, represented by the theta subscript. This list of grammatical functions is divided into governable (subcategorizable) grammatical functions (arguments) and nongovernable (nonsubcategorizable) grammatical functions (modifiers/adjuncts), as summarized in Table 1. 2 LFGs may also involve morphological and semantic levels of representation. 331 Computational","@endWordPosition":"1344","@position":"9296","annotationId":"T20","@startWordPosition":"1343","@citStr":"Dalrymple (2001)"},{"#tail":"\n","#text":"indirect object in English. Oblique arguments are realized as prepositional phrases in English. COMP, XCOMP, and XADJ are all clausal functions which differ in the way in which they are controlled. A COMP is a closed function which contains its own internal SUBJ: The judge thinks [COMP that it will resume]. XCOMP and XADJ are open functions not requiring an internal SUBJ. The subject is instead specified externally in the matrix phrase: The judge wants [XCOMP to open an inquiry]. While many linguistic theories state subcategorization requirements in terms of phrase structure (CFG categories), Dalrymple (2001) questions the viability and universality of such an approach because of the variety of ways in which grammatical functions may be realized at the language-specific constituent structure level. LFG argues that subcategorization requirements are best stated at the f-structure level, in functional rather than phrasal terms. This is because of the assumption that abstract grammatical functions are primitive concepts as opposed to derivatives 332 O?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources Figure 2 C- and f-structures for Penn Treebank sentence wsj 0267 72, The inquir","@endWordPosition":"1549","@position":"10710","annotationId":"T21","@startWordPosition":"1548","@citStr":"Dalrymple (2001)"},{"#tail":"\n","#text":" between the nominal and verbal occurrences of the lemma fight. With this, the output for the verb impose in Figure 4 is impose(v,[subj, obj, obl:on]). For some of our experiments, we conflate the different verbal (and other) tags used in the Penn Treebanks to a single verbal marker (Table 4). As a further extension, the extraction procedure reads off the syntactic category of the head of each of the subcategorized syntactic functions: impose(v,[subj(n),obj(n),obl:on]).3 In this way, our methodology is able to produce surface syntactic as well as abstract functional subcategorization details. Dalrymple (2001) argues that there are cases, albeit exceptional ones, in which constraints on syntactic category are an issue in subcategorization. In contrast to much of the work reviewed in Section 3, which limits itself to the extraction of surface syntactic subcategorization details, our system can provide this information as well as details of grammatical function. 3 We do not associate syntactic categories with OBLs as they are always PPs. 341 Computational Linguistics Volume 31, Number 3 Another way in which we develop and extend the basic extraction algorithm is to deal with passive voice and its eff","@endWordPosition":"5263","@position":"34912","annotationId":"T22","@startWordPosition":"5262","@citStr":"Dalrymple (2001)"}]},"title":{"#tail":"\n","#text":"Lexical Functional Grammar. Volume 34 of Syntax and Semantics."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Mary Dalrymple"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1982"},"editor":{"#tail":"\n","#text":"In Pauline Jacobson and Geoffrey Pullum, editors,"},"rawString":{"#tail":"\n","#text":"Dowty, David. 1982. Grammatical relations and Montague grammar. In Pauline Jacobson and Geoffrey Pullum, editors, The Nature of Syntactic Representation. Reidel, Dordrecht, The Netherlands, pages 79?130."},"#text":"\n","pages":{"#tail":"\n","#text":"79--130"},"marker":{"#tail":"\n","#text":"Dowty, 1982"},"title":{"#tail":"\n","#text":"Grammatical relations and Montague grammar."},"booktitle":{"#tail":"\n","#text":"The Nature of Syntactic Representation. Reidel, Dordrecht, The Netherlands,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"David Dowty"}}},{"date":{"#tail":"\n","#text":"2001"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ositions. Still, to date this is the largest number of verbs used in any of the evaluations of the systems for English described in Section 3. Sarkar and Zeman (2000) evaluate 914 Czech verbs against a custom-made gold standard and record a token recall of 88%. However, their evaluation does not examine the extracted subcategorization frames but rather the argument?adjunct distinctions posited by their system. The largest lexical evaluation we know of is that of Schulte im Walde (2002b) for German. She evaluates 3,000 German verbs with a token frequency between 10 and 2,000 against the Duden (Dudenredaktion 2001). We will refer to this work and the methods and results presented by Schulte im Walde again in Sections 6.2 and 6.3. We carried out a large-scale evaluation of our automatically induced lexicon (2,993 active verb lemmas for Penn-II and 3,529 for Penn-III, as well as 1,422 passive verb lemmas from Penn-II) against the COMLEX resource. To our knowledge this is the most extensive evaluation ever carried out for English lexical extraction. We conducted a number of experiments on the subcategorization frames extracted from Penn-II and Penn-III which are described and discussed in Sections 6.2, 6.3","@endWordPosition":"6846","@position":"45293","annotationId":"T23","@startWordPosition":"6845","@citStr":"Dudenredaktion 2001"}},"title":{"#tail":"\n","#text":"DUDEN?Das Stilworterbuch. [DUDEN?The Style Dictionary]."},"volume":{"#tail":"\n","#text":"2"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Dudenredaktion, editor. 2001. DUDEN?Das Stilworterbuch. [DUDEN?The Style Dictionary]. Number 2 in Duden in zwo?lf Banden [Duden in Twelve Volumes]. Dudenverlag, Mannheim, Germany."},"journal":{"#tail":"\n","#text":"Number"},"#text":"\n","marker":{"#tail":"\n","#text":"Dudenredaktion, 2001"},"publisher":{"#tail":"\n","#text":"Dudenverlag,"},"location":{"#tail":"\n","#text":"Mannheim, Germany."},"booktitle":{"#tail":"\n","#text":"in Duden in zwo?lf Banden [Duden in Twelve Volumes]."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"editor Dudenredaktion"}}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Ph.D. thesis,"},"date":{"#tail":"\n","#text":"1999"},"institution":{"#tail":"\n","#text":"University of Stuttgart,"},"rawString":{"#tail":"\n","#text":"Eckle, Judith. 1999. Linguistic Knowledge for Automatic Lexicon Acquisition from German Text Corpora. Ph.D. thesis, University of Stuttgart, Germany."},"#text":"\n","marker":{"#tail":"\n","#text":"Eckle, 1999"},"title":{"#tail":"\n","#text":"Linguistic Knowledge for Automatic Lexicon Acquisition from German Text Corpora."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Judith Eckle"}}},{"date":{"#tail":"\n","#text":"2000"},"note":{"#tail":"\n","#text":"edited by Miriam Butt"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ce with its CFG category. In the next phase of the process (externalization), HPSG lexical entries are automatically extracted from the annotated trees through the application of ?inverse schemata.? 4. Methodology The first step in the application of our methodology is the production of a treebank annotated with LFG f-structure information. F-structures are attribute?value structures which represent abstract syntactic information, approximating to basic predicate?argument?modifier structures. Most of the early work on automatic f-structure annotation (e.g., van Genabith, Way, and Sadler 1999; Frank 2000; Sadler, van Genabith, and Way 2000) was applied only to small data sets (fewer than 200 sentences) and was largely proof of concept. However, more recent work (Cahill et al 2002; Cahill, McCarthy, et al 2004) has presented efforts in evolving and scaling up annotation techniques to the Penn-II Treebank (Marcus et al 1994), containing more than 1,000,000 words and 49,000 sentences. We utilize the automatic annotation algorithm of Cahill et al (2002) and Cahill, McCarthy, et al (2004) to derive a version of Penn-II in which each node in each tree is annotated with LFG functional annotations in","@endWordPosition":"3647","@position":"24721","annotationId":"T24","@startWordPosition":"3646","@citStr":"Frank 2000"}},"title":{"#tail":"\n","#text":"Automatic F-structure annotation of treebank trees."},"#tail":"\n","rawString":{"#tail":"\n","#text":"Frank, Anette. 2000. Automatic F-structure annotation of treebank trees. In Proceedings of the Fifth International Conference on LFG, Berkeley, CA, edited by Miriam Butt and Tracy Holloway King. CSLI, pages 139?160."},"#text":"\n","pages":{"#tail":"\n","#text":"139--160"},"marker":{"#tail":"\n","#text":"Frank, 2000"},"location":{"#tail":"\n","#text":"Berkeley, CA,"},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Fifth International Conference on LFG,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Anette Frank"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Grishman, Ralph, Catherine MacLeod, and Adam Meyers. 1994. COMLEX syntax: Building a computational lexicon. In Proceedings of the 15th International Conference on Computational Linguistics, pages 268?272, Kyoto."},"#text":"\n","pages":{"#tail":"\n","#text":"268--272"},"marker":{"#tail":"\n","#text":"Grishman, MacLeod, Meyers, 1994"},"title":{"#tail":"\n","#text":"COMLEX syntax: Building a computational lexicon."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 15th International Conference on Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Ralph Grishman"},{"#tail":"\n","#text":"Catherine MacLeod"},{"#tail":"\n","#text":"Adam Meyers"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Hajic, Jan. 1998. Building a syntactically annotated corpus: The Prague Dependency Treebank. In Issues in Valency and Meaning, edited by Eva Hajicova. Karolinum, Prague, Czech Republic, pages 106?132."},"#text":"\n","pages":{"#tail":"\n","#text":"106--132"},"marker":{"#tail":"\n","#text":"Hajic, 1998"},"location":{"#tail":"\n","#text":"Prague, Czech Republic,"},"title":{"#tail":"\n","#text":"Building a syntactically annotated corpus: The Prague Dependency Treebank."},"booktitle":{"#tail":"\n","#text":"In Issues in Valency and Meaning, edited by Eva Hajicova. Karolinum,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Jan Hajic"}}},{"volume":{"#tail":"\n","#text":"19"},"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"Hindle, Donald and Mats Rooth. 1993. Ambiguity and lexical relations. Computational Linguistics, 19(1):103?120."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"1"},"marker":{"#tail":"\n","#text":"Hindle, Rooth, 1993"},"title":{"#tail":"\n","#text":"Ambiguity and lexical relations."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Donald Hindle"},{"#tail":"\n","#text":"Mats Rooth"}]}},{"volume":{"#tail":"\n","#text":"2"},"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Hockenmaier, Julia, Gann Bierner, and Jason Baldridge. 2004. Extending the coverage of a CCG system. Journal of Language and Computation, 2(2):165?208."},"journal":{"#tail":"\n","#text":"Journal of Language and Computation,"},"#text":"\n","issue":{"#tail":"\n","#text":"2"},"marker":{"#tail":"\n","#text":"Hockenmaier, Bierner, Baldridge, 2004"},"title":{"#tail":"\n","#text":"Extending the coverage of a CCG system."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Julia Hockenmaier"},{"#tail":"\n","#text":"Gann Bierner"},{"#tail":"\n","#text":"Jason Baldridge"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1980"},"editor":{"#tail":"\n","#text":"Hornby, Albert, editor."},"rawString":{"#tail":"\n","#text":"Hornby, Albert, editor. 1980. Oxford Advanced Learner?s Dictionary of Current English. Oxford University Press, Oxford, UK."},"#text":"\n","marker":{"#tail":"\n","#text":"1980"},"publisher":{"#tail":"\n","#text":"Oxford University Press,"},"location":{"#tail":"\n","#text":"Oxford, UK."},"booktitle":{"#tail":"\n","#text":"Oxford Advanced Learner?s Dictionary of Current English."},"@valid":"true"},{"date":{"#tail":"\n","#text":"1988"},"editor":{"#tail":"\n","#text":"David Dowty, Lauri Karttunen, and Arnold Zwicky, editors,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"05 lemma frame types for 4,362 verb lemmas, with a total of 577 frame types and an average of 4.8 frame types per verb. We present a large-scale evaluation of the complete set of forms extracted against the full COMLEX resource. To our knowledge, this is the largest and most complete evaluation of subcategorization frames acquired automatically for English. 1. Introduction In modern syntactic theories (e.g., lexical-functional grammar [LFG] [Kaplan and Bresnan 1982; Bresnan 2001; Dalrymple 2001], head-driven phrase structure grammar [HPSG] [Pollard and Sag 1994], tree-adjoining grammar [TAG] [Joshi 1988], and combinatory categorial grammar [CCG] [Ades and Steedman 1982]), the lexicon is the central repository for much morphological, syntactic, and semantic information. ? National Centre for Language Technology, School of Computing, Dublin City University, Glasnevin, Dublin 9, Ireland. E-mail: {rodonovan,mburke,acahill,josef,away}@computing.dcu.ie. ? Centre for Advanced Studies, IBM, Dublin, Ireland. Submission received: 19 March 2004; revised submission received: 18 December 2004; accepted for publication: 2 March 2005. ? 2005 Association for Computational Linguistics Computational Linguisti","@endWordPosition":"244","@position":"1804","annotationId":"T25","@startWordPosition":"243","@citStr":"Joshi 1988"}},"title":{"#tail":"\n","#text":"Tree adjoining grammars. In"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Joshi, Aravind. 1988. Tree adjoining grammars. In David Dowty, Lauri Karttunen, and Arnold Zwicky, editors, Natural Language Parsing. Cambridge University Press, Cambridge, pages 206?250."},"#text":"\n","pages":{"#tail":"\n","#text":"206--250"},"marker":{"#tail":"\n","#text":"Joshi, 1988"},"publisher":{"#tail":"\n","#text":"Cambridge University Press,"},"location":{"#tail":"\n","#text":"Cambridge,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Aravind Joshi"}}},{"date":{"#tail":"\n","#text":"1982"},"editor":{"#tail":"\n","#text":"In Joan Bresnan, editor,"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"t predefine the subcategorization frame types extracted, learning them instead from the source data. Including particles and prepositions, we extract 21,005 lemma frame types for 4,362 verb lemmas, with a total of 577 frame types and an average of 4.8 frame types per verb. We present a large-scale evaluation of the complete set of forms extracted against the full COMLEX resource. To our knowledge, this is the largest and most complete evaluation of subcategorization frames acquired automatically for English. 1. Introduction In modern syntactic theories (e.g., lexical-functional grammar [LFG] [Kaplan and Bresnan 1982; Bresnan 2001; Dalrymple 2001], head-driven phrase structure grammar [HPSG] [Pollard and Sag 1994], tree-adjoining grammar [TAG] [Joshi 1988], and combinatory categorial grammar [CCG] [Ades and Steedman 1982]), the lexicon is the central repository for much morphological, syntactic, and semantic information. ? National Centre for Language Technology, School of Computing, Dublin City University, Glasnevin, Dublin 9, Ireland. E-mail: {rodonovan,mburke,acahill,josef,away}@computing.dcu.ie. ? Centre for Advanced Studies, IBM, Dublin, Ireland. Submission received: 19 March 2004; revised submission","@endWordPosition":"225","@position":"1663","annotationId":"T26","@startWordPosition":"222","@citStr":"Kaplan and Bresnan 1982"},{"#tail":"\n","#text":"ection 5 we present results from the extraction process. We evaluate the complete induced lexicon against the COMLEX resource (Grishman, MacLeod, and Meyers 1994) and present the results in Section 6. To our knowledge, this is by far the largest and most complete evaluation of subcategorization frames automatically acquired for English. In Section 7, we examine the coverage of our lexicon in regard to unseen data and the rate at which new lexical entries are learned. Finally, in Section 8 we conclude and give suggestions for future work. 2. Subcategorization in LFG Lexical functional grammar (Kaplan and Bresnan 1982; Bresnan 2001; Dalrymple 2001) is a member of the family of constraint-based grammars. It posits minimally two levels of syntactic representation:2 c(onstituent)-structure encodes details of surface syntactic constituency, whereas f(unctional)-structure expresses abstract syntactic information about predicate?argument?modifier relations and certain morphosyntactic properties such as tense, aspect, and case. C-structure takes the form of phrase structure trees and is defined in terms of CFG rules and lexical entries. F-structure is produced from functional annotations on the nodes of the c-str","@endWordPosition":"1119","@position":"7830","annotationId":"T27","@startWordPosition":"1116","@citStr":"Kaplan and Bresnan 1982"},{"#tail":"\n","#text":"tical functions are primitive concepts as opposed to derivatives 332 O?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources Figure 2 C- and f-structures for Penn Treebank sentence wsj 0267 72, The inquiry soon focused on the judge. of phrase structural position. In LFG, the subcategorization requirements of a particular predicate are expressed by its semantic form: FOCUS?(? SUBJ)(? OBLon)? in Figure 1. The subcategorization requirements expressed by semantic forms are enforced at f-structure level through completeness and coherence well-formedness conditions on f-structure (Kaplan and Bresnan 1982): An f-structure is locally complete iff it contains all the governable grammatical functions that its predicate governs. An f-structure is complete iff it and all its subsidiary f-structures are locally complete. An f-structure is locally coherent iff all the governable grammatical functions that it contains are governed by a local predicate. An f-structure is coherent iff it and all its subsidiary f-structures are locally coherent. (page 211) Consider again the f-structure in Figure 2. The semantic form associated with the verb focus is FOCUS?(? SUBJ)(? OBLon)?. The f-structure is locally co","@endWordPosition":"1691","@position":"11712","annotationId":"T28","@startWordPosition":"1688","@citStr":"Kaplan and Bresnan 1982"},{"#tail":"\n","#text":" 76.4% 32.7% 44.5% 43.6% 56.3% Experiment 3 65.2% 75.9% 15.2% 24.0% 24.7% 35.9% Experiment 3a 65.2% 71.0% 13.6% 21.5% 22.5% 33.0% Table 18 Results of Penn-II evaluation of active frames against COMLEX (relative threshold of 5%). Precision Recall F-score Mapping II Baseline Induced Baseline Induced Baseline Induced Experiment 1 72.1% 83.5% 58.5% 54.7% 64.6% 66.1% Experiment 2 65.2% 81.4% 37.4% 44.8% 47.5% 57.8% Experiment 2a 65.2% 80.9% 32.7% 39.0% 43.6% 52.6% Experiment 3 65.2% 75.9% 15.2% 19.7% 24.7% 31.3% Experiment 3a 65.2% 75.5% 13.6% 17.4% 22.5% 28.3% We applied lexical-redundancy rules (Kaplan and Bresnan 1982) to automatically convert the active COMLEX frames to their passive counterparts: For example, subjects are demoted to optional by oblique agents, and direct objects become subjects. The resulting precision was very high (from 72.3% to 80.2%), and there was the expected drop in recall when prepositional details were included (from 54.7% to 29.3%). Table 19 Penn-II evaluation of active frames against COMLEX using p-dir list (relative threshold of 1%). Mapping II Precision Recall F-score Experiment 3 81.7% 40.8% 54.4% Experiment 3a 83.1% 35.4% 49.7% Table 20 Results of Penn-II evaluation of pass","@endWordPosition":"9922","@position":"64549","annotationId":"T29","@startWordPosition":"9919","@citStr":"Kaplan and Bresnan 1982"}]},"title":{"#tail":"\n","#text":"Lexical functional grammar: A formal system for grammatical representation."},"#tail":"\n","rawString":{"#tail":"\n","#text":"Kaplan, Ronald and Joan Bresnan. 1982. Lexical functional grammar: A formal system for grammatical representation. In Joan Bresnan, editor, The Mental Representation of Grammatical Relations. MIT Press, Cambridge, MA, pages 173?281."},"#text":"\n","pages":{"#tail":"\n","#text":"173--281"},"marker":{"#tail":"\n","#text":"Kaplan, Bresnan, 1982"},"publisher":{"#tail":"\n","#text":"MIT Press,"},"location":{"#tail":"\n","#text":"Cambridge, MA,"},"booktitle":{"#tail":"\n","#text":"The Mental Representation of Grammatical Relations."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Ronald Kaplan"},{"#tail":"\n","#text":"Joan Bresnan"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"King, Tracy Holloway, Richard Crouch, Stefan Riezler, Mary Dalrymple, and Ronald Kaplan. 2003. The PARC 700 Dependency Bank. In Proceedings of the Fourth International Workshop on Linguistically Interpreted Corpora, Budapest."},"#text":"\n","marker":{"#tail":"\n","#text":"King, Crouch, Riezler, Dalrymple, Kaplan, 2003"},"location":{"#tail":"\n","#text":"Budapest."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"Penn Treebank sentence wsj 0008 2, Until Congress acts, the government hasn?t any authority to issue new debt obligations of any kind, the Treasury said. from Section 23 of the Penn Treebank as described in Cahill, McCarthy, et al (2004). For the full set of annotations they achieve precision of over 96.5% and recall of over 96.6%. There is, however, a risk of overfitting when evaluation is limited to a gold standard of this size. More recently, Burke, Cahill, et al (2004a) carried out an evaluation of the automatic annotation algorithm against the publicly available PARC 700 Dependency Bank (King et al 2003), a set of 700 randomly selected sentences from Section 23 which have been parsed, converted to dependency format, and manually corrected and extended by human validators. They report precision of over 88.5% and recall of over 86% (Table 2). The PARC 700 Dependency Bank differs substantially from both the DCU 105 f-structure bank and the automatically generated f-structures in regard to Table 2 Results of f-structure evaluation. DCU 105 PARC 700 Precision 96.52% 88.57% Recall 96.62% 86.10% F-score 96.57% 87.32% 338 O?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources the s","@endWordPosition":"4234","@position":"28396","annotationId":"T30","@startWordPosition":"4231","@citStr":"King et al 2003"}},"title":{"#tail":"\n","#text":"The PARC 700 Dependency Bank."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Fourth International Workshop on Linguistically Interpreted Corpora,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Tracy Holloway King"},{"#tail":"\n","#text":"Richard Crouch"},{"#tail":"\n","#text":"Stefan Riezler"},{"#tail":"\n","#text":"Mary Dalrymple"},{"#tail":"\n","#text":"Ronald Kaplan"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Kingsbury, Paul and Martha Palmer. 2002."},"#text":"\n","marker":{"#tail":"\n","#text":"Kingsbury, Palmer, 2002"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"se reported in O?Donovan et al (2004). The results for the larger, more domain-diverse Penn-III lexicon are very encouraging, in some cases almost 15% above the baseline. We believe our semantic forms are fine-grained, and by choosing to evaluate against COMLEX, we set our sights high: COMLEX is considerably more detailed than the OALD or LDOCE used for other earlier evaluations. Our error analysis also revealed some interesting issues associated with using an external standard such as COMLEX. In the future, we hope to evaluate the automatic annotations and extracted lexicon against Propbank (Kingsbury and Palmer 2002). Apart from the related approach of Miyao, Ninomiya, and Tsujii (2004), which does not distinguish between argument and adjunct prepositional phrases, our treebank and automatic f-structure annotation-based architecture for the automatic acquisition of detailed subcategorization frames is quite unlike any of the architectures presented in the literature. Subcategorization frames are reverse-engineered and almost a byproduct of the automatic f-structure annotation algorithm. It is important to realize that the induction of lexical resources is part of a larger project on the acquisition of wid","@endWordPosition":"12897","@position":"83331","annotationId":"T31","@startWordPosition":"12894","@citStr":"Kingsbury and Palmer 2002"}},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Paul Kingsbury"},{"#tail":"\n","#text":"Martha Palmer"}]}},{"#tail":"\n","date":{"#tail":"\n"},"rawString":{"#tail":"\n","#text":"From Treebank to PropBank. In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC-2002), Las Palmas, Spain."},"#text":"\n","marker":{"#tail":"\n"},"location":{"#tail":"\n","#text":"Las Palmas,"},"title":{"#tail":"\n","#text":"From Treebank to PropBank."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC-2002),"},"@valid":"true"},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Kinyon, Alexandra and Carlos Prolo. 2002."},"#text":"\n","marker":{"#tail":"\n","#text":"Kinyon, Prolo, 2002"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"m Walde limits sentence length for grammar training and parsing. Sentences of length between 5 and 10 words were used to bootstrap the lexicalized grammar model. For lexicalized training, sentences of length between 5 and 13 words were used. The result is a subcategorization lexicon for over 14,000 German verbs. The extensive evaluation carried out by Schulte im Walde will be discussed in greater detail in Section 6. Approaches using treebank-based data as a source for subcategorization information, such as ours, do not predefine the frames to be extracted but rather learn them from the data. Kinyon and Prolo (2002) describe a simple tool which uses fine-grained rules to identify the arguments of verb occurrences in the Penn-II Treebank. This is made possible by manual examination of more than 150 different sequences of syntactic and functional tags in the treebank. Each of these sequences was categorized as a modifier or argument. Arguments were then mapped to traditional syntactic functions. For example, the tag sequence NP-SBJ denotes a mandatory argument, and its syntactic function is subject. In general, argumenthood was preferred over adjuncthoood. As Kinyon and Prolo (2002) does not include an eva","@endWordPosition":"2756","@position":"18897","annotationId":"T32","@startWordPosition":"2753","@citStr":"Kinyon and Prolo (2002)"}},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Alexandra Kinyon"},{"#tail":"\n","#text":"Carlos Prolo"}]}},{"#tail":"\n","date":{"#tail":"\n"},"rawString":{"#tail":"\n","#text":"Identifying verb arguments and their syntactic function in the Penn Treebank. In Proceedings of the Third LREC Conference, pages 1982?1987, Las Palmas, Spain."},"#text":"\n","pages":{"#tail":"\n","#text":"1982--1987"},"marker":{"#tail":"\n"},"location":{"#tail":"\n","#text":"Las Palmas,"},"title":{"#tail":"\n","#text":"Identifying verb arguments and their syntactic function in the Penn Treebank."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Third LREC Conference,"},"@valid":"true"},{"#tail":"\n","tech":{"#tail":"\n","#text":"Technical Report UCAM-CL-TR-530,"},"date":{"#tail":"\n","#text":"2002"},"institution":{"#tail":"\n","#text":"Computer Laboratory, University of Cambridge, UK."},"rawString":{"#tail":"\n","#text":"Korhonen, Anna. 2002. Subcategorization acquisition. As Technical Report UCAM-CL-TR-530, Computer Laboratory, University of Cambridge, UK."},"#text":"\n","marker":{"#tail":"\n","#text":"Korhonen, 2002"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"rs for 3,104 verbs, an average of 1.6 frames per verb. Briscoe and Carroll (1997) predefine 163 verbal subcategorization frames, obtained by manually merging the classes exemplified in the COMLEX (MacLeod, Grishman, and Meyers 1994) and ANLT (Boguraev et al 1987) dictionaries and adding around 30 frames found by manual inspection. The frames incorporate control information and details of specific prepositions. Briscoe and Carroll (1997) refine the BHT with a priori information about the probabilities of subcategorization frame membership and use it to filter the induced frames. Recent work by Korhonen (2002) on the filtering phase of this approach uses linguistic verb classes (based on Levin [1993]) for obtaining more accurate back-off estimates for hypothesis selection. Carroll and Rooth (1998) use a handwritten head-lexicalized, context-free grammar and a text corpus to compute the probability of particular subcategorization patterns. The approach is iterative with the aim of estimating the distribution of subcategorization frames associated with a particular predicate. They perform a mapping between their frames and those of the OALD, resulting in 15 frame types. These do not contain details o","@endWordPosition":"2425","@position":"16637","annotationId":"T33","@startWordPosition":"2424","@citStr":"Korhonen (2002)"}},"title":{"#tail":"\n","#text":"Subcategorization acquisition. As"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Anna Korhonen"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Krotov, Alexander, Mark Hepple, Robert Gaizauskas, and Yorick Wilks. 1998. Compacting the Penn Treebank grammar. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, pages 669?703, Montreal."},"#text":"\n","pages":{"#tail":"\n","#text":"669--703"},"marker":{"#tail":"\n","#text":"Krotov, Hepple, Gaizauskas, Wilks, 1998"},"location":{"#tail":"\n","#text":"Montreal."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"in reference lexicon 89.89% Entries not in reference lexicon 10.11% Known words 7.85% Known words, known frames 7.85% Known words, unknown frames 0 Unknown words 2.32% Unknown words, known frames 2.32% Unknown words, unknown frames 0 between known frames and unknown frames. There are, therefore, four different cases in which an entry may not appear in the reference lexicon. Table 27 shows that the most common case is that of known verbs occurring with a different, although known, subcategorization frame (7.85%). The rate of accession may also be represented graphically. In Charniak (1996) and Krotov et al (1998), it was observed that treebank grammars (CFGs extracted from treebanks) are very large and grow with the size of the treebank. We were interested in discovering whether the acquisition of lexical material from the same data displayed a similar propensity. Figure 8 graphs the rate of induction of semantic form and CFG rule types from Penn-III (the WSJ and parse-annotated Brown corpus combined). Because of the variation in the size of sections between the Brown and the WSJ, we plotted accession against word count. The first part of the graph (up to 1,004,414 words) Figure 8 Comparison of access","@endWordPosition":"12023","@position":"77667","annotationId":"T34","@startWordPosition":"12020","@citStr":"Krotov et al (1998)"}},"title":{"#tail":"\n","#text":"Compacting the Penn Treebank grammar."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Alexander Krotov"},{"#tail":"\n","#text":"Mark Hepple"},{"#tail":"\n","#text":"Robert Gaizauskas"},{"#tail":"\n","#text":"Yorick Wilks"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"Levin, Beth. 1993. English Verb Classes and Alternations. University of Chicago Press, Chicago."},"#text":"\n","marker":{"#tail":"\n","#text":"Levin, 1993"},"publisher":{"#tail":"\n","#text":"University of Chicago Press,"},"location":{"#tail":"\n","#text":"Chicago."},"title":{"#tail":"\n","#text":"English Verb Classes and Alternations."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Beth Levin"}}},{"volume":{"#tail":"\n","#text":"3"},"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Computational Linguistics Volume 31, Number 3 MacLeod, Catherine, Ralph Grishman, and Adam Meyers. 1994. The Comlex Syntax Project: The first year. In Proceedings of the ARPA Workshop on Human Language Technology, pages 669?703, Princeton."},"#text":"\n","pages":{"#tail":"\n","#text":"669--703"},"marker":{"#tail":"\n","#text":"MacLeod, Grishman, Meyers, 1994"},"location":{"#tail":"\n","#text":"Princeton."},"title":{"#tail":"\n","#text":"The Comlex Syntax Project: The first year."},"booktitle":{"#tail":"\n","#text":"Computational Linguistics Volume 31, Number"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Catherine MacLeod"},{"#tail":"\n","#text":"Ralph Grishman"},{"#tail":"\n","#text":"Adam Meyers"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Ph.D. thesis,"},"date":{"#tail":"\n","#text":"1994"},"institution":{"#tail":"\n","#text":"Stanford University,"},"rawString":{"#tail":"\n","#text":"Magerman, David. 1994. Natural Language Parsing as Statistical Pattern Recognition. Ph.D. thesis, Stanford University, Stanford, CA."},"#text":"\n","marker":{"#tail":"\n","#text":"Magerman, 1994"},"location":{"#tail":"\n","#text":"Stanford, CA."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"tion with a variation of Collins?s (1997) approach to the differentiation between complement and adjunct. This results in the construction of a set of lexically anchored elementary trees which make up the TAG in question. The number of frame types extracted (i.e., an elementary tree without a specific lexical anchor) ranged from 2,366 to 8,996. Xia (1999) also presents a similar method for the extraction of a TAG from the Penn Treebank. The extraction procedure consists of three steps: First, the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of Magerman (1994) and Collins (1997). Then the elementary trees are read off in a quite straightforward manner. Finally any invalid elementary trees produced as a result of annotation errors in the treebank are filtered out using linguistic heuristics. The number of frame types extracted by Xia (1999) ranged from 3,014 to 6,099. Hockenmaier, Bierner, and Baldridge (2004) outline a method for the automatic extraction of a large syntactic CCG lexicon from the Penn-II Treebank. For each tree, the algorithm annotates the nodes with CCG categories in a top-down recursive manner. The first step is to label each node","@endWordPosition":"3276","@position":"22279","annotationId":"T35","@startWordPosition":"3275","@citStr":"Magerman (1994)"},{"#tail":"\n","#text":"its the traces used in the treebank in order to interpret LDDs. Unlike our approach, those of Xia (1999) and Hockenmaier, Bierner, and Baldridge (2004) include a substantial initial correction and clean-up of the Penn-II trees. Miyao, Ninomiya, and Tsujii (2004) and Nakanishi, Miyao, and Tsujii (2004) describe a methodology for acquiring an English HPSG from the Penn-II Treebank. Manually defined heuristics are used to automatically annotate each tree in the treebank with partially specified HPSG derivation trees: Head/argument/modifier distinctions are made for each node in the tree based on Magerman (1994) and Collins (1997); 336 O?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources the whole tree is then converted to a binary tree; heuristics are applied to deal with phenomena such as LDDs and coordination and to correct some errors in the treebank, and finally an HPSG category is assigned to each node in the tree in accordance with its CFG category. In the next phase of the process (externalization), HPSG lexical entries are automatically extracted from the annotated trees through the application of ?inverse schemata.? 4. Methodology The first step in the application of ou","@endWordPosition":"3503","@position":"23764","annotationId":"T36","@startWordPosition":"3502","@citStr":"Magerman (1994)"},{"#tail":"\n","#text":"up annotation techniques to the Penn-II Treebank (Marcus et al 1994), containing more than 1,000,000 words and 49,000 sentences. We utilize the automatic annotation algorithm of Cahill et al (2002) and Cahill, McCarthy, et al (2004) to derive a version of Penn-II in which each node in each tree is annotated with LFG functional annotations in the form of attribute-value structure equations. The algorithm uses categorial, configurational, local head, and Penn-II functional and trace information. The annotation procedure is dependent on locating the head daughter, for which an amended version of Magerman (1994) is used. The head is annotated with the LFG equation ?=?. Linguistic generalizations are provided over the left (the prefix) and the right (suffix) context of the head for each syntactic category occurring as the mother nodes of such heads. To give a simple example, the rightmost NP to the left of a VP head under an S is likely to be the subject of the sentence (? SUBJ =?), while the leftmost NP to the right of the V head of a VP is most probably the verb?s object (? OBJ =?). Cahill, McCarthy, et al (2004) provide four classes of annotation principles: one for noncoordinate configurations, on","@endWordPosition":"3784","@position":"25593","annotationId":"T37","@startWordPosition":"3783","@citStr":"Magerman (1994)"}]},"title":{"#tail":"\n","#text":"Natural Language Parsing as Statistical Pattern Recognition."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"David Magerman"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"rawString":{"#tail":"\n","#text":"Magerman, David. 1995. Statistical decision tree models for parsing. In Proceedings of the 33rd Annual Meeting for the Association of Computational Linguistics, pages 276?283, Cambridge, MA."},"#text":"\n","pages":{"#tail":"\n","#text":"276--283"},"marker":{"#tail":"\n","#text":"Magerman, 1995"},"location":{"#tail":"\n","#text":"Cambridge, MA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" has been carried out on the extraction of formalism-specific lexical resources from the Penn-II Treebank, in particular TAG, CCG, and HPSG. As these formalisms are fully lexicalized with an invariant (LTAG and CCG) or limited (HPSG) rule component, the extraction of a lexicon essentially amounts to the creation of a grammar. Chen and Vijay-Shanker (2000) explore a number of related approaches to the extraction of a lexicalized TAG from the Penn-II Treebank with the aim of constructing a statistical model for parsing. The extraction procedure utilizes a head percolation table as introduced by Magerman (1995) in combination with a variation of Collins?s (1997) approach to the differentiation between complement and adjunct. This results in the construction of a set of lexically anchored elementary trees which make up the TAG in question. The number of frame types extracted (i.e., an elementary tree without a specific lexical anchor) ranged from 2,366 to 8,996. Xia (1999) also presents a similar method for the extraction of a TAG from the Penn Treebank. The extraction procedure consists of three steps: First, the bracketing of the trees in the Penn Treebank is corrected and extended based on the app","@endWordPosition":"3175","@position":"21653","annotationId":"T38","@startWordPosition":"3174","@citStr":"Magerman (1995)"}},"title":{"#tail":"\n","#text":"Statistical decision tree models for parsing."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 33rd Annual Meeting for the Association of Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"David Magerman"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"Manning, Christopher. 1993. Automatic acquisition of a large subcategorisation dictionary from corpora. In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, pages 235?242, Columbus, OH."},"#text":"\n","pages":{"#tail":"\n","#text":"235--242"},"marker":{"#tail":"\n","#text":"Manning, 1993"},"location":{"#tail":"\n","#text":"Columbus, OH."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"is the subcategorization requirements of an entry (i.e., the arguments a predicate must take in order to form a grammatical construction). Lexicons, including subcategorization details, were traditionally produced by hand. However, as the manual construction of lexical resources is time consuming, error prone, expensive, and rarely ever complete, it is often the case that the limitations of NLP systems based on lexicalized approaches are due to bottlenecks in the lexicon component. In addition, subcategorization requirements may vary across linguistic domain or genre (Carroll and Rooth 1998). Manning (1993) argues that, aside from missing domain-specific complementation trends, dictionaries produced by hand will tend to lag behind real language use because of their static nature. Given these facts, research on automating acquisition of dictionaries for lexically based NLP systems is a particularly important issue. Aside from the extraction of theory-neutral subcategorization lexicons, there has also been work in the automatic construction of lexical resources which comply with the principles of particular linguistic theories such as LTAG, CCG, and HPSG (Chen and Vijay-Shanker 2000; Xia 1999; Hoc","@endWordPosition":"434","@position":"3218","annotationId":"T39","@startWordPosition":"433","@citStr":"Manning (1993)"},{"#tail":"\n","#text":"prepositions. Brent used hypothesis testing on binomial frequency data to statistically filter the induced frames. Ushioda et al (1993) run a finite-state NP parser on a POS-tagged corpus to calculate the relative frequency of the same six subcategorization verb classes. The experiment is limited by the fact that all prepositional phrases are treated as adjuncts. Ushioda et al (1993) employ an additional statistical method based on log-linear models and Bayes? theorem to filter the extra noise introduced by the parser and were the first to induce relative frequencies for the extracted frames. Manning (1993) attempts to improve on the approach of Brent (1993) by passing raw text through a stochastic tagger and a finite-state parser (which includes a set of simple rules for subcategorization frame recognition) in order to extract verbs and the constituents with which they co-occur. He assumes 19 different subcategorization 334 O?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources frame definitions, and the extracted frames include details of specific prepositions. The extracted frames are noisy as a result of parser errors and so are filtered using the binomial hypothesis theor","@endWordPosition":"2219","@position":"15247","annotationId":"T40","@startWordPosition":"2218","@citStr":"Manning (1993)"}]},"title":{"#tail":"\n","#text":"Automatic acquisition of a large subcategorisation dictionary from corpora."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Christopher Manning"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Marcus, Mitchell, Grace Kim, Mary Ann Marcinkiewicz, Robert MacIntyre, Mark Ferguson, Karen Katz, and Britta Schasberger. 1994. The Penn Treebank: Annotating predicate argument structure. In Proceedings of the ARPA Human Language Technology Workshop, Princeton."},"#text":"\n","marker":{"#tail":"\n","#text":"Marcus, Kim, Marcinkiewicz, MacIntyre, Ferguson, Katz, Schasberger, 1994"},"location":{"#tail":"\n","#text":"Princeton."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" f-structure information. F-structures are attribute?value structures which represent abstract syntactic information, approximating to basic predicate?argument?modifier structures. Most of the early work on automatic f-structure annotation (e.g., van Genabith, Way, and Sadler 1999; Frank 2000; Sadler, van Genabith, and Way 2000) was applied only to small data sets (fewer than 200 sentences) and was largely proof of concept. However, more recent work (Cahill et al 2002; Cahill, McCarthy, et al 2004) has presented efforts in evolving and scaling up annotation techniques to the Penn-II Treebank (Marcus et al 1994), containing more than 1,000,000 words and 49,000 sentences. We utilize the automatic annotation algorithm of Cahill et al (2002) and Cahill, McCarthy, et al (2004) to derive a version of Penn-II in which each node in each tree is annotated with LFG functional annotations in the form of attribute-value structure equations. The algorithm uses categorial, configurational, local head, and Penn-II functional and trace information. The annotation procedure is dependent on locating the head daughter, for which an amended version of Magerman (1994) is used. The head is annotated with the LFG equation","@endWordPosition":"3701","@position":"25046","annotationId":"T41","@startWordPosition":"3698","@citStr":"Marcus et al 1994"}},"title":{"#tail":"\n","#text":"The Penn Treebank: Annotating predicate argument structure."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the ARPA Human Language Technology Workshop,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Mitchell Marcus"},{"#tail":"\n","#text":"Grace Kim"},{"#tail":"\n","#text":"Mary Ann Marcinkiewicz"},{"#tail":"\n","#text":"Robert MacIntyre"},{"#tail":"\n","#text":"Mark Ferguson"},{"#tail":"\n","#text":"Karen Katz"},{"#tail":"\n","#text":"Britta Schasberger"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"note":{"#tail":"\n","#text":"Unpublished manuscript,"},"institution":{"#tail":"\n","#text":"Graduate School of Language Technology, Go?teborg, Sweden."},"rawString":{"#tail":"\n","#text":"Marinov, Svetoslav and Cecilia Hemming. 2004. Automatic Extraction of Subcategorization Frames from the Bulgarian Tree Bank. Unpublished manuscript, Graduate School of Language Technology, Go?teborg, Sweden."},"#text":"\n","marker":{"#tail":"\n","#text":"Marinov, Hemming, 2004"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"nguage with a freer word order than English and so configurational information cannot be relied upon. In a dependency tree, the set of all dependents of the verb make up a so-called observed frame, whereas a subcategorization frame contains a subset of the dependents in the observed frame. Finding subcategorization frames involves filtering adjuncts from the observed frame. This is achieved using three different hypothesis tests: BHT, log-likelihood ratio, and t-score. The system learns 137 subcategorization frames from 19,126 sentences for 914 verbs (those which occurred five times or more). Marinov and Hemming (2004) present preliminary work on the automatic extraction of subcategorization frames for Bulgarian from the BulTreeBank (Simov, Popova, and Osenova 2002). In a similar way to that of Sarkar and Zeman (2000), Marinov and Hemming?s system collects both arguments and adjuncts. It then uses the binomial log-likelihood ratio to filter incorrect frames. The BulTreebank trees are annotated with HPSG-typed feature structure information and thus contain more detail than the dependency trees. The work done for Bulgarian is small-scale, however, as Marinov and Hemming are working with a preliminary version ","@endWordPosition":"2984","@position":"20398","annotationId":"T42","@startWordPosition":"2981","@citStr":"Marinov and Hemming (2004)"}},"title":{"#tail":"\n","#text":"Automatic Extraction of Subcategorization Frames from the Bulgarian Tree Bank."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Svetoslav Marinov"},{"#tail":"\n","#text":"Cecilia Hemming"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"Meyers, Adam, Catherine MacLeod, and Ralph Grishman. 1996. Standardization of the complement/adjunct distinction. In Proceedings of the Seventh EURALEX International Conference, Go?teborg, Sweden."},"#text":"\n","marker":{"#tail":"\n","#text":"Meyers, MacLeod, Grishman, 1996"},"location":{"#tail":"\n","#text":"Go?teborg, Sweden."},"title":{"#tail":"\n","#text":"Standardization of the complement/adjunct distinction."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Seventh EURALEX International Conference,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Adam Meyers"},{"#tail":"\n","#text":"Catherine MacLeod"},{"#tail":"\n","#text":"Ralph Grishman"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Miyao, Yusuke, Takashi Ninomiya, and Jun?ichi Tsujii. 2004. Corpus-oriented grammar development for acquiring a head-driven phrase structure grammar from the Penn Treebank. In Proceedings of the First International Joint Conference on Natural Language Processing (IJCNLP-04), pages 390?398, Hainan Island, China."},"#text":"\n","pages":{"#tail":"\n","#text":"390--398"},"marker":{"#tail":"\n","#text":"Miyao, Ninomiya, Tsujii, 2004"},"location":{"#tail":"\n","#text":"Hainan Island, China."},"title":{"#tail":"\n","#text":"Corpus-oriented grammar development for acquiring a head-driven phrase structure grammar from the Penn Treebank."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the First International Joint Conference on Natural Language Processing (IJCNLP-04),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Yusuke Miyao"},{"#tail":"\n","#text":"Takashi Ninomiya"},{"#tail":"\n","#text":"Junichi Tsujii"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Nakanishi, Hiroko, Yusuke Miyao, and Jun?ichi Tsujii. 2004. Using inverse lexical rules to acquire a wide-coverage lexicalized grammar. In Proceedings of the Workshop ?Beyond Shallow Analyses?Formalisms and Statistical Modelling for Deep Analyses? at the First International Joint Conference on Natural Language Processing (IJCNLP-04), Hainan Island, China."},"#text":"\n","marker":{"#tail":"\n","#text":"Nakanishi, Miyao, Tsujii, 2004"},"location":{"#tail":"\n","#text":"Hainan Island, China."},"title":{"#tail":"\n","#text":"Using inverse lexical rules to acquire a wide-coverage lexicalized grammar."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Workshop ?Beyond Shallow Analyses?Formalisms and Statistical Modelling for Deep Analyses? at the First International Joint Conference on Natural Language Processing (IJCNLP-04),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Hiroko Nakanishi"},{"#tail":"\n","#text":"Yusuke Miyao"},{"#tail":"\n","#text":"Junichi Tsujii"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"O?Donovan, Ruth, Michael Burke, Aoife Cahill, Josef van Genabith, and Andy Way. 2004. Large-scale induction and evaluation of lexical resources from the Penn-II Treebank. In Proceedings of the 42nd Annual Meeting of the Association of Computational Linguistics, pages 368?375, Barcelona."},"#text":"\n","pages":{"#tail":"\n","#text":"368--375"},"marker":{"#tail":"\n","#text":"ODonovan, Burke, Cahill, van Genabith, Way, 2004"},"location":{"#tail":"\n","#text":"Barcelona."},"title":{"#tail":"\n","#text":"Large-scale induction and evaluation of lexical resources from the Penn-II Treebank."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 42nd Annual Meeting of the Association of Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Ruth ODonovan"},{"#tail":"\n","#text":"Michael Burke"},{"#tail":"\n","#text":"Aoife Cahill"},{"#tail":"\n","#text":"Josef van Genabith"},{"#tail":"\n","#text":"Andy Way"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Pollard, Carl and Ivan Sag. 1994. Head-Driven Phrase Structure Grammar. University of Chicago Press, Chicago."},"#text":"\n","marker":{"#tail":"\n","#text":"Pollard, Sag, 1994"},"publisher":{"#tail":"\n","#text":"University of Chicago Press,"},"location":{"#tail":"\n","#text":"Chicago."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"Including particles and prepositions, we extract 21,005 lemma frame types for 4,362 verb lemmas, with a total of 577 frame types and an average of 4.8 frame types per verb. We present a large-scale evaluation of the complete set of forms extracted against the full COMLEX resource. To our knowledge, this is the largest and most complete evaluation of subcategorization frames acquired automatically for English. 1. Introduction In modern syntactic theories (e.g., lexical-functional grammar [LFG] [Kaplan and Bresnan 1982; Bresnan 2001; Dalrymple 2001], head-driven phrase structure grammar [HPSG] [Pollard and Sag 1994], tree-adjoining grammar [TAG] [Joshi 1988], and combinatory categorial grammar [CCG] [Ades and Steedman 1982]), the lexicon is the central repository for much morphological, syntactic, and semantic information. ? National Centre for Language Technology, School of Computing, Dublin City University, Glasnevin, Dublin 9, Ireland. E-mail: {rodonovan,mburke,acahill,josef,away}@computing.dcu.ie. ? Centre for Advanced Studies, IBM, Dublin, Ireland. Submission received: 19 March 2004; revised submission received: 18 December 2004; accepted for publication: 2 March 2005. ? 2005 Association for Comput","@endWordPosition":"239","@position":"1761","annotationId":"T43","@startWordPosition":"236","@citStr":"Pollard and Sag 1994"}},"title":{"#tail":"\n","#text":"Head-Driven Phrase Structure Grammar."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Carl Pollard"},{"#tail":"\n","#text":"Ivan Sag"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1978"},"editor":{"#tail":"\n","#text":"Proctor, Paul, editor."},"rawString":{"#tail":"\n","#text":"Proctor, Paul, editor. 1978. Longman Dictionary of Contemporary English. Longman, London."},"#text":"\n","marker":{"#tail":"\n","#text":"1978"},"publisher":{"#tail":"\n","#text":"Longman,"},"location":{"#tail":"\n","#text":"London."},"booktitle":{"#tail":"\n","#text":"Longman Dictionary of Contemporary English."},"@valid":"true"},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Roland, Douglas and Daniel Jurafsky. 1998. How verb subcategorization frequencies are affected by corpus choice. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, pages 1117?1121, Montreal."},"#text":"\n","pages":{"#tail":"\n","#text":"1117--1121"},"marker":{"#tail":"\n","#text":"Roland, Jurafsky, 1998"},"location":{"#tail":"\n","#text":"Montreal."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"82.3% and 81.7%), an increase in recall (from 50.4% to 60.8% to 58.7%), and an overall increase in F-score (from 61.0% to 69.9% and 68.4%). 6.4 Penn-III (Mapping-II) Recently we have applied our methodology to the Penn-III Treebank, a more balanced corpus resource with a number of text genres. Penn-III consists of the WSJ section from Penn-II as well as a parse-annotated subset of the Brown corpus. The Brown corpus comprises 24,242 trees compiled from a variety of text genres including popular lore, general fiction, science fiction, mystery and detective fiction, and humor. It has been shown (Roland and Jurafsky 1998) that the subcategorization tendencies of verbs vary across linguistic domains. Our aim, therefore, is to increase the scope of the induced lexicon not only in terms of the verb lemmas for which there are entries, but also in terms of the frames with which they co-occur. The f-structure annotation algorithm was extended with only minor amendments to cover the parsed Brown corpus. The most important of these was the way in which we distinguish between oblique and adjunct. We noted in Section 4 that our method of assigning an oblique annotation in Penn-II was precise, albeit conservative. Becaus","@endWordPosition":"10233","@position":"66497","annotationId":"T44","@startWordPosition":"10230","@citStr":"Roland and Jurafsky 1998"},{"#tail":"\n","#text":" in higher recall scores than those achieved when we (effectively) reversed the mapping (COMLEX-LFG Mapping II [Section 6.3]). The first mapping is essentially a conflation of our more fine-grained LFG grammatical functions with the more generic COMLEX functions, while the second mapping tries to maintain as many distinctions as possible. Another drawback to using an existing external gold standard such as COMLEX to evaluate an automatically induced subcategorization lexicon is that the resources are not necessarily constructed from the same source data. As noted above, it is well documented (Roland and Jurafsky 1998) that subcategorization frames (and their frequencies) vary across domains. We have extracted frames from two sources (the WSJ and the Brown corpus), whereas COMLEX was built using examples from the San Jose Mercury News, the Brown corpus, several literary works from the Library of America, scientific abstracts from the U.S. Department of Energy, and the WSJ. For this reason, it is likely to contain a greater variety of subcategorization frames than our induced lexicon. It is also possible that because of human error, COMLEX contains subcategorization frames the validity of which are in doubt,","@endWordPosition":"11184","@position":"72499","annotationId":"T45","@startWordPosition":"11181","@citStr":"Roland and Jurafsky 1998"}]},"title":{"#tail":"\n","#text":"How verb subcategorization frequencies are affected by corpus choice."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Douglas Roland"},{"#tail":"\n","#text":"Daniel Jurafsky"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Sadler, Louisa, Josef van Genabith, and Andy Way. 2000. Automatic F-structure annotation from the AP Treebank. In Proceedings of the Fifth International Conference on LFG, Berkeley, CA, edited by Miriam Butt and Tracy Holloway King. CSLI, pages 226?243."},"#text":"\n","pages":{"#tail":"\n","#text":"226--243"},"marker":{"#tail":"\n","#text":"Sadler, van Genabith, Way, 2000"},"title":{"#tail":"\n","#text":"Automatic F-structure annotation from the AP Treebank."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Fifth International Conference on LFG, Berkeley, CA, edited by Miriam Butt and"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Louisa Sadler"},{"#tail":"\n","#text":"Josef van Genabith"},{"#tail":"\n","#text":"Andy Way"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Sarkar, Anoop and Daniel Zeman. 2000. Automatic extraction of subcategorization frames for Czech. In Proceedings of the 19th International Conference on Computational Linguistics, pages 691?697, Saarbru?cken, Germany."},"#text":"\n","pages":{"#tail":"\n","#text":"691--697"},"marker":{"#tail":"\n","#text":"Sarkar, Zeman, 2000"},"location":{"#tail":"\n","#text":"Saarbru?cken, Germany."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ts of verb occurrences in the Penn-II Treebank. This is made possible by manual examination of more than 150 different sequences of syntactic and functional tags in the treebank. Each of these sequences was categorized as a modifier or argument. Arguments were then mapped to traditional syntactic functions. For example, the tag sequence NP-SBJ denotes a mandatory argument, and its syntactic function is subject. In general, argumenthood was preferred over adjuncthoood. As Kinyon and Prolo (2002) does not include an evaluation, currently it is impossible to say how effective their technique is. Sarkar and Zeman (2000) present an approach to learn previously unknown frames for Czech from the Prague Dependency Bank (Hajic 335 Computational Linguistics Volume 31, Number 3 1998). Czech is a language with a freer word order than English and so configurational information cannot be relied upon. In a dependency tree, the set of all dependents of the verb make up a so-called observed frame, whereas a subcategorization frame contains a subset of the dependents in the observed frame. Finding subcategorization frames involves filtering adjuncts from the observed frame. This is achieved using three different hypothesi","@endWordPosition":"2863","@position":"19597","annotationId":"T46","@startWordPosition":"2860","@citStr":"Sarkar and Zeman (2000)"},{"#tail":"\n","#text":"ich the test lexicon is induced or, indeed, may omit relevant correct frames contained in the data. As a result, systems generally score better against custom-made, manually established gold standards. Carroll and Rooth (1998) achieve an F-score of 77% against the OALD when they evaluate a selection of 100 verbs with absolute frequency of greater than 500 each. Their system recognizes 15 frames, and these do not contain details of subcategorizedfor prepositions. Still, to date this is the largest number of verbs used in any of the evaluations of the systems for English described in Section 3. Sarkar and Zeman (2000) evaluate 914 Czech verbs against a custom-made gold standard and record a token recall of 88%. However, their evaluation does not examine the extracted subcategorization frames but rather the argument?adjunct distinctions posited by their system. The largest lexical evaluation we know of is that of Schulte im Walde (2002b) for German. She evaluates 3,000 German verbs with a token frequency between 10 and 2,000 against the Duden (Dudenredaktion 2001). We will refer to this work and the methods and results presented by Schulte im Walde again in Sections 6.2 and 6.3. We carried out a large-scale","@endWordPosition":"6775","@position":"44839","annotationId":"T47","@startWordPosition":"6772","@citStr":"Sarkar and Zeman (2000)"}]},"title":{"#tail":"\n","#text":"Automatic extraction of subcategorization frames for Czech."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 19th International Conference on Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Anoop Sarkar"},{"#tail":"\n","#text":"Daniel Zeman"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Schulte im Walde, Sabine. 2002a. A subcategorisation lexicon for German verbs induced from a lexicalised PCFG. In Proceedings of the Third LREC Conference, pages 1351?1357, Las Palmas, Spain."},"#text":"\n","pages":{"#tail":"\n","#text":"1351--1357"},"marker":{"#tail":"\n","#text":"Walde, Sabine, 2002"},"location":{"#tail":"\n","#text":"Las Palmas,"},"title":{"#tail":"\n","#text":"A subcategorisation lexicon for German verbs induced from a lexicalised PCFG."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Third LREC Conference,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Schulte im Walde"},{"#tail":"\n","#text":"Sabine"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Schulte im Walde, Sabine. 2002b. Evaluating verb subcategorisation frames learned by a German statistical grammar against manual definitions in the Duden Dictionary. In Proceedings of the 10th EURALEX International Congress, pages 187?197, Copenhagen."},"#text":"\n","pages":{"#tail":"\n","#text":"187--197"},"marker":{"#tail":"\n","#text":"Walde, Sabine, 2002"},"location":{"#tail":"\n","#text":"Copenhagen."},"title":{"#tail":"\n","#text":"Evaluating verb subcategorisation frames learned by a German statistical grammar against manual definitions in the Duden Dictionary."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 10th EURALEX International Congress,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Schulte im Walde"},{"#tail":"\n","#text":"Sabine"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"editor":{"#tail":"\n","#text":"In Andrew Wilson, Paul Rayson, and Tony McEnery, editors,"},"rawString":{"#tail":"\n","#text":"Simov, Kiril, Gergana Popova, and Petya Osenova. 2002. HPSG-based syntactic treebank of Bulgarian (BulTreeBank). In Andrew Wilson, Paul Rayson, and Tony McEnery, editors, A Rainbow of Corpora: Corpus Linguistics and the Languages of the World. Lincon-Europa, Munich, pages 135?142."},"#text":"\n","pages":{"#tail":"\n","#text":"135--142"},"marker":{"#tail":"\n","#text":"Simov, Popova, Osenova, 2002"},"location":{"#tail":"\n","#text":"Munich,"},"title":{"#tail":"\n","#text":"HPSG-based syntactic treebank of Bulgarian (BulTreeBank)."},"booktitle":{"#tail":"\n","#text":"A Rainbow of Corpora: Corpus Linguistics and the Languages of the World. Lincon-Europa,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kiril Simov"},{"#tail":"\n","#text":"Gergana Popova"},{"#tail":"\n","#text":"Petya Osenova"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"Ushioda, Akira, David Evans, Ted Gibson, and Alex Waibel. 1993. The Automatic acquisition of frequencies of verb subcategorization frames from tagged O?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources corpora. In SIGLEX ACL Workshop on the Acquisition of Lexical Knowledge from Text, pages 95?106, Columbus, OH."},"#text":"\n","pages":{"#tail":"\n","#text":"95--106"},"marker":{"#tail":"\n","#text":"Ushioda, Evans, Gibson, Waibel, 1993"},"location":{"#tail":"\n","#text":"Columbus, OH."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ted treebank data as their input. Typically in the approaches based on raw text, a number of subcategorization patterns are predefined, a set of verb subcategorization frame associations are hypothesized from the data, and statistical methods are applied to reliably select hypotheses for the final lexicon. Brent (1993) relies on morphosyntactic cues in the untagged Brown corpus as indicators of six predefined subcategorization frames. The frames do not include details of specific prepositions. Brent used hypothesis testing on binomial frequency data to statistically filter the induced frames. Ushioda et al (1993) run a finite-state NP parser on a POS-tagged corpus to calculate the relative frequency of the same six subcategorization verb classes. The experiment is limited by the fact that all prepositional phrases are treated as adjuncts. Ushioda et al (1993) employ an additional statistical method based on log-linear models and Bayes? theorem to filter the extra noise introduced by the parser and were the first to induce relative frequencies for the extracted frames. Manning (1993) attempts to improve on the approach of Brent (1993) by passing raw text through a stochastic tagger and a finite-state p","@endWordPosition":"2143","@position":"14768","annotationId":"T48","@startWordPosition":"2140","@citStr":"Ushioda et al (1993)"},{"#tail":"\n","#text":"cognizing passive constructions is reflected by the f-score of 96% reported in Table 3 for the PASSIVE feature. The syntactic functions COMP and XCOMP refer to clausal complements with different predicate control patterns as described in Section 2. However, as it stands, neither of these functions betrays anything about the syntactic nature of the constructs in question. Many lexicons, both automatically acquired and manually created, are more fine grained in their approaches to subcategorized clausal arguments, differentiating, for example, between a that-clause and a to + infinitive clause (Ushioda et al 1993). With only a slight modification, our system, along with the details provided by the automatically generated f-structures, allows us to extract frames with an equivalent level of detail. For example, to identify a that-clause, we use Figure 5 Automatically generated f-structure for the Penn-II Treebank string wsj 0003 23. By 1997, almost all remaining uses of cancer-causing asbestos will be outlawed. 342 O?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources Table 5 Semantic forms for the verb accept. Semantic form Occurrences Conditional probability accept([subj, obj]) 122","@endWordPosition":"5548","@position":"36752","annotationId":"T49","@startWordPosition":"5545","@citStr":"Ushioda et al 1993"}]},"title":{"#tail":"\n","#text":"The Automatic acquisition of frequencies of verb subcategorization frames from tagged O?Donovan et al Large-Scale Induction and Evaluation of Lexical Resources corpora."},"booktitle":{"#tail":"\n","#text":"In SIGLEX ACL Workshop on the Acquisition of Lexical Knowledge from Text,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Akira Ushioda"},{"#tail":"\n","#text":"David Evans"},{"#tail":"\n","#text":"Ted Gibson"},{"#tail":"\n","#text":"Alex Waibel"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"van Genabith, Josef, Louisa Sadler, and Andy Way. 1999. Data-driven compilation of LFG semantic forms. In EACL-99 Workshop on Linguistically Interpreted Corpora (LINC-99), pages 69?76, Bergen, Norway."},"#text":"\n","pages":{"#tail":"\n","#text":"69--76"},"marker":{"#tail":"\n","#text":"van Genabith, Sadler, Way, 1999"},"location":{"#tail":"\n","#text":"Bergen,"},"title":{"#tail":"\n","#text":"Data-driven compilation of LFG semantic forms."},"booktitle":{"#tail":"\n","#text":"In EACL-99 Workshop on Linguistically Interpreted Corpora (LINC-99),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Josef van Genabith"},{"#tail":"\n","#text":"Louisa Sadler"},{"#tail":"\n","#text":"Andy Way"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"note":{"#tail":"\n","#text":"Available at http://cslipublications.stanford.edu/."},"rawString":{"#tail":"\n","#text":"van Genabith, Josef, Andy Way, and Louisa Sadler. 1999. Semi-automatic generation of F-structures from Treebanks. In Proceedings of the Fourth International Conference on Lexical-Functional Grammar, Manchester, UK. Available at http://cslipublications.stanford.edu/."},"#text":"\n","marker":{"#tail":"\n","#text":"van Genabith, Way, Sadler, 1999"},"location":{"#tail":"\n","#text":"Manchester, UK."},"title":{"#tail":"\n","#text":"Semi-automatic generation of F-structures from Treebanks."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Fourth International Conference on Lexical-Functional Grammar,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Josef van Genabith"},{"#tail":"\n","#text":"Andy Way"},{"#tail":"\n","#text":"Louisa Sadler"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"PhD thesis,"},"date":{"#tail":"\n","#text":"1999"},"institution":{"#tail":"\n","#text":"University of Stuttgart,"},"rawString":{"#tail":"\n","#text":"Wauschkuhn, Oliver. 1999. Automatische Extraktion von Verbvalenzen aus deutschen Textkorpora [Automatic Extraction of Verb Valence from German Text Corpora]. PhD thesis, University of Stuttgart, Germany."},"#text":"\n","marker":{"#tail":"\n","#text":"Wauschkuhn, 1999"},"title":{"#tail":"\n","#text":"Automatische Extraktion von Verbvalenzen aus deutschen Textkorpora [Automatic Extraction of Verb Valence from German Text Corpora]."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Oliver Wauschkuhn"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"Xia, Fei. 1999. Extracting tree adjoining grammars from bracketed corpora. In Fifth Natural Language Processing Pacific Rim Symposium (NLPRS-99), Beijing, China."},"#text":"\n","marker":{"#tail":"\n","#text":"Xia, 1999"},"location":{"#tail":"\n","#text":"Beijing, China."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"anning (1993) argues that, aside from missing domain-specific complementation trends, dictionaries produced by hand will tend to lag behind real language use because of their static nature. Given these facts, research on automating acquisition of dictionaries for lexically based NLP systems is a particularly important issue. Aside from the extraction of theory-neutral subcategorization lexicons, there has also been work in the automatic construction of lexical resources which comply with the principles of particular linguistic theories such as LTAG, CCG, and HPSG (Chen and Vijay-Shanker 2000; Xia 1999; Hockenmaier, Bierner, and Baldridge 2004; Nakanishi, Miyao, and Tsujii 2004). In this article we present an approach to automating the process of lexical acquisition for LFG (i.e., grammatical-function-based systems). However, our approach also generalizes to CFG category-based approaches. In LFG, subcategorization requirements are enforced through semantic forms specifying which grammatical functions are required by a particular predicate. Our approach is based on earlier work on LFG semantic form extraction (van Genabith, Sadler, and Way 1999) and recent progress in automatically annotatin","@endWordPosition":"520","@position":"3813","annotationId":"T50","@startWordPosition":"519","@citStr":"Xia 1999"},{"#tail":"\n","#text":"r of related approaches to the extraction of a lexicalized TAG from the Penn-II Treebank with the aim of constructing a statistical model for parsing. The extraction procedure utilizes a head percolation table as introduced by Magerman (1995) in combination with a variation of Collins?s (1997) approach to the differentiation between complement and adjunct. This results in the construction of a set of lexically anchored elementary trees which make up the TAG in question. The number of frame types extracted (i.e., an elementary tree without a specific lexical anchor) ranged from 2,366 to 8,996. Xia (1999) also presents a similar method for the extraction of a TAG from the Penn Treebank. The extraction procedure consists of three steps: First, the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of Magerman (1994) and Collins (1997). Then the elementary trees are read off in a quite straightforward manner. Finally any invalid elementary trees produced as a result of annotation errors in the treebank are filtered out using linguistic heuristics. The number of frame types extracted by Xia (1999) ranged from 3,014 to 6,099. Hockenmaier, Bierner, and Ba","@endWordPosition":"3233","@position":"22021","annotationId":"T51","@startWordPosition":"3232","@citStr":"Xia (1999)"},{"#tail":"\n","#text":" a method for the automatic extraction of a large syntactic CCG lexicon from the Penn-II Treebank. For each tree, the algorithm annotates the nodes with CCG categories in a top-down recursive manner. The first step is to label each node as either a head, complement, or adjunct based on the approaches of Magerman (1994) and Collins (1997). Each node is subsequently assigned the relevant category based on its constituent type and surface configuration. The algorithm handles ?like? coordination and exploits the traces used in the treebank in order to interpret LDDs. Unlike our approach, those of Xia (1999) and Hockenmaier, Bierner, and Baldridge (2004) include a substantial initial correction and clean-up of the Penn-II trees. Miyao, Ninomiya, and Tsujii (2004) and Nakanishi, Miyao, and Tsujii (2004) describe a methodology for acquiring an English HPSG from the Penn-II Treebank. Manually defined heuristics are used to automatically annotate each tree in the treebank with partially specified HPSG derivation trees: Head/argument/modifier distinctions are made for each node in the tree based on Magerman (1994) and Collins (1997); 336 O?Donovan et al Large-Scale Induction and Evaluation of Lexical ","@endWordPosition":"3430","@position":"23253","annotationId":"T52","@startWordPosition":"3429","@citStr":"Xia (1999)"},{"#tail":"\n","#text":" those containing XCOMPs and those containing OBJ2S. Out of 80 fns, 14 were judged to be incorrect when manually examined. These can be broken down as follows: one intransitive frame, three ditransitive frames, three frames containing a COMP, and seven frames containing an oblique were found to be invalid. 7. Lexical Accession Rates In addition to evaluating the quality of our extracted semantic forms, we also examined the rate at which they are induced. This can be expressed as a measure of the coverage of the induced lexicon on new data. Following Hockenmaier, Bierner, and Baldridge (2002), Xia (1999), and Miyao, Ninomiya, and Tsujii (2004), we extract a reference lexicon from Sections 02?21 of the WSJ. We then compare this to a test lexicon from Section 23. Table 27 shows the results of the evaluation of the coverage of an induced lexicon for verbs only. There is a corresponding semantic form in the reference lexicon for 89.89% of the verbs in Section 23. 10.11% of the entries in the test lexicon did not appear in the reference lexicon. Within this group, we can distinguish between known words, which have an entry in the reference lexicon, and unknown words, which do not exist at all in t","@endWordPosition":"11729","@position":"75979","annotationId":"T53","@startWordPosition":"11728","@citStr":"Xia (1999)"}]},"title":{"#tail":"\n","#text":"Extracting tree adjoining grammars from bracketed corpora."},"booktitle":{"#tail":"\n","#text":"In Fifth Natural Language Processing Pacific Rim Symposium (NLPRS-99),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Fei Xia"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Xue, Nianwen, Fu-Dong Chiou, and Martha Palmer. 2002. Building a large-scale annotated Chinese corpus. In Proceedings of the 19th International Conference on Computational Linguistics (COLING 2002), Taipei, Taiwan."},"#text":"\n","marker":{"#tail":"\n","#text":"Xue, Chiou, Palmer, 2002"},"location":{"#tail":"\n","#text":"Taipei, Taiwan."},"title":{"#tail":"\n","#text":"Building a large-scale annotated Chinese corpus."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 19th International Conference on Computational Linguistics (COLING"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Nianwen Xue"},{"#tail":"\n","#text":"Fu-Dong Chiou"},{"#tail":"\n","#text":"Martha Palmer"}]}}]}}]}}
