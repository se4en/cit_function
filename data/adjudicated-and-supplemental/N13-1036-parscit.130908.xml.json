{"algorithms":{"#text":"\n","@version":"110505","algorithm":{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Chris Callison-Burch, Philipp Koehn, and Miles Osborne. 2006. Improved statistical machine translation using paraphrases. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 17\u201324."},"#text":"\n","pages":{"#tail":"\n","#text":"17--24"},"marker":{"#tail":"\n","#text":"Callison-Burch, Koehn, Osborne, 2006"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of \u201cresource-rich\u201d related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a morphologically rich language, Malay, to extend the phrase table in a Malay-toEnglish SMT system. Pivoting on MSA or acquiring more DA-English data? Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data. They used Amazon\u2019s Mechanical Turk (MTurk) to create a DAEnglish parallel corpus of 1.5M words and added it to a 150M MSA-English parallel corpus to create the training corpus of their SMT system. They also used MTurk to translate their d","@endWordPosition":"1702","@position":"10460","annotationId":"T1","@startWordPosition":"1699","@citStr":"Callison-Burch et al., 2006"}},"title":{"#tail":"\n","#text":"Improved statistical machine translation using paraphrases."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Chris Callison-Burch"},{"#tail":"\n","#text":"Philipp Koehn"},{"#tail":"\n","#text":"Miles Osborne"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2010"},"rawString":{"#tail":"\n","#text":"Jinhua Du, Jie Jiang, and Andy Way. 2010. Facilitating translation using source language paraphrase lattices. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP\u201910, pages 420\u2013429, Cambridge, Massachusetts."},"#text":"\n","pages":{"#tail":"\n","#text":"420--429"},"marker":{"#tail":"\n","#text":"Du, Jiang, Way, 2010"},"location":{"#tail":"\n","#text":"Cambridge, Massachusetts."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ogical analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of \u201cresource-rich\u201d related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a morphologically rich language, Malay, to extend the phrase table in a Malay-toEnglish SMT system. Pivoting on MSA or acquiring more DA-English data? Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data. They used Amazon\u2019s Mechanical Turk (MTurk) to create a DAEnglish parallel corpus of 1.5M words and added it to a 150M MSA-English parallel corpus to create the training corpus of their SMT system. They also used MTurk to translate their dialectal test set ","@endWordPosition":"1706","@position":"10478","annotationId":"T2","@startWordPosition":"1703","@citStr":"Du et al., 2010"}},"title":{"#tail":"\n","#text":"Facilitating translation using source language paraphrase lattices."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP\u201910,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Jinhua Du"},{"#tail":"\n","#text":"Jie Jiang"},{"#tail":"\n","#text":"Andy Way"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"Nizar Habash and Owen Rambow. 2005. Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL\u201905), pages 573\u2013580, Ann Arbor, Michigan."},"#text":"\n","pages":{"#tail":"\n","#text":"573--580"},"marker":{"#tail":"\n","#text":"Habash, Rambow, 2005"},"location":{"#tail":"\n","#text":"Ann Arbor, Michigan."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" MSA words and construct a lattice of possible sentences. ELISSA uses a language model to rank and select the generated sentences. ELISSA supports untokenized (raw) input only. ELISSA supports three types of output: top-1 choice, an n-best list or a map file that maps source words/phrases to target phrases. The top-1 and nbest lists are determined using an untokenized MSA language model to rank the paths in the MSA translation output lattice. This variety of output types makes it easy to plug ELISSA with other systems and to use it as a DA preprocessing tool for other MSA systems, e.g., MADA (Habash and Rambow, 2005) or AMIRA (Diab et al., 2007). ELISSA\u2019s approach consists of three major steps preceded by a preprocessing and normalization step, that prepares the input text to be handled (e.g., UTF8 cleaning, Alif/Ya normalization, word-lengthening normalization), and followed by a post-processing step, that produces the output in the desired form (e.g., encoding choice). The three major steps are Selection, Translation, and Language Modeling. 5.1 Selection In the first step, ELISSA identifies which words or phrases to paraphrase and which words or phrases to leave as is. ELISSA provides different methods ","@endWordPosition":"2291","@position":"13943","annotationId":"T3","@startWordPosition":"2288","@citStr":"Habash and Rambow, 2005"},{"#tail":"\n","#text":"model for our system is trained on the English side of the bitext augmented with English Gigaword (Graff and Cieri, 2003). We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. The English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Habash and Rambow, 2005; Roth et al., 2008). The Arabic text is also Alif/Ya normalized. MADA-produced Arabic lemmas are used for word alignment. We use the same development (dev) and test sets used by Salloum and Habash (2011) (we will call them speech-dev and speech-test, respectively) and we compare to them in the next sections. We also evaluate on two web-crawled blind test sets: the Levantine test set presented in Zbib et al. (2012) (we will call it web-lev-test) and the Egyptian Dev-MTv2 development data of the DARPA BOLT program (we will call it web-egy-test). The speech-dev set has 1,496 sentences with 32,04","@endWordPosition":"3812","@position":"23471","annotationId":"T4","@startWordPosition":"3808","@citStr":"Habash and Rambow, 2005"}]},"title":{"#tail":"\n","#text":"Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL\u201905),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Nizar Habash"},{"#tail":"\n","#text":"Owen Rambow"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Philipp Koehn, Hieu Hoang, Alexandra Birch, Christopher Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Christopher Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177\u2013180, Prague, Czech Republic."},"#text":"\n","pages":{"#tail":"\n","#text":"177--180"},"marker":{"#tail":"\n","#text":"Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007"},"location":{"#tail":"\n","#text":"Prague, Czech Republic."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"is copied from Table 1 for convenience. The second part shows ELISSA\u2019s output on the dialectal sentence and its Google Translate translation. The produced MSA is not perfect, but is clearly an improvement over doing nothing as far as usability for MT into English. 6 Evaluation In this section, we present two evaluations of ELISSA. The first is an extrinsic evaluation of ELISSA as part of MSA-pivoting for DA-to-English SMT. And the second is an intrinsic evaluation of the quality of ELISSA\u2019s MSA output. 6.1 DA-English MT Evaluation 6.1.1 Experimental Setup We use the open-source Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system trained on mostly MSA data (64M words on the Arabic side) obtained from several LDC corpora including some limited DA data. Our system uses a standard phrase-based architecture. The parallel corpus is word-aligned using GIZA++ (Och and Ney, 2003). Phrase translations of up to 10 words are extracted in the Moses phrase table. The language model for our system is trained on the English side of the bitext augmented with English Gigaword (Graff and Cieri, 2003). We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to maxim","@endWordPosition":"3644","@position":"22472","annotationId":"T5","@startWordPosition":"3641","@citStr":"Koehn et al., 2007"}},"title":{"#tail":"\n","#text":"Moses: open source toolkit for statistical machine translation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,"},"@valid":"false","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Philipp Koehn"},{"#tail":"\n","#text":"Hieu Hoang"},{"#tail":"\n","#text":"Alexandra Birch"},{"#tail":"\n","#text":"Christopher Callison-Burch"},{"#tail":"\n","#text":"Marcello Federico"},{"#tail":"\n","#text":"Nicola Bertoldi"},{"#tail":"\n","#text":"Brooke Cowan"},{"#tail":"\n","#text":"Wade Shen"},{"#tail":"\n","#text":"Christine Moran"},{"#tail":"\n","#text":"Richard Zens"},{"#tail":"\n","#text":"Christopher Dyer"},{"#tail":"\n","#text":"Ondrej Bojar"},{"#tail":"\n","#text":"Alexandra Constantin"},{"#tail":"\n","#text":"Evan Herbst"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Shankar Kumar, Franz J. Och, and Wolfgang Macherey. 2007. Improving word alignment with bridge languages. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 42\u201350, Prague, Czech Republic."},"#text":"\n","pages":{"#tail":"\n","#text":"42--50"},"marker":{"#tail":"\n","#text":"Kumar, Och, Macherey, 2007"},"location":{"#tail":"\n","#text":"Prague, Czech Republic."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of \u201cresource-rich\u201d related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a morphologically rich language, Malay, to extend the phrase table in a Malay-toEnglish SMT system. Pivoting on MSA or acquiring more DA-English data? Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data. They used Amazon\u2019s Mechanical Turk (MTurk) to create a DAEnglish parallel corpus of 1","@endWordPosition":"1675","@position":"10307","annotationId":"T6","@startWordPosition":"1672","@citStr":"Kumar et al., 2007"}},"title":{"#tail":"\n","#text":"Improving word alignment with bridge languages."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Shankar Kumar"},{"#tail":"\n","#text":"Franz J Och"},{"#tail":"\n","#text":"Wolfgang Macherey"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2011"},"rawString":{"#tail":"\n","#text":"Preslav Nakov and Hwee Tou Ng. 2011. Translating from Morphologically Complex Languages: A Paraphrase-Based Approach. In Proceedings of the Meeting of the Association for Computational Linguistics (ACL\u20192011), Portland, Oregon, USA."},"#text":"\n","marker":{"#tail":"\n","#text":"Nakov, Ng, 2011"},"location":{"#tail":"\n","#text":"Portland, Oregon, USA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"d a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of \u201cresource-rich\u201d related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a morphologically rich language, Malay, to extend the phrase table in a Malay-toEnglish SMT system. Pivoting on MSA or acquiring more DA-English data? Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data. They used Amazon\u2019s Mechanical Turk (MTurk) to create a DAEnglish parallel corpus of 1.5M words and added it to a 150M MSA-English parallel corpus to create the training corpus of their SMT system. They also used MTurk to translate their dialectal test set to MSA in order to compare the MSA-pivoting appro","@endWordPosition":"1716","@position":"10527","annotationId":"T7","@startWordPosition":"1713","@citStr":"Nakov and Ng (2011)"}},"title":{"#tail":"\n","#text":"Translating from Morphologically Complex Languages: A Paraphrase-Based Approach."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Meeting of the Association for Computational Linguistics (ACL\u20192011),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Preslav Nakov"},{"#tail":"\n","#text":"Hwee Tou Ng"}]}},{"volume":{"#tail":"\n","#text":"29"},"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"F. J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19\u201351."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"1"},"marker":{"#tail":"\n","#text":"Och, Ney, 2003"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"is section, we present two evaluations of ELISSA. The first is an extrinsic evaluation of ELISSA as part of MSA-pivoting for DA-to-English SMT. And the second is an intrinsic evaluation of the quality of ELISSA\u2019s MSA output. 6.1 DA-English MT Evaluation 6.1.1 Experimental Setup We use the open-source Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system trained on mostly MSA data (64M words on the Arabic side) obtained from several LDC corpora including some limited DA data. Our system uses a standard phrase-based architecture. The parallel corpus is word-aligned using GIZA++ (Och and Ney, 2003). Phrase translations of up to 10 words are extracted in the Moses phrase table. The language model for our system is trained on the English side of the bitext augmented with English Gigaword (Graff and Cieri, 2003). We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. The English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization s","@endWordPosition":"3691","@position":"22754","annotationId":"T8","@startWordPosition":"3688","@citStr":"Och and Ney, 2003"}},"title":{"#tail":"\n","#text":"A systematic comparison of various statistical alignment models."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"F J Och"},{"#tail":"\n","#text":"H Ney"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2011"},"rawString":{"#tail":"\n","#text":"Wael Salloum and Nizar Habash. 2011. Dialectal to Standard Arabic Paraphrasing to Improve ArabicEnglish Statistical Machine Translation. In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties, pages 10\u201321, Edinburgh, Scotland."},"#text":"\n","pages":{"#tail":"\n","#text":"10--21"},"marker":{"#tail":"\n","#text":"Salloum, Habash, 2011"},"location":{"#tail":"\n","#text":"Edinburgh, Scotland."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"es of MSA (e.g., optional diacritics and spelling inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DAEnglish corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 349 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-","@endWordPosition":"1292","@position":"7914","annotationId":"T9","@startWordPosition":"1289","@citStr":"Salloum and Habash, 2011"},{"#tail":"\n","#text":".g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of \u201cresource-rich\u201d related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a","@endWordPosition":"1626","@position":"9990","annotationId":"T10","@startWordPosition":"1623","@citStr":"Salloum and Habash, 2011"},{"#tail":"\n","#text":" to study interactions between the two types of solutions in the future. Our work is most similar to Sawaf (2010)\u2019s MSApivoting approach. In his approach, DA is normalized into MSA using character-based DA normalization rules, a DA morphological analyzer, a DA normalization decoder that relies on language models, and a lexicon. Similarly, we use some character normalization rules, a DA morphological analyzer, and DA-MSA dictionaries. In contrast, we use hand-written morphosyntactic transfer rules that focus on translating DA morphemes and lemmas to their MSA equivalents. In our previous work (Salloum and Habash, 2011; Salloum and Habash, 2012), we applied our approach to tokenized Arabic and our DA-MSA transfer component used feature transfer rules only. We did not use a language model to pick the best path; instead we kept the ambiguity in the lattice and passed it to our SMT system. In contrast, in this paper, we run ELISSA on untokenized Arabic, we use 350 feature, lemma, and surface form transfer rules, and we pick the best path of the generated MSA lattice through a language model. Certain aspects of our approach are similar to Riesa and Yarowsky (2006)\u2019s, in that we use morphological analysis for DA","@endWordPosition":"2014","@position":"12362","annotationId":"T11","@startWordPosition":"2011","@citStr":"Salloum and Habash, 2011"},{"#tail":"\n","#text":"ds. Selection methods are classified into Word-based selection and Phrase-based selection. Word-based selection. Methods of this type fall in the following categories: a. User token-based selection: The user can mark specific words for selection using the tag \u2018/DIA\u2019 (stands for \u2018dialect\u2019) after each word to select. b. User type-based selection: The user can specify a list of words to select from, e.g., OOVs. Also the user can provide a list of words and their frequencies and specify a cut-off threshold to prevent selecting a frequent word. c. Morphology-based word selection: ELISSA uses ADAM (Salloum and Habash, 2011) to select words that have DA analyses only (DIAONLY) or DA/MSA analyses (DIAMSA). d. Dictionary-based selection: ELISSA selects words based on their existence in the DA side of our DA-MSA dictionaries. e. All: ELISSA selects every word in an input sentence. Phrase-based selection. This selection type uses hand-written rules to identify dialectal multi-word constructions that are mappable to single or multiword MSA constructions. The current count of these rules is 25. Table 2 presents some rule categories and related examples. In the current version of ELISSA, words can be selected using eith","@endWordPosition":"2507","@position":"15335","annotationId":"T12","@startWordPosition":"2504","@citStr":"Salloum and Habash, 2011"},{"#tail":"\n","#text":"es] Enclitic w+ mA rAHw +l +A conj+ [neg] [rAH PV subj:3MP] +prep +pron3FS and+ not they go +to +her Transfer Word 1 Word 2 Word 3 Proclitics [Lemma & Features] [Lemma & Features] [Lemma & Features] Enclitic conj+ [ lam ] [ðahab IV subj:3MP] [ Alý ] +pron3FS and+ did not they go to +her Generation w+ lm yðhbwA Aly +hA MSA Phrase AîD�Ë@� @ñJ.ë .E ÕËð wlm yðhbwA ˇAlyhA \u2018And they did not go to her\u2019 Figure 1: An example illustrating the analysis-transfer-generation steps to translate a dialectal multi-word expression into its MSA equivalent phrase. dialectal morphological analysis step uses ADAM (Salloum and Habash, 2011) to get a list of dialectal analyses. The morphosyntactic transfer step uses lemma-to-lemma (L2L) and features-tofeatures (F2F) transfer rules to change lemmas, clitics or features, and even split up the dialectal word into multiple MSA word analyses (such as splitting negation words and indirect objects). The MSA morphological generation step uses the general tokenizer/generator TOKAN (Habash, 2007) to generate untokenized surface form words. For more details, see Salloum and Habash (2011). Phrase-based translation. Unlike the wordbased translation techniques which map single DA words to sing","@endWordPosition":"2971","@position":"18395","annotationId":"T13","@startWordPosition":"2968","@citStr":"Salloum and Habash, 2011"},{"#tail":"\n","#text":"hts are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. The English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Habash and Rambow, 2005; Roth et al., 2008). The Arabic text is also Alif/Ya normalized. MADA-produced Arabic lemmas are used for word alignment. We use the same development (dev) and test sets used by Salloum and Habash (2011) (we will call them speech-dev and speech-test, respectively) and we compare to them in the next sections. We also evaluate on two web-crawled blind test sets: the Levantine test set presented in Zbib et al. (2012) (we will call it web-lev-test) and the Egyptian Dev-MTv2 development data of the DARPA BOLT program (we will call it web-egy-test). The speech-dev set has 1,496 sentences with 32,047 untokenized Arabic words. The speech-test set has 1,568 sentences with 353 32,492 untokenized Arabic words. The web-levtest set has 2,728 sentences with 21,179 untokenized Arabic words. The web-egy-test","@endWordPosition":"3846","@position":"23675","annotationId":"T14","@startWordPosition":"3843","@citStr":"Salloum and Habash (2011)"},{"#tail":"\n","#text":"ng phrases improve the three best performers of word-based selection. The best performer, shown in the last raw, suggests using phrase-based selection and restricted word-based selection. The restriction is to include OOV words and selected low frequency words that have at least one dialectal analysis or appear in our dialectal dictionaries. Comparing the best performer to the OOV selection mode system shows that translating low frequency in-vocabulary dialectal words and phrases to their MSA paraphrases can improve the English translation. This is a similar conclusion to our previous work in Salloum and Habash (2011). 6.1.3 Results on the Blind Test Sets We run the system settings that performed best on the dev set along with the OOV selection mode system on the three blind test set. Results and their differences from the baseline are reported in Table 5. We see that OOV selection mode system always improves over the baseline for all test sets. Also, the best performer on the dev is the best performer for all test sets. The improvements of the best performer over the OOV selection mode system on all test sets confirm that translating low frequency invocabulary dialectal words and phrases to their MSA para","@endWordPosition":"4940","@position":"30360","annotationId":"T15","@startWordPosition":"4937","@citStr":"Salloum and Habash (2011)"}]},"title":{"#tail":"\n","#text":"Dialectal to Standard Arabic Paraphrasing to Improve ArabicEnglish Statistical Machine Translation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Wael Salloum"},{"#tail":"\n","#text":"Nizar Habash"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2011"},"rawString":{"#tail":"\n","#text":"Wael Salloum and Nizar Habash. 2011. Dialectal to Standard Arabic Paraphrasing to Improve ArabicEnglish Statistical Machine Translation. In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties, pages 10\u201321, Edinburgh, Scotland."},"#text":"\n","pages":{"#tail":"\n","#text":"10--21"},"marker":{"#tail":"\n","#text":"Salloum, Habash, 2011"},"location":{"#tail":"\n","#text":"Edinburgh, Scotland."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"es of MSA (e.g., optional diacritics and spelling inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DAEnglish corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 349 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-","@endWordPosition":"1292","@position":"7914","annotationId":"T16","@startWordPosition":"1289","@citStr":"Salloum and Habash, 2011"},{"#tail":"\n","#text":".g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of \u201cresource-rich\u201d related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a","@endWordPosition":"1626","@position":"9990","annotationId":"T17","@startWordPosition":"1623","@citStr":"Salloum and Habash, 2011"},{"#tail":"\n","#text":" to study interactions between the two types of solutions in the future. Our work is most similar to Sawaf (2010)\u2019s MSApivoting approach. In his approach, DA is normalized into MSA using character-based DA normalization rules, a DA morphological analyzer, a DA normalization decoder that relies on language models, and a lexicon. Similarly, we use some character normalization rules, a DA morphological analyzer, and DA-MSA dictionaries. In contrast, we use hand-written morphosyntactic transfer rules that focus on translating DA morphemes and lemmas to their MSA equivalents. In our previous work (Salloum and Habash, 2011; Salloum and Habash, 2012), we applied our approach to tokenized Arabic and our DA-MSA transfer component used feature transfer rules only. We did not use a language model to pick the best path; instead we kept the ambiguity in the lattice and passed it to our SMT system. In contrast, in this paper, we run ELISSA on untokenized Arabic, we use 350 feature, lemma, and surface form transfer rules, and we pick the best path of the generated MSA lattice through a language model. Certain aspects of our approach are similar to Riesa and Yarowsky (2006)\u2019s, in that we use morphological analysis for DA","@endWordPosition":"2014","@position":"12362","annotationId":"T18","@startWordPosition":"2011","@citStr":"Salloum and Habash, 2011"},{"#tail":"\n","#text":"ds. Selection methods are classified into Word-based selection and Phrase-based selection. Word-based selection. Methods of this type fall in the following categories: a. User token-based selection: The user can mark specific words for selection using the tag \u2018/DIA\u2019 (stands for \u2018dialect\u2019) after each word to select. b. User type-based selection: The user can specify a list of words to select from, e.g., OOVs. Also the user can provide a list of words and their frequencies and specify a cut-off threshold to prevent selecting a frequent word. c. Morphology-based word selection: ELISSA uses ADAM (Salloum and Habash, 2011) to select words that have DA analyses only (DIAONLY) or DA/MSA analyses (DIAMSA). d. Dictionary-based selection: ELISSA selects words based on their existence in the DA side of our DA-MSA dictionaries. e. All: ELISSA selects every word in an input sentence. Phrase-based selection. This selection type uses hand-written rules to identify dialectal multi-word constructions that are mappable to single or multiword MSA constructions. The current count of these rules is 25. Table 2 presents some rule categories and related examples. In the current version of ELISSA, words can be selected using eith","@endWordPosition":"2507","@position":"15335","annotationId":"T19","@startWordPosition":"2504","@citStr":"Salloum and Habash, 2011"},{"#tail":"\n","#text":"es] Enclitic w+ mA rAHw +l +A conj+ [neg] [rAH PV subj:3MP] +prep +pron3FS and+ not they go +to +her Transfer Word 1 Word 2 Word 3 Proclitics [Lemma & Features] [Lemma & Features] [Lemma & Features] Enclitic conj+ [ lam ] [ðahab IV subj:3MP] [ Alý ] +pron3FS and+ did not they go to +her Generation w+ lm yðhbwA Aly +hA MSA Phrase AîD�Ë@� @ñJ.ë .E ÕËð wlm yðhbwA ˇAlyhA \u2018And they did not go to her\u2019 Figure 1: An example illustrating the analysis-transfer-generation steps to translate a dialectal multi-word expression into its MSA equivalent phrase. dialectal morphological analysis step uses ADAM (Salloum and Habash, 2011) to get a list of dialectal analyses. The morphosyntactic transfer step uses lemma-to-lemma (L2L) and features-tofeatures (F2F) transfer rules to change lemmas, clitics or features, and even split up the dialectal word into multiple MSA word analyses (such as splitting negation words and indirect objects). The MSA morphological generation step uses the general tokenizer/generator TOKAN (Habash, 2007) to generate untokenized surface form words. For more details, see Salloum and Habash (2011). Phrase-based translation. Unlike the wordbased translation techniques which map single DA words to sing","@endWordPosition":"2971","@position":"18395","annotationId":"T20","@startWordPosition":"2968","@citStr":"Salloum and Habash, 2011"},{"#tail":"\n","#text":"hts are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. The English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Habash and Rambow, 2005; Roth et al., 2008). The Arabic text is also Alif/Ya normalized. MADA-produced Arabic lemmas are used for word alignment. We use the same development (dev) and test sets used by Salloum and Habash (2011) (we will call them speech-dev and speech-test, respectively) and we compare to them in the next sections. We also evaluate on two web-crawled blind test sets: the Levantine test set presented in Zbib et al. (2012) (we will call it web-lev-test) and the Egyptian Dev-MTv2 development data of the DARPA BOLT program (we will call it web-egy-test). The speech-dev set has 1,496 sentences with 32,047 untokenized Arabic words. The speech-test set has 1,568 sentences with 353 32,492 untokenized Arabic words. The web-levtest set has 2,728 sentences with 21,179 untokenized Arabic words. The web-egy-test","@endWordPosition":"3846","@position":"23675","annotationId":"T21","@startWordPosition":"3843","@citStr":"Salloum and Habash (2011)"},{"#tail":"\n","#text":"ng phrases improve the three best performers of word-based selection. The best performer, shown in the last raw, suggests using phrase-based selection and restricted word-based selection. The restriction is to include OOV words and selected low frequency words that have at least one dialectal analysis or appear in our dialectal dictionaries. Comparing the best performer to the OOV selection mode system shows that translating low frequency in-vocabulary dialectal words and phrases to their MSA paraphrases can improve the English translation. This is a similar conclusion to our previous work in Salloum and Habash (2011). 6.1.3 Results on the Blind Test Sets We run the system settings that performed best on the dev set along with the OOV selection mode system on the three blind test set. Results and their differences from the baseline are reported in Table 5. We see that OOV selection mode system always improves over the baseline for all test sets. Also, the best performer on the dev is the best performer for all test sets. The improvements of the best performer over the OOV selection mode system on all test sets confirm that translating low frequency invocabulary dialectal words and phrases to their MSA para","@endWordPosition":"4940","@position":"30360","annotationId":"T22","@startWordPosition":"4937","@citStr":"Salloum and Habash (2011)"}]},"title":{"#tail":"\n","#text":"Dialectal to Standard Arabic Paraphrasing to Improve ArabicEnglish Statistical Machine Translation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Wael Salloum"},{"#tail":"\n","#text":"Nizar Habash"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2011"},"rawString":{"#tail":"\n","#text":"Wael Salloum and Nizar Habash. 2011. Dialectal to Standard Arabic Paraphrasing to Improve ArabicEnglish Statistical Machine Translation. In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties, pages 10\u201321, Edinburgh, Scotland."},"#text":"\n","pages":{"#tail":"\n","#text":"10--21"},"marker":{"#tail":"\n","#text":"Salloum, Habash, 2011"},"location":{"#tail":"\n","#text":"Edinburgh, Scotland."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"es of MSA (e.g., optional diacritics and spelling inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DAEnglish corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 349 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-","@endWordPosition":"1292","@position":"7914","annotationId":"T23","@startWordPosition":"1289","@citStr":"Salloum and Habash, 2011"},{"#tail":"\n","#text":".g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of \u201cresource-rich\u201d related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a","@endWordPosition":"1626","@position":"9990","annotationId":"T24","@startWordPosition":"1623","@citStr":"Salloum and Habash, 2011"},{"#tail":"\n","#text":" to study interactions between the two types of solutions in the future. Our work is most similar to Sawaf (2010)\u2019s MSApivoting approach. In his approach, DA is normalized into MSA using character-based DA normalization rules, a DA morphological analyzer, a DA normalization decoder that relies on language models, and a lexicon. Similarly, we use some character normalization rules, a DA morphological analyzer, and DA-MSA dictionaries. In contrast, we use hand-written morphosyntactic transfer rules that focus on translating DA morphemes and lemmas to their MSA equivalents. In our previous work (Salloum and Habash, 2011; Salloum and Habash, 2012), we applied our approach to tokenized Arabic and our DA-MSA transfer component used feature transfer rules only. We did not use a language model to pick the best path; instead we kept the ambiguity in the lattice and passed it to our SMT system. In contrast, in this paper, we run ELISSA on untokenized Arabic, we use 350 feature, lemma, and surface form transfer rules, and we pick the best path of the generated MSA lattice through a language model. Certain aspects of our approach are similar to Riesa and Yarowsky (2006)\u2019s, in that we use morphological analysis for DA","@endWordPosition":"2014","@position":"12362","annotationId":"T25","@startWordPosition":"2011","@citStr":"Salloum and Habash, 2011"},{"#tail":"\n","#text":"ds. Selection methods are classified into Word-based selection and Phrase-based selection. Word-based selection. Methods of this type fall in the following categories: a. User token-based selection: The user can mark specific words for selection using the tag \u2018/DIA\u2019 (stands for \u2018dialect\u2019) after each word to select. b. User type-based selection: The user can specify a list of words to select from, e.g., OOVs. Also the user can provide a list of words and their frequencies and specify a cut-off threshold to prevent selecting a frequent word. c. Morphology-based word selection: ELISSA uses ADAM (Salloum and Habash, 2011) to select words that have DA analyses only (DIAONLY) or DA/MSA analyses (DIAMSA). d. Dictionary-based selection: ELISSA selects words based on their existence in the DA side of our DA-MSA dictionaries. e. All: ELISSA selects every word in an input sentence. Phrase-based selection. This selection type uses hand-written rules to identify dialectal multi-word constructions that are mappable to single or multiword MSA constructions. The current count of these rules is 25. Table 2 presents some rule categories and related examples. In the current version of ELISSA, words can be selected using eith","@endWordPosition":"2507","@position":"15335","annotationId":"T26","@startWordPosition":"2504","@citStr":"Salloum and Habash, 2011"},{"#tail":"\n","#text":"es] Enclitic w+ mA rAHw +l +A conj+ [neg] [rAH PV subj:3MP] +prep +pron3FS and+ not they go +to +her Transfer Word 1 Word 2 Word 3 Proclitics [Lemma & Features] [Lemma & Features] [Lemma & Features] Enclitic conj+ [ lam ] [ðahab IV subj:3MP] [ Alý ] +pron3FS and+ did not they go to +her Generation w+ lm yðhbwA Aly +hA MSA Phrase AîD�Ë@� @ñJ.ë .E ÕËð wlm yðhbwA ˇAlyhA \u2018And they did not go to her\u2019 Figure 1: An example illustrating the analysis-transfer-generation steps to translate a dialectal multi-word expression into its MSA equivalent phrase. dialectal morphological analysis step uses ADAM (Salloum and Habash, 2011) to get a list of dialectal analyses. The morphosyntactic transfer step uses lemma-to-lemma (L2L) and features-tofeatures (F2F) transfer rules to change lemmas, clitics or features, and even split up the dialectal word into multiple MSA word analyses (such as splitting negation words and indirect objects). The MSA morphological generation step uses the general tokenizer/generator TOKAN (Habash, 2007) to generate untokenized surface form words. For more details, see Salloum and Habash (2011). Phrase-based translation. Unlike the wordbased translation techniques which map single DA words to sing","@endWordPosition":"2971","@position":"18395","annotationId":"T27","@startWordPosition":"2968","@citStr":"Salloum and Habash, 2011"},{"#tail":"\n","#text":"hts are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. The English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Habash and Rambow, 2005; Roth et al., 2008). The Arabic text is also Alif/Ya normalized. MADA-produced Arabic lemmas are used for word alignment. We use the same development (dev) and test sets used by Salloum and Habash (2011) (we will call them speech-dev and speech-test, respectively) and we compare to them in the next sections. We also evaluate on two web-crawled blind test sets: the Levantine test set presented in Zbib et al. (2012) (we will call it web-lev-test) and the Egyptian Dev-MTv2 development data of the DARPA BOLT program (we will call it web-egy-test). The speech-dev set has 1,496 sentences with 32,047 untokenized Arabic words. The speech-test set has 1,568 sentences with 353 32,492 untokenized Arabic words. The web-levtest set has 2,728 sentences with 21,179 untokenized Arabic words. The web-egy-test","@endWordPosition":"3846","@position":"23675","annotationId":"T28","@startWordPosition":"3843","@citStr":"Salloum and Habash (2011)"},{"#tail":"\n","#text":"ng phrases improve the three best performers of word-based selection. The best performer, shown in the last raw, suggests using phrase-based selection and restricted word-based selection. The restriction is to include OOV words and selected low frequency words that have at least one dialectal analysis or appear in our dialectal dictionaries. Comparing the best performer to the OOV selection mode system shows that translating low frequency in-vocabulary dialectal words and phrases to their MSA paraphrases can improve the English translation. This is a similar conclusion to our previous work in Salloum and Habash (2011). 6.1.3 Results on the Blind Test Sets We run the system settings that performed best on the dev set along with the OOV selection mode system on the three blind test set. Results and their differences from the baseline are reported in Table 5. We see that OOV selection mode system always improves over the baseline for all test sets. Also, the best performer on the dev is the best performer for all test sets. The improvements of the best performer over the OOV selection mode system on all test sets confirm that translating low frequency invocabulary dialectal words and phrases to their MSA para","@endWordPosition":"4940","@position":"30360","annotationId":"T29","@startWordPosition":"4937","@citStr":"Salloum and Habash (2011)"}]},"title":{"#tail":"\n","#text":"Dialectal to Standard Arabic Paraphrasing to Improve ArabicEnglish Statistical Machine Translation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Wael Salloum"},{"#tail":"\n","#text":"Nizar Habash"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Masao Utiyama and Hitoshi Isahara. 2007. A comparison of pivot methods for phrase-based statistical machine translation. In HLT-NAACL, pages 484\u2013491."},"#text":"\n","pages":{"#tail":"\n","#text":"484--491"},"marker":{"#tail":"\n","#text":"Utiyama, Isahara, 2007"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of \u201cresource-rich\u201d related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a morphologically rich language, Malay, to extend the phrase table in a Malay-toEnglish SMT system. Pivoting on MSA or acquiring more DA-English data? Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data. They used Amazon\u2019s Mechanical Turk (MTurk) to create a DAEnglish","@endWordPosition":"1671","@position":"10286","annotationId":"T30","@startWordPosition":"1667","@citStr":"Utiyama and Isahara, 2007"}},"title":{"#tail":"\n","#text":"A comparison of pivot methods for phrase-based statistical machine translation."},"booktitle":{"#tail":"\n","#text":"In HLT-NAACL,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Masao Utiyama"},{"#tail":"\n","#text":"Hitoshi Isahara"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Xiaoheng Zhang. 1998. Dialect MT: a case study between Cantonese and Mandarin. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, ACL \u201998, pages 1460\u2013 1464, Montreal, Canada."},"#text":"\n","pages":{"#tail":"\n","#text":"1460--1464"},"marker":{"#tail":"\n","#text":"Zhang, 1998"},"location":{"#tail":"\n","#text":"Montreal, Canada."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" mining the web to build a DA-to-MSA lexicon. In the context of DA-to-English SMT, Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut the OOV words by half. Machine Translation for Closely Related Languages. Using closely related languages has been shown to improve MT quality when resources are limited. Hajiˇc et al. (2000) argued that for very close languages, e.g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of \u201cresource-rich","@endWordPosition":"1560","@position":"9557","annotationId":"T31","@startWordPosition":"1559","@citStr":"Zhang (1998)"}},"title":{"#tail":"\n","#text":"Dialect MT: a case study between Cantonese and Mandarin."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, ACL \u201998,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Xiaoheng Zhang"}}}]}}}}
