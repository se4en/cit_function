and decoding algorithms. We also show how the comparability of candidates considered by the beam is an important factor in the performance. We argue that the conceptual and computational simplicity of the framework, together with its language-independent nature, make it a competitive choice for a range of syntactic processing tasks and one that should be considered for comparison by developers of alternative approaches. 1. Introduction In this article we study a range of syntactic processing tasks using a general framework for structural prediction that consists of the generalized perceptron (Collins 2002) and * University of Cambridge Computer Laboratory, William Gates Building, 15 JJ Thomson Avenue, Cambridge, UK. E-mail: yue.zhang®cl.cam.ac.uk. ** University of Cambridge Computer Laboratory, William Gates Building, 15 JJ Thomson Avenue, Cambridge, UK. E-mail: stephen.clark®cl.cam.ac.uk. Submission received: 10 November 2009; revised submission received: 12 August 2010; accepted for publication: 20 September 2010. © 2011 Association for Computational Linguistics Computational Linguistics Volume 37, Number 1 beam-search. We show that the framework, which is conceptually and computationally sim
 non-local features. The generalized perceptron is equally flexible, relying only on a decoder for each problem and using a trivial online update procedure for each training example. An advantage of the linear perceptron models we use is that they are global models, assigning a score to a complete hypothesis for each problem rather than assigning scores to parts which are then combined under statistical independence assumptions. Here we are following a recent line of work applying global discriminative models to tagging and wide-coverage parsing problems (Lafferty, McCallum, and Pereira 2001; Collins 2002; Collins and Roark 2004; McDonald, Crammer, and Pereira 2005; Clark and Curran 2007; Carreras, Collins, and Koo 2008; Finkel, Kleeman, and Manning 2008). The flexibility of our framework leads to competitive accuracies for each of the tasks we consider. For word segmentation, we show how the framework can accommodate a word-based approach, rather than the standard and more restrictive character-based tagging approaches. For POS-tagging, we consider joint segmentation and POS-tagging, showing that a single beam-search decoder can be used to achieve a significant accuracy boost over the pipelin
tures. The generalized perceptron is equally flexible, relying only on a decoder for each problem and using a trivial online update procedure for each training example. An advantage of the linear perceptron models we use is that they are global models, assigning a score to a complete hypothesis for each problem rather than assigning scores to parts which are then combined under statistical independence assumptions. Here we are following a recent line of work applying global discriminative models to tagging and wide-coverage parsing problems (Lafferty, McCallum, and Pereira 2001; Collins 2002; Collins and Roark 2004; McDonald, Crammer, and Pereira 2005; Clark and Curran 2007; Carreras, Collins, and Koo 2008; Finkel, Kleeman, and Manning 2008). The flexibility of our framework leads to competitive accuracies for each of the tasks we consider. For word segmentation, we show how the framework can accommodate a word-based approach, rather than the standard and more restrictive character-based tagging approaches. For POS-tagging, we consider joint segmentation and POS-tagging, showing that a single beam-search decoder can be used to achieve a significant accuracy boost over the pipeline baseline. For Chinese 
g only on a decoder for each problem and using a trivial online update procedure for each training example. An advantage of the linear perceptron models we use is that they are global models, assigning a score to a complete hypothesis for each problem rather than assigning scores to parts which are then combined under statistical independence assumptions. Here we are following a recent line of work applying global discriminative models to tagging and wide-coverage parsing problems (Lafferty, McCallum, and Pereira 2001; Collins 2002; Collins and Roark 2004; McDonald, Crammer, and Pereira 2005; Clark and Curran 2007; Carreras, Collins, and Koo 2008; Finkel, Kleeman, and Manning 2008). The flexibility of our framework leads to competitive accuracies for each of the tasks we consider. For word segmentation, we show how the framework can accommodate a word-based approach, rather than the standard and more restrictive character-based tagging approaches. For POS-tagging, we consider joint segmentation and POS-tagging, showing that a single beam-search decoder can be used to achieve a significant accuracy boost over the pipeline baseline. For Chinese and English dependency parsing, we show how both graph-based
pproaches into a single model which outperforms both in isolation. Finally, for Chinese phrase-structure parsing, we describe a global model for a shift-reduce parsing algorithm, in contrast to current deterministic approaches which use only local models at each step of the parsing process. For all these tasks we present results competitive with the best results in the literature. In Section 2 we describe our general framework of the generic beam-search algorithm and the generalized perceptron. Then in the subsequent sections we describe each task in turn, based on conference papers including Zhang and Clark (2007, 2008a, 2008b, 2009, 2010), presented in our single coherent framework. We give an updated set of results, plus a number of additional experiments which probe further into the advantages and disadvantages of our framework. For the segmentation task, we also compare our beam-search framework with alternative decoding algorithms including an exact dynamic-programming method, showing that the beam-search method is significantly faster with comparable accuracy. For the joint segmentation and POS-tagging task, we present a novel solution using the framework in this article, and show that it gives 
r single coherent framework. We give an updated set of results, plus a number of additional experiments which probe further into the advantages and disadvantages of our framework. For the segmentation task, we also compare our beam-search framework with alternative decoding algorithms including an exact dynamic-programming method, showing that the beam-search method is significantly faster with comparable accuracy. For the joint segmentation and POS-tagging task, we present a novel solution using the framework in this article, and show that it gives comparable accuracies to our previous work (Zhang and Clark 2008a), while being more than an order of magnitude faster. In Section 7 we provide further discussion of the framework based on the studies of the individual tasks. We present the main advantages of the framework, and give an analysis of the main reasons for the high speeds and accuracies achieved. We also discuss how this framework can be applied to a potential new task, and show that the comparability of candidates in the incremental process is an important factor to consider. In summary, we study a general framework for incremental structural prediction, showing how the framework can be tailor
rees. Given an input sentence x, the output F(x) is defined as the highest scored among the possible output structures for x: F(x) = argmax Score(y) (1) y∈GEN(x) where GEN(x) denotes the set of possible outputs for an input sentence x, and Score(y) is some real-valued function on Y. To compute Score(y), the output structure y is mapped into a global feature vector Φ(y) E N . Here a feature is a count of the occurrences of a certain pattern in an output structure, extracted according to a set of feature templates, and d is the total number of features. The term global feature vector is used by Collins (2002) to distinguish between feature counts for whole sequences and the local feature vectors in maximum entropy tagging models, which are boolean-valued vectors containing the indicator features for one element in the sequence (Ratnaparkhi 1998). Having defined the feature vector, Score(y) is computed using a linear model: Score(y) = Φ(y) · w� (2) where w� E Rd is the parameter vector of the model, the value of which is defined by supervised learning using the generalized perceptron. For the general framework we study in this article, the output y is required to be built through an incremental pro
ss is effectively coercing the decoder to produce the correct output for each training example. The algorithm can perform multiple passes over the same training sentences. In all experiments, we decide the number of training iterations using a set of development test data, by choosing the number that gives the highest 109 Computational Linguistics Volume 37, Number 1 Inputs: training examples (xi, yi) Initialization: set w� = 0 Algorithm: for r = 1..P, i = 1..N calculate zi = decode(xi) if zi =� yi w� = w� + Φ(yi) − Φ(zi) Outputs: w� Figure 2 The generalized perceptron algorithm, adapted from Collins (2002). development test accuracy as the final number in testing. Figure 2 gives the algorithm, where N is the number of training sentences and P is the number of passes over the data. The averaged perceptron algorithm (Collins 2002) is a standard way of reducing overfitting on the training data. It was motivated by the voted-perceptron algorithm (Freund and Schapire 1999) and has been shown to give improved accuracy over the non-averaged perceptron on a number of tasks. Let N be the number of training sentences, P the number of training iterations, and 0,r the parameter vector immediately after the
e training data. It was motivated by the voted-perceptron algorithm (Freund and Schapire 1999) and has been shown to give improved accuracy over the non-averaged perceptron on a number of tasks. Let N be the number of training sentences, P the number of training iterations, and 0,r the parameter vector immediately after the ith sentence in the rth iteration. The averaged parameter vector γ� E Rd is defined as 1 &,r y = PN L. i=1..N,r=1..P and it is used instead of w� as the model parameters. We use the averaged perceptron for all the tasks we consider. We also use the early-update strategy of Collins and Roark (2004), which is a modified version of the perceptron algorithm specifically for incremental decoding using beam search. At any step during the decoding process to calculate zi, if all partial candidates in the agenda are incorrect, decoding is stopped and the parameter vector is updated according to the current best candidate in the agenda and the corresponding gold-standard partial output. To perform early-update, the decoder needs to keep a version of the correct partial output for each incremental step, so that the parameter values are adjusted as soon as the beam loses track of the correct stat
The advantage of character-based segmentation is that well-known tagging approaches can be applied directly to the CWS problem. There are various character-based models in the literature. They differ mainly in the learning algorithm and the features used. Several discriminative learning algorithms have been applied to the character-based systems. Examples include Xue (2003), Peng, Feng, and McCallum (2004), and Wang et al. (2006), which use maximum entropy and conditional random field models, and Jiang et al. (2008), which uses the perceptron model. The standard feature set is that defined by Ng and Low (2004), though other feature sets are reported to improve the accuracy (Zhao, Huang, and Li 2006). Zhao, Huang, and Li (2006) also showed that the best accuracy for conditional random field (CRF) models is given by using a set of six character segmentation tags, rather than the standard set {beginning, middle, end, single} shown previously. Standard search algorithms for sequence tagging have been applied to the decoding process, such as the dynamic-programming algorithm and beam-search. A disadvantage of character-based models is the use of limited contextual information. For these methods, context
. For these methods, context is confined to the neighboring characters. Other contextual information, in particular the surrounding words, is not included. Consider the sentence , which can be from (among which) (foreign) (companies), or (in China) (foreign companies) (business). Note that the five-character window surrounding is the same in both cases, making the tagging decision for that character difficult given the local window. The correct decision can be made, however, by comparing the two three-word windows containing this character. 111 Computational Linguistics Volume 37, Number 1 In Zhang and Clark (2007) we proposed a word-based approach to segmentation, which provides a direct solution to the problem. In comparison with the character-based approach, our segmentor does not map the CWS problem into sequence labeling. By using a global linear model, it addresses the segmentation problem directly, extracting word-based features from the output segmented structure. Hence we call our word segmentation model the word-based approach. In fact, word-based segmentors can be seen as a generalization of character-based segmentors, because any character-based features can be defined in a word-based model.
 or separated from its previous character. 112 Zhang and Clark Syntactic Processing Table 1 Feature templates for the word segmentor. Feature template When c0 is 1 w−1 1 separated 2 w−1w−2 separated 3 w−1, where len(w−1) = separated 4 start(w−1)len(w−1) separated 5 end(w−1)len(w−1) separated 6 end(w−1)c0 separated 7 c−1c0 appended 8 begin(w−1)end(w−1) separated 9 w−1c0 separated 10 end(w−2)w−1 separated 11 start(w−1)c0 separated 12 end(w−2)end(w−1) separated 13 w−2len(w−1) separated 14 len(w−2)w−1 separated w = word; c = character. The index of the current character is 0. 3.2 Comparisons with Zhang and Clark (2007) Both the segmentor of this article and our segmentor of Zhang and Clark (2007) use a global linear model trained discriminatively using the perceptron. However, when comparing state items in the agenda, our 2007 segmentor treated full words in the same way as partial words, scoring them using the same feature templates. This scoring mechanism can potentially have a negative effect on the accuracy. In this article, we take a different strategy and apply full-word feature templates only when the next input character is separated from the word. In fact, most of the feature templates in Table 1 a
nguish this system from our system without combination of character-based information, we call our segmentor in Section 3.1 the pure wordbased segmentor and the segmentor that uses character-based features the combined segmentor in our experimental sections. 3.4 Experiments We performed two sets of experiments. In the first set of experiments, we used the Chinese Treebank (CTB) data to study the speed/accuracy tradeoff by varying the size of the beam. In the second set of experiments, we used training and testing sets from the first and second international Chinese word segmentation bakeoffs (Sproat and Emerson 2003; Emerson 2005) to compare the accuracies to other models in the literature, including our segmentor of Zhang and Clark (2007). F-score is used as the accuracy measure: 2pr/(p + r), where precision p is the percentage of words in the decoder output that are segmented correctly, and recall r is the percentage of gold-standard output words that are correctly segmented by the decoder. CWS systems are evaluated by two types of tests. The closed tests require that the system is trained only with a designated training corpus. Any extra knowledge is not allowed, including common surnames, Chinese and
 pure wordbased segmentor and the segmentor that uses character-based features the combined segmentor in our experimental sections. 3.4 Experiments We performed two sets of experiments. In the first set of experiments, we used the Chinese Treebank (CTB) data to study the speed/accuracy tradeoff by varying the size of the beam. In the second set of experiments, we used training and testing sets from the first and second international Chinese word segmentation bakeoffs (Sproat and Emerson 2003; Emerson 2005) to compare the accuracies to other models in the literature, including our segmentor of Zhang and Clark (2007). F-score is used as the accuracy measure: 2pr/(p + r), where precision p is the percentage of words in the decoder output that are segmented correctly, and recall r is the percentage of gold-standard output words that are correctly segmented by the decoder. CWS systems are evaluated by two types of tests. The closed tests require that the system is trained only with a designated training corpus. Any extra knowledge is not allowed, including common surnames, Chinese and Arabic numbers, European letters, lexicons, parts-of-speech, semantics, and so on. The open tests do not impose such restrict
character; s = segmentation tag. The index of the current character is 0. 114 Zhang and Clark Syntactic Processing Table 3 Training, development, and test data for word segmentation on CTB5. Sections Sentences Words Training 1–270, 400–931, 1001–1151 18,085 493,892 Dev 301–325 350 6,821 Test 271–300 348 8,008 the decoder has the potential to increase. This explains the increased accuracies when B increases from 1 to 16. However, the amount of increase drops when the beam size increases. 3.4.2 Closed Test on the SIGHAN Bakeoffs. Four training and testing corpora were used in the first bakeoff (Sproat and Emerson 2003), including the Academia Sinica Corpus (AS), the Penn Chinese Treebank Corpus (CTB), the Hong Kong City University Corpus (CU), and the Peking University Corpus (PU). However, because the testing data from the Penn Chinese Treebank Corpus is currently unavailable to us, we excluded this corpus from our experiments. The corpora are encoded in GB (PU, CTB) and BIG5 (AS, CU). In order to test them consistently in our system, they are all converted to UTF8 without loss of information. The results are shown in Table 4. We follow the format from Peng, Feng, and McCallum (2004), where each row repres
4), where each row represents a CWS model. The first three columns represent tests with the AS, CU, and PU corpora, respectively. The best score in each column is shown in bold. The last two columns represent the average accuracy of each model over the tests it participated in (SAV), and our average over the same tests (OAV), respectively. The first eight rows represent models from Sproat and Emerson (2003) that participated in at least one closed test from the table, row “Peng” represents the CRF model from Peng, Feng, and McCallum (2004), row “Zhang 2007” represents our model as reported in Zhang and Clark (2007), and the last two rows represent our model in this article, using only word-based features in Table 1 and combined features in Tables 1 plus 2, respectively. In Zhang and Clark (2007) we fixed the number of training iterations to six for all experiments, according to a separate set of development data. An alternative way to decide the number of training iterations is to set apart 10% from the training data Figure 3 Speed/accuracy tradeoff of the segmentor. 115 Computational Linguistics Volume 37, Number 1 Table 4 The accuracies of various word segmentors over the first SIGHAN bakeoff data. AS
s in boldface. *Zhang 2007 with the (Carreras, Surdeanu, and Marquez 2006) method applied (see text for details). as development test data, and use the rest for development training. For testing, all training data are used for training, with the number of training iterations set to be the number which gave the highest accuracy during the development experiments. This method was used by Carreras, Surdeanu, and Marquez (2006) in their parsing model. We apply it to our segmentor model in this article. Moreover, we also use this method to decide the number of training iterations for our system of Zhang and Clark (2007), and show the accuracies in row “Zhang 2007*”. For each row the best average is shown in bold. We achieved the best accuracy in all three corpora, and better overall accuracy than all the other models using the method of this article. Our new method to decide the number of training iterations also gave improved accuracies compared to our 2007 model. The combination of character-based features and our original word-based features gave slight improvement in the overall accuracy. Four training and testing corpora were used in the second bakeoff (Emerson 2005), including the Academia Sinica corpu
g the same feature templates we defined. In this section, we study two alternative decoding algorithms to the beam-search decoder, including a multiplebeam search algorithm, which can be viewed as an alternative decoder specifically designed for the word segmentation and joint segmentation and tagging problems, and a dynamic-programming algorithm. Both algorithms explore a larger part of the search space than the single beam-search algorithm, and we compare the accuracy and speed of these algorithms within the generalized perceptron learning framework. 3.5.1 A Multiple-Beam Search Decoder. In Zhang and Clark (2008a) we proposed a multiple-beam decoder for the problem of joint word segmentation and POS-tagging, in which state items only contain complete words. This algorithm can be naturally adapted for word segmentation. Compared with the single-beam decoder, it explores a larger fraction of the search space. Moreover, the multiple-beam decoder does not have the problem of comparing partial words with full words in a single agenda, which our segmentor of Zhang and Clark (2007) has. We implement this decoder for segmentation and compare its accuracies with our single-beam decoder. Instead of a single ag
acy and speed of these algorithms within the generalized perceptron learning framework. 3.5.1 A Multiple-Beam Search Decoder. In Zhang and Clark (2008a) we proposed a multiple-beam decoder for the problem of joint word segmentation and POS-tagging, in which state items only contain complete words. This algorithm can be naturally adapted for word segmentation. Compared with the single-beam decoder, it explores a larger fraction of the search space. Moreover, the multiple-beam decoder does not have the problem of comparing partial words with full words in a single agenda, which our segmentor of Zhang and Clark (2007) has. We implement this decoder for segmentation and compare its accuracies with our single-beam decoder. Instead of a single agenda, the multiple-beam algorithm keeps an agenda for each character in the input sentence, recording the best partial candidates ending with the character. Like the single beam decoder, the input sentence is processed incrementally. However, at each stage, partial sequence candidates are available at all previous characters. Therefore, the decoder can examine all candidate words ending with the current character. These possible words are combined with the relevant pa
on and POS-tagging is the problem of solving word segmentation and POS-tagging simultaneously. Traditionally, Chinese word segmentation and POS-tagging are performed in a pipeline. The output from the word segmentor is taken as the input for the POS-tagger. A disadvantage of pipelined segmentation and POStagging is that POS-tag information, which is potentially useful for segmentation, is not used during the segmentation step. In addition, word segmentation errors are propagated to the POS-tagger, leading to lower quality of the overall segmented and 1 The experiments were performed using the Zhang and Clark (2007) feature set and single-beam decoder, and our new way to decide the number of training iterations in this article. The single-beam results correspond to “Zhang 2007*” in Tables 4 and 5. 120 Zhang and Clark Syntactic Processing POS-tagged output. Joint word segmentation and POS-tagging is a method that addresses these problems. In Zhang and Clark (2008a) we proposed a joint word segmentor and POS-tagger using a multiple-beam decoder, and showed that it outperformed a pipelined baseline. We recently showed that comparable accuracies can be achieved by a single-beam decoder, which runs an order o
tentially useful for segmentation, is not used during the segmentation step. In addition, word segmentation errors are propagated to the POS-tagger, leading to lower quality of the overall segmented and 1 The experiments were performed using the Zhang and Clark (2007) feature set and single-beam decoder, and our new way to decide the number of training iterations in this article. The single-beam results correspond to “Zhang 2007*” in Tables 4 and 5. 120 Zhang and Clark Syntactic Processing POS-tagged output. Joint word segmentation and POS-tagging is a method that addresses these problems. In Zhang and Clark (2008a) we proposed a joint word segmentor and POS-tagger using a multiple-beam decoder, and showed that it outperformed a pipelined baseline. We recently showed that comparable accuracies can be achieved by a single-beam decoder, which runs an order of magnitude faster (Zhang and Clark 2010). In this section, we describe our single-beam system using our general framework, and provide a detailed comparison with our multiple-beam and baseline systems of Zhang and Clark (2008a). 4.1 Instantiating the General Framework Given an input sentence, our joint segmentor and POS-tagger builds an output increm
est contains a complete segmented and POS-tagged output and an empty queue. The linear model from Section 2 is applied to score state items, differentiating partial words from full words in the aforementioned ways, and the model parameters are trained with the averaged perceptron. The features for a state item are extracted incrementally according to Equation (3), where for the ith character, Φ(δ(y,i)) is computed according to the feature templates in both Table 1, which are related to word segmentation, and Table 7, which are related to POS-tagging. During training, the earlyupdate method of Collins and Roark (2004), as described in Section 2, is used. It ensures that state items on the beam are highly probable at each incremental step, and is crucial to the high accuracy given by a single-beam. 4.2 Pruning We use several pruning methods from Zhang and Clark (2008a), most of which serve to improve the accuracy by removing irrelevant candidates from the beam. First, the system records the maximum number of characters that a word with a particular POStag can have. For example, from the Chinese Treebank that we used for our experiments, most POS are associated only with one- or two-character words. The only
 the averaged perceptron. The features for a state item are extracted incrementally according to Equation (3), where for the ith character, Φ(δ(y,i)) is computed according to the feature templates in both Table 1, which are related to word segmentation, and Table 7, which are related to POS-tagging. During training, the earlyupdate method of Collins and Roark (2004), as described in Section 2, is used. It ensures that state items on the beam are highly probable at each incremental step, and is crucial to the high accuracy given by a single-beam. 4.2 Pruning We use several pruning methods from Zhang and Clark (2008a), most of which serve to improve the accuracy by removing irrelevant candidates from the beam. First, the system records the maximum number of characters that a word with a particular POStag can have. For example, from the Chinese Treebank that we used for our experiments, most POS are associated only with one- or two-character words. The only POS-tags that are seen with words over ten characters long are NN (noun), NR (proper noun), and CD (numbers). The maximum word length information is initialized as all ones, and updated according to each training example before it is processed. 121 Com
x of the current character is 0. Second, a tag dictionary is used to record POS-tags associated with each word. During decoding, frequent words and words with “closed set” tags2 are only assigned POS-tags according to the tag dictionary, while other words are assigned every POStag to make candidate outputs. Whether a word is a frequent word is decided by the number of times it has been seen in the training process. Denoting the number of times the most frequent word has been seen by M, a word is a frequent word if it has been seen more than M15,000 + 5 times. The threshold value is taken from Zhang and Clark (2008a), and we did not adjust it during development. Word frequencies are initialized as zeros and updated according to each training example before it is processed; the tag dictionary is initialized as empty and updated according to each training example before it is processed. Third, we make an additional record of the initial characters for words with “closed set” tags. During decoding, when the current character is added as the start of a new word, “closed set” tags are only assigned to the word if it is consistent with the record. This type of pruning is used in addition to the tag dictionary
if two candidates cand1 and cand2 generated at the same step have the same signature, and the score of cand1 is higher than the score of cand2, then at any future step, the highest scored candidate 2 “Closed set” tags are the set of POS-tags which are only associated with a fixed set of words, according to the Penn Chinese Treebank specifications (Xia 2000). 122 Zhang and Clark Syntactic Processing generated from cand1 will always have a higher score than the highest scored candidate generated from cand2. From these four pruning methods, only the third was not used by our multiplebeam system (Zhang and Clark 2008a). This was designed to help keep likely partial words in the agenda and improve the accuracy, and does not give our system a speed advantage over our multiple-beam system. 4.3 Comparison with Multiple-Beam Search (Zhang and Clark 2008a) Our system of Zhang and Clark (2008a) was based on the perceptron and a multiplebeam decoder. That decoder can be seen as a slower alternative of our decoder in this article, but one which explores a larger part of the search space. The comparison between our joint segmentation and tagging systems of Zhang and Clark (2008a) and this article is similar to the 
 our segmentors in sections 3.5.1 and 3.1. In Zhang and Clark (2008a), we argued that the straightforward implementation of the singlebeam decoder cannot give competitive accuracies to the multiple-beam decoder, and the main difficulties for a single-beam decoder are in the representing of partial words, and the handling of an exponentially large combined search space using one beam. In this section, we give a description of our system of Zhang and Clark (2008a), and discuss the reason we can achieve competitive accuracies using a single beam in this article. 4.3.1 The Multiple-Beam System of Zhang and Clark (2008a). The decoder of our multiplebeam system can be formulated as an instance of the multiple-beam decoder described in Section 3.5.1. Similar to the multiple-beam search decoder for word segmentation, the decoder compares candidates only with complete tagged words, and enables the size of the search space to scale with the input size. A set of state items is kept for each character to record possible segmented and POS-tagged sentences ending with the character. Just as with the single-beam decoder, the input sentence is processed incrementally. However, when a character is processed, the number
est consists of a complete segmented and POS-tagged sentence and an empty incoming queue. The linear model from Section 2 is again applied directly to score state items, and the model parameters are trained with the averaged perceptron algorithm. The features 123 Computational Linguistics Volume 37, Number 1 for a state item are extracted according to the union of the feature templates for the baseline segmentor and the baseline POS-tagger. 4.3.2 Discussion. An important problem that we solve for a single-beam decoder for the global model is the handling of partial words. As we pointed out in Zhang and Clark (2008a), it is very difficult to score partial words properly when they are compared with full words, although such comparison is necessary for incremental decoding with a single-beam. To allow comparisons with full words, partial words can either be treated as full words, or handled differently. We showed in Zhang and Clark (2008a) that a naive single-beam decoder which treats partial words in the same way as full words failed to give a competitive accuracy. An important reason for the low accuracy is over-segmentation during beamsearch. Consider the three characters (tap water). The first two cha
 treated as two singlecharacter words, they can make sense in a sentence such as (please) (self) (come) (take). Therefore, when using single-beam search to process (tap water), the two-character word candidate is likely to have been thrown off the agenda before the third character is considered, leading to an unrecoverable segmentation error. This problem is even more severe for a joint segmentor and POS-tagger than for a pure word segmentor, because the POS-tags and POS-tag bigram of and further supports them being separated when is considered. The multiple-beam search decoder we proposed in Zhang and Clark (2008a) can be seen as a means to ensure that the three characters always have a chance to be considered as a single word. It explores candidate segmentations from the beginning of the sentence until each character, and avoids the problem of processing partial words by considering only full words. However, because it explores a larger part of the search space than a single-beam decoder, its time complexity is correspondingly higher. In our single-beam system, we treat partial words differently from full words, so that in the previous example, the decoder can take the first two characters in (tap wa
mentation and tagging accuracy, where the overall accuracy is JF = 2pr/(p + r) with the precision p being the percentage of correctly segmented and tagged words in the decoder output, and the recall r being the percentage of gold-standard tagged 3 The next incoming characters are also a useful source of information for predicting the POS. However, our system achieved competitive accuracy compared to our multiple-beam system without such character lookahead features. 125 Computational Linguistics Volume 37, Number 1 words that are correctly identified by the decoder. For direct comparison with Ng and Low (2004), the POS-tagging accuracy is also calculated by the percentage of correct tags on each character. 4.4.1 Development Experiments. Our development data consists of 150K words in 4,798 sentences. Eighty percent (80%) of the data were randomly chosen as the development training data, and the rest were used as the development test data. Our development tests were mainly used to decide the size of the beam, the number of training iterations, and to observe the effect of early update. Figure 6 shows the accuracy curves for joint segmentation and POS-tagging by the number of training iterations, usin
le-beam # SF JF JA SF JF JA SF JF JA Av. 95.2 90.3 92.2 95.8 91.4 93.0 95.9 91.3 93.0 SF = segmentation F-score; JF = overall segmentation and POS-tagging F-score; JA = tagging accuracy by character. F-score of 83.38%. When using early update, the algorithm reached the best accuracy at the 30th training iteration, obtaining a segmentation F-score of 91.14% and a joint F-score of 84.06%. 4.4.2 Cross-Validation Results. Ten-fold cross validation is performed to test the accuracy of the joint word segmentor and POS-tagger, and to make comparisons with existing models in the literature. Following Ng and Low (2004), we partition the sentences in CTB3, ordered by sentence ID, into 10 groups evenly. In the nth test, the nth group is used as the testing data. Table 8 shows the cross-validation accuracies of the pipeline baseline system and the joint system using single and multiple beam decoders. SF, JF and JA represent segmentation F-score, tagging F-score, and tagging accuracy, respectively. The joint segmentor and tagger systems outperformed the baseline consistently, while the single beam-search decoder in this article gave comparable accuracies to our multiple-beam algorithm of Zhang and Clark (2008a)
owing Ng and Low (2004), we partition the sentences in CTB3, ordered by sentence ID, into 10 groups evenly. In the nth test, the nth group is used as the testing data. Table 8 shows the cross-validation accuracies of the pipeline baseline system and the joint system using single and multiple beam decoders. SF, JF and JA represent segmentation F-score, tagging F-score, and tagging accuracy, respectively. The joint segmentor and tagger systems outperformed the baseline consistently, while the single beam-search decoder in this article gave comparable accuracies to our multiple-beam algorithm of Zhang and Clark (2008a). Speed comparisons of the three systems using the same 10-fold cross-validation are shown in Table 9. TE, ML, and SP represents the testing time (seconds), model loading time (seconds), and speed (number of sentences per second), respectively. Speed is calculated as number of test sentences divided by the test time (excluding model loading). For the baseline system, test time and model loading time for both the segmentor and the POS-tagger are recorded. The joint system using a single beam decoder was over 10 times faster than the multiple-beam system, and the baseline system was more than 
rison of overall accuracies of various joint segmentor and POS-taggers by 10-fold cross validation using CTB. Model SF JF JA Baseline+ (Ng) 95.1 – 91.7 Joint+ (Ng) 95.2 – 91.9 Baseline+* (Shi) 95.85 91.67 – Joint+* (Shi) 96.05 91.86 – Baseline (ours) 95.20 90.33 92.17 Joint (our multiple-beam) 95.90 91.34 93.02 Joint (our single-beam) 95.84 91.37 93.01 SF = segmentation F-score; JF = joint segmentation and POS-tagging F-score; JA = tagging accuracy by character. + Knowledge about special characters. * Knowledge from semantic net outside CTB. shown in a row, where Ng represents the models from Ng and Low (2004), which applies a character tagging approach to perform word segmentation and POS-tagging simultaneously, and Shi represents the models from Shi and Wang (2007), which is a reranking system for segmentation and POS-tagging. These two models are described in more detail in the related work section. Each accuracy measure is shown in a column, including the segmentation F-score (SF), the overall tagging F-score (JF), and the tagging accuracy by character (JA). As can be seen from the table, our joint models achieved the largest improvement over the baseline, reducing the segmentation error by mor
oint model of Shi and Wang (2007). Despite the higher accuracy improvement from the baseline, the joint system did not give higher overall accuracy. One possible reason is that Shi and Wang (2007) included knowledge about special characters and semantic knowledge from Web corpora (which may explain the higher baseline accuracy), whereas our system is completely data-driven. However, the comparison is indirect because our partitions of the CTB corpus are different. Shi and Wang (2007) also chunked the sentences before doing 10-fold cross validation, but used an uneven split. We chose to follow Ng and Low (2004) and split the sentences evenly to facilitate further comparison. Compared with Ng and Low (2004), our baseline model gave slightly better accuracy, consistent with our previous observations about the word segmentors in Section 3. Due to the large accuracy gain from the baseline, our joint model performed much better. In summary, when compared with existing joint word segmentation and POStagging systems using cross-validation tests, our proposed model achieved the best accuracy boost from the pipelined baseline, and competitive overall accuracy. Our system based on the general framework of thi
ction 3. Due to the large accuracy gain from the baseline, our joint model performed much better. In summary, when compared with existing joint word segmentation and POStagging systems using cross-validation tests, our proposed model achieved the best accuracy boost from the pipelined baseline, and competitive overall accuracy. Our system based on the general framework of this article gave comparable accuracies to our multiple-beam system in Zhang and Clark (2008a), and a speed that is over an order of magnitude higher than the multiple-beam algorithm. 4.4.3 Test Results Using CTB5. We follow Kruengkrai et al. (2009) and split the CTB5 into training, development testing, and testing sets, as shown in Table 11. The data are used 128 Zhang and Clark Syntactic Processing Table 11 Training, development, and test data from CTB5 for joint word segmentation and POS-tagging. Sections Sentences Words Training 1–270, 400–931, 1001–1151 18,085 493,892 Dev 301–325 350 6,821 Test 271–300 348 8,008 to compare the accuracies of our joint system with models in the literature, and to draw the speed/accuracy tradeoff graph. Kruengkrai et al. (2009) made use of character type knowledge for spaces, numerals, symbols, alphabe
 tradeoff graph. Kruengkrai et al. (2009) made use of character type knowledge for spaces, numerals, symbols, alphabets, and Chinese and other characters. In the previous experiments, our system did not use any knowledge beyond the training data. To make the comparison fairer, we included knowledge of English letters and Arabic numbers in this experiment. During both training and decoding, English letters and Arabic numbers are segmented using rules, treating consecutive English letters or Arabic numbers as a single word. The results are shown in Table 12, where row N07 refers to the model of Nakagawa and Uchimoto (2007), rows J08a and J08b refer to the models of Jiang et al. (2008) and Jiang, Mi, and Liu (2008), and row K09 refers to the models of Kruengkrai et al. (2009). Columns SF and JF refer to segmentation and joint segmentation and tagging accuracies, respectively. Our system gave comparable accuracies to these recent works, obtaining the best (same as the error-driven version of K09) joint F-score. The accuracy/speed tradeoff graphs for the joint segmentor and POS-taggers, together with the baseline pipeline system, are shown in Figure 7. For each point in each curve, the development test data were u
he previous experiments, our system did not use any knowledge beyond the training data. To make the comparison fairer, we included knowledge of English letters and Arabic numbers in this experiment. During both training and decoding, English letters and Arabic numbers are segmented using rules, treating consecutive English letters or Arabic numbers as a single word. The results are shown in Table 12, where row N07 refers to the model of Nakagawa and Uchimoto (2007), rows J08a and J08b refer to the models of Jiang et al. (2008) and Jiang, Mi, and Liu (2008), and row K09 refers to the models of Kruengkrai et al. (2009). Columns SF and JF refer to segmentation and joint segmentation and tagging accuracies, respectively. Our system gave comparable accuracies to these recent works, obtaining the best (same as the error-driven version of K09) joint F-score. The accuracy/speed tradeoff graphs for the joint segmentor and POS-taggers, together with the baseline pipeline system, are shown in Figure 7. For each point in each curve, the development test data were used to decide the number of training iterations, and then the speed and accuracy were measured using test data. No character knowledge is used in any syste
each such high speeds, and the baseline system could not produce a higher accuracy than 92.83%. The single-beam joint system gave the highest accuracy of 93.50% when the beam size was 16 and the speed was 1.01 thousand characters per second, and the F-score dropped slightly when the beam further increased to 32. The points in the multiple-beam curve correspond to beam sizes of 1, 2, 4, 8, and 16, respectively, from right to left. The multiple-beam system gave the highest F-score of 93.62% when the beam size was 16, but the speed was down to 0.06 thousand sentences per second. 4.5 Related Work Ng and Low (2004) mapped the joint segmentation and POS-tagging task into a single character sequence tagging problem. Two types of tags are assigned to each character to represent its segmentation and POS. For example, the tag b NN indicates a character at the beginning of a noun, and the tag e VV indicates a character at the end of a verb. Using this method, POS features are allowed to interact with segmentation. Because tagging is restricted to characters, the search space is reduced to O((4T)n), where 4 is the number of segmentation tags and T is the size of the tag set. Beam-search decoding is effective w
ormation is used to improve segmentation only for the B segmentor outputs. In comparison to the two systems described here, our joint system does not impose any hard constraints on the interaction between segmentation and POS information. Jiang, Mi, and Liu (2008) proposed a reranking system that builds a pruned word lattice instead of generating a B-best list by the segmentor. The advantage of this reranking method compared to Shi and Wang’s (2007) method is that more ambiguity is kept in the reranking stage. The reranking algorithm used a similar model to our joint segmentor and POS-tagger. Nakagawa and Uchimoto (2007) proposed a hybrid model for word segmentation and POS tagging using an HMM-based approach. Word information is used to process known words, and character information is used for unknown words in a similar way to Ng and Low (2004). In comparison, our model handles character and word information simultaneously in a single perceptron model. Recently, Kruengkrai et al. (2009) developed this hybrid model further by scoring characters and words in the same model. Their idea is similar to our joint segmentor and POS-tagger in Zhang and Clark (2008a). 5. Dependency Parsing Dependency parsing is the p
ang, Mi, and Liu (2008) proposed a reranking system that builds a pruned word lattice instead of generating a B-best list by the segmentor. The advantage of this reranking method compared to Shi and Wang’s (2007) method is that more ambiguity is kept in the reranking stage. The reranking algorithm used a similar model to our joint segmentor and POS-tagger. Nakagawa and Uchimoto (2007) proposed a hybrid model for word segmentation and POS tagging using an HMM-based approach. Word information is used to process known words, and character information is used for unknown words in a similar way to Ng and Low (2004). In comparison, our model handles character and word information simultaneously in a single perceptron model. Recently, Kruengkrai et al. (2009) developed this hybrid model further by scoring characters and words in the same model. Their idea is similar to our joint segmentor and POS-tagger in Zhang and Clark (2008a). 5. Dependency Parsing Dependency parsing is the problem of producing the syntactic structure for an input sentence according to dependency grammar. The output structure of a dependency parser is called a dependency graph; in this article, only dependency trees are considered. As
. The advantage of this reranking method compared to Shi and Wang’s (2007) method is that more ambiguity is kept in the reranking stage. The reranking algorithm used a similar model to our joint segmentor and POS-tagger. Nakagawa and Uchimoto (2007) proposed a hybrid model for word segmentation and POS tagging using an HMM-based approach. Word information is used to process known words, and character information is used for unknown words in a similar way to Ng and Low (2004). In comparison, our model handles character and word information simultaneously in a single perceptron model. Recently, Kruengkrai et al. (2009) developed this hybrid model further by scoring characters and words in the same model. Their idea is similar to our joint segmentor and POS-tagger in Zhang and Clark (2008a). 5. Dependency Parsing Dependency parsing is the problem of producing the syntactic structure for an input sentence according to dependency grammar. The output structure of a dependency parser is called a dependency graph; in this article, only dependency trees are considered. As can be seen from Figure 8, a dependency tree consists of a set of vertices and directed arcs. Each arc represents the relationship between a pai
 parsing) consists of an empty stack, and an incoming queue of the whole input. The function EXPAND(candidate, dependency parsing) applies all possible actions to candidate and generates a set of new state items. GOALTEST(dependency parsing, best) returns true if best has reached the final state, and false otherwise. The score of a parse tree is computed by the global linear model in Equation (2), where the parameter vector w� for the model is computed by the averaged perceptron training algorithm described in Section 2.2. During training of the dependency parser, the early-update strategy of Collins and Roark (2004) is used. The intuition is to improve learning by avoiding irrelevant information, as discussed earlier: When all the items in the current agenda are incorrect, further parsing steps will be irrelevant because the correct partial output no longer exists in the candidate ranking. Both the transition-based and the combined parsers use this training and decoding framework. The main difference between the two parsers is in the definition of the feature templates. Whereas the transition-based parser uses only transition-based features, the combined parser applies features from the graph-based parse
 accuracy can be achieved by this intuitive method of candidate comparison. 5.2 Experiments for English We used Penn Treebank 3 for our experiments, which was separated into the training, development, and test sets in the same way as McDonald, Crammer, and Pereira (2005), shown in Table 15. Bracketed sentences from the Treebank were translated into dependency structures using the head-finding rules from Yamada and Matsumoto (2003). Before parsing, POS-tags are assigned to the input sentence using our baseline POS-tagger of Zhang and Clark (2008a), which can be seen as the perceptron tagger of Collins (2002) with beam-search. Like McDonald, Crammer, and Pereira (2005), we evaluated the parsing accuracy by the precision of lexical heads (the percentage of input words, excluding punctuation, that have been assigned the correct parent) and by the percentage of complete matches, in which all words excluding punctuation have been assigned the correct parent. A set of development tests, including the convergence of the perceptron, can be found in Zhang and Clark (2008a). In this article, we report only the final test accuracies and a set of additional speed/accuracy tradeoff results. The accuracies of 
08a). In this article, we report only the final test accuracies and a set of additional speed/accuracy tradeoff results. The accuracies of our transition-based and combined parsers on English data are shown together with other systems in Table 16. In the table, each row represents a parsing model. Rows Yamada 2003 and MSTParser represent Yamada and Matsumoto (2003), and MSTParser with templates 1–6 from Table 14 (McDonald and Pereira 2006), respectively. Rows Transition and Combined represent our pure transition-based and combined parsers, respectively. Row Huang 2010 shows the recent work of Huang and Sagae (2010), which applies dynamic-programming packing to transition-based dependency parsing. Rows Koo 2008 and Chen 2009 represent the models of Koo, Carreras, and Collins (2008) and Chen et al. (2009), which perform semi-supervised learning by word-clustering and self-training, respectively. Columns Word and Complete show the precision of lexical Table 15 The training, development, and test data for English dependency parsing. Sections Sentences Words Training 2–21 39,832 950,028 Development 22 1,700 40,117 Test 23 2,416 56,684 135 Computational Linguistics Volume 37, Number 1 Table 16 Accuracy compar
8. Rows Transition and Combined show our models in the same way as for the English experiments from Section 5.2. Row Duan 2007 represents the transition-based model from Duan, Zhao, and Xu (2007), which applied beam-search to the deterministic model from Yamada and Matsumoto (2003). Row Table 18 Test accuracies of various dependency parsers on CTB5 data. Non-root Root Complete Duan 2007 84.36 73.70 32.70 Transition 84.69 76.73 32.79 Huang 2010 85.52 78.32 33.72 Combined 86.21 76.26 34.41 See text for details. 137 Computational Linguistics Volume 37, Number 1 Huang 2010 represents the model of Huang and Sagae (2010), which applies dynamicprogramming packing to transition-based parsing. The observations were similar to the English tests. The combined parser outperformed the transition-based parsers. It gave the best accuracy we are aware of for supervised dependency parsing using the CTB. One last question we investigate for this article is the overall performance when the parser is pipelined with a POS-tagger, or with the joint segmentation and POS-tagging algorithm in Section 4, forming a complete pipeline for Chinese inputs. The results are shown in Table 19. For these experiments, we tune the pipeline
Computational Linguistics Volume 37, Number 1 whole input sentence, the function EXPAND(candidate, constituent parsing) extends candidate by using all applicable actions to generate a set of new state items, and GOALTEST (constituent parsing, best) returns true if best reaches the final state, and false otherwise. The score of a parse tree is computed by the global linear model in Equation (2), where the parameter vector w� for the model is computed by the averaged perceptron training algorithm described in Section 2.2. As in the training of the dependency parser, the early-update strategy of Collins and Roark (2004) is used. Table 20 shows the set of feature templates for the model. Individual features are generated from these templates by first instantiating a template with particular labels, words, and tags, and then pairing the instantiated template with a particular action. In the table, the symbols S0, S1, S2, and S3 represent the top four nodes on the stack, and the symbols N0, N1, N2, and N3 represent the first four words in the incoming queue. S0L, S0R, and S0U represent the left and right child for binary branching S0, and the single child for unary branching S0, respectively; w represents the l
 is that our parser is based on a discriminative learning model with global features, whereas the parser from Wang et al. (2006) is based on a local classifier that optimizes each individual choice. Instead of greedy local decoding, we used beamsearch in the decoder. An early work that applies beam-search to constituent parsing is Ratnaparkhi (1999). The main difference between our parser and Ratnaparkhi’s is that we use a global discriminative model, whereas Ratnaparkhi’s parser has separate probabilities of actions chained together in a conditional model. Both our parser and the parser from Collins and Roark (2004) use a global discriminative model and an incremental parsing process. The major difference is that Collins and Roark, like Roark (2001), follow a top–down derivation strategy, whereas we chose to use a shift-reduce process which has been shown to give state-of-the-art accuracies for Chinese (Wang et al. 2006). In addition, we did not include a generative baseline model in the discriminative model, as did Collins and Roark (2004). 7. Discussion We have demonstrated in the previous sections that accuracies competitive with the state-of-the-art can be achieved by our general framework for Chines
2006). In addition, we did not include a generative baseline model in the discriminative model, as did Collins and Roark (2004). 7. Discussion We have demonstrated in the previous sections that accuracies competitive with the state-of-the-art can be achieved by our general framework for Chinese word segmentation, joint word segmentation and POS-tagging, Chinese and English dependency parsing, and Chinese phrase-structure parsing. Besides these tasks, our baseline POStagger in Section 4 is also implemented in the framework. When it is applied to English POS-tagging using feature templates from Collins (2002), it gave similar accuracy to the Table 25 Comparison of dependency accuracies between phrase-structure parsing and dependency parsing using CTB5 data. Non-root Root Complete Dependency parser 86.21% 76.26% 34.41% Constituent parser 86.95% 79.19% 36.08% 146 Zhang and Clark Syntactic Processing dynamic-programming decoder of Collins (2002). All these experiments suggest that the general yet efficient framework provides a competitive solution for structural prediction problems with an incremental output-building process. In this section, we discuss the main reasons for the effectiveness of the g
aracter-based approach by including word information; our joint word segmentor and POS-tagger utilizes POS information for word segmentation; our combined dependency parser includes statistical information from two different methods in a single, consistently trained model. The models gave state-of-the-art accuracies in these problems, demonstrating the advantage of using flexible information covering large parts of the output structure. Compared to alternative discriminative training algorithms such as structural SVM (Tsochantaridis et al. 2004) and CRFs (Lafferty, McCallum, and Pereira 2001; Clark and Curran 2007), the perceptron has a simple parameter update process, which is often efficient in both memory usage and running time depending on the decoding algorithm. Consider joint word segmentation and POS-tagging for example; we found in our experiments that practical training times can be achieved by the perceptron algorithm, but not with structural SVM. MIRA (Crammer and Singer 2003) and its simplifications (McDonald, Crammer, and Pereira 2005; Crammer et al. 2006) are also commonly used learning algorithms to train a global linear model. They can be treated as slower but potentially more accurate a
ompleted earlier than others. When this happens, we choose to retain fully built outputs in the agenda while continuing the decoding process, until the highest scored item in the agenda is a complete parse. Therefore, there are situations when different parses in the agenda have a different number of actions. This did not turn out to be a significant problem. We believe that the most effective way to organize output comparison is largely an empirical question. Finally, alternative components can be used to replace the learning or decoding algorithms of the framework to give higher accuracies. Huang and Sagae (2010) have recently applied dynamic-programming to dependency parsing to pack items that have the same signature in the beam, and obtained higher accuracy than our transition-based dependency parser in Section 5. 8. Conclusion We explored word segmentation, joint word segmentation and POS-tagging, dependency parsing, and phrase-structure parsing using a general framework of a global linear model, trained by the perceptron algorithm and decoded with beam-search. We have chosen to focus on Chinese; the framework itself and our algorithms for the specific problems are language-independent, however. In
endent, however. In Section 5 we reported results on English dependency parsing. Despite the rather simple nature of the decoding and training processes, the framework achieved accuracies competitive with the state-ofthe-art for all the tasks we considered, by making use of a large range of statistical information. As further evidence of the effectiveness of our framework, we have recently adapted our phrase-structure parser in Section 6 to parsing with a lexicalized grammar formalism, Combinatory Categorial Grammar (CCG), and achieved higher F-scores than the state-of-the-art C&C CCG parser (Clark and Curran 2007). The range of problems that we have studied suggests that our framework is a simple yet competitive option for structural prediction problems in general. Our source code can be found at www.sourceforge.net/projects/zpar. It contains the general framework, our implementations of the four tasks addressed in this article, and other tools for syntactic processing. 148 Zhang and Clark Syntactic Processing Acknowledgments This work was largely carried out while Yue Zhang was a DPhil student at the Oxford University Computing Laboratory, where he was supported by an ORS Scholarship and the Clarendon
