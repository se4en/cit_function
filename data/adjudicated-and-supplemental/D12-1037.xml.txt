aining method to address these two problems. Unlike a global training method, such as MERT, in which a single weight is learned and used for all the input sentences, we perform training and testing in one step by learning a sentencewise weight for each input sentence. We propose efficient incremental training methods to put the local training into practice. In NIST Chinese-to-English translation tasks, our local training method significantly outperforms MERT with the maximal improvements up to 2.0 BLEU points, meanwhile its efficiency is comparable to that of the global method. 1 Introduction Och and Ney (2002) introduced the log-linear model for statistical machine translation (SMT), in which translation is considered as the following optimization problem: e?(f ;W ) = arg max e P(e|f ;W ) = arg max e exp { W ? h(f, e) } ? e? exp { W ? h(f, e?) } = arg max e { W ? h(f, e) } , (1) where f and e (e?) are source and target sentences, respectively. h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W . Some methods are based on likelihood (Och and Ney, 2002; Blunsom et al2008),
he log-linear model for statistical machine translation (SMT), in which translation is considered as the following optimization problem: e?(f ;W ) = arg max e P(e|f ;W ) = arg max e exp { W ? h(f, e) } ? e? exp { W ? h(f, e?) } = arg max e { W ? h(f, e) } , (1) where f and e (e?) are source and target sentences, respectively. h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W . Some methods are based on likelihood (Och and Ney, 2002; Blunsom et al2008), error rate (Och, 2003; Zhao and Chen, 2009; Pauls et al2009; Galley and Quirk, 2011), margin (Watanabe et al2007; Chiang et al2008) and ranking (Hopkins and May, 2011), and among which minimum error rate training (MERT) (Och, 2003) is the most popular one. All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set. We call them a global training method. One of its advantages is that it allows us to train a single weight offline and thereby it is efficient. However, due to the diversity and uneven dist
ar model for statistical machine translation (SMT), in which translation is considered as the following optimization problem: e?(f ;W ) = arg max e P(e|f ;W ) = arg max e exp { W ? h(f, e) } ? e? exp { W ? h(f, e?) } = arg max e { W ? h(f, e) } , (1) where f and e (e?) are source and target sentences, respectively. h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W . Some methods are based on likelihood (Och and Ney, 2002; Blunsom et al2008), error rate (Och, 2003; Zhao and Chen, 2009; Pauls et al2009; Galley and Quirk, 2011), margin (Watanabe et al2007; Chiang et al2008) and ranking (Hopkins and May, 2011), and among which minimum error rate training (MERT) (Och, 2003) is the most popular one. All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set. We call them a global training method. One of its advantages is that it allows us to train a single weight offline and thereby it is efficient. However, due to the diversity and uneven distribution of source se
lation (SMT), in which translation is considered as the following optimization problem: e?(f ;W ) = arg max e P(e|f ;W ) = arg max e exp { W ? h(f, e) } ? e? exp { W ? h(f, e?) } = arg max e { W ? h(f, e) } , (1) where f and e (e?) are source and target sentences, respectively. h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W . Some methods are based on likelihood (Och and Ney, 2002; Blunsom et al2008), error rate (Och, 2003; Zhao and Chen, 2009; Pauls et al2009; Galley and Quirk, 2011), margin (Watanabe et al2007; Chiang et al2008) and ranking (Hopkins and May, 2011), and among which minimum error rate training (MERT) (Och, 2003) is the most popular one. All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set. We call them a global training method. One of its advantages is that it allows us to train a single weight offline and thereby it is efficient. However, due to the diversity and uneven distribution of source sentences(Li et al2010), there are some shor
em: e?(f ;W ) = arg max e P(e|f ;W ) = arg max e exp { W ? h(f, e) } ? e? exp { W ? h(f, e?) } = arg max e { W ? h(f, e) } , (1) where f and e (e?) are source and target sentences, respectively. h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W . Some methods are based on likelihood (Och and Ney, 2002; Blunsom et al2008), error rate (Och, 2003; Zhao and Chen, 2009; Pauls et al2009; Galley and Quirk, 2011), margin (Watanabe et al2007; Chiang et al2008) and ranking (Hopkins and May, 2011), and among which minimum error rate training (MERT) (Och, 2003) is the most popular one. All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set. We call them a global training method. One of its advantages is that it allows us to train a single weight offline and thereby it is efficient. However, due to the diversity and uneven distribution of source sentences(Li et al2010), there are some shortcomings in this pipeline. Firstly, on the document level, the performance of these
 today ? <1,2> 0.3 2 today several weeks . <3,2> 0.1 (a) (b) 2 21 2 222,0 ( , ) ( , )h f e h f e? ? ?? ? 2 22 2 212,0 ( , ) ( , )h f e h f e? ?? ?1 11 1 11, 0 ( , ) ( , )h f e h f e? ?? ? 1 12 1 111,0 ( , ) ( , )h f e h f e? ? ?? ? 2 22 2 21( , ) ( , )h f e h f e? 1 11 1 12( , ) ( , )h f e h f e? <-2,0> <-1,0> <1,0> <2,0> 0h1h . .* * 2 21 2 22( , ) ( , )h f e h f e? 1 12 1 11( , ) ( , )h f e h f e? Figure 1: (a). An Example candidate space of dimensionality two. score is a evaluation metric of e. (b). The nonlinearly separable classification problem transformed from (a) via tuning as ranking (Hopkins and May, 2011). Since score of e11 is greater than that of e12, ?1, 0? corresponds to a possitive example denoted as ???, and ??1, 0? corresponds to a negative example denoted as ?*?. Since the transformed classification problem is not linearly separable, there does not exist a single weight which can obtain e11 and e21 as translation results meanwhile. However, one can obtain e11 and e21 with weights: ?1, 1? and ??1, 1?, respectively. 19.04 when the Moses system is tuned on NIST02 by MERT. However, its performance is improved to 21.28 points when tuned on NIST06. The automatic selection of a development se
 and MERT can not find a single weight to satisfy all of the sentences. Figure 1(a) shows such an example, in which a development set contains two sentences f1 and f2 with translations e and feature vectors h. When we tune examples in Figure 1(a) by MERT, it can be regarded as a nonlinearly separable classification problem illustrated in Figure 1(b). Therefore, there exists no single weightW which simultaneously obtains e11 and e21 as translation for f1 and f2 via Equation (1). However, we can achieve this with two weights: ?1, 1? for f1 and ??1, 1? for f2. In this paper, inspired by KNN-SVM (Zhang et al., 2006), we propose a local training method, which trains sentence-wise weights instead of a single weight, to address the above two problems. Compared with global training methods, such as MERT, in which training and testing are separated, our method works in an online fashion, in which training is performed during testing. This online fashion has an advantage in that it can adapt the weights for each of the test sentences, by dynamically tuning the weights on translation examples which are similar to these test sentences. Similar to the method of development set automatical selection, the local tra
incremental training methods which avoid retraining and iterative decoding on a development set. Our local training method has two advantages: firstly, it significantly outperforms MERT, especially when test set is different from the development set; secondly, it improves the translation consistency. Experiments on NIST Chinese-to-English translation tasks show that our local training method significantly gains over MERT, with the maximum improvements up to 2.0 BLEU, and its efficiency is comparable to that of the global training method. 2 Local Training and Testing The local training method (Bottou and Vapnik, 1992) is widely employed in computer vision (Zhang et al2006; Cheng et al2010). Compared with the global training method which tries to fit a single weight on the training data, the local one learns weights based on the local neighborhood information for each test example. It is superior to 403 the global one when the data sets are not evenly distributed (Bottou and Vapnik, 1992; Zhang et al 2006). Algorithm 1 Naive Local Training Method Input: T = {ti}Ni=1(test set), K (retrieval size), Dev(development set), D(retrieval data) Output: Translation results of T 1: for all sentence ti such that 1 ? i 
cantly gains over MERT, with the maximum improvements up to 2.0 BLEU, and its efficiency is comparable to that of the global training method. 2 Local Training and Testing The local training method (Bottou and Vapnik, 1992) is widely employed in computer vision (Zhang et al2006; Cheng et al2010). Compared with the global training method which tries to fit a single weight on the training data, the local one learns weights based on the local neighborhood information for each test example. It is superior to 403 the global one when the data sets are not evenly distributed (Bottou and Vapnik, 1992; Zhang et al 2006). Algorithm 1 Naive Local Training Method Input: T = {ti}Ni=1(test set), K (retrieval size), Dev(development set), D(retrieval data) Output: Translation results of T 1: for all sentence ti such that 1 ? i ? N do 2: Retrieve the training examples Di with size K for ti from D according to a similarity; 3: Train a local weight W i based on Dev and Di; 4: Decode ti with W i; 5: end for Suppose T be a test set, Dev a development set, and D a retrieval data. The local training in SMT is described in the Algorithm 1. For each sentence ti in test set, training examples Di is retrieved from D using a s
nd the incremental training in line 5 of Algorithm 2. 3 Acquiring Training Examples In line 4 of Algorithm 2, to retrieve training examples for the sentence ti , we first need a metric to retrieve similar translation examples. We assume that the metric satisfy the property: more similar the test sentence and translation examples are, the better translation result one obtains when decoding the test sentence with the weight trained on the translation examples. The metric we consider here is derived from an example-based machine translation. To retrieve translation examples for a test sentence, (Watanabe and Sumita, 2003) defined a metric based on the combination of edit distance and TF-IDF (Manning and Schu?tze, 1999) as follows: dist(f1, f2) = ? ? edit-dist(f1, f2)+ (1? ?)? tf-idf(f1, f2), (2) where ?(0 ? ? ? 1) is an interpolation weight, fi(i = 1, 2) is a word sequence and can be also considered as a document. In this paper, we extract similar examples from training data. Like examplebased translation in which similar source sentences have similar translations, we assume that the optimal translation weights of the similar source sentences are closer. 4 Incremental Training Based on Ultraconservative Update
(0 ? ? ? 1) is an interpolation weight, fi(i = 1, 2) is a word sequence and can be also considered as a document. In this paper, we extract similar examples from training data. Like examplebased translation in which similar source sentences have similar translations, we assume that the optimal translation weights of the similar source sentences are closer. 4 Incremental Training Based on Ultraconservative Update Compared with retraining mode, incremental training can improve the training efficiency. In the field of machine learning research, incremental training has been employed in the work (Cauwenberghs and Poggio, 2001; Shilton et al2005), but there is little work for tuning parameters of statistical machine translation. The biggest difficulty lies in that the feature vector of a given training example, i.e. translation example, is unavailable until actually decoding the example, since the derivation is a latent variable. In this section, we will investigate the incremental training methods in SMT scenario. Following the notations in Algorithm 2, Wb is the baseline weight, Di = {?f ij , c i j , r i j?} K j=1 denotes training examples for ti. For the sake of brevity, we will drop the index i, Di = {?fj , cj 
ethods in SMT scenario. Following the notations in Algorithm 2, Wb is the baseline weight, Di = {?f ij , c i j , r i j?} K j=1 denotes training examples for ti. For the sake of brevity, we will drop the index i, Di = {?fj , cj , rj?}Kj=1, in the rest of this paper. Our goal is to find an optimal weight, denoted by W i, which is a local weight and used for decoding the sentence ti. Unlike the global method which performs tuning on the whole development set Dev +Di as in Algorithm 1, W i can be incrementally learned by optimizing onDi based on Wb. We employ the idea of ultraconservative update (Crammer and Singer, 2003; Crammer et al2006) to propose two incremental methods for local training in Algorithm 2 as follows. Ultraconservative update is an efficient way to consider the trade-off between the progress made on development set Dev and the progress made on Di. It desires that the optimal weight W i is not only close to the baseline weight Wb, but also achieves the low loss over the retrieved examples Di. The idea of ultraconservative update can be formalized as follows: min W { d(W,Wb) + ? ? Loss(D i,W ) } , (3) where d(W,Wb) is a distance metric over a pair of weights W and Wb. It penalizes the weights
 + ? ? Loss(D i,W ) } , (3) where d(W,Wb) is a distance metric over a pair of weights W and Wb. It penalizes the weights far away from Wb and it is L2 norm in this paper. Loss(Di,W ) is a loss function of W defined on Di and it evaluates the performance of W over Di. ? is a positive hyperparameter. If Di is more similar to the test sentence ti, the better performance will be achieved for the larger ?. In particular, ifDi consists of only a single sentence ti, the best performance will be obtained when ? goes to infinity. 4.1 Margin Based Ultraconservative Update MIRA(Crammer and Singer, 2003; Crammer et al 2006) is a form of ultraconservative update in (3) whoseLoss is defined as hinge loss based on margin over the pairwise translation candiates in Di. It tries to minimize the following quadratic program: 1 2 ||W ?Wb|| 2+ ? K K? j=1 max 1?n?|cj | ( `jn?W ??h(fj , ejn) ) with ?h(fj , ejn) = h(fj , ej?)? h(fj , ejn), (4) 405 where h(fj , e) is the feature vector of candidate e, ejn is a translation member of fj in cj , ej? is the oracle one in cj , `jn is a loss between ej? and ejn and it is the same as referred in (Chiang et al2008), and |cj | denotes the number of members in cj . Different from (Wata
ly optimize the error rate of translation candidates with respect to their references in Di. Formally, the objective function of error rate based ultraconservative update (EBUU) is as follows: 1 2 ?W ?Wb? 2 + ? K K? j=1 Error(rj ; e?(fj ;W )), (5) where e?(fj ;W ) is defined in Equation (1), and Error(rj , e) is the sentence-wise minus BLEU (Papineni et al2002) of a candidate e with respect to rj . Due to the existence of L2 norm in objective function (5), the optimization algorithm MERT can not be applied for this question since the exact line search routine does not hold here. Motivated by (Och, 2003; Smith and Eisner, 2006), we approximate the Error in (5) by the expected loss, and then derive the following function: 1 2 ?W?Wb? 2+ ? K K? j=1 ? e Error(rj ; e)P?(e|fj ;W ), (6) Systems NIST02 NIST05 NIST06 NIST08 Moses 30.39 26.31 25.34 19.07 Moses hier 33.68 26.94 26.28 18.65 In-Hiero 31.24 27.07 26.32 19.03 Table 1: The performance comparison of the baseline InHiero VS Moses and Moses hier. with P?(e|fj ;W ) = exp[?W ? h(fj , e)] ? e??cj exp[?W ? h(fj , e ?)] , (7) where ? > 0 is a real number valued smoother. One can see that, in the extreme case, for ? ? ?, (6) converges to (5). We app
ly the gradient decent method to minimize the function (6), as it is smooth with respect to ?. Since the function (6) is non-convex, the solution obtained by gradient descent method may depend on the initial point. In this paper, we set the initial point as Wb in order to achieve a desirable solution. 5 Experiments and Results 5.1 Setting We conduct our experiments on the Chinese-toEnglish translation task. The training data is FBIS corpus consisting of about 240k sentence pairs. The development set is NIST02 evaluation data, and the test datasets are NIST05, NIST06,and NIST08. We run GIZA++ (Och and Ney, 2000) on the training corpus in both directions (Koehn et al 2003) to obtain the word alignment for each sentence pair. We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing (Chen and Goodman, 1998). In our experiments the translation performances are measured by case-insensitive BLEU4 metric (Papineni et al2002) and we use mtevalv13a.pl as the evaluation tool. The significance testing is performed by paired bootstrap re-sampling (Koehn, 2004). We use an in-house developed hierarchical phrase
 it is smooth with respect to ?. Since the function (6) is non-convex, the solution obtained by gradient descent method may depend on the initial point. In this paper, we set the initial point as Wb in order to achieve a desirable solution. 5 Experiments and Results 5.1 Setting We conduct our experiments on the Chinese-toEnglish translation task. The training data is FBIS corpus consisting of about 240k sentence pairs. The development set is NIST02 evaluation data, and the test datasets are NIST05, NIST06,and NIST08. We run GIZA++ (Och and Ney, 2000) on the training corpus in both directions (Koehn et al 2003) to obtain the word alignment for each sentence pair. We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing (Chen and Goodman, 1998). In our experiments the translation performances are measured by case-insensitive BLEU4 metric (Papineni et al2002) and we use mtevalv13a.pl as the evaluation tool. The significance testing is performed by paired bootstrap re-sampling (Koehn, 2004). We use an in-house developed hierarchical phrase-based translation (Chiang, 2005) as our baseline system, and
ial point as Wb in order to achieve a desirable solution. 5 Experiments and Results 5.1 Setting We conduct our experiments on the Chinese-toEnglish translation task. The training data is FBIS corpus consisting of about 240k sentence pairs. The development set is NIST02 evaluation data, and the test datasets are NIST05, NIST06,and NIST08. We run GIZA++ (Och and Ney, 2000) on the training corpus in both directions (Koehn et al 2003) to obtain the word alignment for each sentence pair. We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing (Chen and Goodman, 1998). In our experiments the translation performances are measured by case-insensitive BLEU4 metric (Papineni et al2002) and we use mtevalv13a.pl as the evaluation tool. The significance testing is performed by paired bootstrap re-sampling (Koehn, 2004). We use an in-house developed hierarchical phrase-based translation (Chiang, 2005) as our baseline system, and we denote it as In-Hiero. To obtain satisfactory baseline performance, we tune InHiero system for 5 times using MERT, and then se406 Methods Steps Seconds Global method Decoding 2
ution. 5 Experiments and Results 5.1 Setting We conduct our experiments on the Chinese-toEnglish translation task. The training data is FBIS corpus consisting of about 240k sentence pairs. The development set is NIST02 evaluation data, and the test datasets are NIST05, NIST06,and NIST08. We run GIZA++ (Och and Ney, 2000) on the training corpus in both directions (Koehn et al 2003) to obtain the word alignment for each sentence pair. We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing (Chen and Goodman, 1998). In our experiments the translation performances are measured by case-insensitive BLEU4 metric (Papineni et al2002) and we use mtevalv13a.pl as the evaluation tool. The significance testing is performed by paired bootstrap re-sampling (Koehn, 2004). We use an in-house developed hierarchical phrase-based translation (Chiang, 2005) as our baseline system, and we denote it as In-Hiero. To obtain satisfactory baseline performance, we tune InHiero system for 5 times using MERT, and then se406 Methods Steps Seconds Global method Decoding 2.0 Local method Retrieval +0.6 Local training +0.3 Table 2: 
e NIST05, NIST06,and NIST08. We run GIZA++ (Och and Ney, 2000) on the training corpus in both directions (Koehn et al 2003) to obtain the word alignment for each sentence pair. We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing (Chen and Goodman, 1998). In our experiments the translation performances are measured by case-insensitive BLEU4 metric (Papineni et al2002) and we use mtevalv13a.pl as the evaluation tool. The significance testing is performed by paired bootstrap re-sampling (Koehn, 2004). We use an in-house developed hierarchical phrase-based translation (Chiang, 2005) as our baseline system, and we denote it as In-Hiero. To obtain satisfactory baseline performance, we tune InHiero system for 5 times using MERT, and then se406 Methods Steps Seconds Global method Decoding 2.0 Local method Retrieval +0.6 Local training +0.3 Table 2: The efficiency of the local training and testing measured by sentence averaged runtime. Methods NIST05 NIST06 NIST08 Global MERT 27.07 26.32 19.03 Local MBUU 27.75+ 27.88+ 20.84+ EBUU 27.85+ 27.99+ 21.08+ Table 3: The performance comparison of local
pus in both directions (Koehn et al 2003) to obtain the word alignment for each sentence pair. We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits (Stolcke, 2002) with modified Kneser-Ney smoothing (Chen and Goodman, 1998). In our experiments the translation performances are measured by case-insensitive BLEU4 metric (Papineni et al2002) and we use mtevalv13a.pl as the evaluation tool. The significance testing is performed by paired bootstrap re-sampling (Koehn, 2004). We use an in-house developed hierarchical phrase-based translation (Chiang, 2005) as our baseline system, and we denote it as In-Hiero. To obtain satisfactory baseline performance, we tune InHiero system for 5 times using MERT, and then se406 Methods Steps Seconds Global method Decoding 2.0 Local method Retrieval +0.6 Local training +0.3 Table 2: The efficiency of the local training and testing measured by sentence averaged runtime. Methods NIST05 NIST06 NIST08 Global MERT 27.07 26.32 19.03 Local MBUU 27.75+ 27.88+ 20.84+ EBUU 27.85+ 27.99+ 21.08+ Table 3: The performance comparison of local training methods (MBUU and EBUU) and a global method (MERT). NIST05 is the set use
candidates. In our experiments, we employ the two incremental training methods, i.e. MBUU and EBUU. Both of the hyperparameters ? are tuned on NIST05 and set as 0.018 and 0.06 for MBUU and EBUU, respectively. In the incremental training step, only one CPU is employed. Table 2 depicts that testing each sentence with local training method takes 2.9 seconds, which is comparable to the testing time 2.0 seconds with global training method4. This shows that the local method is efficient. Further, compared to the retrieval, the local training is not the bottleneck. Actually, if we use LSH technique (Andoni and Indyk, 2008) in retrieval process, the local method can be easily scaled to a larger training data. 5.3 Results and Analysis Table 3 shows the main results of our local training methods. The EBUU training method significantly outperforms the MERT baseline, and the improvement even achieves up to 2.0 BLEU points on NIST08. We can also see that EBUU and MBUU are comparable on these three test sets. Both of these two local training methods achieve significant improvements over the MERT baseline, which proves the effectiveness of our local training method over global training method. Although both local metho
 varying retrieval size in Algorithm 2 based on EBUU. Methods NIST05 NIST06 NIST08 MERT 27.07 26.32 19.03 EBUU 27.85 27.99 21.08 Oracle 29.46 29.35 22.09 Table 8: The performance of Oracle of 2-best results which consist of 1-best resluts of MERT and 1-best resluts of EBUU. lated approximately. Table 8 presents the performance of the oracle translations selected from the 1-best translation results of MERT and EBUU. Clearly, there exists more potential improvement for local training method. 6 Related Work Several works have proposed discriminative techniques to train log-linear model for SMT. (Och and Ney, 2002; Blunsom et al2008) used maximum likelihood estimation to learn weights for MT. (Och, 2003; Moore and Quirk, 2008; Zhao and Chen, 2009; Galley and Quirk, 2011) employed an evaluation metric as a loss function and directly optimized it. (Watanabe et al2007; Chiang et al2008; Hopkins and May, 2011) proposed other optimization objectives by introducing a margin-based and ranking-based indirect loss functions. All the methods mentioned above train a single weight for the whole development set, whereas our local training method learns a weight for each sentence. Further, our translation framework 
 19.03 EBUU 27.85 27.99 21.08 Oracle 29.46 29.35 22.09 Table 8: The performance of Oracle of 2-best results which consist of 1-best resluts of MERT and 1-best resluts of EBUU. lated approximately. Table 8 presents the performance of the oracle translations selected from the 1-best translation results of MERT and EBUU. Clearly, there exists more potential improvement for local training method. 6 Related Work Several works have proposed discriminative techniques to train log-linear model for SMT. (Och and Ney, 2002; Blunsom et al2008) used maximum likelihood estimation to learn weights for MT. (Och, 2003; Moore and Quirk, 2008; Zhao and Chen, 2009; Galley and Quirk, 2011) employed an evaluation metric as a loss function and directly optimized it. (Watanabe et al2007; Chiang et al2008; Hopkins and May, 2011) proposed other optimization objectives by introducing a margin-based and ranking-based indirect loss functions. All the methods mentioned above train a single weight for the whole development set, whereas our local training method learns a weight for each sentence. Further, our translation framework integrates the training and testing into one unit, instead of treating them separately. One
 27.85 27.99 21.08 Oracle 29.46 29.35 22.09 Table 8: The performance of Oracle of 2-best results which consist of 1-best resluts of MERT and 1-best resluts of EBUU. lated approximately. Table 8 presents the performance of the oracle translations selected from the 1-best translation results of MERT and EBUU. Clearly, there exists more potential improvement for local training method. 6 Related Work Several works have proposed discriminative techniques to train log-linear model for SMT. (Och and Ney, 2002; Blunsom et al2008) used maximum likelihood estimation to learn weights for MT. (Och, 2003; Moore and Quirk, 2008; Zhao and Chen, 2009; Galley and Quirk, 2011) employed an evaluation metric as a loss function and directly optimized it. (Watanabe et al2007; Chiang et al2008; Hopkins and May, 2011) proposed other optimization objectives by introducing a margin-based and ranking-based indirect loss functions. All the methods mentioned above train a single weight for the whole development set, whereas our local training method learns a weight for each sentence. Further, our translation framework integrates the training and testing into one unit, instead of treating them separately. One of the advantages is t
le 29.46 29.35 22.09 Table 8: The performance of Oracle of 2-best results which consist of 1-best resluts of MERT and 1-best resluts of EBUU. lated approximately. Table 8 presents the performance of the oracle translations selected from the 1-best translation results of MERT and EBUU. Clearly, there exists more potential improvement for local training method. 6 Related Work Several works have proposed discriminative techniques to train log-linear model for SMT. (Och and Ney, 2002; Blunsom et al2008) used maximum likelihood estimation to learn weights for MT. (Och, 2003; Moore and Quirk, 2008; Zhao and Chen, 2009; Galley and Quirk, 2011) employed an evaluation metric as a loss function and directly optimized it. (Watanabe et al2007; Chiang et al2008; Hopkins and May, 2011) proposed other optimization objectives by introducing a margin-based and ranking-based indirect loss functions. All the methods mentioned above train a single weight for the whole development set, whereas our local training method learns a weight for each sentence. Further, our translation framework integrates the training and testing into one unit, instead of treating them separately. One of the advantages is that it can adapt the 
Table 8: The performance of Oracle of 2-best results which consist of 1-best resluts of MERT and 1-best resluts of EBUU. lated approximately. Table 8 presents the performance of the oracle translations selected from the 1-best translation results of MERT and EBUU. Clearly, there exists more potential improvement for local training method. 6 Related Work Several works have proposed discriminative techniques to train log-linear model for SMT. (Och and Ney, 2002; Blunsom et al2008) used maximum likelihood estimation to learn weights for MT. (Och, 2003; Moore and Quirk, 2008; Zhao and Chen, 2009; Galley and Quirk, 2011) employed an evaluation metric as a loss function and directly optimized it. (Watanabe et al2007; Chiang et al2008; Hopkins and May, 2011) proposed other optimization objectives by introducing a margin-based and ranking-based indirect loss functions. All the methods mentioned above train a single weight for the whole development set, whereas our local training method learns a weight for each sentence. Further, our translation framework integrates the training and testing into one unit, instead of treating them separately. One of the advantages is that it can adapt the weights for each of the t
y. Table 8 presents the performance of the oracle translations selected from the 1-best translation results of MERT and EBUU. Clearly, there exists more potential improvement for local training method. 6 Related Work Several works have proposed discriminative techniques to train log-linear model for SMT. (Och and Ney, 2002; Blunsom et al2008) used maximum likelihood estimation to learn weights for MT. (Och, 2003; Moore and Quirk, 2008; Zhao and Chen, 2009; Galley and Quirk, 2011) employed an evaluation metric as a loss function and directly optimized it. (Watanabe et al2007; Chiang et al2008; Hopkins and May, 2011) proposed other optimization objectives by introducing a margin-based and ranking-based indirect loss functions. All the methods mentioned above train a single weight for the whole development set, whereas our local training method learns a weight for each sentence. Further, our translation framework integrates the training and testing into one unit, instead of treating them separately. One of the advantages is that it can adapt the weights for each of the test sentences. Our method resorts to some translation examples, which is similar as example-based translation or translation memory (Watan
2011) proposed other optimization objectives by introducing a margin-based and ranking-based indirect loss functions. All the methods mentioned above train a single weight for the whole development set, whereas our local training method learns a weight for each sentence. Further, our translation framework integrates the training and testing into one unit, instead of treating them separately. One of the advantages is that it can adapt the weights for each of the test sentences. Our method resorts to some translation examples, which is similar as example-based translation or translation memory (Watanabe and Sumita, 2003; He et al2010; Ma et al2011). Instead of using translation examples to construct translation rules for enlarging the decoding space, we employed them to discriminatively learn local weights. Similar to (Hildebrand et al2005; Lu? et al 2007), our method also employes IR methods to retrieve examples for a given test set. Their methods utilize the retrieved examples to acquire translation model and can be seen as the adaptation of translation model. However, ours uses the retrieved examples to tune the weights and thus can be considered as the adaptation of tuning. Furthermore, since ours does n
