olution is to spread the ?semantic load? of lexical entries to other morphemes not typically taken to bear semantic content. This approach follows current trends in linguistic theory, and more perspicuously accounts for alternations in argument structure. I demonstrate how such a framework can be computationally realized with a feature-based, agenda-driven chart parser for the Minimalist Program. 1 Introduction The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content. Due to advances in statistical syntactic parsing techniques (Collins, 1997; Charniak, 2001), attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences. A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots). Verbs are viewed as simple predicates over their arguments. This approach has its roots in Fillmore?s Case Grammar (1968), and serves as the foundation for two current large-scale semantic annotation projects: FrameNet (Baker et al, 1998) and PropBank (Kingsbury
pread the ?semantic load? of lexical entries to other morphemes not typically taken to bear semantic content. This approach follows current trends in linguistic theory, and more perspicuously accounts for alternations in argument structure. I demonstrate how such a framework can be computationally realized with a feature-based, agenda-driven chart parser for the Minimalist Program. 1 Introduction The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content. Due to advances in statistical syntactic parsing techniques (Collins, 1997; Charniak, 2001), attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences. A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots). Verbs are viewed as simple predicates over their arguments. This approach has its roots in Fillmore?s Case Grammar (1968), and serves as the foundation for two current large-scale semantic annotation projects: FrameNet (Baker et al, 1998) and PropBank (Kingsbury et al, 2002). Un
yntactic parsing techniques (Collins, 1997; Charniak, 2001), attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences. A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots). Verbs are viewed as simple predicates over their arguments. This approach has its roots in Fillmore?s Case Grammar (1968), and serves as the foundation for two current large-scale semantic annotation projects: FrameNet (Baker et al, 1998) and PropBank (Kingsbury et al, 2002). Underlying the semantic roles approach is a lexicalist assumption, that is, each verb?s lexical entry completely encodes (more formally, projects) its syntactic and semantic structures. Alternations in argument structure are usually attributed to multiple lexical entries (i.e., verb senses). Under the lexicalist approach, the semantics of the verb break might look something like this: (1) break(agent, theme) agent: subject theme: object break(agent, theme, instrument) agent: subject theme: object instrument: oblique(with) break(theme) theme: subject . . .
ins, 1997; Charniak, 2001), attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences. A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots). Verbs are viewed as simple predicates over their arguments. This approach has its roots in Fillmore?s Case Grammar (1968), and serves as the foundation for two current large-scale semantic annotation projects: FrameNet (Baker et al, 1998) and PropBank (Kingsbury et al, 2002). Underlying the semantic roles approach is a lexicalist assumption, that is, each verb?s lexical entry completely encodes (more formally, projects) its syntactic and semantic structures. Alternations in argument structure are usually attributed to multiple lexical entries (i.e., verb senses). Under the lexicalist approach, the semantics of the verb break might look something like this: (1) break(agent, theme) agent: subject theme: object break(agent, theme, instrument) agent: subject theme: object instrument: oblique(with) break(theme) theme: subject . . . The lexicon explicitly specifies the
t: oblique(with) break(theme) theme: subject . . . The lexicon explicitly specifies the different subcategorization frames of a verb, e.g., the causative frame, the causative instrumental frame, the inchoative frame, etc. The major drawback of this approach, however, is the tremendous amount of redundancy in the lexicon?for example, the class of prototypical transitive verbs where the agent appears as the subject and the theme as the direct object must all duplicate this pattern. The typical solution to the redundancy problem is to group verbs according to their argument realization patterns (Levin, 1993), possibly arranged in an inheritance hierarchy. The argument structure and syntax-tosemantics mapping would then only need to be specified once for each verb class. In addition, lexical rules could be formulated to derive certain alternations from more basic forms. Nevertheless, the lexicalist approach does not capture productive morphological processes that pervade natural language, for example, flat.V ? flatten.ADJ or hammer.N ? hammer.V; most frameworks for computational semantics fail to capture the deeper derivational relationship between morphologically-related terms. For languages with
calist approach does not capture productive morphological processes that pervade natural language, for example, flat.V ? flatten.ADJ or hammer.N ? hammer.V; most frameworks for computational semantics fail to capture the deeper derivational relationship between morphologically-related terms. For languages with rich derivational morphology, this problem is often critical: the standard architectural view of morphological analysis as a preprocessor presents difficulties in handling semantically meaningful affixes. In this paper, I present a computational implementation of Distributed Morphology (Halle and Marantz, 1993), a non-lexicalist linguistic theory that erases the distinction between syntactic derivation and morphological derivation. This framework leads to finer-grained semantics capable of better capturing linguistic generalizations. 2 Event Structure It has previously been argued that representations based on a fixed collection of semantic roles cannot adequately capture natural language semantics. The actual inventory of semantic roles, along with precise definitions and diagnostics, remains an unsolved problem; see (Levin and Rappaport Hovav, 1996). Fixed roles are too coarsegrained to account fo
nostics, remains an unsolved problem; see (Levin and Rappaport Hovav, 1996). Fixed roles are too coarsegrained to account for certain semantic distinctions?the only recourse, to expand the inventory of roles, comes with the price of increased complexity, e.g., in the syntaxto-semantics mapping. There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure?representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity (Dowty, 1979; Jackendoff, 1983; Pustejovsky, 1991b; Rappaport Hovav and Levin, 1998). Consider the following example: (2) He sweeps the floor clean. [ [ DO(he, sweeps(the floor)) ] CAUSE [ BECOME [ clean(the floor) ] ] ] Dowty breaks the event described by (2) into two subevents, the activity of sweeping the floor and its result, the state of the floor being clean. A more recent approach, advocated by Rappaport Hovav and Levin (1998), describes a basic set of event templates corresponding to Vendler?s event classes (Vendler, 1957): (3) a. [ x ACT<MANNER> ] (activity) b. [ x <STATE> ] (state) c. [ BECOME [
ins an unsolved problem; see (Levin and Rappaport Hovav, 1996). Fixed roles are too coarsegrained to account for certain semantic distinctions?the only recourse, to expand the inventory of roles, comes with the price of increased complexity, e.g., in the syntaxto-semantics mapping. There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure?representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity (Dowty, 1979; Jackendoff, 1983; Pustejovsky, 1991b; Rappaport Hovav and Levin, 1998). Consider the following example: (2) He sweeps the floor clean. [ [ DO(he, sweeps(the floor)) ] CAUSE [ BECOME [ clean(the floor) ] ] ] Dowty breaks the event described by (2) into two subevents, the activity of sweeping the floor and its result, the state of the floor being clean. A more recent approach, advocated by Rappaport Hovav and Levin (1998), describes a basic set of event templates corresponding to Vendler?s event classes (Vendler, 1957): (3) a. [ x ACT<MANNER> ] (activity) b. [ x <STATE> ] (state) c. [ BECOME [ x <STATE> ] ] (ac
oblem; see (Levin and Rappaport Hovav, 1996). Fixed roles are too coarsegrained to account for certain semantic distinctions?the only recourse, to expand the inventory of roles, comes with the price of increased complexity, e.g., in the syntaxto-semantics mapping. There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure?representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity (Dowty, 1979; Jackendoff, 1983; Pustejovsky, 1991b; Rappaport Hovav and Levin, 1998). Consider the following example: (2) He sweeps the floor clean. [ [ DO(he, sweeps(the floor)) ] CAUSE [ BECOME [ clean(the floor) ] ] ] Dowty breaks the event described by (2) into two subevents, the activity of sweeping the floor and its result, the state of the floor being clean. A more recent approach, advocated by Rappaport Hovav and Levin (1998), describes a basic set of event templates corresponding to Vendler?s event classes (Vendler, 1957): (3) a. [ x ACT<MANNER> ] (activity) b. [ x <STATE> ] (state) c. [ BECOME [ x <STATE> ] ] (achievement) d. [ x C
t Hovav, 1996). Fixed roles are too coarsegrained to account for certain semantic distinctions?the only recourse, to expand the inventory of roles, comes with the price of increased complexity, e.g., in the syntaxto-semantics mapping. There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure?representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity (Dowty, 1979; Jackendoff, 1983; Pustejovsky, 1991b; Rappaport Hovav and Levin, 1998). Consider the following example: (2) He sweeps the floor clean. [ [ DO(he, sweeps(the floor)) ] CAUSE [ BECOME [ clean(the floor) ] ] ] Dowty breaks the event described by (2) into two subevents, the activity of sweeping the floor and its result, the state of the floor being clean. A more recent approach, advocated by Rappaport Hovav and Levin (1998), describes a basic set of event templates corresponding to Vendler?s event classes (Vendler, 1957): (3) a. [ x ACT<MANNER> ] (activity) b. [ x <STATE> ] (state) c. [ BECOME [ x <STATE> ] ] (achievement) d. [ x CAUSE [ BECOME [ x <STATE> ] ] ] (ac
primitive predicates representing concepts such as causality and inchoativity (Dowty, 1979; Jackendoff, 1983; Pustejovsky, 1991b; Rappaport Hovav and Levin, 1998). Consider the following example: (2) He sweeps the floor clean. [ [ DO(he, sweeps(the floor)) ] CAUSE [ BECOME [ clean(the floor) ] ] ] Dowty breaks the event described by (2) into two subevents, the activity of sweeping the floor and its result, the state of the floor being clean. A more recent approach, advocated by Rappaport Hovav and Levin (1998), describes a basic set of event templates corresponding to Vendler?s event classes (Vendler, 1957): (3) a. [ x ACT<MANNER> ] (activity) b. [ x <STATE> ] (state) c. [ BECOME [ x <STATE> ] ] (achievement) d. [ x CAUSE [ BECOME [ x <STATE> ] ] ] (accomplishment) e. [ [ x ACT<MANNER> ] CAUSE [ BECOME [ x <STATE> ] ] ] (accomplishment) A process called Template Augmentation allows basic event templates to be freely ?augmented? to any other event template. This process, for example, explains the resultative form of surface contact verbs like sweep: (4) a. Phil swept the floor. [ Phil ACT<SWEEP> floor ] b. Phil swept the floor clean. [ [ Phil ACT<SWEEP> floor ] CAUSE [ BECOME [ floor <CLEAN> ] ] 
al items, that is, fragments of event structure are directly associated with derivational morphemes. We have the following situation: (7) JflatK = [state flat] Jis flatK = ?xBE(x, [state flat]) J-enK = ?s?xARG?(x, e) ? BECOME(BE(s), e) Jflat-enK = ?x.ARG?(x, e)? BECOME(BE([state flat]), e) In this case, the complete event structure of a word can be compositionally derived from its component morphemes. This framework, where the ?semantic load? is spread more evenly throughout the lexicon to lexical categories not typically thought to bear semantic content, is essentially the model advocated by Pustejovsky (1991a), among many others. Note that such an approach is no longer lexicalist: each lexical item does not fully encode its associated syntactic and semantic structures. Rather, meanings are composed from component morphemes. In addition to -en, other productive derivational suffixes in English such as -er, -ize, -ion, just to name a few, can be analyzed in a similar way. In fact, we may view morphological rules for composing morphemes into larger phonological units the same way we view syntactic rules for combining constituents into higher-level projections, i.e., why distinguish VP ? V + NP from 
clusion that follows naturally from this analysis is that fragments of event structure are directly encoded in the syntactic structure. We could, in fact, further postulate that all event structure is encoded syntactically, i.e., that lexical semantic representation is isomorphic to syntactic structure. Sometimes, these functional elements are overtly realized, e.g., -en. Often, however, these functional elements responsible for licensing event interpretations are not phonologically realized. These observations and this line of reasoning has not escaped the attention of theoretical linguists: Hale and Keyser (1993) propose that argument structure is, in fact, encoded syntactically. They describe a cascading verb phrase analysis with multiple phonetically empty verbal projections corresponding to concepts such as inchoativity and agentivity. This present framework builds on the work of Hale and Keyser, but in addition to advancing a more refined theory of verbal argument structure, I also describe a computational implementation. 4 Event Types Although the study of event types can be traced back to Aristotle, it wasn?t until the twentieth century when philosophers and linguists developed classifications o
nal ontology of event types. Examples of the four event types are given below: (8) States Activities know run believe walk Accomplishments Achievements paint a picture recognize make a chair find Under Vendler?s classification, activities and states both depict situations that are inherently temporally unbounded (atelic); states denote static situations, whereas activities denote on-going dynamic situations. Accomplishments and achievements both express a change of state, and hence are temporally bounded (telic); achievements are punctual, whereas accomplishments extend over a period of time. Tenny (1987) observes that accomplishments differ from achievements only in terms of event duration, which is often a question of granularity. From typological studies, it appears that states, change of states, and activities form the most basic ontology of event types. They correspond to the primitives BE, BECOME, and DO proposed by a variety of linguists; let us adopt these conceptual primitives as the basic vocabulary of our lexical semantic representation. Following the non-lexicalist tradition, these primitives are argued to occupy functional projections in the syntactic structure, as so-called light
chievements only in terms of event duration, which is often a question of granularity. From typological studies, it appears that states, change of states, and activities form the most basic ontology of event types. They correspond to the primitives BE, BECOME, and DO proposed by a variety of linguists; let us adopt these conceptual primitives as the basic vocabulary of our lexical semantic representation. Following the non-lexicalist tradition, these primitives are argued to occupy functional projections in the syntactic structure, as so-called light verbs. Here, I adopt the model proposed by Marantz (1997) and decompose lexical verbs into verbalizing heads and verbal roots. Verbalizing heads introduce relevant eventive interpretations in the syntax, and correspond to (assumed) universal primitives of the human cognitive system. On the other hand, verbal roots represent abstract (categoryless) concepts and basically correspond to open-class items drawn from encyclopedic knowledge. I assume an inventory of three verbalizing heads, each corresponding to an aforementioned primitive: (9) vDO [+dynamic, ?inchoative] = DO v? [+dynamic, +inchoative] = BECOME vBE [?dynamic] = BE The light verb vDO licen
 in the syntax, and correspond to (assumed) universal primitives of the human cognitive system. On the other hand, verbal roots represent abstract (categoryless) concepts and basically correspond to open-class items drawn from encyclopedic knowledge. I assume an inventory of three verbalizing heads, each corresponding to an aforementioned primitive: (9) vDO [+dynamic, ?inchoative] = DO v? [+dynamic, +inchoative] = BECOME vBE [?dynamic] = BE The light verb vDO licenses an atelic non-inchoative event, and is compatible with verbal roots expressing activity. It projects a functional head, voice (Kratzer, 1994), whose specifier is the external argument. (10) John ran. voiceP DP John voice vDOP vDO ? run ARGext(John, e) ? DO([activity run], e) The entire voiceP is further embedded under a tense projection (not shown here), and the verbal complex undergoes head movement and left adjoins to any overt tense markings. Similarly, the external argument raises to [Spec, TP]. This is in accordance with modern linguistic theory, more specifically, the subject-internal hypothesis. The verbal root can itself idiosyncratically license a DP to give rise to a transitive sentence (subjected, naturally, to selection
4) John broke the window. voiceP DP John voice vDOP vDO v?P DP window v? vBE ? break CAUSE(e1, e2) ? ARGext(John, e1) ? DO([activity undef], e1) ? ARG?(window, e2) ? BECOME(BE([state break]), e2) Note that in the causative form, vDO is unmodified by a verbal root?the manner of activity is left unspecified, i.e., ?John did something that caused the window to undergo the change of state break.? Given this framework, deadjectival verbs such as flatten can be directly derived in the syntax: (15) The tire flattened. v?P DP tire v? -en vBEP vBE ? flat ARG?(tire, e) ? BECOME(BE([state flat]), e) In (Lin, 2004), I present evidence from Mandarin Chinese that this analysis is on the right track. The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework. 5 Minimalist Derivations My theory of verbal argument structure can be implemented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing. The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky?s Minimalist Program (Stabler, 1997; Harkema, 2000; Niyogi, 2001). Lexical entries in the 
BE ? flat ARG?(tire, e) ? BECOME(BE([state flat]), e) In (Lin, 2004), I present evidence from Mandarin Chinese that this analysis is on the right track. The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework. 5 Minimalist Derivations My theory of verbal argument structure can be implemented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing. The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky?s Minimalist Program (Stabler, 1997; Harkema, 2000; Niyogi, 2001). Lexical entries in the system are minimally specified, each consisting of a phonetic form, a list of relevant features, and semantics in the form of a ? expression. The basic structure building operation, MERGE, takes two items and creates a larger item. In the process, compatible features are canceled and one of the items projects. Simultaneously, the ? expression associated with the licensor is applied to the ? expression associated with the licensee (in theoretical linguistic terms, SpellOut). The most basic feature is the =x licensor feature, which cancels o
tire, e) ? BECOME(BE([state flat]), e) In (Lin, 2004), I present evidence from Mandarin Chinese that this analysis is on the right track. The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework. 5 Minimalist Derivations My theory of verbal argument structure can be implemented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing. The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky?s Minimalist Program (Stabler, 1997; Harkema, 2000; Niyogi, 2001). Lexical entries in the system are minimally specified, each consisting of a phonetic form, a list of relevant features, and semantics in the form of a ? expression. The basic structure building operation, MERGE, takes two items and creates a larger item. In the process, compatible features are canceled and one of the items projects. Simultaneously, the ? expression associated with the licensor is applied to the ? expression associated with the licensee (in theoretical linguistic terms, SpellOut). The most basic feature is the =x licensor feature, which cancels out a correspond
ME(BE([state flat]), e) In (Lin, 2004), I present evidence from Mandarin Chinese that this analysis is on the right track. The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework. 5 Minimalist Derivations My theory of verbal argument structure can be implemented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing. The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky?s Minimalist Program (Stabler, 1997; Harkema, 2000; Niyogi, 2001). Lexical entries in the system are minimally specified, each consisting of a phonetic form, a list of relevant features, and semantics in the form of a ? expression. The basic structure building operation, MERGE, takes two items and creates a larger item. In the process, compatible features are canceled and one of the items projects. Simultaneously, the ? expression associated with the licensor is applied to the ? expression associated with the licensee (in theoretical linguistic terms, SpellOut). The most basic feature is the =x licensor feature, which cancels out a corresponding x licensee 
onetic content of the licensee is affixed to the left or right of the licensor?s phonetic content, respectively. These licensor features also cancel corresponding x licensee features: (17) < book -s :::>n d -k book :n < de- bone ::<n V bone :n Finally, feature checking is implemented by +x/-x features. The +x denotes a need to discharge features, and the -x denotes a need for features. A simple example of this is the case assignment involved in building a prepositional phrase, i.e., prepositions must assign case, and DPs much receive case. (18) < on :::=d:::+k ploc < the :::=n:d ::-k shelf :n Niyogi (2001) has developed an agenda-driven chart parser for the feature-driven formalism described above; please refer to his paper for a description of the parsing algorithm. I have adapted it for my needs and developed grammar fragments that reflect my non-lexicalist semantic framework. As an example, a simplified derivation of the sentence ?The tire flattened.? is shown in Figure 1. The currently implemented system is still at the ?toy parser? stage. Although the effectiveness and coverage < // ::>s vbe?x.BE(x) /flat/ :s[state flat] < /flat -en/ ::::>be =d ?x.?y.ARG?(y, e)? BECOME(x, e) < ::>s :::vbe 
state flat] < /flat -en/ ::::>be =d ?x.?y.ARG?(y, e)? BECOME(x, e) < ::>s :::vbe BE([state flat]) :s > /the tire/ ::d tire < /flat -en/ ::::>be ::=d ?y.ARG?(y, e)? BECOME(BE([state tall]), e) < :::>s::::vbe :s ARG?(he, e) ? BECOME(BE([state tall(3cm)]), e) Figure 1: Simplified derivation for the sentence ?The tire flattened.? of my parser remains to be seen, similar approaches have been successful at capturing complex linguistic phenomena. With a minimal set of features and a small number of lexical entries, Niyogi (2001) has successfully modeled many of the argument alternations described by Levin (1993) using a Hale and Keyser (1993) style analysis. I believe that with a suitable lexicon (either hand crafted or automatically induced), my framework can be elaborated into a system whose performance is comparable to that of current statistical parsers, but with the added advantage of simultaneously providing a richer lexical semantic representation of the input sentence than flat predicate argument structures based on semantic roles. 6 Conclusion A combination of factors in the natural development of computational linguistics as a field has conspired to narrow the diversity of techniques being 
en/ ::::>be =d ?x.?y.ARG?(y, e)? BECOME(x, e) < ::>s :::vbe BE([state flat]) :s > /the tire/ ::d tire < /flat -en/ ::::>be ::=d ?y.ARG?(y, e)? BECOME(BE([state tall]), e) < :::>s::::vbe :s ARG?(he, e) ? BECOME(BE([state tall(3cm)]), e) Figure 1: Simplified derivation for the sentence ?The tire flattened.? of my parser remains to be seen, similar approaches have been successful at capturing complex linguistic phenomena. With a minimal set of features and a small number of lexical entries, Niyogi (2001) has successfully modeled many of the argument alternations described by Levin (1993) using a Hale and Keyser (1993) style analysis. I believe that with a suitable lexicon (either hand crafted or automatically induced), my framework can be elaborated into a system whose performance is comparable to that of current statistical parsers, but with the added advantage of simultaneously providing a richer lexical semantic representation of the input sentence than flat predicate argument structures based on semantic roles. 6 Conclusion A combination of factors in the natural development of computational linguistics as a field has conspired to narrow the diversity of techniques being explored by researchers. While 
