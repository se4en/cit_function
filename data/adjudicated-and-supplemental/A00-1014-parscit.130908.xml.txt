r output over the telephone. We used the Bell Labs TTS system (Sproat, 1998), which in addition to converting plain text into speech, accepts text strings annotated to override default pitch height, accent placement, speaking rate, etc.2 3.1 Semantic Interpretation MIMIC utilizes a non-recursive frame-based semantic representation commonly used in spoken dialogue systems (e.g. (Seneff et al., 1991; Lamel, 1998)), which represents an utterance as a set of attribute-value pairs. Figure 2(a) shows the frame-based semantic representation for the utterance &quot;What time is Analyze This playing 2 See (Nakatani and Chu-Carroll, 2000) for how MIMIC's dialoguelevel knowledge is used to override default prosodic assignments for concept-to-speech generation. Question-Type: When Movie: Analyze This Theater: null Town: Montclair (a) Semantic Representation Question-Type: When Movie: mandatory Theater: mandatory Town: optional (b) Task Specification Figure 2: Semantic Representation and Task Specification in Montclair?&quot; MIMIC's semantic representation is constructed by first extracting, for each attribute, a set of keywords from the user utterance. Using a vector-based topic identification process (Salton, 1971; Chu-Carroll and 
* attribute unspecified */ Instantiate(ambiguous-attr) Else /* more than one value specified Constrain(ambiguous-attr) Else if InvalidAction detected ProvideNegativeAnswer(SemRep) Else 1* well-formed query */ answer 4-- database-query(SemRep) ProvideAnswer(answer) Figure 4: Goal Selection Algorithm user queries (steps 1-8)5 (van Beek et al., 1993; Raskutti and Zukerman, 1993; Qu and Beale, 1999), and 2) providing answers to well-formed queries (steps 9-11). 3.2.3 Strategy Selection Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction (Whittaker and Stenton, 1988; Walker and Whittaker, 1990; Chu-Carroll and Brown, 1998). Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution. Since task initiative models contribution to domain/problemsolving goals, while dialogue initiative affects the cur5An alternative strategy to step (4) is to perform a database lookup based on the ambiguous query and summarize the results (Litman et al., 1998), which we leave for future work. rent discourse goal, we developed alternative strategies for achieving the goals in Figure 4 based on initiative distribu
stantiate(ambiguous-attr) Else /* more than one value specified Constrain(ambiguous-attr) Else if InvalidAction detected ProvideNegativeAnswer(SemRep) Else 1* well-formed query */ answer 4-- database-query(SemRep) ProvideAnswer(answer) Figure 4: Goal Selection Algorithm user queries (steps 1-8)5 (van Beek et al., 1993; Raskutti and Zukerman, 1993; Qu and Beale, 1999), and 2) providing answers to well-formed queries (steps 9-11). 3.2.3 Strategy Selection Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction (Whittaker and Stenton, 1988; Walker and Whittaker, 1990; Chu-Carroll and Brown, 1998). Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution. Since task initiative models contribution to domain/problemsolving goals, while dialogue initiative affects the cur5An alternative strategy to step (4) is to perform a database lookup based on the ambiguous query and summarize the results (Litman et al., 1998), which we leave for future work. rent discourse goal, we developed alternative strategies for achieving the goals in Figure 4 based on initiative distribution, as shown in Table 1. T
ps 9-11). 3.2.3 Strategy Selection Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction (Whittaker and Stenton, 1988; Walker and Whittaker, 1990; Chu-Carroll and Brown, 1998). Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution. Since task initiative models contribution to domain/problemsolving goals, while dialogue initiative affects the cur5An alternative strategy to step (4) is to perform a database lookup based on the ambiguous query and summarize the results (Litman et al., 1998), which we leave for future work. rent discourse goal, we developed alternative strategies for achieving the goals in Figure 4 based on initiative distribution, as shown in Table 1. The strategies employed when MIMIC has only dialogue initiative are similar to the mixed initiative dialogue strategies employed by many existing spoken dialogue systems (e.g., (Bennacef et at., 1996; Stent et al., 1999)). To instantiate an attribute, MIMIC adopts the InfoSeek dialogue act to solicit the missing information. In contrast, when MIMIC has both initiatives, it plays a more active role by presenting the
o domain/problemsolving goals, while dialogue initiative affects the cur5An alternative strategy to step (4) is to perform a database lookup based on the ambiguous query and summarize the results (Litman et al., 1998), which we leave for future work. rent discourse goal, we developed alternative strategies for achieving the goals in Figure 4 based on initiative distribution, as shown in Table 1. The strategies employed when MIMIC has only dialogue initiative are similar to the mixed initiative dialogue strategies employed by many existing spoken dialogue systems (e.g., (Bennacef et at., 1996; Stent et al., 1999)). To instantiate an attribute, MIMIC adopts the InfoSeek dialogue act to solicit the missing information. In contrast, when MIMIC has both initiatives, it plays a more active role by presenting the user with additional information comprising valid instantiations of the attribute (GiveOptions). Given an invalid query, MIMIC notifies the user of the failed query and provides an openended prompt when it only has dialogue initiative. When MIMIC has both initiatives, however, in addition to NotifyFailure, it suggests an alternative close to the user's original query and provides a limited prompt. 
ys take over task initiative and suggest an alternative item. 5 System Evaluation We conducted two experiments to evaluate MIMIC's automatic adaptation capabilities. We compared MIMIC with two control systems: MIMIC-SI, a system-initiative version of MIMIC in which the system retains both initiatives throughout the dialogue, and MIMIC-MI, a nonadaptive mixed-initiative version of MIMIC that resembles the behavior of many existing dialogue systems. In this section we summarize these experiments and their results. A companion paper describes the evaluation process and results in further detail (Chu-Carroll and Nickerson, 2000). Each experiment involved eight users interacting with MIMIC and MIMIC-SI or MIMIC-MI to perform a set of tasks, each requiring the user to obtain specific movie information. User satisfaction was assessed by asking the subjects to fill out a questionnaire after interacting with each version of the system. Furthermore, a number of performance features, largely based on the PARADISE dialogue evaluation scheme (Walker et al., 1997), were automatically logged, derived, or manually annotated. In addition, we logged the cues automatically detected in each user utterance, as well as the initiative 
tems. In this section we summarize these experiments and their results. A companion paper describes the evaluation process and results in further detail (Chu-Carroll and Nickerson, 2000). Each experiment involved eight users interacting with MIMIC and MIMIC-SI or MIMIC-MI to perform a set of tasks, each requiring the user to obtain specific movie information. User satisfaction was assessed by asking the subjects to fill out a questionnaire after interacting with each version of the system. Furthermore, a number of performance features, largely based on the PARADISE dialogue evaluation scheme (Walker et al., 1997), were automatically logged, derived, or manually annotated. In addition, we logged the cues automatically detected in each user utterance, as well as the initiative distribution for each turn and the dialogue acts selected to generate each system response. The features gathered from the dialogue interactions were analyzed along three dimensions: system performance, discourse features (in terms of characteristics of the resulting dialogues, such as the cues detected in user utterances), and initiative distribution. Our results show that MIMIC's adaptation capabilities 1) led to better system p
