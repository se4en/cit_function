{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","listItem":[{"#tail":"\n","@confidence":"0.632699333333333","#text":"\n1983; Pustejovsky, 1991b; Rappaport Hovav and Levin,\n1998). Consider the following example:\n(2) He sweeps the floor clean.\n[ [ DO(he, sweeps(the floor)) ] CAUSE\n[ BECOME [ clean(the floor) ] ] ]\nDowty breaks the event described by (2) into two\nsubevents, the activity of sweeping the floor and its result,\nthe state of the floor being clean. A more recent approach,\nadvocated by Rappaport Hovav and Levin (1998), de-\nscribes a basic set of event templates corresponding to\nVendler?s event classes (Vendler, 1957):\n(3) a. [ x ACT<MANNER> ] (activity)\n"},{"#tail":"\n","@confidence":"0.994425666666667","#text":"\n(4) a. Phil swept the floor.\n[ Phil ACT<SWEEP> floor ]\nb. Phil swept the floor clean.\n"},{"#tail":"\n","@confidence":"0.7573025","#text":"\n(5) a. The tire is flat.\nb. The tire flattened.\n"},{"#tail":"\n","@confidence":"0.7312625","#text":"\n(6) a. BE(tire, [state flat])\nb. ARG?(tire, e) ? BECOME(BE([state flat]), e)\n"}],"figure":[{"#tail":"\n","@confidence":"0.8912174","#text":"\n(8)\nStates Activities\nknow run\nbelieve walk\nAccomplishments Achievements\n"},{"#tail":"\n","@confidence":"0.912816444444444","#text":"\n(10) John ran.\nvoiceP\nDP\nJohn\nvoice vDOP\nvDO\n?\nrun\nARGext(John, e) ? DO([activity run], e)\n"},{"#tail":"\n","@confidence":"0.940919878787879","#text":"\n(11) John ran the marathon.\nvoiceP\nDP\nJohn voice vDOP\nvDO\n?\nP\nrun DP\nthe marathon\nARGext(John, e) ? DO([activity run(marathon)], e)\nSimilarly, vBE licenses static situations, and is compat-\nible with verbal roots expressing state:\n(12) Mary is tall.\nvBEP\nDP\nMary\nvBE\nis\n?\ntall\nBE(Mary, [state tall])\nThe light verb v? licenses telic inchoative events (i.e.,\nchange of states), which correspond to the BECOME\nprimitive:\n(13) The window broke:\nv?P\nDP\nwindow\nv?\nvBE\n?\nbreak\nARG?(window, e) ? BECOME(BE([state break]), e)\n"},{"#tail":"\n","@confidence":"0.83595175","#text":"\n(14) John broke the window.\nvoiceP\nDP\nJohn voice vDOP\n"},{"#tail":"\n","@confidence":"0.462128272727273","#text":"\n(15) The tire flattened.\nv?P\nDP\ntire\nv?\n-en\nvBEP\nvBE\n?\nflat\nARG?(tire, e) ? BECOME(BE([state flat]), e)\n"},{"#tail":"\n","@confidence":"0.86465","#text":"\n(16) <\nthe\n:::=n d -k\nshelf\n:n\n"},{"#tail":"\n","@confidence":"0.9660191","#text":"\n(17) <\nbook -s\n:::>n d -k\nbook\n:n\n<\nde- bone\n::<n V\nbone\n:n\n"},{"#tail":"\n","@confidence":"0.94989325","#text":"\n(18) <\non\n:::=d:::+k ploc\n<\nthe\n:::=n:d ::-k\nshelf\n:n\n"},{"#tail":"\n","@confidence":"0.993157038461538","#text":"\n<\n//\n::>s vbe?x.BE(x)\n/flat/\n:s[state flat]\n<\n/flat -en/\n::::>be =d\n?x.?y.ARG?(y, e)?\nBECOME(x, e)\n<\n::>s :::vbe\nBE([state flat])\n:s\n>\n/the tire/\n::d\ntire\n<\n/flat -en/\n::::>be ::=d\n?y.ARG?(y, e)?\nBECOME(BE([state tall]), e)\n<\n:::>s::::vbe :s\nARG?(he, e) ? BECOME(BE([state tall(3cm)]), e)\n"}],"address":{"#tail":"\n","@confidence":"0.982189","#text":"\nCambridge, MA 02139\n"},"author":{"#tail":"\n","@confidence":"0.99494","#text":"\nJimmy Lin\n"},"equation":[{"#tail":"\n","@confidence":"0.979636833333333","#text":"\nb. [ x <STATE> ] (state)\nc. [ BECOME [ x <STATE> ] ] (achievement)\nd. [ x CAUSE [ BECOME [ x <STATE> ] ] ]\n(accomplishment)\ne. [ [ x ACT<MANNER> ] CAUSE [ BECOME\n[ x <STATE> ] ] ] (accomplishment)\n"},{"#tail":"\n","@confidence":"0.9261555","#text":"\n[ [ Phil ACT<SWEEP> floor ] CAUSE\n[ BECOME [ floor <CLEAN> ] ] ]\n"},{"#tail":"\n","@confidence":"0.9065616","#text":"\n(7) JflatK = [state flat]\nJis flatK = ?xBE(x, [state flat])\nJ-enK = ?s?xARG?(x, e) ? BECOME(BE(s), e)\nJflat-enK = ?x.ARG?(x, e)?\nBECOME(BE([state flat]), e)\n"},{"#tail":"\n","@confidence":"0.773766666666667","#text":"\n(9) vDO [+dynamic, ?inchoative] = DO\nv? [+dynamic, +inchoative] = BECOME\nvBE [?dynamic] = BE\n"},{"#tail":"\n","@confidence":"0.7608208","#text":"\nvDO v?P\nDP\nwindow\nv?\nvBE\n?\nbreak\nCAUSE(e1, e2) ? ARGext(John, e1) ?\nDO([activity undef], e1) ? ARG?(window, e2) ?\nBECOME(BE([state break]), e2)\n"}],"title":{"#tail":"\n","@confidence":"0.995898","#text":"\nA Computational Framework for Non-Lexicalist Semantics\n"},"@confidence":"0.000000","#tail":"\n","reference":{"#tail":"\n","@confidence":"0.998837273809523","#text":"\nCollin F. Baker, Charles J. Fillmore, and John B. Lowe.\n1998. The Berkeley FrameNet project. In Proceedings\nof the 36th Annual Meeting of the Association for Com-\nputational Linguistics and 17th International Con-\nference on Computational Linguistics (COLING/ACL\n1998).\nEugene Charniak. 2001. Immediate head parsing for\nlanguage models. In Proceedings of the 39th Annual\nMeeting of the Association for Computational Linguis-\ntics (ACL-2001).\nMichael Collins. 1997. Three generative lexicalized\nmodels for statistical parsing. In Proceedings of the\n35th Annual Meeting of the Association for Computa-\ntional Linguistics (ACL-1997).\nDavid Dowty. 1979. Word Meaning and Montague\nGrammar. D. Reidel Publishing Company, Dordrecht,\nThe Netherlands.\nCharles J. Fillmore. 1968. The case for case. In E. Bach\nand R. Harms, editors, Universals in Linguistic The-\nory, pages 1?88. Holt, Rinehart, and Winston, New\nYork.\nKenneth Hale and Samuel Jay Keyser. 1993. On argu-\nment structure and the lexical expression of syntactic\nrelations. In Kenneth Hale and Samuel Jay Keyser,\neditors, The View from Building 20: Essays in Linguis-\ntics in Honor of Sylvain Bromberger. MIT Press, Cam-\nbridge, Massachusetts.\nMorris Halle and Alec Marantz. 1993. Distributed mor-\nphology and the pieces of inflection. In Kenneth Hale\nand S. Jay Keyser, editors, In The View from Build-\ning 20, pages 111?176. MIT Press, Cambridge, Mas-\nsachusetts.\nHenk Harkema. 2000. A recognizer for minimalist\ngrammars. In Proceedings of the Sixth International\nWorkshop on Parsing Technologies (IWPT 2000).\nRay Jackendoff. 1983. Semantics and Cognition. MIT\nPress, Cambridge, Massachusetts.\nPaul Kingsbury, Martha Palmer, and Mitch Marcus.\n2002. Adding semantic annotation to the Penn Tree-\nBank. In Proceeding of 2002 Human Language Tech-\nnology Conference (HLT 2002).\nAngelika Kratzer. 1994. The event argument and the se-\nmantics of voice. Unpublished manuscript, University\nof Massachusetts, Amherst.\nBeth Levin and Malka Rappaport Hovav. 1996. From\nlexical semantics to argument realization. Unpub-\nlished manuscript, Northwestern University and Bar\nIlan University.\nBeth Levin. 1993. English Verb Classes and Alter-\nnations: A Preliminary Investigation. University of\nChicago Press, Chicago, Illinois.\nBeth Levin. 1999. Objecthood: An event structure per-\nspective. In Proceedings of the 35th Annual Meeting\nof the Chicago Linguistics Society.\nJimmy Lin. 2004. Event Structure and the Encoding of\nArguments: The Syntax of the English and Mandarin\nVerb Phrase. Ph.D. thesis, Department of Electrical\nEngineering and Computer Science, Massachusetts In-\nstitute of Technology.\nAlec Marantz. 1997. No escape from syntax: Don?t try\nmorphological analysis in the privacy of your own lex-\nicon. In Proceedings of the 21st Annual Penn Linguis-\ntics Colloquium.\nSourabh Niyogi. 2001. A minimalist implementation\nof verb subcategorization. In Proceedings of the Sev-\nenth International Workshop on Parsing Technologies\n(IWPT-2001).\nJames Pustejovsky. 1991a. The generative lexicon.\nComputational Linguistics, 17(4):409?441.\nJames Pustejovsky. 1991b. The syntax of event structure.\nCognition, 41:47?81.\nMalka Rappaport Hovav and Beth Levin. 1998. Building\nverb meanings. In Miriam Butt and Wilhelm Geuder,\neditors, The Projection of Arguments: Lexical and\nCompositional Factors. CSLI Publications, Stanford,\nCalifornia.\nEdward Stabler. 1997. Derivational minimalism. In\nChristian Retore?, editor, Logical Aspects of Computa-\ntional Linguistics. Springer.\nCarol Tenny. 1987. Grammaticalizing Aspect and Affect-\nedness. Ph.D. thesis, Massachusetts Institute of Tech-\nnology.\nZeno Vendler. 1957. Verbs and times. Philosophical\nReview, 56:143?160.\n"},"bodyText":[{"#tail":"\n","@confidence":"0.987007222222222","#text":"\nUnder a lexicalist approach to semantics, a verb\ncompletely encodes its syntactic and semantic\nstructures, along with the relevant syntax-to-\nsemantics mapping; polysemy is typically at-\ntributed to the existence of different lexical en-\ntries. A lexicon organized in this fashion con-\ntains much redundant information and is un-\nable to capture cross-categorial morphological\nderivations. The solution is to spread the ?se-\nmantic load? of lexical entries to other mor-\nphemes not typically taken to bear semantic\ncontent. This approach follows current trends\nin linguistic theory, and more perspicuously ac-\ncounts for alternations in argument structure.\nI demonstrate how such a framework can be\ncomputationally realized with a feature-based,\nagenda-driven chart parser for the Minimalist\nProgram.\n"},{"#tail":"\n","@confidence":"0.966379709677419","#text":"\nThe understanding of natural language text includes not\nonly analysis of syntactic structure, but also of semantic\ncontent. Due to advances in statistical syntactic parsing\ntechniques (Collins, 1997; Charniak, 2001), attention has\nrecently shifted towards the harder question of analyzing\nthe meaning of natural language sentences.\nA common lexical semantic representation in the com-\nputational linguistics literature is a frame-based model\nwhere syntactic arguments are associated with various se-\nmantic roles (essentially frame slots). Verbs are viewed\nas simple predicates over their arguments. This approach\nhas its roots in Fillmore?s Case Grammar (1968), and\nserves as the foundation for two current large-scale se-\nmantic annotation projects: FrameNet (Baker et al, 1998)\nand PropBank (Kingsbury et al, 2002).\nUnderlying the semantic roles approach is a lexical-\nist assumption, that is, each verb?s lexical entry com-\npletely encodes (more formally, projects) its syntactic and\nsemantic structures. Alternations in argument structure\nare usually attributed to multiple lexical entries (i.e., verb\nsenses). Under the lexicalist approach, the semantics of\nthe verb break might look something like this:\n(1) break(agent, theme)\nagent: subject theme: object\nbreak(agent, theme, instrument)\nagent: subject theme: object\ninstrument: oblique(with)\nbreak(theme)\ntheme: subject\n. . .\nThe lexicon explicitly specifies the different subcate-\ngorization frames of a verb, e.g., the causative frame, the\ncausative instrumental frame, the inchoative frame, etc.\nThe major drawback of this approach, however, is the\ntremendous amount of redundancy in the lexicon?for\nexample, the class of prototypical transitive verbs where\nthe agent appears as the subject and the theme as the di-\nrect object must all duplicate this pattern.\nThe typical solution to the redundancy problem is\nto group verbs according to their argument realization\npatterns (Levin, 1993), possibly arranged in an inheri-\ntance hierarchy. The argument structure and syntax-to-\nsemantics mapping would then only need to be specified\nonce for each verb class. In addition, lexical rules could\nbe formulated to derive certain alternations from more ba-\nsic forms.\nNevertheless, the lexicalist approach does not capture\nproductive morphological processes that pervade natu-\nral language, for example, flat.V ? flatten.ADJ or ham-\nmer.N ? hammer.V; most frameworks for computational\nsemantics fail to capture the deeper derivational relation-\nship between morphologically-related terms. For lan-\nguages with rich derivational morphology, this problem\nis often critical: the standard architectural view of mor-\nphological analysis as a preprocessor presents difficulties\nin handling semantically meaningful affixes.\nIn this paper, I present a computational implementation\nof Distributed Morphology (Halle and Marantz, 1993), a\nnon-lexicalist linguistic theory that erases the distinction\nbetween syntactic derivation and morphological deriva-\ntion. This framework leads to finer-grained semantics ca-\npable of better capturing linguistic generalizations.\n"},{"#tail":"\n","@confidence":"0.9840408125","#text":"\nIt has previously been argued that representations based\non a fixed collection of semantic roles cannot adequately\ncapture natural language semantics. The actual inventory\nof semantic roles, along with precise definitions and di-\nagnostics, remains an unsolved problem; see (Levin and\nRappaport Hovav, 1996). Fixed roles are too coarse-\ngrained to account for certain semantic distinctions?the\nonly recourse, to expand the inventory of roles, comes\nwith the price of increased complexity, e.g., in the syntax-\nto-semantics mapping.\nThere is a general consensus among theoretical lin-\nguists that the proper representation of verbal argument\nstructure is event structure?representations grounded in\na theory of events that decompose semantic roles in\nterms of primitive predicates representing concepts such\nas causality and inchoativity (Dowty, 1979; Jackendoff,\n"},{"#tail":"\n","@confidence":"0.71697375","#text":"\nA process called Template Augmentation allows basic\nevent templates to be freely ?augmented? to any other\nevent template. This process, for example, explains the\nresultative form of surface contact verbs like sweep:\n"},{"#tail":"\n","@confidence":"0.999005857142857","#text":"\nFollowing this long tradition of research, I propose a\nsyntactically-based event representation specifically de-\nsigned to handle alternations in argument structure. Fur-\nthermore, I will show how this theoretical analysis can\nbe implemented in a feature-driven computational frame-\nwork. The product is an agenda-driven, chart-based\nparser for the Minimalist Program.\n"},{"#tail":"\n","@confidence":"0.993991666666667","#text":"\nA primary advantage of decompositional (non-lexicalist)\ntheories of lexical semantics is the ability to transpar-\nently relate morphologically related words?explaining,\nfor example, categorial divergences in terms of differ-\nences in event structure. Consider the adjective flat and\nthe deadjectival verb flatten:\n"},{"#tail":"\n","@confidence":"0.866414","#text":"\nClearly, (5a) is a stative sentence denoting a static situ-\nation, while (5b) denotes an inchoative event, i.e., a tran-\nsition from ?tire is not flat? to ?tire is flat?. One might\nassign the above two sentence the following logical form:\n"},{"#tail":"\n","@confidence":"0.993841833333333","#text":"\nIn Davidsonian terms, dynamic events introduce event\narguments, whereas static situations do not. In (6b), the\nsemantic argument that undergoes the change of state\n(ARG?) is introduced externally via the event argument.\nConsidering that the only difference between flat.ADJ\nand flatten.V is the suffix -en, it must be the source of\ninchoativity and contribute the change of state reading\nthat distinguishes the verb from the adjective. Here, we\nhave evidence that derivational affixes affect the seman-\ntic representation of lexical items, that is, fragments of\nevent structure are directly associated with derivational\nmorphemes. We have the following situation:\n"},{"#tail":"\n","@confidence":"0.991020340909091","#text":"\nIn this case, the complete event structure of a word\ncan be compositionally derived from its component mor-\nphemes. This framework, where the ?semantic load? is\nspread more evenly throughout the lexicon to lexical cat-\negories not typically thought to bear semantic content, is\nessentially the model advocated by Pustejovsky (1991a),\namong many others. Note that such an approach is no\nlonger lexicalist: each lexical item does not fully encode\nits associated syntactic and semantic structures. Rather,\nmeanings are composed from component morphemes.\nIn addition to -en, other productive derivational suf-\nfixes in English such as -er, -ize, -ion, just to name a\nfew, can be analyzed in a similar way. In fact, we may\nview morphological rules for composing morphemes into\nlarger phonological units the same way we view syntac-\ntic rules for combining constituents into higher-level pro-\njections, i.e., why distinguish VP ? V + NP from V\n? Adj + -en? With this arbitrary distinction erased, we\nare left with a unified morpho-syntactic framework for\nintegrating levels of grammar previously thought to be\nseparate?this is indeed one of the major goals of Dis-\ntributed Morphology. This theoretical framework trans-\nlates into a computational model better suited for analyz-\ning the semantics of natural language, particularly those\nrich in morphology.\nA conclusion that follows naturally from this analysis\nis that fragments of event structure are directly encoded\nin the syntactic structure. We could, in fact, further pos-\ntulate that all event structure is encoded syntactically, i.e.,\nthat lexical semantic representation is isomorphic to syn-\ntactic structure. Sometimes, these functional elements are\novertly realized, e.g., -en. Often, however, these func-\ntional elements responsible for licensing event interpre-\ntations are not phonologically realized.\nThese observations and this line of reasoning has not\nescaped the attention of theoretical linguists: Hale and\nKeyser (1993) propose that argument structure is, in fact,\nencoded syntactically. They describe a cascading verb\nphrase analysis with multiple phonetically empty verbal\nprojections corresponding to concepts such as inchoativ-\nity and agentivity. This present framework builds on the\nwork of Hale and Keyser, but in addition to advancing a\nmore refined theory of verbal argument structure, I also\ndescribe a computational implementation.\n"},{"#tail":"\n","@confidence":"0.9706526","#text":"\nAlthough the study of event types can be traced back\nto Aristotle, it wasn?t until the twentieth century when\nphilosophers and linguists developed classifications of\nevents that capture logical entailments and the co-\noccurrence restrictions between verbs and other syntactic\nelements such as tenses and adverbials. Vendler?s (1957)\nfour-way classification of events into states, activities, ac-\ncomplishments, and achievements serves as a good start-\ning point for a computational ontology of event types.\nExamples of the four event types are given below:\n"},{"#tail":"\n","@confidence":"0.958471806451613","#text":"\npaint a picture recognize\nmake a chair find\nUnder Vendler?s classification, activities and states\nboth depict situations that are inherently temporally un-\nbounded (atelic); states denote static situations, whereas\nactivities denote on-going dynamic situations. Accom-\nplishments and achievements both express a change of\nstate, and hence are temporally bounded (telic); achieve-\nments are punctual, whereas accomplishments extend\nover a period of time. Tenny (1987) observes that ac-\ncomplishments differ from achievements only in terms of\nevent duration, which is often a question of granularity.\nFrom typological studies, it appears that states, change\nof states, and activities form the most basic ontology of\nevent types. They correspond to the primitives BE, BE-\nCOME, and DO proposed by a variety of linguists; let us\nadopt these conceptual primitives as the basic vocabulary\nof our lexical semantic representation.\nFollowing the non-lexicalist tradition, these primitives\nare argued to occupy functional projections in the syntac-\ntic structure, as so-called light verbs. Here, I adopt the\nmodel proposed by Marantz (1997) and decompose lexi-\ncal verbs into verbalizing heads and verbal roots. Verbal-\nizing heads introduce relevant eventive interpretations in\nthe syntax, and correspond to (assumed) universal primi-\ntives of the human cognitive system. On the other hand,\nverbal roots represent abstract (categoryless) concepts\nand basically correspond to open-class items drawn from\nencyclopedic knowledge. I assume an inventory of three\nverbalizing heads, each corresponding to an aforemen-\ntioned primitive:\n"},{"#tail":"\n","@confidence":"0.97853725","#text":"\nThe light verb vDO licenses an atelic non-inchoative\nevent, and is compatible with verbal roots expressing ac-\ntivity. It projects a functional head, voice (Kratzer, 1994),\nwhose specifier is the external argument.\n"},{"#tail":"\n","@confidence":"0.914579272727273","#text":"\nThe entire voiceP is further embedded under a tense\nprojection (not shown here), and the verbal complex un-\ndergoes head movement and left adjoins to any overt\ntense markings. Similarly, the external argument raises to\n[Spec, TP]. This is in accordance with modern linguistic\ntheory, more specifically, the subject-internal hypothesis.\nThe verbal root can itself idiosyncratically license a\nDP to give rise to a transitive sentence (subjected, nat-\nurally, to selectional restrictions). These constructions\ncorrespond to what Levin calls ?non-core transitive sen-\ntences? (1999):\n"},{"#tail":"\n","@confidence":"0.949785285714286","#text":"\nThe structure denotes an event where an entity under-\ngoes a change of state to the end state specified by the\nroot. v?P can be optionally embedded as the complement\nof a vDO, accounting for the causative/inchoative alterna-\ntion. Cyclic head movement (incorporation) of the verbal\nroots into the verbalizing heads up to the highest verbal\nprojection accounts for the surface form of the sentence.\n"},{"#tail":"\n","@confidence":"0.949431833333333","#text":"\nNote that in the causative form, vDO is unmodified by\na verbal root?the manner of activity is left unspecified,\ni.e., ?John did something that caused the window to un-\ndergo the change of state break.?\nGiven this framework, deadjectival verbs such as flat-\nten can be directly derived in the syntax:\n"},{"#tail":"\n","@confidence":"0.98020225","#text":"\nIn (Lin, 2004), I present evidence from Mandarin Chi-\nnese that this analysis is on the right track. The rest of\nthis paper, however, will be concerned with the computa-\ntional implementation of my theoretical framework.\n"},{"#tail":"\n","@confidence":"0.997877875","#text":"\nMy theory of verbal argument structure can be imple-\nmented in a unified morpho-syntactic parsing model\nthat interleaves syntactic and semantic parsing. The\nsystem is in the form of an agenda-driven chart-based\nparser whose foundation is similar to previous formaliza-\ntions of Chomsky?s Minimalist Program (Stabler, 1997;\nHarkema, 2000; Niyogi, 2001).\nLexical entries in the system are minimally specified,\neach consisting of a phonetic form, a list of relevant fea-\ntures, and semantics in the form of a ? expression.\nThe basic structure building operation, MERGE, takes\ntwo items and creates a larger item. In the process,\ncompatible features are canceled and one of the items\nprojects. Simultaneously, the ? expression associated\nwith the licensor is applied to the ? expression associated\nwith the licensee (in theoretical linguistic terms, Spell-\nOut).\nThe most basic feature is the =x licensor feature,\nwhich cancels out a corresponding x licensee feature and\nprojects. A simple example is a determiner selecting a\nnoun to form a determiner phrase (akin to the context free\nrule DP ? det noun). This is shown below (underline in-\ndicates canceled features, and the node label < indicates\nthat the left item projects):\n"},{"#tail":"\n","@confidence":"0.9972222","#text":"\nThe features >x and <x trigger head movement (in-\ncorporation), i.e., the phonetic content of the licensee is\naffixed to the left or right of the licensor?s phonetic con-\ntent, respectively. These licensor features also cancel cor-\nresponding x licensee features:\n"},{"#tail":"\n","@confidence":"0.989077","#text":"\nFinally, feature checking is implemented by +x/-x fea-\ntures. The +x denotes a need to discharge features, and\nthe -x denotes a need for features. A simple example of\nthis is the case assignment involved in building a preposi-\ntional phrase, i.e., prepositions must assign case, and DPs\nmuch receive case.\n"},{"#tail":"\n","@confidence":"0.993540333333333","#text":"\nNiyogi (2001) has developed an agenda-driven chart\nparser for the feature-driven formalism described above;\nplease refer to his paper for a description of the parsing\nalgorithm. I have adapted it for my needs and developed\ngrammar fragments that reflect my non-lexicalist seman-\ntic framework. As an example, a simplified derivation of\nthe sentence ?The tire flattened.? is shown in Figure 1.\nThe currently implemented system is still at the ?toy\nparser? stage. Although the effectiveness and coverage\n"},{"#tail":"\n","@confidence":"0.998090846153846","#text":"\nof my parser remains to be seen, similar approaches have\nbeen successful at capturing complex linguistic phenom-\nena. With a minimal set of features and a small num-\nber of lexical entries, Niyogi (2001) has successfully\nmodeled many of the argument alternations described by\nLevin (1993) using a Hale and Keyser (1993) style anal-\nysis. I believe that with a suitable lexicon (either hand\ncrafted or automatically induced), my framework can be\nelaborated into a system whose performance is compara-\nble to that of current statistical parsers, but with the added\nadvantage of simultaneously providing a richer lexical se-\nmantic representation of the input sentence than flat pred-\nicate argument structures based on semantic roles.\n"},{"#tail":"\n","@confidence":"0.99993635","#text":"\nA combination of factors in the natural development of\ncomputational linguistics as a field has conspired to nar-\nrow the diversity of techniques being explored by re-\nsearchers. While empirical and quantitative research is\nthe mark of a mature field, such an approach is not with-\nout its adverse side-effects. Both syntactic and semantic\nparsing technology faces a classic chicken-and-egg prob-\nlem. In order for any new framework to become widely\nadopted, it must prove to be competitive with state-of-\nthe-art systems in terms of performance. However, ro-\nbust parsing cannot be achieved without either labori-\nously crafting grammars or a massive dedicated annota-\ntion effort (and experience has shown the latter method\nto be superior). Therein, however, lies the catch: neither\neffort is likely to be undertaken unless a new framework\nproves to be quantitatively superior than previously es-\ntablished methodologies. Lacking quantitative measures\ncurrently, the merits of my proposed framework can only\nbe gauged on theoretical grounds and its future potential\nto better capture a variety of linguistic phenomena.\n"}],"#text":"\n","affiliation":{"#tail":"\n","@confidence":"0.97168","#text":"\nMIT Computer Science and Artificial Intelligence Laboratory\n"},"sectionHeader":[{"#tail":"\n","@confidence":"0.990763","@genericHeader":"abstract","#text":"\nAbstract\n"},{"#tail":"\n","@confidence":"0.996736","@genericHeader":"introduction","#text":"\n1 Introduction\n"},{"#tail":"\n","@confidence":"0.97276","@genericHeader":"method","#text":"\n2 Event Structure\n"},{"#tail":"\n","@confidence":"0.980346","@genericHeader":"method","#text":"\n3 A Decompositional Framework\n"},{"#tail":"\n","@confidence":"0.985774","@genericHeader":"method","#text":"\n4 Event Types\n"},{"#tail":"\n","@confidence":"0.994663","@genericHeader":"method","#text":"\n5 Minimalist Derivations\n"},{"#tail":"\n","@confidence":"0.997791","@genericHeader":"conclusions","#text":"\n6 Conclusion\n"},{"#tail":"\n","@confidence":"0.986389","@genericHeader":"references","#text":"\nReferences\n"}],"figureCaption":{"#tail":"\n","@confidence":"0.8158435","#text":"\nFigure 1: Simplified derivation for the sentence ?The tire\nflattened.?\n"},"email":{"#tail":"\n","@confidence":"0.997582","#text":"\njimmylin@csail.mit.edu\n"}}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.530083","#tail":"\n","@no":"0","address":{"#tail":"\n","@confidence":"0.999943","#text":"Cambridge, MA 02139"},"#text":"\n","affiliation":{"#tail":"\n","@confidence":"0.99998","#text":"MIT Computer Science and Artificial Intelligence Laboratory"},"author":{"#tail":"\n","@confidence":"0.999977","#text":"Jimmy Lin"},"intro":{"#tail":"\n","@confidence":"0.554844","#text":"Program."},"abstract":{"#tail":"\n","@confidence":"0.996475444444444","#text":"Under a lexicalist approach to semantics, a verb completely encodes its syntactic and semantic structures, along with the relevant syntax-tosemantics mapping; polysemy is typically attributed to the existence of different lexical entries. A lexicon organized in this fashion contains much redundant information and is unable to capture cross-categorial morphological derivations. The solution is to spread the ?semantic load? of lexical entries to other morphemes not typically taken to bear semantic content. This approach follows current trends in linguistic theory, and more perspicuously accounts for alternations in argument structure. I demonstrate how such a framework can be computationally realized with a feature-based, agenda-driven chart parser for the Minimalist"},"title":{"#tail":"\n","@confidence":"0.999394","#text":"A Computational Framework for Non-Lexicalist Semantics"},"email":{"#tail":"\n","@confidence":"0.999896","#text":"jimmylin@csail.mit.edu"}}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet project. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics (COLING/ACL 1998)."},"#text":"\n","marker":{"#tail":"\n","#text":"Baker, Fillmore, Lowe, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"yntactic parsing techniques (Collins, 1997; Charniak, 2001), attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences. A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots). Verbs are viewed as simple predicates over their arguments. This approach has its roots in Fillmore?s Case Grammar (1968), and serves as the foundation for two current large-scale semantic annotation projects: FrameNet (Baker et al, 1998) and PropBank (Kingsbury et al, 2002). Underlying the semantic roles approach is a lexicalist assumption, that is, each verb?s lexical entry completely encodes (more formally, projects) its syntactic and semantic structures. Alternations in argument structure are usually attributed to multiple lexical entries (i.e., verb senses). Under the lexicalist approach, the semantics of the verb break might look something like this: (1) break(agent, theme) agent: subject theme: object break(agent, theme, instrument) agent: subject theme: object instrument: oblique(with) break(theme) theme: subject . . .","@endWordPosition":"248","@position":"1751","annotationId":"T1","@startWordPosition":"245","@citStr":"Baker et al, 1998"}},"title":{"#tail":"\n","#text":"The Berkeley FrameNet project."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics (COLING/ACL"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Collin F Baker"},{"#tail":"\n","#text":"Charles J Fillmore"},{"#tail":"\n","#text":"John B Lowe"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Eugene Charniak. 2001. Immediate head parsing for language models. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL-2001)."},"#text":"\n","marker":{"#tail":"\n","#text":"Charniak, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"pread the ?semantic load? of lexical entries to other morphemes not typically taken to bear semantic content. This approach follows current trends in linguistic theory, and more perspicuously accounts for alternations in argument structure. I demonstrate how such a framework can be computationally realized with a feature-based, agenda-driven chart parser for the Minimalist Program. 1 Introduction The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content. Due to advances in statistical syntactic parsing techniques (Collins, 1997; Charniak, 2001), attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences. A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots). Verbs are viewed as simple predicates over their arguments. This approach has its roots in Fillmore?s Case Grammar (1968), and serves as the foundation for two current large-scale semantic annotation projects: FrameNet (Baker et al, 1998) and PropBank (Kingsbury et al, 2002). Un","@endWordPosition":"167","@position":"1192","annotationId":"T2","@startWordPosition":"166","@citStr":"Charniak, 2001"}},"title":{"#tail":"\n","#text":"Immediate head parsing for language models."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL-2001)."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Eugene Charniak"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Michael Collins. 1997. Three generative lexicalized models for statistical parsing. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL-1997)."},"#text":"\n","marker":{"#tail":"\n","#text":"Collins, 1997"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"olution is to spread the ?semantic load? of lexical entries to other morphemes not typically taken to bear semantic content. This approach follows current trends in linguistic theory, and more perspicuously accounts for alternations in argument structure. I demonstrate how such a framework can be computationally realized with a feature-based, agenda-driven chart parser for the Minimalist Program. 1 Introduction The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content. Due to advances in statistical syntactic parsing techniques (Collins, 1997; Charniak, 2001), attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences. A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots). Verbs are viewed as simple predicates over their arguments. This approach has its roots in Fillmore?s Case Grammar (1968), and serves as the foundation for two current large-scale semantic annotation projects: FrameNet (Baker et al, 1998) and PropBank (Kingsbury","@endWordPosition":"165","@position":"1175","annotationId":"T3","@startWordPosition":"164","@citStr":"Collins, 1997"}},"title":{"#tail":"\n","#text":"Three generative lexicalized models for statistical parsing."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL-1997)."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Michael Collins"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1979"},"rawString":{"#tail":"\n","#text":"David Dowty. 1979. Word Meaning and Montague Grammar. D. Reidel Publishing Company, Dordrecht, The Netherlands."},"#text":"\n","marker":{"#tail":"\n","#text":"Dowty, 1979"},"publisher":{"#tail":"\n","#text":"Reidel Publishing Company,"},"location":{"#tail":"\n","#text":"Dordrecht, The Netherlands."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"nostics, remains an unsolved problem; see (Levin and Rappaport Hovav, 1996). Fixed roles are too coarsegrained to account for certain semantic distinctions?the only recourse, to expand the inventory of roles, comes with the price of increased complexity, e.g., in the syntaxto-semantics mapping. There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure?representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity (Dowty, 1979; Jackendoff, 1983; Pustejovsky, 1991b; Rappaport Hovav and Levin, 1998). Consider the following example: (2) He sweeps the floor clean. [ [ DO(he, sweeps(the floor)) ] CAUSE [ BECOME [ clean(the floor) ] ] ] Dowty breaks the event described by (2) into two subevents, the activity of sweeping the floor and its result, the state of the floor being clean. A more recent approach, advocated by Rappaport Hovav and Levin (1998), describes a basic set of event templates corresponding to Vendler?s event classes (Vendler, 1957): (3) a. [ x ACT<MANNER> ] (activity) b. [ x <STATE> ] (state) c. [ BECOME [","@endWordPosition":"698","@position":"4913","annotationId":"T4","@startWordPosition":"697","@citStr":"Dowty, 1979"}},"title":{"#tail":"\n","#text":"Word Meaning and"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"David Dowty"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1968"},"editor":{"#tail":"\n","#text":"In E. Bach and R. Harms, editors,"},"rawString":{"#tail":"\n","#text":"Charles J. Fillmore. 1968. The case for case. In E. Bach and R. Harms, editors, Universals in Linguistic Theory, pages 1?88. Holt, Rinehart, and Winston, New York."},"#text":"\n","pages":{"#tail":"\n","#text":"1--88"},"marker":{"#tail":"\n","#text":"Fillmore, 1968"},"location":{"#tail":"\n","#text":"Holt, Rinehart, and Winston, New York."},"title":{"#tail":"\n","#text":"The case for case."},"booktitle":{"#tail":"\n","#text":"Universals in Linguistic Theory,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Charles J Fillmore"}}},{"date":{"#tail":"\n","#text":"1993"},"editor":{"#tail":"\n","#text":"In Kenneth Hale and Samuel Jay Keyser, editors,"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"clusion that follows naturally from this analysis is that fragments of event structure are directly encoded in the syntactic structure. We could, in fact, further postulate that all event structure is encoded syntactically, i.e., that lexical semantic representation is isomorphic to syntactic structure. Sometimes, these functional elements are overtly realized, e.g., -en. Often, however, these functional elements responsible for licensing event interpretations are not phonologically realized. These observations and this line of reasoning has not escaped the attention of theoretical linguists: Hale and Keyser (1993) propose that argument structure is, in fact, encoded syntactically. They describe a cascading verb phrase analysis with multiple phonetically empty verbal projections corresponding to concepts such as inchoativity and agentivity. This present framework builds on the work of Hale and Keyser, but in addition to advancing a more refined theory of verbal argument structure, I also describe a computational implementation. 4 Event Types Although the study of event types can be traced back to Aristotle, it wasn?t until the twentieth century when philosophers and linguists developed classifications o","@endWordPosition":"1482","@position":"9883","annotationId":"T5","@startWordPosition":"1479","@citStr":"Hale and Keyser (1993)"},{"#tail":"\n","#text":"en/ ::::>be =d ?x.?y.ARG?(y, e)? BECOME(x, e) < ::>s :::vbe BE([state flat]) :s > /the tire/ ::d tire < /flat -en/ ::::>be ::=d ?y.ARG?(y, e)? BECOME(BE([state tall]), e) < :::>s::::vbe :s ARG?(he, e) ? BECOME(BE([state tall(3cm)]), e) Figure 1: Simplified derivation for the sentence ?The tire flattened.? of my parser remains to be seen, similar approaches have been successful at capturing complex linguistic phenomena. With a minimal set of features and a small number of lexical entries, Niyogi (2001) has successfully modeled many of the argument alternations described by Levin (1993) using a Hale and Keyser (1993) style analysis. I believe that with a suitable lexicon (either hand crafted or automatically induced), my framework can be elaborated into a system whose performance is comparable to that of current statistical parsers, but with the added advantage of simultaneously providing a richer lexical semantic representation of the input sentence than flat predicate argument structures based on semantic roles. 6 Conclusion A combination of factors in the natural development of computational linguistics as a field has conspired to narrow the diversity of techniques being explored by researchers. While ","@endWordPosition":"2818","@position":"18360","annotationId":"T6","@startWordPosition":"2815","@citStr":"Hale and Keyser (1993)"}]},"title":{"#tail":"\n","#text":"On argument structure and the lexical expression of syntactic relations."},"#tail":"\n","rawString":{"#tail":"\n","#text":"Kenneth Hale and Samuel Jay Keyser. 1993. On argument structure and the lexical expression of syntactic relations. In Kenneth Hale and Samuel Jay Keyser, editors, The View from Building 20: Essays in Linguistics in Honor of Sylvain Bromberger. MIT Press, Cambridge, Massachusetts."},"#text":"\n","marker":{"#tail":"\n","#text":"Hale, Keyser, 1993"},"publisher":{"#tail":"\n","#text":"MIT Press,"},"location":{"#tail":"\n","#text":"Cambridge, Massachusetts."},"booktitle":{"#tail":"\n","#text":"The View from Building 20: Essays in Linguistics in Honor of Sylvain Bromberger."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kenneth Hale"},{"#tail":"\n","#text":"Samuel Jay Keyser"}]}},{"date":{"#tail":"\n","#text":"1993"},"editor":{"#tail":"\n","#text":"In Kenneth Hale and S. Jay Keyser, editors,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"calist approach does not capture productive morphological processes that pervade natural language, for example, flat.V ? flatten.ADJ or hammer.N ? hammer.V; most frameworks for computational semantics fail to capture the deeper derivational relationship between morphologically-related terms. For languages with rich derivational morphology, this problem is often critical: the standard architectural view of morphological analysis as a preprocessor presents difficulties in handling semantically meaningful affixes. In this paper, I present a computational implementation of Distributed Morphology (Halle and Marantz, 1993), a non-lexicalist linguistic theory that erases the distinction between syntactic derivation and morphological derivation. This framework leads to finer-grained semantics capable of better capturing linguistic generalizations. 2 Event Structure It has previously been argued that representations based on a fixed collection of semantic roles cannot adequately capture natural language semantics. The actual inventory of semantic roles, along with precise definitions and diagnostics, remains an unsolved problem; see (Levin and Rappaport Hovav, 1996). Fixed roles are too coarsegrained to account fo","@endWordPosition":"546","@position":"3826","annotationId":"T7","@startWordPosition":"543","@citStr":"Halle and Marantz, 1993"}},"title":{"#tail":"\n","#text":"Distributed morphology and the pieces of inflection."},"#tail":"\n","rawString":{"#tail":"\n","#text":"Morris Halle and Alec Marantz. 1993. Distributed morphology and the pieces of inflection. In Kenneth Hale and S. Jay Keyser, editors, In The View from Building 20, pages 111?176. MIT Press, Cambridge, Massachusetts."},"#text":"\n","pages":{"#tail":"\n","#text":"111--176"},"marker":{"#tail":"\n","#text":"Halle, Marantz, 1993"},"publisher":{"#tail":"\n","#text":"MIT Press,"},"location":{"#tail":"\n","#text":"Cambridge, Massachusetts."},"booktitle":{"#tail":"\n","#text":"In The View from Building 20,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Morris Halle"},{"#tail":"\n","#text":"Alec Marantz"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Henk Harkema. 2000. A recognizer for minimalist grammars. In Proceedings of the Sixth International Workshop on Parsing Technologies (IWPT 2000)."},"#text":"\n","marker":{"#tail":"\n","#text":"Harkema, 2000"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"tire, e) ? BECOME(BE([state flat]), e) In (Lin, 2004), I present evidence from Mandarin Chinese that this analysis is on the right track. The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework. 5 Minimalist Derivations My theory of verbal argument structure can be implemented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing. The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky?s Minimalist Program (Stabler, 1997; Harkema, 2000; Niyogi, 2001). Lexical entries in the system are minimally specified, each consisting of a phonetic form, a list of relevant features, and semantics in the form of a ? expression. The basic structure building operation, MERGE, takes two items and creates a larger item. In the process, compatible features are canceled and one of the items projects. Simultaneously, the ? expression associated with the licensor is applied to the ? expression associated with the licensee (in theoretical linguistic terms, SpellOut). The most basic feature is the =x licensor feature, which cancels out a correspond","@endWordPosition":"2361","@position":"15597","annotationId":"T8","@startWordPosition":"2360","@citStr":"Harkema, 2000"}},"title":{"#tail":"\n","#text":"A recognizer for minimalist grammars."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Sixth International Workshop on Parsing Technologies (IWPT"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Henk Harkema"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1983"},"rawString":{"#tail":"\n","#text":"Ray Jackendoff. 1983. Semantics and Cognition. MIT Press, Cambridge, Massachusetts."},"#text":"\n","marker":{"#tail":"\n","#text":"Jackendoff, 1983"},"publisher":{"#tail":"\n","#text":"MIT Press,"},"location":{"#tail":"\n","#text":"Cambridge, Massachusetts."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ins an unsolved problem; see (Levin and Rappaport Hovav, 1996). Fixed roles are too coarsegrained to account for certain semantic distinctions?the only recourse, to expand the inventory of roles, comes with the price of increased complexity, e.g., in the syntaxto-semantics mapping. There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure?representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity (Dowty, 1979; Jackendoff, 1983; Pustejovsky, 1991b; Rappaport Hovav and Levin, 1998). Consider the following example: (2) He sweeps the floor clean. [ [ DO(he, sweeps(the floor)) ] CAUSE [ BECOME [ clean(the floor) ] ] ] Dowty breaks the event described by (2) into two subevents, the activity of sweeping the floor and its result, the state of the floor being clean. A more recent approach, advocated by Rappaport Hovav and Levin (1998), describes a basic set of event templates corresponding to Vendler?s event classes (Vendler, 1957): (3) a. [ x ACT<MANNER> ] (activity) b. [ x <STATE> ] (state) c. [ BECOME [ x <STATE> ] ] (ac","@endWordPosition":"700","@position":"4931","annotationId":"T9","@startWordPosition":"699","@citStr":"Jackendoff, 1983"}},"title":{"#tail":"\n","#text":"Semantics and Cognition."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Ray Jackendoff"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Paul Kingsbury, Martha Palmer, and Mitch Marcus. 2002. Adding semantic annotation to the Penn TreeBank. In Proceeding of 2002 Human Language Technology Conference (HLT 2002)."},"#text":"\n","marker":{"#tail":"\n","#text":"Kingsbury, Palmer, Marcus, 2002"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ins, 1997; Charniak, 2001), attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences. A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots). Verbs are viewed as simple predicates over their arguments. This approach has its roots in Fillmore?s Case Grammar (1968), and serves as the foundation for two current large-scale semantic annotation projects: FrameNet (Baker et al, 1998) and PropBank (Kingsbury et al, 2002). Underlying the semantic roles approach is a lexicalist assumption, that is, each verb?s lexical entry completely encodes (more formally, projects) its syntactic and semantic structures. Alternations in argument structure are usually attributed to multiple lexical entries (i.e., verb senses). Under the lexicalist approach, the semantics of the verb break might look something like this: (1) break(agent, theme) agent: subject theme: object break(agent, theme, instrument) agent: subject theme: object instrument: oblique(with) break(theme) theme: subject . . . The lexicon explicitly specifies the","@endWordPosition":"254","@position":"1788","annotationId":"T10","@startWordPosition":"251","@citStr":"Kingsbury et al, 2002"}},"title":{"#tail":"\n","#text":"Adding semantic annotation to the Penn TreeBank."},"booktitle":{"#tail":"\n","#text":"In Proceeding of 2002 Human Language Technology Conference (HLT"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Paul Kingsbury"},{"#tail":"\n","#text":"Martha Palmer"},{"#tail":"\n","#text":"Mitch Marcus"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"note":{"#tail":"\n","#text":"Unpublished manuscript,"},"institution":{"#tail":"\n","#text":"University of Massachusetts,"},"rawString":{"#tail":"\n","#text":"Angelika Kratzer. 1994. The event argument and the semantics of voice. Unpublished manuscript, University of Massachusetts, Amherst."},"#text":"\n","marker":{"#tail":"\n","#text":"Kratzer, 1994"},"location":{"#tail":"\n","#text":"Amherst."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" in the syntax, and correspond to (assumed) universal primitives of the human cognitive system. On the other hand, verbal roots represent abstract (categoryless) concepts and basically correspond to open-class items drawn from encyclopedic knowledge. I assume an inventory of three verbalizing heads, each corresponding to an aforementioned primitive: (9) vDO [+dynamic, ?inchoative] = DO v? [+dynamic, +inchoative] = BECOME vBE [?dynamic] = BE The light verb vDO licenses an atelic non-inchoative event, and is compatible with verbal roots expressing activity. It projects a functional head, voice (Kratzer, 1994), whose specifier is the external argument. (10) John ran. voiceP DP John voice vDOP vDO ? run ARGext(John, e) ? DO([activity run], e) The entire voiceP is further embedded under a tense projection (not shown here), and the verbal complex undergoes head movement and left adjoins to any overt tense markings. Similarly, the external argument raises to [Spec, TP]. This is in accordance with modern linguistic theory, more specifically, the subject-internal hypothesis. The verbal root can itself idiosyncratically license a DP to give rise to a transitive sentence (subjected, naturally, to selection","@endWordPosition":"1911","@position":"12806","annotationId":"T11","@startWordPosition":"1910","@citStr":"Kratzer, 1994"}},"title":{"#tail":"\n","#text":"The event argument and the semantics of voice."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Angelika Kratzer"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"note":{"#tail":"\n","#text":"Unpublished manuscript,"},"institution":{"#tail":"\n","#text":"Northwestern University and Bar Ilan University."},"rawString":{"#tail":"\n","#text":"Beth Levin and Malka Rappaport Hovav. 1996. From lexical semantics to argument realization. Unpublished manuscript, Northwestern University and Bar Ilan University."},"#text":"\n","marker":{"#tail":"\n","#text":"Levin, Hovav, 1996"},"title":{"#tail":"\n","#text":"From lexical semantics to argument realization."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Beth Levin"},{"#tail":"\n","#text":"Malka Rappaport Hovav"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"Beth Levin. 1993. English Verb Classes and Alternations: A Preliminary Investigation. University of Chicago Press, Chicago, Illinois."},"#text":"\n","marker":{"#tail":"\n","#text":"Levin, 1993"},"publisher":{"#tail":"\n","#text":"University of Chicago Press,"},"location":{"#tail":"\n","#text":"Chicago, Illinois."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"t: oblique(with) break(theme) theme: subject . . . The lexicon explicitly specifies the different subcategorization frames of a verb, e.g., the causative frame, the causative instrumental frame, the inchoative frame, etc. The major drawback of this approach, however, is the tremendous amount of redundancy in the lexicon?for example, the class of prototypical transitive verbs where the agent appears as the subject and the theme as the direct object must all duplicate this pattern. The typical solution to the redundancy problem is to group verbs according to their argument realization patterns (Levin, 1993), possibly arranged in an inheritance hierarchy. The argument structure and syntax-tosemantics mapping would then only need to be specified once for each verb class. In addition, lexical rules could be formulated to derive certain alternations from more basic forms. Nevertheless, the lexicalist approach does not capture productive morphological processes that pervade natural language, for example, flat.V ? flatten.ADJ or hammer.N ? hammer.V; most frameworks for computational semantics fail to capture the deeper derivational relationship between morphologically-related terms. For languages with","@endWordPosition":"418","@position":"2913","annotationId":"T12","@startWordPosition":"417","@citStr":"Levin, 1993"},{"#tail":"\n","#text":"state flat] < /flat -en/ ::::>be =d ?x.?y.ARG?(y, e)? BECOME(x, e) < ::>s :::vbe BE([state flat]) :s > /the tire/ ::d tire < /flat -en/ ::::>be ::=d ?y.ARG?(y, e)? BECOME(BE([state tall]), e) < :::>s::::vbe :s ARG?(he, e) ? BECOME(BE([state tall(3cm)]), e) Figure 1: Simplified derivation for the sentence ?The tire flattened.? of my parser remains to be seen, similar approaches have been successful at capturing complex linguistic phenomena. With a minimal set of features and a small number of lexical entries, Niyogi (2001) has successfully modeled many of the argument alternations described by Levin (1993) using a Hale and Keyser (1993) style analysis. I believe that with a suitable lexicon (either hand crafted or automatically induced), my framework can be elaborated into a system whose performance is comparable to that of current statistical parsers, but with the added advantage of simultaneously providing a richer lexical semantic representation of the input sentence than flat predicate argument structures based on semantic roles. 6 Conclusion A combination of factors in the natural development of computational linguistics as a field has conspired to narrow the diversity of techniques being ","@endWordPosition":"2812","@position":"18329","annotationId":"T13","@startWordPosition":"2811","@citStr":"Levin (1993)"}]},"title":{"#tail":"\n","#text":"English Verb Classes and Alternations: A Preliminary Investigation."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Beth Levin"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"Beth Levin. 1999. Objecthood: An event structure perspective. In Proceedings of the 35th Annual Meeting of the Chicago Linguistics Society."},"#text":"\n","marker":{"#tail":"\n","#text":"Levin, 1999"},"title":{"#tail":"\n","#text":"Objecthood: An event structure perspective."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 35th Annual Meeting of the Chicago Linguistics Society."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Beth Levin"}}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Ph.D. thesis,"},"date":{"#tail":"\n","#text":"2004"},"institution":{"#tail":"\n","#text":"Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology."},"rawString":{"#tail":"\n","#text":"Jimmy Lin. 2004. Event Structure and the Encoding of Arguments: The Syntax of the English and Mandarin Verb Phrase. Ph.D. thesis, Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology."},"#text":"\n","marker":{"#tail":"\n","#text":"Lin, 2004"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"4) John broke the window. voiceP DP John voice vDOP vDO v?P DP window v? vBE ? break CAUSE(e1, e2) ? ARGext(John, e1) ? DO([activity undef], e1) ? ARG?(window, e2) ? BECOME(BE([state break]), e2) Note that in the causative form, vDO is unmodified by a verbal root?the manner of activity is left unspecified, i.e., ?John did something that caused the window to undergo the change of state break.? Given this framework, deadjectival verbs such as flatten can be directly derived in the syntax: (15) The tire flattened. v?P DP tire v? -en vBEP vBE ? flat ARG?(tire, e) ? BECOME(BE([state flat]), e) In (Lin, 2004), I present evidence from Mandarin Chinese that this analysis is on the right track. The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework. 5 Minimalist Derivations My theory of verbal argument structure can be implemented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing. The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky?s Minimalist Program (Stabler, 1997; Harkema, 2000; Niyogi, 2001). Lexical entries in the ","@endWordPosition":"2276","@position":"15037","annotationId":"T14","@startWordPosition":"2275","@citStr":"Lin, 2004"}},"title":{"#tail":"\n","#text":"Event Structure and the Encoding of Arguments: The Syntax of the English and Mandarin Verb Phrase."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Jimmy Lin"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Alec Marantz. 1997. No escape from syntax: Don?t try morphological analysis in the privacy of your own lexicon. In Proceedings of the 21st Annual Penn Linguistics Colloquium."},"#text":"\n","marker":{"#tail":"\n","#text":"Marantz, 1997"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"chievements only in terms of event duration, which is often a question of granularity. From typological studies, it appears that states, change of states, and activities form the most basic ontology of event types. They correspond to the primitives BE, BECOME, and DO proposed by a variety of linguists; let us adopt these conceptual primitives as the basic vocabulary of our lexical semantic representation. Following the non-lexicalist tradition, these primitives are argued to occupy functional projections in the syntactic structure, as so-called light verbs. Here, I adopt the model proposed by Marantz (1997) and decompose lexical verbs into verbalizing heads and verbal roots. Verbalizing heads introduce relevant eventive interpretations in the syntax, and correspond to (assumed) universal primitives of the human cognitive system. On the other hand, verbal roots represent abstract (categoryless) concepts and basically correspond to open-class items drawn from encyclopedic knowledge. I assume an inventory of three verbalizing heads, each corresponding to an aforementioned primitive: (9) vDO [+dynamic, ?inchoative] = DO v? [+dynamic, +inchoative] = BECOME vBE [?dynamic] = BE The light verb vDO licen","@endWordPosition":"1802","@position":"12061","annotationId":"T15","@startWordPosition":"1801","@citStr":"Marantz (1997)"}},"title":{"#tail":"\n","#text":"No escape from syntax: Don?t try morphological analysis in the privacy of your own lexicon."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 21st Annual Penn Linguistics Colloquium."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Alec Marantz"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Sourabh Niyogi. 2001. A minimalist implementation of verb subcategorization. In Proceedings of the Seventh International Workshop on Parsing Technologies (IWPT-2001)."},"#text":"\n","marker":{"#tail":"\n","#text":"Niyogi, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ME(BE([state flat]), e) In (Lin, 2004), I present evidence from Mandarin Chinese that this analysis is on the right track. The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework. 5 Minimalist Derivations My theory of verbal argument structure can be implemented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing. The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky?s Minimalist Program (Stabler, 1997; Harkema, 2000; Niyogi, 2001). Lexical entries in the system are minimally specified, each consisting of a phonetic form, a list of relevant features, and semantics in the form of a ? expression. The basic structure building operation, MERGE, takes two items and creates a larger item. In the process, compatible features are canceled and one of the items projects. Simultaneously, the ? expression associated with the licensor is applied to the ? expression associated with the licensee (in theoretical linguistic terms, SpellOut). The most basic feature is the =x licensor feature, which cancels out a corresponding x licensee ","@endWordPosition":"2363","@position":"15612","annotationId":"T16","@startWordPosition":"2362","@citStr":"Niyogi, 2001"},{"#tail":"\n","#text":"onetic content of the licensee is affixed to the left or right of the licensor?s phonetic content, respectively. These licensor features also cancel corresponding x licensee features: (17) < book -s :::>n d -k book :n < de- bone ::<n V bone :n Finally, feature checking is implemented by +x/-x features. The +x denotes a need to discharge features, and the -x denotes a need for features. A simple example of this is the case assignment involved in building a prepositional phrase, i.e., prepositions must assign case, and DPs much receive case. (18) < on :::=d:::+k ploc < the :::=n:d ::-k shelf :n Niyogi (2001) has developed an agenda-driven chart parser for the feature-driven formalism described above; please refer to his paper for a description of the parsing algorithm. I have adapted it for my needs and developed grammar fragments that reflect my non-lexicalist semantic framework. As an example, a simplified derivation of the sentence ?The tire flattened.? is shown in Figure 1. The currently implemented system is still at the ?toy parser? stage. Although the effectiveness and coverage < // ::>s vbe?x.BE(x) /flat/ :s[state flat] < /flat -en/ ::::>be =d ?x.?y.ARG?(y, e)? BECOME(x, e) < ::>s :::vbe ","@endWordPosition":"2635","@position":"17198","annotationId":"T17","@startWordPosition":"2634","@citStr":"Niyogi (2001)"}]},"title":{"#tail":"\n","#text":"A minimalist implementation of verb subcategorization."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Seventh International Workshop on Parsing Technologies (IWPT-2001)."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Sourabh Niyogi"}}},{"volume":{"#tail":"\n","#text":"17"},"#tail":"\n","date":{"#tail":"\n","#text":"1991"},"rawString":{"#tail":"\n","#text":"James Pustejovsky. 1991a. The generative lexicon. Computational Linguistics, 17(4):409?441."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"4"},"marker":{"#tail":"\n","#text":"Pustejovsky, 1991"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"oblem; see (Levin and Rappaport Hovav, 1996). Fixed roles are too coarsegrained to account for certain semantic distinctions?the only recourse, to expand the inventory of roles, comes with the price of increased complexity, e.g., in the syntaxto-semantics mapping. There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure?representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity (Dowty, 1979; Jackendoff, 1983; Pustejovsky, 1991b; Rappaport Hovav and Levin, 1998). Consider the following example: (2) He sweeps the floor clean. [ [ DO(he, sweeps(the floor)) ] CAUSE [ BECOME [ clean(the floor) ] ] ] Dowty breaks the event described by (2) into two subevents, the activity of sweeping the floor and its result, the state of the floor being clean. A more recent approach, advocated by Rappaport Hovav and Levin (1998), describes a basic set of event templates corresponding to Vendler?s event classes (Vendler, 1957): (3) a. [ x ACT<MANNER> ] (activity) b. [ x <STATE> ] (state) c. [ BECOME [ x <STATE> ] ] (achievement) d. [ x C","@endWordPosition":"702","@position":"4950","annotationId":"T18","@startWordPosition":"701","@citStr":"Pustejovsky, 1991"},{"#tail":"\n","#text":"al items, that is, fragments of event structure are directly associated with derivational morphemes. We have the following situation: (7) JflatK = [state flat] Jis flatK = ?xBE(x, [state flat]) J-enK = ?s?xARG?(x, e) ? BECOME(BE(s), e) Jflat-enK = ?x.ARG?(x, e)? BECOME(BE([state flat]), e) In this case, the complete event structure of a word can be compositionally derived from its component morphemes. This framework, where the ?semantic load? is spread more evenly throughout the lexicon to lexical categories not typically thought to bear semantic content, is essentially the model advocated by Pustejovsky (1991a), among many others. Note that such an approach is no longer lexicalist: each lexical item does not fully encode its associated syntactic and semantic structures. Rather, meanings are composed from component morphemes. In addition to -en, other productive derivational suffixes in English such as -er, -ize, -ion, just to name a few, can be analyzed in a similar way. In fact, we may view morphological rules for composing morphemes into larger phonological units the same way we view syntactic rules for combining constituents into higher-level projections, i.e., why distinguish VP ? V + NP from ","@endWordPosition":"1231","@position":"8247","annotationId":"T19","@startWordPosition":"1230","@citStr":"Pustejovsky (1991"}]},"title":{"#tail":"\n","#text":"The generative lexicon."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"James Pustejovsky"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1991"},"rawString":{"#tail":"\n","#text":"James Pustejovsky. 1991b. The syntax of event structure. Cognition, 41:47?81."},"journal":{"#tail":"\n","#text":"Cognition,"},"#text":"\n","pages":{"#tail":"\n","#text":"41--47"},"marker":{"#tail":"\n","#text":"Pustejovsky, 1991"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"oblem; see (Levin and Rappaport Hovav, 1996). Fixed roles are too coarsegrained to account for certain semantic distinctions?the only recourse, to expand the inventory of roles, comes with the price of increased complexity, e.g., in the syntaxto-semantics mapping. There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure?representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity (Dowty, 1979; Jackendoff, 1983; Pustejovsky, 1991b; Rappaport Hovav and Levin, 1998). Consider the following example: (2) He sweeps the floor clean. [ [ DO(he, sweeps(the floor)) ] CAUSE [ BECOME [ clean(the floor) ] ] ] Dowty breaks the event described by (2) into two subevents, the activity of sweeping the floor and its result, the state of the floor being clean. A more recent approach, advocated by Rappaport Hovav and Levin (1998), describes a basic set of event templates corresponding to Vendler?s event classes (Vendler, 1957): (3) a. [ x ACT<MANNER> ] (activity) b. [ x <STATE> ] (state) c. [ BECOME [ x <STATE> ] ] (achievement) d. [ x C","@endWordPosition":"702","@position":"4950","annotationId":"T20","@startWordPosition":"701","@citStr":"Pustejovsky, 1991"},{"#tail":"\n","#text":"al items, that is, fragments of event structure are directly associated with derivational morphemes. We have the following situation: (7) JflatK = [state flat] Jis flatK = ?xBE(x, [state flat]) J-enK = ?s?xARG?(x, e) ? BECOME(BE(s), e) Jflat-enK = ?x.ARG?(x, e)? BECOME(BE([state flat]), e) In this case, the complete event structure of a word can be compositionally derived from its component morphemes. This framework, where the ?semantic load? is spread more evenly throughout the lexicon to lexical categories not typically thought to bear semantic content, is essentially the model advocated by Pustejovsky (1991a), among many others. Note that such an approach is no longer lexicalist: each lexical item does not fully encode its associated syntactic and semantic structures. Rather, meanings are composed from component morphemes. In addition to -en, other productive derivational suffixes in English such as -er, -ize, -ion, just to name a few, can be analyzed in a similar way. In fact, we may view morphological rules for composing morphemes into larger phonological units the same way we view syntactic rules for combining constituents into higher-level projections, i.e., why distinguish VP ? V + NP from ","@endWordPosition":"1231","@position":"8247","annotationId":"T21","@startWordPosition":"1230","@citStr":"Pustejovsky (1991"}]},"title":{"#tail":"\n","#text":"The syntax of event structure."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"James Pustejovsky"}}},{"date":{"#tail":"\n","#text":"1998"},"editor":{"#tail":"\n","#text":"In Miriam Butt and Wilhelm Geuder, editors,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"t Hovav, 1996). Fixed roles are too coarsegrained to account for certain semantic distinctions?the only recourse, to expand the inventory of roles, comes with the price of increased complexity, e.g., in the syntaxto-semantics mapping. There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure?representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity (Dowty, 1979; Jackendoff, 1983; Pustejovsky, 1991b; Rappaport Hovav and Levin, 1998). Consider the following example: (2) He sweeps the floor clean. [ [ DO(he, sweeps(the floor)) ] CAUSE [ BECOME [ clean(the floor) ] ] ] Dowty breaks the event described by (2) into two subevents, the activity of sweeping the floor and its result, the state of the floor being clean. A more recent approach, advocated by Rappaport Hovav and Levin (1998), describes a basic set of event templates corresponding to Vendler?s event classes (Vendler, 1957): (3) a. [ x ACT<MANNER> ] (activity) b. [ x <STATE> ] (state) c. [ BECOME [ x <STATE> ] ] (achievement) d. [ x CAUSE [ BECOME [ x <STATE> ] ] ] (ac","@endWordPosition":"707","@position":"4985","annotationId":"T22","@startWordPosition":"704","@citStr":"Hovav and Levin, 1998"}},"title":{"#tail":"\n","#text":"Building verb meanings."},"#tail":"\n","rawString":{"#tail":"\n","#text":"Malka Rappaport Hovav and Beth Levin. 1998. Building verb meanings. In Miriam Butt and Wilhelm Geuder, editors, The Projection of Arguments: Lexical and Compositional Factors. CSLI Publications, Stanford, California."},"#text":"\n","marker":{"#tail":"\n","#text":"Hovav, Levin, 1998"},"publisher":{"#tail":"\n","#text":"CSLI Publications,"},"location":{"#tail":"\n","#text":"Stanford, California."},"booktitle":{"#tail":"\n","#text":"The Projection of Arguments: Lexical and Compositional Factors."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Malka Rappaport Hovav"},{"#tail":"\n","#text":"Beth Levin"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"editor":{"#tail":"\n","#text":"In Christian Retore?, editor,"},"rawString":{"#tail":"\n","#text":"Edward Stabler. 1997. Derivational minimalism. In Christian Retore?, editor, Logical Aspects of Computational Linguistics. Springer."},"#text":"\n","marker":{"#tail":"\n","#text":"Stabler, 1997"},"publisher":{"#tail":"\n","#text":"Springer."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"BE ? flat ARG?(tire, e) ? BECOME(BE([state flat]), e) In (Lin, 2004), I present evidence from Mandarin Chinese that this analysis is on the right track. The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework. 5 Minimalist Derivations My theory of verbal argument structure can be implemented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing. The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky?s Minimalist Program (Stabler, 1997; Harkema, 2000; Niyogi, 2001). Lexical entries in the system are minimally specified, each consisting of a phonetic form, a list of relevant features, and semantics in the form of a ? expression. The basic structure building operation, MERGE, takes two items and creates a larger item. In the process, compatible features are canceled and one of the items projects. Simultaneously, the ? expression associated with the licensor is applied to the ? expression associated with the licensee (in theoretical linguistic terms, SpellOut). The most basic feature is the =x licensor feature, which cancels o","@endWordPosition":"2359","@position":"15582","annotationId":"T23","@startWordPosition":"2358","@citStr":"Stabler, 1997"}},"title":{"#tail":"\n","#text":"Derivational minimalism."},"booktitle":{"#tail":"\n","#text":"Logical Aspects of Computational Linguistics."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Edward Stabler"}}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Ph.D. thesis,"},"date":{"#tail":"\n","#text":"1987"},"institution":{"#tail":"\n","#text":"Massachusetts Institute of Technology."},"rawString":{"#tail":"\n","#text":"Carol Tenny. 1987. Grammaticalizing Aspect and Affectedness. Ph.D. thesis, Massachusetts Institute of Technology."},"#text":"\n","marker":{"#tail":"\n","#text":"Tenny, 1987"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"nal ontology of event types. Examples of the four event types are given below: (8) States Activities know run believe walk Accomplishments Achievements paint a picture recognize make a chair find Under Vendler?s classification, activities and states both depict situations that are inherently temporally unbounded (atelic); states denote static situations, whereas activities denote on-going dynamic situations. Accomplishments and achievements both express a change of state, and hence are temporally bounded (telic); achievements are punctual, whereas accomplishments extend over a period of time. Tenny (1987) observes that accomplishments differ from achievements only in terms of event duration, which is often a question of granularity. From typological studies, it appears that states, change of states, and activities form the most basic ontology of event types. They correspond to the primitives BE, BECOME, and DO proposed by a variety of linguists; let us adopt these conceptual primitives as the basic vocabulary of our lexical semantic representation. Following the non-lexicalist tradition, these primitives are argued to occupy functional projections in the syntactic structure, as so-called light","@endWordPosition":"1701","@position":"11403","annotationId":"T24","@startWordPosition":"1700","@citStr":"Tenny (1987)"}},"title":{"#tail":"\n","#text":"Grammaticalizing Aspect and Affectedness."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Carol Tenny"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1957"},"rawString":{"#tail":"\n","#text":"Zeno Vendler. 1957. Verbs and times. Philosophical Review, 56:143?160."},"journal":{"#tail":"\n","#text":"Philosophical Review,"},"#text":"\n","pages":{"#tail":"\n","#text":"56--143"},"marker":{"#tail":"\n","#text":"Vendler, 1957"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"primitive predicates representing concepts such as causality and inchoativity (Dowty, 1979; Jackendoff, 1983; Pustejovsky, 1991b; Rappaport Hovav and Levin, 1998). Consider the following example: (2) He sweeps the floor clean. [ [ DO(he, sweeps(the floor)) ] CAUSE [ BECOME [ clean(the floor) ] ] ] Dowty breaks the event described by (2) into two subevents, the activity of sweeping the floor and its result, the state of the floor being clean. A more recent approach, advocated by Rappaport Hovav and Levin (1998), describes a basic set of event templates corresponding to Vendler?s event classes (Vendler, 1957): (3) a. [ x ACT<MANNER> ] (activity) b. [ x <STATE> ] (state) c. [ BECOME [ x <STATE> ] ] (achievement) d. [ x CAUSE [ BECOME [ x <STATE> ] ] ] (accomplishment) e. [ [ x ACT<MANNER> ] CAUSE [ BECOME [ x <STATE> ] ] ] (accomplishment) A process called Template Augmentation allows basic event templates to be freely ?augmented? to any other event template. This process, for example, explains the resultative form of surface contact verbs like sweep: (4) a. Phil swept the floor. [ Phil ACT<SWEEP> floor ] b. Phil swept the floor clean. [ [ Phil ACT<SWEEP> floor ] CAUSE [ BECOME [ floor <CLEAN> ] ] ","@endWordPosition":"784","@position":"5437","annotationId":"T25","@startWordPosition":"783","@citStr":"Vendler, 1957"}},"title":{"#tail":"\n","#text":"Verbs and times."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Zeno Vendler"}}}]}}]}}
