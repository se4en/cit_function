{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","figure":[{"#tail":"\n","@confidence":"0.766713666666667","#text":"\nAppendix A for derivation):\nDual Projection : arg min\n??0\n"},{"#tail":"\n","@confidence":"0.574321842105263","#text":"\nComputational Linguistics Volume 36, Number 3\ndirectional alignments\n??\nZ ???Z . We define a mixture model p(z) = 12\n??p (z) + 12\n??p (z)\nwhere ??p (??z ) = 0 and vice versa (i.e., the alignment of one directional model has prob-\nability zero according to the other model). We then define the following feature for each\ntarget?source position pair i, j:\nSymmetric Features : fij(x, z) =\n?\n?\n?\n?\n?\n+1 z ? ??Z and ??z i = j\n?1 z ? ??Z and ??z j = i\n0 otherwise\n.\n"},{"#tail":"\n","@confidence":"0.775474333333333","#text":"\narg max\n?\nLlabeled(?) ? ??E[||Ep? [f(x, z) ? b||\n"},{"#tail":"\n","@confidence":"0.990619789473684","#text":"\nL(?, ?) = ? log(Z?) ? bx ??\n||?||22\n2? +\n||?||22\n4? ? ?\n2 (A.1)\n?L(?, ?)\n?? =\n||?||22\n2?2\n? ||?||\n2\n2\n4?2\n? 2 = 0 =? ? = ||?||22 (A.2)\nReplacing back into L(?, ?) we get the dual objective:\nDual E? : arg max\n??0\n?bx ?? log(Z?) ? ||?||2  (A.3)\n"}],"author":[{"#tail":"\n","@confidence":"0.742762","#text":"\nKuzman Ganchev??\n"},{"#tail":"\n","@confidence":"0.78407","#text":"\nBen Taskar?\n"}],"equation":[{"#tail":"\n","@confidence":"0.9894054","#text":"\np?(x, z  |y) =\nI\n?\ni=1\npd(zi  |zi?1)pt(xi  |yzi ) (1)\n"},{"#tail":"\n","@confidence":"0.989019285714286","#text":"\nLog-Likelihood : L(?) = ?E[log p?(x  |y)] = ?E[log\n?\nz\np?(x, z  |y)] (2)\nwhere ?E[ f (x, y)] = 1N\n?N\nn=1 f (x\n"},{"#tail":"\n","@confidence":"0.969520555555556","#text":"\nq(z  |x, y) (Neal and Hinton 1998):\nEM Lower Bound : L(?) ? F(q, ?) = ?E\n[\n?\nz\nq(z  |x, y) log p?(x, z  |y)\nq(z  |x, y)\n]\n(3)\n"},{"#tail":"\n","@confidence":"0.980158294117647","#text":"\nat iteration t + 1 are given by:\nE : qt+1(z  |x) = arg max\nq(z|x)\nF(q, ?t) = arg min\nq(z|x)\nKL(q(z  |x)  ||p?t (z  |x)) = p?t (z  |x) (4)\nM : ?t+1 = arg max\n?\nF(qt+1, ?) = arg max\n?\n?E\n[\n?\nz\nqt+1(z  |x) log p?(x, z)\n]\n(5)\n"},{"#tail":"\n","@confidence":"0.94684","#text":"\nq(z|x)?Qx\nKL(q(z  |x) ? p?(z|x)). The regu-\nlarized objective is:\nPosterior Regularized Likelihood : L(?) ? ?E[KL(Qx ? p?(z|x))]. (7)\n"},{"#tail":"\n","@confidence":"0.9901812","#text":"\n?L(?) + ?E[KL(Qx ? p?(z|x))] = 1N\nN\n?\nn=1\nKL(?(xn) ? p?(x)) + KL(Qxn ? p?(z|xn)) (8)\n"},{"#tail":"\n","@confidence":"0.924610833333333","#text":"\n?N\nn=1 KL(?(x\nn) ? p?(x)) plus posterior\nregularization 1N\n?N\nn=1 KL(Qxn ? p?(z|xn)), where ?(xn) is a delta function at xn. The diagram\n"},{"#tail":"\n","@confidence":"0.968678666666667","#text":"\nPrimal Projection : KL(Qx ? p?(z|x)) = min\nq(z|x)?Qx\nKL(q(z  |x) ? p?(z|x)) (9)\n"},{"#tail":"\n","@confidence":"0.761408","#text":"\nbx ? + log Z(?) +  ||?||2 (10)\nwhere Z(?) =\n?\nz p?(z|x) exp(?? ? f(x, z)) is the normalization constant and the primal\n"},{"#tail":"\n","@confidence":"0.91727475","#text":"\nFactored Posterior : p(z  |x) = 1Z\n?\nc?C\n?(x, zc) (11)\n"},{"#tail":"\n","@confidence":"0.950114909090909","#text":"\nFactored Features : f(x, z) =\n?\nc?C\nf(x, zc) (12)\nThen q(z  |x) has the same form as p?(z  |x):\nq(z  |x) = 1Zp(z  |x) exp(??\nf(x, z)) = 1Z\n?\nc?C\n?(x, zc) exp\n??f(x,zc ) (13)\n"},{"#tail":"\n","@confidence":"0.7578848","#text":"\n?i ? 0;1\nwhile ||?(?)||2 > ? do2\n??(x, zc) ? ?(x, zc) exp??\nf(x,zc );3\nq(z  |x) ? forwardBackward(??(x, zc));4\n? ? ? + ???(?);5\nend6\nAlgorithm 1: Computing KL(Qx ? p?(z|x)) = min\nq?Qx\nKL(q(z|x) ? p?(z|x))\n"},{"#tail":"\n","@confidence":"0.968454666666667","#text":"\nE? : arg min\nq,?\nKL(q(z|x) ? p?t (z|x)) s.t. Eq[f(x, z)] ? bx ? ?; ||?||22 ? 2 (14)\n"},{"#tail":"\n","@confidence":"0.844025944444444","#text":"\nusing q(z  |x) = arg min\nq(z|x)?Qx\nKL(q(z  |x)|p?(z  |x)) instead of p?(z  |x) to decode.\nfor t = 1..T do1\nfor each training sentence x do2\nE?-Step: qt+1(z  |x) = arg min\nq(z|x)?Qx\nKL(q(z  |x)||p?t (z  |x))\n3\nend4\nM-Step: ?t+1 = arg max? ?E\n[\n?\nz q\nt+1(z  |x) log p?(z, x)\n]\n5\nend6\n"},{"#tail":"\n","@confidence":"0.88232925","#text":"\nBijective Features : fj(x, z) =\n?\ni\n1(zi = j).\n"},{"#tail":"\n","@confidence":"0.9982455","#text":"\nq?(z|x) =\n??p (z  |x) + ??p (z  |x)\n2\nexp{??f(x, z)}\nZ?\n=\n??q (z|x) Z??q??p (x) +\n??q (z|x) Z??q??p (x)\n2Z?\n(15)\n"},{"#tail":"\n","@confidence":"0.997311","#text":"\n??q (z|x) = 1Z??q\n??p (z, x) exp{??f(x, z)} with Z??q =\n?\nz\n??p (z, x) exp{??f(x, z)}\n??q (z|x) = 1Z??q\n??p (z, x) exp{??f(x, z)} with Z??q =\n?\nz\n??p (z, x) exp{??f(x, z)}\n"},{"#tail":"\n","@confidence":"0.83913575","#text":"\nZ??q\n??p (x) +\nZ??q\n??p (x) ). The effect of this constraint is illustrated in\n"},{"#tail":"\n","@confidence":"0.540448555555556","#text":"\n?E\n[\nlog??p ?1 (x) + log\n??p ?2 (x) + log\n?\nz\n??p ?1 (z  |x)\n??p ?2 (z  |x)\n]\n"},{"#tail":"\n","@confidence":"0.849156","#text":"\nq(z|x),?\nL( q(z|x), ?, ?, ?, ?) with ? ? 0 and ? ? 0,\nwhere\nL( q(z|x), ?, ?, ?, ?) = KL( q(z|x) ? p?(z|x)) + ?(Eq[f(x, z)] ? bx ? ?)\n+ ?(||?||22 ? 2) + ?(\n?\nz\nq(z|x) ? 1)\n?L( q(z|x), ?, ?, ?, ?)\n? q(z|x) = log( q(z|x)) + 1 ? log( p?(z|x)) + ?\nf(x, z) + ? = 0\n=? q(z|x) = p?(z|x) exp(??\nf(x, z))\ne exp(?)\n?L( q(z|x), ?, ?, ?, ?)\n??i\n= 2??i ? ?i = 0 =? ?i =\n?i\n2?\nPlugging q(z|x) and ? in L( q(z|x), ?, ?, ?, ?) and taking the derivative with respect to ?:\n?L(?, ?, ?)\n?? =\n?\nz\np?(z|x) exp(??f(x, z))\ne exp(?)\n? 1 = 0 =? ? = log(\n?\nz p?(z|x) exp(??f(x, z))\ne )\nSimplifying q(z|x) = p?(z|x) exp(??\nf(x,z))\nZ?\nwhere Z? =\n?\nz p?(z|x) exp(??f(x, z)) en-\n"}],"subsectionHeader":[{"#tail":"\n","@confidence":"0.973757","#text":"\n2.1 HMM Word Alignment Model\n"},{"#tail":"\n","@confidence":"0.997001","#text":"\n2.2 Training\n"},{"#tail":"\n","@confidence":"0.996803","#text":"\n2.3 Decoding\n"},{"#tail":"\n","@confidence":"0.999785","#text":"\n3.1 Posterior Regularization Framework\n"},{"#tail":"\n","@confidence":"0.996383","#text":"\n3.2 Posterior Regularization via Expectation Maximization\n"},{"#tail":"\n","@confidence":"0.996533","#text":"\n3.3 Bijectivity Constraints\n"},{"#tail":"\n","@confidence":"0.989219","#text":"\n3.4 Symmetry Constraints\n"},{"#tail":"\n","@confidence":"0.994064","#text":"\n4.1 Experimental Setup\n"},{"#tail":"\n","@confidence":"0.995231","#text":"\n4.2 Alignment Results\n"},{"#tail":"\n","@confidence":"0.978098","#text":"\n4.3 Rare vs. Common Words\n"},{"#tail":"\n","@confidence":"0.998809","#text":"\n4.4 Symmetrization\n"},{"#tail":"\n","@confidence":"0.996064","#text":"\n4.5 Analysis\n"},{"#tail":"\n","@confidence":"0.988269","#text":"\n5.1 Phrase-Based Machine Translation\n"},{"#tail":"\n","@confidence":"0.999802","#text":"\n5.2 Syntax Transfer\n"}],"footnote":[{"#tail":"\n","@confidence":"0.977837","#text":"\n1 www.seas.upenn.edu/?strctlrn/CAT/.\n"},{"#tail":"\n","@confidence":"0.9149345","#text":"\n3 www.statmt.org/moses/?n=FactoredTraining.HomePage.\n4 IBM Model 4 uses Viterbi decoding as Giza++ does not support MBR decoding.\n"},{"#tail":"\n","@confidence":"0.969393","#text":"\ntested three values of the threshold (0.2, 0.4, 0.6) which try to capture different tradeoffs\n5 The open source Moses (Hoang et al 2007) toolkit from www.statmt.org/moses/.\n6 www.statmt.org/wmt08/baseline.html.\n"}],"construct":{"#tail":"\n","@confidence":"0.3739075","#text":"\nAlgorithm 2: PR optimization via modified EM. E?-Step is computed using\nAlgorithm 1.\n"},"title":{"#tail":"\n","@confidence":"0.443054","#text":"\nLearning Tractable Word Alignment Models\nwith Complex Constraints\nJoa?o V. Grac?a?\nL2F INESC-ID\n"},"@confidence":"0.000000","#tail":"\n","reference":[{"#tail":"\n","@confidence":"0.997997625","#text":"\nBannard, Colin and Chris Callison-Burch.\n2005. Paraphrasing with bilingual parallel\ncorpora. In ACL ?05: Proceedings of the\n43rd Annual Meeting of the Association for\nComputational Linguistics, pages 597?604,\nMorristown, NJ.\nBellare, Kedar, Gregory Druck, and Andrew\nMcCallum. 2009. Alternating projections\n"},{"#tail":"\n","@confidence":"0.959807596638656","#text":"\nGrac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints\nfor learning with expectation constraints.\nIn Proceedings of the Twenty-Fifth Conference\nAnnual Conference on Uncertainty in\nArtificial Intelligence, pages 43?50,\nCorvallis, OR.\nBertsekas, Dimitri P. 1999. Nonlinear\nProgramming: 2nd Edition. Athena\nScientific, Nashua, NH.\nBrown, Peter F., Stephen A. Della Pietra,\nVincent J. Della Pietra, Meredith J.\nGoldsmith, Jan Hajic, Robert L. Mercer,\nand Surya Mohanty. 1993a. But\ndictionaries are data too. In HLT ?93:\nProceedings of the Workshop on Human\nLanguage Technology, pages 202?205,\nMorristown, NJ.\nBrown, Peter F., Stephen A. Della Pietra,\nVincent J. Della Pietra, and Robert L.\nMercer. 1993b. The mathematics of\nstatistical machine translation: Parameter\nestimation. Computational Linguistics,\n19(2):263?311.\nChiang, David, Adam Lopez, Nitin\nMadnani, Christof Monz, Philip Resnik,\nand Michael Subotin. 2005. The Hiero\nmachine translation system: Extensions,\nevaluation, and analysis. In Proceedings\nof the Human Language Technology\nConference and Conference on Empirical\nMethods in Natural Language Processing,\npages 779?786, Vancouver.\nDempster, Arthur P., Nan M. Laird, and\nDonald B. Rubin. 1977. Maximum\nlikelihood from incomplete data via the\nem algorithm. Royal Statistical Society,\nSeries B, 39(1):1?38.\nDeNero, John and Dan Klein. 2007. Tailoring\nword alignments to syntactic machine\ntranslation. In Proceedings of the 45th\nAnnual Meeting of the Association of\nComputational Linguistics, pages 17?24,\nPrague.\nDeng, Yonggang and William Byrne. 2005.\nHMM word and phrase alignment for\nstatistical machine translation. In HLT ?05:\nProceedings of the Conference on Human\nLanguage Technology and Empirical\nMethods in Natural Language Processing,\npages 169?176, Morristown, NJ.\nAssociation for Computational Linguistics.\nFraser, Alexander and Daniel Marcu. 2007.\nGetting the structure right for word\nalignment: Leaf. In Proceedings of the Joint\nConference on Empirical Methods in Natural\nLanguage Processing and Computational\nNatural Language Learning\n(EMNLP-CoNLL), pages 51?60, Prague.\nGalley, Michel, Mark Hopkins, Kevin Knight,\nand Daniel Marcu. 2004. What?s in a\ntranslation rule? In HLT-NAACL 2004:\nMain Proceedings, pages 273?280,\nBoston, MA.\nGanchev, Kuzman, Jennifer Gillenwater, and\nBen Taskar. 2009. Dependency grammar\ninduction via bitext projection constraints.\nIn ACL-IJCNLP ?09: Proceedings of the Joint\nConference of the 47th Annual Meeting\nof the ACL and the 4th International Joint\nConference on Natural Language Processing\nof the AFNLP: Volume 1, pages 369?377,\nMorristown, NJ.\nGanchev, Kuzman, Joa?o V. Grac?a, and Ben\nTaskar. 2008. Better alignments = better\ntranslations? In Proceedings of ACL-08: HLT,\npages 986?993, Columbus, OH.\nGrac?a, Joa?o V., Kuzman Ganchev, and Ben\nTaskar. 2007. Expectation maximization\nand posterior constraints. In J. C. Platt,\nD. Koller, Y. Singer, and S. Roweis, editors,\nAdvances in Neural Information Processing\nSystems 20. MIT Press, Cambridge, MA,\npages 569?576.\nGrac?a, Joa?o V., Kuzman Ganchev, and\nBen Taskar. 2009. Postcat - posterior\nconstrained alignment toolkit. The Prague\nBulletin Of Mathematical Linguistics - Special\nIssue: Open Source Tools for Machine\nTranslation, 91:27?37.\nGrac?a, Joa?o V., Joana P. Pardal, Lu??sa Coheur,\nand Diamantino Caseiro. 2008. Building\na golden collection of parallel\nmulti-language word alignment. In\nProceedings of the Sixth International\nLanguage Resources and Evaluation\n(LREC?08), Marrakech.\nHoang, Hieu, Alexandra Birch, Chris\nCallison-Burch, Richard Zens, Rwth\nAachen, Alexandra Constantin, Marcello\nFederico, Nicola Bertoldi, Chris Dyer,\nBrooke Cowan, Wade Shen, Christine\nMoran, and Ondrej Bojar. 2007. Moses:\nOpen source toolkit for statistical machine\ntranslation. In Proceedings of the 45th\nAnnual Meeting of the Association for\nComputational Linguistics Companion\nVolume Proceedings of the Demo and Poster\nSessions, pages 177?180, Prague.\nHwa, Rebecca, Philip Resnik, Amy\nWeinberg, Clara Cabezas, and Okan Kolak.\n2005. Bootstrapping parsers via syntactic\nprojection across parallel texts. Natural\nLanguage Engineering, 11:11?311.\nKoehn, Philipp. 2005. Europarl: A parallel\ncorpus for statistical machine translation.\nIn Machine Translation Summit,\n12?15 September, Phuket.\nKoehn, Philipp, Franz Josef Och, and Daniel\nMarcu. 2003. Statistical phrase-based\n"},{"#tail":"\n","@confidence":"0.999763315315315","#text":"\nComputational Linguistics Volume 36, Number 3\ntranslation. In Proceedings of the 2003\nConference of the North American Chapter of\nthe Association for Computational Linguistics\non Human Language Technology (NAACL),\npages 48?54, Morristown, NJ.\nKumar, Shankar and William Byrne. 2002.\nMinimum Bayes-Risk word alignments of\nbilingual texts. In Proceedings of the ACL-02\nConference on Empirical Methods in Natural\nLanguage Processing, pages 140?147,\nPhiladelphia, PA.\nLambert, Patrik, Adria` De Gispert, Rafael\nBanchs, and Jose? B. Marino. 2005.\nGuidelines for word alignment evaluation\nand manual alignment. Language Resources\nand Evaluation, 39(4):267?285.\nLiang, Percy, Michael I. Jordan, and Dan\nKlein. 2009. Learning from measurements\nin exponential families. In ICML ?09:\nProceedings of the 26th Annual International\nConference on Machine Learning,\npages 641?648, New York, NY.\nLiang, Percy, Ben Taskar, and Dan Klein.\n2006. Alignment by agreement. In\nProceedings of the Human Language\nTechnology Conference of the NAACL, Main\nConference, pages 104?111, New York, NY.\nLopez, Adam and Philip Resnik. 2006.\nWord-based alignment, phrase-based\ntranslation: Whats the link? In Proceedings\nof the 7th Conference of the Association for\nMachine Translation in the Americas\n(AMTA): Visions for the Future of Machine\nTranslation, pages 90?99, Boston, MA.\nMann, G. and A. McCallum. 2007. Simple,\nrobust, scalable semi-supervised learning\nvia expectation regularization. In\nProceedings of the 24th International\nConference on Machine Learning, page 600,\nCorvallis, OR.\nMann, Gideon S. and Andrew McCallum.\n2008. Generalized expectation criteria\nfor semi-supervised learning of\nconditional random fields. In Proceedings\nof ACL-08: HLT, pages 870?878,\nColumbus, OH.\nMatusov, Evgeny, Nicola Ueffing, and\nHermann Ney. 2006. Computing\nconsensus translation from multiple\nmachine translation systems using\nenhanced hypotheses alignment. In\nProceedings of the EACL, pages 33?40,\nCambridge.\nMcDonald, Ryan, Koby Crammer, and\nFernando Pereira. 2005. Online\nlarge-margin training of dependency\nparsers. In ACL ?05: Proceedings of the\n43rd Annual Meeting of the Association for\nComputational Linguistics, pages 91?98,\nMorristown, NJ.\nNeal, Radford M. and Geoffrey E. Hinton.\n1998. A new view of the EM algorithm that\njustifies incremental, sparse and other\nvariants. In M. I. Jordan, editor, Learning in\nGraphical Models. Kluwer, Amsterdam,\npages 355?368.\nNocedal, Jorge and Stephen J. Wright.\n1999. Numerical Optimization. Springer,\nBerlin.\nOch, Franz Josef and Hermann Ney. 2000.\nImproved statistical alignment models.\nIn ACL ?00: Proceedings of the 38th\nAnnual Meeting on Association for\nComputational Linguistics, pages 440?447,\nMorristown, NJ.\nOch, Franz Josef and Hermann Ney. 2003.\nA systematic comparison of various\nstatistical alignment models. Computational\nLinguistics, 29(1):19?51.\nSmith, Noah A. and Jason Eisner. 2006.\nAnnealing structural bias in multilingual\nweighted grammar induction. In ACL-44:\nProceedings of the 21st International\nConference on Computational Linguistics and\nthe 44th Annual Meeting of the Association for\nComputational Linguistics, pages 569?576,\nMorristown, NJ.\nSnyder, Benjamin and Regina Barzilay.\n2008. Unsupervised multilingual learning\nfor morphological segmentation. In\nProceedings of ACL-08: HLT, pages 737?745,\nColumbus, OH.\nTiedemann, Jo?rg. 2007. Building a\nmultilingual parallel subtitle corpus. In\nProceedings of the 17th Conference on\nComputational Linguistics in the Netherlands\n(CLIN 17), Leuven.\nVogel, Stephan, Hermann Ney, and\nChristoph Tillmann. 1996. Hmm-based\nword alignment in statistical translation.\nIn Proceedings of the 16th Conference on\nComputational Linguistics, pages 836?841,\nMorristown, NJ.\nYarowsky, David and Grace Ngai. 2001.\nInducing multilingual POS taggers and NP\nbracketers via robust projection across\naligned corpora. In Proceedings of the North\nAmerican Chapter Of The Association For\nComputational Linguistics, pages 1?8,\nMorristown, NJ.\n"}],"bodyText":[{"#tail":"\n","@confidence":"0.991154166666667","#text":"\nWord-level alignment of bilingual text is a critical resource for a growing variety of tasks. Proba-\nbilistic models for word alignment present a fundamental trade-off between richness of captured\nconstraints and correlations versus efficiency and tractability of inference. In this article, we\nuse the Posterior Regularization framework (Grac?a, Ganchev, and Taskar 2007) to incorporate\ncomplex constraints into probabilistic models during learning without changing the efficiency\nof the underlying model. We focus on the simple and tractable hidden Markov model, and\npresent an efficient learning algorithm for incorporating approximate bijectivity and symmetry\nconstraints. Models estimated with these constraints produce a significant boost in performance\nas measured by both precision and recall of manually annotated alignments for six language\npairs. We also report experiments on two different tasks where word alignments are required:\nphrase-based machine translation and syntax transfer, and show promising improvements over\nstandard methods.\n"},{"#tail":"\n","@confidence":"0.940601234375","#text":"\nThe seminal work of Brown et al (1993b) introduced a series of probabilistic models\n(IBM Models 1?5) for statistical machine translation and the concept of ?word-by-\nword? alignment, the correspondence between words in source and target languages.\nAlthough no longer competitive as end-to-end translation models, the IBM Models,\nas well as the hidden Markov model (HMM) of Vogel, Ney, and Tillmann (1996),\nare still widely used for word alignment. Word alignments are used primarily for\nextracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn,\nOch, and Marcu 2003] and rules [Galley et al 2004; Chiang et al 2005]) as well as for\n? INESC-ID Lisboa, Spoken Language Systems Lab, R. Alves Redol 9, 1000-029 LISBOA, Portugal.\nE-mail: joao.graca@l2f.inesc-id.pt.\n?? University of Pennsylvania, Department of Computer and Information Science, Levine Hall, 3330 Walnut\nStreet, Philadelphia, PA 19104-6309. E-mail: kuzman@cis.upenn.edu.\n? University of Pennsylvania, Department of Computer and Information Science, 3330 Walnut Street,\nPhiladelphia, PA 19104-6389. E-mail: taskar@cis.upenn.edu.\nSubmission received: 1 August 2009; revised submission received: 24 December 2009; accepted for\npublication: 10 March 2010.\n? 2010 Association for Computational Linguistics\nComputational Linguistics Volume 36, Number 3\nMT system combination (Matusov, Ueffing, and Ney 2006). But their importance has\ngrown far beyond machine translation: for instance, transferring annotations between\nlanguages (Yarowsky and Ngai 2001; Hwa et al 2005; Ganchev, Gillenwater, and\nTaskar 2009); discovery of paraphrases (Bannard and Callison-Burch 2005); and joint\nunsupervised POS and parser induction across languages (Snyder and Barzilay 2008).\nIBM Models 1 and 2 and the HMM are simple and tractable probabilistic models,\nwhich produce the target sentence one target word at a time by choosing a source word\nand generating its translation. IBM Models 3, 4, and 5 attempt to capture fertility (the\ntendency of each source word to generate several target words), resulting in probabilis-\ntically deficient, intractable models that require local heuristic search and are difficult to\nimplement and extend. Many researchers use the GIZA++ software package (Och and\nNey 2003) as a black box, selecting IBM Model 4 as a compromise between alignment\nquality and efficiency. All of the models are asymmetric (switching target and source\nlanguages produces drastically different results) and the simpler models (IBM Models 1,\n2, and HMM) do not enforce bijectivity (the majority of words translating as a single\nword). Although there are systematic translation phenomena where one cannot hope to\nobtain 1-to-1 alignments, we observe that in over 6 different European language pairs\nthe majority of alignments are in fact 1-to-1 (86?98%). This leads to the common practice\nof post-processing heuristics for intersecting directional alignments to produce nearly\nbijective and symmetric results (Koehn, Och, and Marcu 2003).\nIn this article we focus on the HMM word alignment model (Vogel, Ney, and\nTillmann 1996), using a novel unsupervised learning framework that significantly\nboosts its performance. The new training framework, called Posterior Regulariza-\ntion (Grac?a, Ganchev, and Taskar 2007), incorporates prior knowledge in the form of\nconstraints on the model?s posteriors. The constraints are expressed as inequalities on\nthe expected value under the posterior distribution of user-defined features. Although\nthe base model remains unchanged, learning guides the model to satisfy these con-\nstraints. We propose two such constraints: (i) bijectivity: one word should not translate\nto many words; and (ii) symmetry: directional alignments should agree. Both of these\nconstraints significantly improve the performance of the model both in precision and\nrecall, with the symmetry constraint generally producing more accurate alignments.\nSection 3 presents the Posterior Regularization (PR) framework and describes how to\nencode such constraints in an efficient manner, requiring only repeated inference in the\noriginal model to enforce the constraints. Section 4 presents a detailed evaluation of\nthe alignments produced. The constraints over posteriors consistently and significantly\noutperform the unconstrained HMM model, evaluated against manual annotations.\nMoreover, this training procedure outperforms the more complex IBM Model 4 nine\ntimes out of 12. We examine the influence of constraints on the resulting posterior dis-\ntributions and find that they are especially effective for increasing alignment accuracy\nfor rare words. We also demonstrate a new methodology to avoid overfitting using a\nsmall development corpus. Section 5 evaluates the new framework on two different\ntasks that depend on word alignments. Section 5.1 focuses on MT and shows that the\nbetter alignments also lead to better translation systems, adding to similar evidence\npresented in Ganchev, Grac?a, and Taskar (2008). Section 5.2 shows that the alignments\nwe produce are better suited for transfer of syntactic dependency parse annotations.\nAn implementation of this work (Grac?a, Ganchev, and Taskar 2009) is available under a\n"},{"#tail":"\n","@confidence":"0.994780791666667","#text":"\nA word alignment for a parallel sentence pair represents the correspondence between\nwords in a source language and their translations in a target language (Brown et al\n1993b). There are many reasons why a simple word-to-word (1-to-1) correspondence\nis not possible for every sentence pair: for instance, auxiliary verbs used in one lan-\nguage but not the other (e.g., English He walked and French Il est alle?), articles required\nin one language but optional in the other (e.g., English Cars use gas and Portuguese\nOs carros usam gasolina), cases where the content is expressed using multiple words\nin one language and a single word in the other language (e.g., agglutination such as\nEnglish weapons of mass destruction and German Massenvernichtungswaffen), and expres-\nsions translated indirectly. Due to this inherent ambiguity, manual annotations usually\ndistinguish between sure correspondences for unambiguous translations, and possible,\nfor ambiguous translations (Och and Ney 2003). The top row of Figure 1 shows two\nword alignments between an English?French sentence pair. We use the following nota-\ntion: the alignment on the left (right) will be referenced as source?target (target?source)\nand contains source (target) words as rows and target (source) words as columns. Each\nentry in the matrix corresponds to a source?target word pair, and is the candidate for an\nalignment link. Sure links are represented as squares with borders, and possible links\nFigure 1\nPosterior marginal distributions for different models for an English to French sentence\ntranslation. Left: EN?FR model. Right: FR? EN model. Top: Regular HMM posteriors.\nMiddle: After applying bijective constraint. Bottom: After applying symmetric constraint. Sure\nalignments are squares with borders; possible alignments are squares without borders. Circle\nsize indicates probability value. Circle color in the middle and bottom rows indicates differences\nin posterior from the top row: green = higher probability; red = lower probability.\n"},{"#tail":"\n","@confidence":"0.984353333333333","#text":"\nare represented as squares without borders. Circles indicate the posterior probability\nassociated with a given link and will be explained latter.\nWe use six manually annotated corpora whose characteristics are summarized in\n"},{"#tail":"\n","@confidence":"0.937193444444445","#text":"\nSpanish/French (Es-Fr) portions of the Europarl corpus using annotations described\nby Grac?a et al (2008), where we split the gold alignments into a dev/test set in a ratio of\n40%/60%. Table 1 shows some of the variety of challenges presented by each corpus.\nFor example, En-Es has longer sentences and hence more ambiguity for alignment.\nFurthermore, it has a smaller percentage of bijective (1-to-1) alignments, which makes\nword fertility more important. Overall, the great majority of links are bijective across\nthe corpora (86?98%). This characteristic will be explored by the constraints described\nin this article. For the evaluations in Section 4, the percentage of sure links (out of all\nlinks) will correlate with difficulty because only sure links are considered for recall.\n"},{"#tail":"\n","@confidence":"0.996817777777778","#text":"\nIn this article we focus on the HMM for word alignment proposed by Vogel, Ney, and\nTillmann (1996). This model generalizes IBM Models 1 and 2 (Brown et al 1993b),\nby introducing a first-order Markov dependence between consecutive alignment link\ndecisions. The model is an (input?output) HMM with I positions whose hidden state\nsequence z = (z1, . . . , zI ) with zi ? {null, 1, . . . , J} corresponds to a sequence of source\nword positions, where J is the source sentence length, and with null representing un-\naligned target words. Each observation corresponds to a word in the target language xi.\nThe probability of an alignment z and target sentence x given a source sentence y can\nbe expressed as:\n"},{"#tail":"\n","@confidence":"0.979268","#text":"\nwhere pt(xi  |yzi ) is the probability of a target word at position i being a translation of the\nsource word at position zi (translation probability), and pd(zi  |zi?1) is the probability\n"},{"#tail":"\n","@confidence":"0.97889364","#text":"\nGrac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints\nof translating a word at position zi, given that the previous translated word was at\nposition zi?1 (distortion probability). Note that this model is directional: Each target\nword (observation) can be aligned to at most one source word (hidden state), whereas a\nsource word could be used multiple times.\nWe refer to translation parameters pt and distortions parameters pd jointly as ?.\nThere are several important standard details of the parametrization: The distortion\nprobability pd(zi  |zi?1) depends only on the distance (zi ? zi?1) between the source po-\nsitions the states represent. Only distances in the range ?5 are modeled explicitly, with\nlarger distances assigned equal probabilities. The probability of the initial hidden state,\npd(z1  |z0) is modeled separately from the other distortion probabilities. To incorporate\nnull links, we add a translation probability given null: pt(xi  |ynull). Following standard\npractice, null links also maintain position information and do not allow distortion. To\nimplement this, we create position-specific null hidden states for each source position,\nand set pd(nulli|yi? ) = 0 and pd(nulli|nulli? ) = 0 for all i = i?. The model is simple, with\ncomplexity of inference O(I ? J2). There are several problems with the model that arise\nfrom its directionality, however.\n Non-bijective: Multiple target words can be linked to a single source\nword. This is rarely desirable. For instance, the model produces\nnon-bijective links 22% of the time for En-Fr instead of 2%.\n Asymmetric: By switching the (arbitrary) choice of which language is\nsource and which is target, the HMM produces very different results. For\nexample, intersecting the sets of alignments produced by the two possible\nchoices for source preserves less than half of their union for both En-Fr\nand En-Pt.2\n"},{"#tail":"\n","@confidence":"0.913738","#text":"\nStandard HMM training seeks model parameters ? that maximize the log-likelihood of\nthe parallel corpus:\n"},{"#tail":"\n","@confidence":"0.981079","#text":"\nn, yn) denotes the empirical average of a function f (xn, yn)\nover the N pairs of sentences {(x1, y1) . . . , (xN, yN )} in the training corpus. Because\nof the latent alignment variables z, the log-likelihood function for the HMM model\nis not concave, and the model is fit using the Expectation Maximization (EM) algo-\nrithm (Dempster, Laird, and Rubin 1977). EM maximizes L(?) via block-coordinate\nascent on a lower bound F(q, ?) using an auxiliary distribution over the latent variables\n"},{"#tail":"\n","@confidence":"0.955164666666667","#text":"\nComputational Linguistics Volume 36, Number 3\nTo simplify notation, we will drop the dependence on y and will write p?(x, z  |y) as\np?(x, z), p?(z  |x, y) as p?(z  |x) and q(z  |x, y) as q(z  |x). The alternating E and M steps\n"},{"#tail":"\n","@confidence":"0.993218653846154","#text":"\nwhere KL(q||p) = Eq[log q(?)p(?) ] is the Kullback-Leibler divergence. The EM algorithm is\nguaranteed to converge to a local maximum of L(?) under mild conditions (Neal and\nHinton 1998). The E step computes the posteriors qt+1(z  |x) = p?t (z  |x) over the latent\nvariables (alignments) given the observed variables (sentence pair) and current param-\neters ?t, which is accomplished by the forward-backward algorithm for HMMs. The M\nstep uses qt+1 to ?softly fill in? the values of alignments z and estimate parameters ?t+1.\nThis step is particularly easy for HMMs, where ?t+1 simply involves normalizing (ex-\npected) counts. This modular split into two intuitive and straightforward steps accounts\nfor the vast popularity of EM.\nIn Figure 1, each entry in the alignment matrix contains a circle indicating the align-\nment link posterior for that particular word pair after training an HMM model with the\nEM algorithm (see the experimental set up in Section 4.1). Note that the link posteriors\nare concentrated around particular source words (rare words occurring less than five\ntimes in the corpus) in both directions, instead of being spread across different words.\nThis is a well-known problem when training using EM called the ?garbage collector ef-\nfect? (Brown et al 1993a). A rare word in the source language links to many words in the\ntarget language that we would ideally like to see unaligned, or aligned to other words\nin the sentence. The reason this happens is that the generative model has to distribute\ntranslation probability for each source word among different candidate target words.\nIf one translation is much more common than another, but the rare translation is used\nin the sentence, the model might have a very low translation probability for the correct\nalignment. On the other hand, because the rare source word occurs only in a few sen-\ntences it needs to spread its probability mass over fewer competing translations. In this\ncase, choosing to align the rare word to all of these words leads to a higher likelihood\nthan correctly linking them or linking them to the special null word, because it increases\nthe likelihood of this sentence without lowering the likelihood of many other sentences.\n"},{"#tail":"\n","@confidence":"0.9987635","#text":"\nAlignments are normally predicted using the Viterbi algorithm (which selects the single\nmost probable path through the HMM?s lattice).\nAnother possibility that often works better is to use Minimum Bayes-Risk (MBR)\ndecoding (Kumar and Byrne 2002; Liang, Taskar, and Klein 2006; Grac?a, Ganchev, and\nTaskar 2007). Using this decoding we include an alignment link i ? j if the posterior\nprobability that word i aligns to word j is above some threshold. This allows the\naccumulation of probability from several low-scoring alignments that agree on one\nalignment link. The threshold is tuned on some small amount of labeled data?in\nour case the development set?to minimize some loss. Kumar and Byrne (2002) study\ndifferent loss functions that incorporate linguistic knowledge, and show significant\n"},{"#tail":"\n","@confidence":"0.9950262","#text":"\nGrac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints\nimprovement over likelihood decoding. Note that this could potentially result in an\nalignment having zero probability under the model, as many-to-many alignments can\nbe produced in this way. MBR decoding has several advantages over Viterbi decoding.\nFirst, independently of the particular choice of the loss function, by picking a specific\nthreshold we can trade off precision and recall of the predicted word alignments. In\nfact, in this work when comparing different alignment sets we do not commit to any\nloss function but instead compare precision vs recall curves, by generating alignments\nfor different thresholds (0..1). Second, with this method we can ignore the null word\nprobabilities, which tend to be poorly estimated.\n"},{"#tail":"\n","@confidence":"0.996608115384615","#text":"\nWord alignment models in general and the HMM in particular are very gross over-\nsimplifications of the translation process and the optimal likelihood parameters learned\noften do not correspond to sensible alignments. One solution to this problem is to\nadd more complexity to the model to better reflect the translation process. This is the\napproach taken by IBM Models 4+ (Brown et al 1993b; Och and Ney 2003), and more\nrecently by the LEAF model (Fraser and Marcu 2007). Unfortunately, these changes\nmake the models probabilistically deficient and intractable, requiring approximations\nand heuristic learning and inference prone to search errors. Instead, we propose to\nuse a learning framework called Posterior Regularization (Grac?a, Ganchev, and Taskar\n2007) that incorporates side information into unsupervised estimation in the form of\nconstraints on the model?s posteriors. The constraints are expressed as inequalities on\nthe expected values under the posterior distribution of user-defined constraint features\n(not necessarily the same features used by the model). Because in most applications\nwhat we are interested in are the latent variables (in this case the alignments), con-\nstraining the posteriors allows a more direct way to achieve the desired behavior.\nOn the other hand, constraining the expected value of the features instead of adding\nthem to the model allows us to express features that would otherwise make the model\nintractable. For example, enforcing that each hidden state of an HMM model should be\nused at most once per sentence would break the Markov property and make the model\nintractable. In contrast, we will show how to enforce the constraint that each hidden\nstate is used at most once in expectation. The underlying model remains unchanged,\nbut the learning method changes. During learning, our method is similar to the EM\nalgorithm with the addition of solving an optimization problem similar to a maximum\nentropy problem inside the E Step. The following subsections present the Posterior\nRegularization framework, followed by a description of how to encode two pieces of\nprior information aimed at solving the problems described at the end of Section 2.\n"},{"#tail":"\n","@confidence":"0.997367","#text":"\nThe goal of the Posterior Regularization (PR) framework is to guide a model during\nlearning towards satisfying some prior knowledge about the desired latent variables\n(in this case word alignments), encoded as constraints over their expectations. The\nkey advantage of using regularization on posterior expectations is that the base model\nremains unchanged, but during learning, it is driven to obey the constraints by setting\nappropriate parameters ?. Moreover, experiments show that enforcing constraints in ex-\npectation results in predicted alignments that also satisfy the constraints. More formally,\nposterior information in PR is specified with sets Qx of allowed distributions over the\n"},{"#tail":"\n","@confidence":"0.984175071428571","#text":"\nComputational Linguistics Volume 36, Number 3\nhidden variables z which satisfy inequality constraints on some user-defined feature\nexpectations, with violations bounded by  ? 0:\nConstrained Posterior Set : Qx = {q(z  |x) : ??, Eq[f(x, z)] ? bx ? ?; ||?||22 ? 2} (6)\nQx denotes the set of valid distributions where some feature expectations are bounded\nby bx and  ? 0 is an allowable violation slack. Setting  = 0 enforces inequality\nconstraints strictly. In order to introduce equality constraints, we use two inequality\nconstraints with opposite signs. We assume that Qx is non-empty for each example x.\nFurthermore, the set Qx needs to be convex. In this work we restrict ourselves to\nlinear inequalities because, as will be shown, subsequently this simplifies the learning\nalgorithm. Note that Qx, f(x, z), and bx also depend on y, the corresponding source\nsentence, but we suppress the dependence for brevity. In PR, the log-likelihood of a\nmodel is penalized with the KL-divergence between the desired distribution space Qx\nand the model posteriors, KL(Qx ? p?(z|x)) = min\n"},{"#tail":"\n","@confidence":"0.997760714285714","#text":"\nThe objective trades off likelihood and distance to the desired posterior subspace (mod-\nulo getting stuck in local maxima) and provides an effective method of controlling the\nposteriors.\nAnother way of interpreting the objective is to express the marginal log-likelihood\nL(?) as a KL distance: KL(?(xn) ? p?(x)) where ?(xn) is a delta function at xn. Hence the\nobjective is a sum of two average KL terms, one in the space of distributions over x and\none in the space of distributions over z:\n"},{"#tail":"\n","@confidence":"0.77230575","#text":"\nThis view of the PR objective is illustrated in Figure 2.\nFigure 2\nMaximizing the PR objective is equivalent to minimizing the empirical average of two\nKL divergences: The negative log-likelihood ?L(?) = 1N\n"},{"#tail":"\n","@confidence":"0.90535","#text":"\nillustrates the effect of the likelihood term and the regularization term operating over the two\nspaces of distributions: the observed variables x and the latent variables z. (The effect of the prior\non ? is not shown.)\n"},{"#tail":"\n","@confidence":"0.9084285","#text":"\nGrac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints\nComputing the PR objective involves solving the optimization problem for each x:\n"},{"#tail":"\n","@confidence":"0.985527","#text":"\nDirectly minimizing this objective is hard because there is an exponential number of\nalignments z; however, the problem becomes easy to solve in its dual formulation (see\n"},{"#tail":"\n","@confidence":"0.9929845","#text":"\nsolution is q(z|x) = p?(z|x) exp{??f(x, z)}/Z(?). There is one dual variable per ex-\npectation constraint, and the dual gradient at ? = 0 is ?(?) = bx ? Eq[f(x, z)] +  ?i||?||2 .\nNote that this primal?dual relationship is very similar to the one between maximum\nlikelihood and maximum entropy. If bx corresponds to empirical expectations and\np?(z|x) is uniform, then Equation (10) would be a log-likelihood and Equation (14) (fol-\nlowing) would be a maximum entropy problem. As with maximum entropy, gradient\ncomputation involves computing an expectation under q(z  |x), which can be performed\nefficiently if the features f(x, z) factor in the same way as the model p?(x, z), and the\nconstraints are linear. The conditional distribution over z represented by a graphical\nmodel such as HMM can be written as a product of factors over cliques C:\n"},{"#tail":"\n","@confidence":"0.997658","#text":"\nIn an HMM, the cliques C are simply the nodes zi and the edges (zi, zi+1) and the factors\ncorrespond to the distortion and translation probabilities. We will assume f is factorized\nas a sum over the same cliques (we will show below how symmetry and bijectivity\nconstraints can be expressed in this way):\n"},{"#tail":"\n","@confidence":"0.895823666666667","#text":"\nHence the projection step uses the same inference algorithm (forward?backward for\nHMMs) to compute the gradient, only modifying the local factors using the current\nsetting of ?.\n"},{"#tail":"\n","@confidence":"0.979295388888889","#text":"\nComputational Linguistics Volume 36, Number 3\nWe optimize the dual objective using the gradient based methods shown in\nAlgorithm 1. Here ? is an optimization precision, ? is a step size chosen with the strong\nWolfe?s rule (Nocedal and Wright 1999). Here, ??(?) represents an ascent direction\nchosen as follows: For inequality constraints, it is the projected gradient (Bertsekas\n1999); for equality constraints with slack, we use conjugate gradient (Nocedal and\nWright 1999), noting that when ? = 0, the objective is not differentiable. In practice\nthis only happens at the start of optimization and we use a sub-gradient for the first\ndirection.\nComputing the projection requires an algorithm for inference in the original model,\nand uses that inference as a subroutine. For HMM word alignments, we need to make\nseveral calls to forward?backward in order to choose ?. Setting the optimization pre-\ncision ? more loosely allows the optimization to terminate more quickly but at a less\naccurate value. We found that aggressive optimization significantly improves alignment\nquality for both constraints we used and consequently choose ? so that tighter values\ndo not significantly improve performance. This explains why we report better results\nhere in this paper than in Ganchev, Grac?a, and Taskar (2008), which uses a more naive\noptimization (see Section 4.1).\n"},{"#tail":"\n","@confidence":"0.99968","#text":"\nWe can optimize the PR objective using a procedure very similar to the expectation\nmaximization (EM) algorithm. Recall from Equation (4) that in the E step, q(z  |x) is\nset to the posterior over hidden variables given the current ?. To converge to the PR\nobjective, we must modify the E step so that q(z  |x) is a projection of the posteriors onto\nthe constraint set Qx for each example x (Grac?a, Ganchev, and Taskar 2007).\n"},{"#tail":"\n","@confidence":"0.992061","#text":"\nThe new posteriors q(z|x) are used to compute sufficient statistics for this instance and\nhence to update the model?s parameters in the M step (Equation (5)), which remains\nunchanged. This scheme is illustrated in Figure 3 and in Algorithm 2. The only imple-\nmentation difference is that we must now perform the KL projection before collecting\nsufficient statistics. We found it can help to also perform this projection at test time,\n"},{"#tail":"\n","@confidence":"0.559756333333333","#text":"\nGrac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints\nFigure 3\nModified EM for optimizing PR objective L(?) ? ?E[KL(Qx ? p?(z|x))].\n"},{"#tail":"\n","@confidence":"0.988488375","#text":"\nWe observed in Table 1 that most alignments are 1-to-1 and we would like to introduce\nthis prior information into the model. Unfortunately including such a constraint in the\nmodel directly breaks the Markov property in a fairly fundamental way. In particular\ncomputing the normalization would require the summation of 1-to-1 or near 1-to-1\nweighted matchings, which is a classic #P-complete problem. Introducing alignment\ndegree constraints in expectation using the PR framework is easy and tractable. We\nencode them as the constraint E[f(x, z)] ? 1 where we have one feature f for each source\nword j that counts how many times it is aligned to a target word in the alignment z:\n"},{"#tail":"\n","@confidence":"0.9910997","#text":"\nThe second row of Figure 1 shows an example of the posteriors after applying bijectivity\nconstraints; the first row is before the projection. Green (respectively, red) circles indicate\nthat the probability mass for that particular link increased (respectively, decreased)\nwhen compared with the EM-trained HMM. For example, in the top left panel, the\nword schism is used more than once, causing erroneous alignments. Projecting to the\nbijectivity constraint set prevents this and most of the mass is (for this example) moved\nto the correct word pairs. Enforcing the constraint at training and decoding increases\nthe fraction of 1-to-1 alignment links from 78% to 97.3% for En-Fr (manual annotations\nhave 98.1%); for En-Pt the increase is from 84.7% to 95.8% (manual annotations have\n90.8%) (see Section 4.1).\n"},{"#tail":"\n","@confidence":"0.996332333333333","#text":"\nThe directional nature of the generative models used to recover word alignments con-\nflicts with their interpretation as translations. In practice, we see that the choice of which\nlanguage is source versus target matters and changes the mistakes made by the model\n(the first row of panels in Figure 1). The standard approach is to train two models\nindependently and then intersect their predictions (Och and Ney 2003). However, we\nshow that it is much better to train two directional models concurrently, coupling\ntheir posterior distributions over alignments to approximately agree. Let the directional\nmodels be defined as: ??p (??z ) (source?target) and ??p (??z ) (target?source). We suppress\ndependence on x and y for brevity. Define z to range over the union of all possible\n"},{"#tail":"\n","@confidence":"0.988062833333334","#text":"\nIf the feature fij has an expected value of zero, then both models predict the i, j link\nwith equal probability. We therefore impose the constraint Eq[ fij(x, z)] = 0 (possibly with\nsome small slack). Note that satisfying this implies satisfying the bijectivity constraint\npresented earlier. To compute expectations of these features under the model q we only\nneed to be able to compute them under each directional HMM. To see this, we have by\nthe definition of q? and p?,\n"},{"#tail":"\n","@confidence":"0.82001","#text":"\nwhere we have defined:\n"},{"#tail":"\n","@confidence":"0.849573","#text":"\nAll these quantities can be computed separately in each model using forward?backward\nand, furthermore, Z? = 12 (\n"},{"#tail":"\n","@confidence":"0.990353625","#text":"\nthe bottom panels of Figure 1. The projected link posteriors are equal for the two\nmodels, and in most cases the probability mass was moved to the correct alignment\nlinks. The exception is the word pair internal/le. In this case, the model chose to incor-\nrectly have a high posterior for the alignment link rather than generating internal from\nnull in one direction and le from null in the other.\nWe can measure symmetry of predicted alignments as the ratio of the size of the\nintersection to the size of the union. Symmetry constraints increase symmetry from 48%\nto 89.9% for En-Fr and from 48% to 94.2% for En-Pt (see Section 4.1).\n"},{"#tail":"\n","@confidence":"0.996023333333333","#text":"\nWe begin with a comparison of word alignment quality evaluated against manually\nannotated alignments as measured by precision and recall. We use the six parallel\ncorpora with gold annotations described in the beginning of Section 2.\n"},{"#tail":"\n","@confidence":"0.9976528","#text":"\nWe discarded all training data sentence pairs where one of the sentences contained\nmore than 40 words. Following common practice, we added the unlabeled development\nand test data sets to the pool of unlabeled sentences. We initialized the IBM Model 1\ntranslation table with uniform probabilities over word pairs that occur together in the\nsame sentence and trained the IBM Model 1 for 5 iterations. All HMM alignment models\n"},{"#tail":"\n","@confidence":"0.997777242424243","#text":"\nGrac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints\nwere initialized with the translation table from IBM Model 1 and uniform distortion\nprobabilities. We run each training procedure until the area under the precision/recall\ncurve measured on a development corpus stops increasing (see Figure 4 for an example\nof such a curve). Using the precision/recall curve gives a broader sense of the model?s\nperformance than using a single point (by tuning a threshold for a particular metric). In\nmost cases this meant four iterations for normal EM training and two iterations using\nposterior regularization. We suspect that the constraints make the space easier to search.\nThe convergence criterion for the projection algorithm was the normalized l2 norm\nof the gradient (gradient norm divided by number of constraints) being smaller than\n? (see Algorithm 1). For bijective constraints, we set ? to 0.005 and used zero slack.\nFor symmetric constraints, ? and slack were set to 0.001. We chose ? aggressively\nand lower values did not significantly increase performance. Less aggressive settings\ncause degradation of performance: For example, for En-Fr using 10k sentences, and\nrunning four iterations of constrained EM, the area under the precision/recall curve for\nthe symmetric model changed from 70% with ? = 0.1 to 85% using ? = 0.001. On the\nother hand, the number of iterations required to project the constraints increases for\nsmaller values of ?. The number of forward?backward calls for normal HMM is 40k\n(one for each sentence and EM iteration), for the symmetric model using ? = 0.1 was\naround 41k and using ? = 0.001 was around 26M (14 minutes to 4 hours 14 minutes\nof training time, 17 times slower, for the different settings of ?). We note that better\noptimization methods, such as L-BFGS, or using a warm start for the parameters at each\nEM iteration (parameters from the previous iteration), or training the models online,\nwould potentially decrease the running time of our method.\nThe intent of this experimental section is to evaluate the gains from using con-\nstraints during learning, hence the main comparison is between HMM trained with\nnormal EM vs. trained with PR plus constraints. We also report results for IBM Model 4,\nbecause it is often used as the default word alignment model, and can be used as a\nreference. However, we would like to note that IBM Model 4 is a more complex model,\nable to capture more structure, albeit at the cost of intractable inference. Because our\napproach is orthogonal to the base model used, the constraints described here could\nbe applied in principle to IBM Model 4 if exact inference was efficient, hopefully\nyielding similar improvements. We used a standard implementation of IBM Model\n"},{"#tail":"\n","@confidence":"0.9139248","#text":"\nnot use the same stopping criterion to avoid overfitting and we are not able to produce\nprecision/recall curves. We trained IBM Model 4 using the default configuration of the\nFigure 4\nPrecision/Recall curves for different models using 1,000k sentences. Precision on the horizontal\naxis. Left: Hansard EN-FR direction. Right: EN-PT Portuguese-English direction.\n"},{"#tail":"\n","@confidence":"0.681408","#text":"\nHMM, and five iterations of IBM Model 4.\n"},{"#tail":"\n","@confidence":"0.992879375","#text":"\nIn this section we present results on alignment quality. All comparisons are made using\nMBR decoding because this decoding method always outperforms Viterbi decoding.4\nFor the models with constraints we project the posteriors at decode time (i.e., we use\nq(z  |x) to decode). This gives a small but consistent improvement. Figure 4 shows\nprecision/recall curves for the different models on the En-Fr corpus using English as\nthe source language (left), and on the En-Pt corpus using Portuguese as the source.\nPrecision/recall curves are obtained by varying the posterior threshold from 0 to 1 and\nthen plotting the different precision and recall values obtained.\nWe observe several trends from Figure 4. First, both types of constraints improve\nover the HMM in terms of both precision and recall (their precision/recall curve is\nalways above). Second, S-HMM performs slightly better than B-HMM. IBM Model 4\nis comparable with both constraints (after symmetrization). The results for all language\npairs are in Figure 5. For ease of comparison, we choose a decoding threshold for HMM\nmodels to achieve the recall of the corresponding IBM Model 4 and report precision.\nOur methods always improve over the HMM by 10% to 15%, and improve over IBM\nModel 4 nine times out of 12. Comparing the constraints with each other we see that\n"},{"#tail":"\n","@confidence":"0.894308923076923","#text":"\nGrac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints\nFigure 6\nWord alignment precision as a function of training data size (number of sentence pairs).\nPosterior decoding threshold chosen to achieve IBM Model 4 recall in the Hansard corpus. Right:\nEnglish as source. Left: French as source.\nS-HMM performs better than B-HMM in 10 out of 12 cases. Because S-HMM indirectly\nenforces bijectivity and models sequential correlations on both sides, this is perhaps not\nsurprising.\nFigure 6 shows performance as a function of training data size. As before, we decode\nto achieve the recall of IBM Model 4. For small training corpora adding the constraints\nprovides larger improvements (20?30%) but we still achieve significant gains even with\na million parallel sentences (15%). Greater improvements for small data sizes indicate\nthat our approach can be especially effective for resource-poor language pairs.\n"},{"#tail":"\n","@confidence":"0.999929111111111","#text":"\nOne of the main benefits of using the posterior regularization constraints described is\nan alleviation of the garbage collector effect (Brown et al 1993a). Figure 7 breaks down\nperformance improvements by common versus rare words. As before, we use posterior\ndecoding, tuning the threshold to match IBM Model 4 recall. For common words, this\ntuning maintains recall very close for all models so we do not show this in the figure. In\nthe top left panel of Figure 7, we see that precision of common words follows the pattern\nwe saw for the corpus overall: Symmetric and bijective outperform both IBM Model 4\nand the baseline HMM, with symmetric slightly better than bijective. The results for\ncommon words vary more slowly as we increase the quantity of training data than they\ndid for the full corpus. In the top right panel of Figure 7 we show the precision for rare\nwords. For the baseline HMM as well as for IBM Model 4, this is very low precisely\nbecause of the garbage collector problem: Rare words become erroneously aligned to\nuntranslated words, leading to low precision. In fact the constrained models achieve\nabsolute precision improvements of up to 50% over the baseline. By removing these\nerroneous alignments the translation table becomes more accurate, allowing higher re-\ncall on the full corpus. In the bottom panel of Figure 7, we observe a slightly diminished\nrecall for rare words. This slight drop in recall is due to moving the mass corresponding\nto rare words to null.\n"},{"#tail":"\n","@confidence":"0.998217666666667","#text":"\nAs discussed earlier, the word alignment models are asymmetric, whereas most appli-\ncations require a single alignment for each sentence pair. Typically this is achieved by\na symmetrization heuristic that takes two directional alignments and produces a single\n"},{"#tail":"\n","@confidence":"0.968458714285714","#text":"\nalignment. For MT the most commonly used heuristic is called grow diagonal final\n(Och and Ney 2003). This starts with the intersection of the sets of aligned points and\nadds points around the diagonal that are in the union of the two sets of aligned points.\nThe alignment produced has high recall relative to the intersection and only slightly\nlower recall than the union. In syntax transfer the intersection heuristic is normally\nused, because one wants to have high precision links to transfer knowledge between\nlanguages. One pitfall of these symmetrization heuristics is that they can obfuscate the\nlink between the original alignment and the ones used for a specific task, making errors\nmore difficult to analyze. Because they are heuristics tuned for a particular phrase-\nbased translation system, it is not clear when they will help and when they will hinder\nsystem performance. In this work we followed a more principled approach that uses\nFigure 8\nPrecision/recall curves for the different models after soft union symmetrization. Precision is on\nthe horizontal axis. Left EN-FR, Right PT-ES.\n"},{"#tail":"\n","@confidence":"0.99713","#text":"\nGrac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints\nthe knowledge about the posterior distributions of each directional model. We include a\npoint in the final alignment if the average of the posteriors under the two models for that\npoint is above a threshold. This heuristic is called soft union (DeNero and Klein 2007).\nFigure 8 shows the Precision/Recall curves after symmetrization for the En-Fr corpus.\nThe posterior regularization?trained models still performed better, but the differences\nget smaller after doing the symmetrization. This should not be very surprising, because\nthe soft union symmetrization can be viewed as an approximation of our symmetry\nconstraint applied only at decode time. Applying the symmetrization to the model with\nsymmetry constraints does not affect performance.\n"},{"#tail":"\n","@confidence":"0.9855456","#text":"\nIn this section we discuss some scenarios in which the constraints make the alignments\nbetter, and some scenarios where they fail. We have already discussed the garbage\ncollector effect and how both models address it. Both of the constraints also bias the\nmodel to have at most probability one in any row or column of the posterior matrix,\nencouraging 1-to-1 alignments. Obviously whenever alignments are systematically not\n1-to-1 , this can lead to errors (for instance the examples described in Section 2).\nAn example presented in Figure 9 shows the posterior marginal distributions for an\nEnglish/French sentence pair using the same notation as in Figure 1. In the top panel of\nFigure 9\nPosterior distributions for different models for an English to French sentence translation. Left:\nEN?FR model. Right: FR? EN model. Top: Regular HMM posteriors. Middle: After applying\nthe bijective constraint. Bottom: After applying the symmetric constraint. Sure alignments are\nsquares with borders; possible alignments are squares without borders. Circle size indicates\nprobability value. Circle color in the middle and bottom rows indicates differences in posterior\nfrom the top row; green = higher probability; red = lower probability.\n"},{"#tail":"\n","@confidence":"0.946921217391305","#text":"\nComputational Linguistics Volume 36, Number 3\nFigure 9, we see the baseline models, where the English word met is incorrectly being\naligned to se?ance est ouverte. This makes it impossible to recover the correct alignment\nhouse/se?ance. Either constraint corrects this problem. On the other hand, by enforcing\na 1-to-1 mapping the correct alignment met / est ouverte is lost. Going back to the first\nrow (regular HMM) this alignment is correct in one direction and absent in the other\n(due to the many-to-1 model restriction) but we can recover that information using the\nsymmetrization heuristics, since the point is present at least in one direction with high\nprobability mass. This is not the case for the constraint-based models that reduce the\nmass of that alignment in both directions. Going back to the right panel of Figure 8, we\ncan see that for low values of precision the HMM model actually achieves better recall\nthan the constraint-based methods. There are two possible solutions to alleviate this\ntype of problem, both with their caveats. One solution is to model the fertility of each\nword in a way similar to IBM Model 4, or more generally to model alignments of multi-\nple words. This can lead to significant computational burden, and is not guaranteed to\nimprove results. A more complicated model may require approximations that destroy\nits performance gain, or require larger corpora to estimate its parameters. Another\noption is to perform some linguistically motivated pre-processing of the language pair\nto conjoin words. This of course has the disadvantage that it needs to be specific to a\nlanguage pair in order to include information such as ?English simple past is written\nusing a single word, so join together French passe? compose?.? An additional problem\nwith joining words to alleviate inter-language divergences is that it can increase data\nsparsity.\n"},{"#tail":"\n","@confidence":"0.999609","#text":"\nIn this section we evaluate the alignments resulting from using the proposed constraints\nin two different tasks: Statistical machine translation where alignments are used to\nrestrict the number of possible minimal translation units; and syntax transfer, where\nalignments are used to decide how to transfer dependency links.\n"},{"#tail":"\n","@confidence":"0.9986085","#text":"\nWe now investigate whether our alignments produce improvements in an end-to-end\nphrase-based machine translation system. We use a state-of-the-art machine translation\nsystem,5 and follow the experimental setup used for the 2008 shared task on machine\ntranslation (ACL 2008 Third Workshop on Statistical Machine Translation). The full\npipeline consists of the following steps: (1) prepare the data (lowercase, tokenize, and\nfilter long sentences); (2) build language models; (3) create word alignments in each\ndirection; (4) symmetrize directional word alignments; (5) build phrase table; (6) tune\nweights for the phrase table. For more details consult the shared task description.6 To\nevaluate the quality of the produced alignments, we keep the pipeline unchanged, and\nuse the models described earlier to generate the word alignments in Step 3. For Step 4,\nwe use the soft union symmetrization heuristic. Symmetrization has almost no effect on\nalignments produced by S-HMM, but we use it for uniformity in the experiments. We\n"},{"#tail":"\n","@confidence":"0.98390225","#text":"\nof precision vs. recall, and pick the best according to the translation performance on\ndevelopment data. Table 2 summarizes the results for the different corpora. For refer-\nence we include IBM Model 4 as suggested in the task description. PR training always\noutperforms EM training and outperforms IBM Model 4 in all but one experiment.\nDifferences in BLEU range from 0.2 to 0.9. The two constraints help to a different extent\nfor different corpora and translation directions, in a somewhat unpredictable manner.\nIn general our impression is that the connection between alignment quality and BLEU\nscores is complicated, and changes are difficult to explain and justify. The number of\niterations for MERT optimization to converge varied from 2 to 28; and the best choice of\nthreshold on the development set did not always correspond to the best on the test set.\nContrary to conventional wisdom in the MT community, bigger phrase tables did not\nalways perform better. In 14 out of 18 cases, the threshold picked was 0.4 (medium size\nphrase tables) and the other four times 0.2 was picked (smaller phrase tables). When\nwe include only high confidence alignments, more phrases are extracted but many of\nthese are erroneous. Potentially this leads to a poor estimate of the phrase probabilities.\nSee Lopez and Resnik (2006) for further discussion.\n"},{"#tail":"\n","@confidence":"0.999624944444444","#text":"\nIn this section, we compare the different alignments produced with and without PR\nbased on how well they can be used for transfer of linguistic resources across languages.\nWe used the system proposed by Ganchev, Gillenwater, and Taskar (2009). This system\nuses a word-aligned corpus and a parser for a resource-rich language (source language)\nin order to create a parser for a resource-poor language (target language). We consider\na parse tree on the source language as a set of dependency edges to be transferred. For\neach such edge, if both end points are aligned to words in the target language, then\nthe edge is transferred. These edges are then used as weak supervision when training\na generative or discriminative dependency parser. In order to evaluate the alignments\nwe computed the fraction of correctly transferred edges as a function of the average\nnumber of edges transferred by using supervised parse trees on the target side. By\nchanging the threshold in MBR decoding of alignments, we can trade off accuracy of the\ntransferred edges vs. transferring more edges. We generated supervised parses using\nthe first-order model from the MST parser (McDonald, Crammer, and Pereira 2005)\ntrained on the Penn Treebank for English and the CoNLL X parses for Bulgarian and\nSpanish. Following Ganchev, Gillenwater, and Taskar (2009), we filter alignment links\nbetween words with incompatible POS tags. Figure 10 shows our results for transferring\nfrom English to Bulgarian (En?Bg) and from English to Spanish (En?Es). The En?Bg\n"},{"#tail":"\n","@confidence":"0.955309888888889","#text":"\nComputational Linguistics Volume 36, Number 3\nFigure 10\nEdge conservation for cross-lingual grammar induction. Left: En?Bg subtitle corpus; Right:\nEn?Es parliamentary proceedings. Vertical axis: percentage of transferred edges that are correct.\nHorizontal axis: average number of transferred edges per sentence.\nresults are based on a corpus of movie subtitles (Tiedemann 2007), and are consequently\nshorter sentences, whereas the En?Es results are based on a corpus of parliamentary\nproceedings (Koehn 2005). We see in Figure 10 that for both domains, the models trained\nusing posterior regularization perform better than the baseline model trained using EM.\n"},{"#tail":"\n","@confidence":"0.931282774193548","#text":"\nThe idea of introducing constraints over a model to better guide the learning process\nhas appeared before. In the context of word alignment, Deng and Byrne (2005) use a\nstate-duration HMM in order to model word-to-phrase translations. The fertility of each\nsource word is implicitly encoded in the durations of the HMM states. Without any\nrestrictions, likelihood prefers to always use longer phrases and the authors try to con-\ntrol this behavior by multiplying every transition probability by a constant ? > 1. This\nencourages more transitions and hence shorter phrases. For the task of unsupervised\ndependency parsing, Smith and Eisner (2006) add a constraint of the form ?the average\nlength of dependencies should be X? to capture the locality of syntax (at least half\nof the dependencies are between adjacent words), using a scheme they call structural\nannealing. They modify the model?s distribution over trees p?(y) by a penalty term\nas: p\n?\n?(y) ? p?(y)e\n(?\n?\ne?y length(e)), where length(e) is the surface length of edge e. The\nfactor ? changes from a high value to a lower one so that the preference for short edges\n(hence a smaller sum) is stronger at the start of training.\nThese two approaches also have the goal of controlling unsupervised learning, and\nthe form of the modified distributions is reminiscent of the form that the projected\nposteriors take. However, the approaches differ substantially from PR. Smith and Eisner\n(2006) make a statement of the form ?scale the total length of edges?, which depending\non the value of ? will prefer to have more shorter/longer edges. Such statements are\nnot data dependent. Depending on the value of ?, for instance if ? ? 0, even if the data\nis such that the model already uses too many short edges on average, this value of\n? will push for more short edges. By contrast the statements we can make in PR are\nof the form ?there should be more short edges than long edges?. Such a statement is\ndata-dependent in the sense that if the model satisfies the constraints then we do not\nneed to change it; if it is far from satisfying it we might need to make very dramatic\nchanges.\n"},{"#tail":"\n","@confidence":"0.9971815","#text":"\nGrac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints\nPR is closely related to the work of Mann and McCallum (2007, 2008), who concur-\nrently developed the idea of using penalties based on posterior expectations of features\nto guide semi-supervised learning. They call their method generalized expectation (GE)\nconstraints or alternatively expectation regularization. In the original GE framework,\nthe posteriors of the model on unlabeled data are regularized directly. They train a\ndiscriminative model, using conditional likelihood on labeled data and an ?expectation\nregularization? penalty term on the unlabeled data:\n"},{"#tail":"\n","@confidence":"0.968388333333333","#text":"\n2]. (16)\nNotice that there is no intermediate distribution q. For some kinds of constraints this\nobjective is difficult to optimize in ? and in order to improve efficiency, Bellare, Druck,\nand McCallum (2009) propose interpreting the PR framework as an approximation\nto the GE objective in Equation (16). They compare the two frameworks on several\ndata sets and find that performance is similar. Liang, Jordan, and Klein (2009) cast\nthe problem of incorporating partial information about latent variables into a Bayesian\nframework using ?measurements,? and after several approximation steps, they arrive\nat the objective we optimize.\nThe idea of jointly training two directional models has been explored by Liang,\nTaskar, and Klein (2006), although under a very different formalization. They de-\nfine a joint objective max\n"},{"#tail":"\n","@confidence":"0.953968","#text":"\n. However, the\nproduct distribution ??p ?1 (z  |x)\n??p ?2 (z  |x) ranges over all one-to-one alignments and\ncomputing it is #P-complete (Liang, Taskar, and Klein 2006). They approximate this\ndistribution as a product of marginals: q(z) =\n?\ni,j\n??p ?1 (zi,j  |x)\n??p ?2 (zi,j  |x), but it is not\nclear what objective the approximate procedure actually optimizes.\n"},{"#tail":"\n","@confidence":"0.998902315789474","#text":"\nIn this article we explored a novel learning framework, Posterior Regularization, for\nincorporating rich constraints over the posterior distributions of word alignments. We\nfocused on the HMM word alignment model, and showed how we could incorpo-\nrate complex constraints like bijectivity and symmetry while keeping the inference\nin the model tractable. Using these constraints we showed consistent and significant\nimprovements in six different language pairs even when compared to a more complex\nmodel such as IBM Model 4. In addition to alleviating the ?garbage collector? effect, we\nshow that the obtained posterior distributions better reflect the desired alignments. Both\nconstraints are biasing the models towards 1-to-1 alignments, which may be inappro-\npriate in some situations, and we show some systematic mistakes that the constraints\nintroduce and suggest possible fixes.\nWe experimented with two different tasks that rely on word alignments, phrase-\nbased MT and syntax transfer. For phrase-based MT, the improved alignments lead\nto a modest increase in BLEU performance. For syntax transfer, we have shown that\nthe number of edges of a dependency tree that can be accurately transferred from one\nlanguage to another increases as a result of improved alignments.\nOur framework opens up the possibility of efficiently adding many other con-\nstraints that are directly applicable to word alignments, such as preferring alignments\nthat respect dependency tree structure, part of speech tags, or syntactic boundaries.\n"},{"#tail":"\n","@confidence":"0.7461925","#text":"\nsures that q(z|x) is properly normalized. Plugging ? into L(?, ?, ?) and taking the\nderivative with respect to ?, we get:\n"},{"#tail":"\n","@confidence":"0.98623825","#text":"\nJ. V. Grac?a was supported by a fellowship\nfrom Fundac?a?o para a Cie?ncia e Tecnologia\n(SFRH/ BD/ 27528/ 2006) and by FCT\nproject CMU-PT/HuMach/0039/2008.\nK. Ganchev was partially supported by\nNSF ITR EIA 0205448. Ben Taskar was\npartially supported by DARPA CSSG\n2009 grant.\n"}],"#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.930971","#text":"\nUniversity of Pennsylvania\n"},{"#tail":"\n","@confidence":"0.897422","#text":"\nUniversity of Pennsylvania\n"}],"sectionHeader":[{"#tail":"\n","@confidence":"0.982922","@genericHeader":"abstract","#text":"\n1. Introduction\n"},{"#tail":"\n","@confidence":"0.56979","@genericHeader":"keywords","#text":"\nGPL license.1\n"},{"#tail":"\n","@confidence":"0.983723","@genericHeader":"introduction","#text":"\n2. Background\n"},{"#tail":"\n","@confidence":"0.427835","@genericHeader":"method","#text":"\n2 For both of these points, see the experimental setup in Section 4.1.\n"},{"#tail":"\n","@confidence":"0.910155","@genericHeader":"method","#text":"\n3. Posterior Regularization\n"},{"#tail":"\n","@confidence":"0.750856","@genericHeader":"method","#text":"\n4. Alignment Quality Evaluation\n"},{"#tail":"\n","@confidence":"0.735401","@genericHeader":"method","#text":"\n4 (Och and Ney 2003) and because changing the existing code is not trivial, we could\n"},{"#tail":"\n","@confidence":"0.960242","@genericHeader":"method","#text":"\n5. Task-Specific Alignment Evaluation\n"},{"#tail":"\n","@confidence":"0.997982","@genericHeader":"related work","#text":"\n6. Related Work\n"},{"#tail":"\n","@confidence":"0.756833","@genericHeader":"conclusions","#text":"\n7. Conclusion\n"},{"#tail":"\n","@confidence":"0.846068","@genericHeader":"acknowledgments","#text":"\nAcknowledgments\n"},{"#tail":"\n","@confidence":"0.985653","@genericHeader":"references","#text":"\nReferences\n"}],"tableCaption":[{"#tail":"\n","@confidence":"0.986779","#text":"\nTable 1. The corpora are: the Hansard corpus (Och and Ney 2000) of English/French\n"},{"#tail":"\n","@confidence":"0.48018575","#text":"\nGrac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints\nTable 2\nBLEU scores for all language pairs. The best threshold was selected according to the\ndevelopment set after the last MERT iteration. Bold denotes the best score.\n"}],"page":[{"#tail":"\n","@confidence":"0.998443","#text":"\n482\n"},{"#tail":"\n","@confidence":"0.999562","#text":"\n483\n"},{"#tail":"\n","@confidence":"0.999094","#text":"\n484\n"},{"#tail":"\n","@confidence":"0.99864","#text":"\n485\n"},{"#tail":"\n","@confidence":"0.998868","#text":"\n486\n"},{"#tail":"\n","@confidence":"0.995759","#text":"\n487\n"},{"#tail":"\n","@confidence":"0.995889","#text":"\n488\n"},{"#tail":"\n","@confidence":"0.991706","#text":"\n489\n"},{"#tail":"\n","@confidence":"0.764175","#text":"\n490\n"},{"#tail":"\n","@confidence":"0.983953","#text":"\n491\n"},{"#tail":"\n","@confidence":"0.992667","#text":"\n492\n"},{"#tail":"\n","@confidence":"0.994858","#text":"\n493\n"},{"#tail":"\n","@confidence":"0.999659","#text":"\n494\n"},{"#tail":"\n","@confidence":"0.997127","#text":"\n495\n"},{"#tail":"\n","@confidence":"0.99773","#text":"\n496\n"},{"#tail":"\n","@confidence":"0.995752","#text":"\n497\n"},{"#tail":"\n","@confidence":"0.997334","#text":"\n498\n"},{"#tail":"\n","@confidence":"0.995996","#text":"\n499\n"},{"#tail":"\n","@confidence":"0.919875","#text":"\n500\n"},{"#tail":"\n","@confidence":"0.644706","#text":"\n2\n"},{"#tail":"\n","@confidence":"0.568544","#text":"\n?1,?2\n"},{"#tail":"\n","@confidence":"0.985749","#text":"\n501\n"},{"#tail":"\n","@confidence":"0.974293","#text":"\n502\n"},{"#tail":"\n","@confidence":"0.960144","#text":"\n503\n"},{"#tail":"\n","@confidence":"0.999259","#text":"\n504\n"}],"keyword":{"#tail":"\n","@confidence":"0.445773","#text":"\nGrac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints\n"},"figureCaption":{"#tail":"\n","@confidence":"0.611031","#text":"\nComputational Linguistics Volume 36, Number 3\nFigure 7\nPrecision and Recall as a function of training data size for En-Fr by common and rare words.\nTop Left: Common Precision, Top Right: Rare Precision, Bottom: Rare Recall.\n"},"table":[{"#tail":"\n","@confidence":"0.775787363636363","#text":"\nComputational Linguistics Volume 36, Number 3\nTable 1\nTest corpora statistics: English?French, English?Spanish, English?Portuguese,\nPortuguese?Spanish, Portuguese?French, and Spanish?French.\nCorpus Sentence Pairs Ave Length Max Length % Sure % 1-1\nEn/Fr 447 16/17 30/30 21 98\nEn/Es 400 29/31 90/99 67 86\nEn/Pt 60 11/11 20/20 54 91\nPt/Es 60 11/11 20/20 69 92\nPt/Fr 60 11/12 20/20 77 88\nEs/Fr 60 11/12 20/20 79 87\n"},{"#tail":"\n","@confidence":"0.57811375","#text":"\nCanadian Parliamentary proceedings (En-Fr), and the English/Spanish portion of the\nEuroparl corpus (Koehn 2005) where the annotation is from EPPS (Lambert et al 2005)\n(En-Es) using standard test and development set split. We also used the English/\nPortuguese (En-Pt), Portuguese/Spanish (Pt-Es), Portuguese/French (Pt-Fr), and\n"},{"#tail":"\n","@confidence":"0.874235333333333","#text":"\nComputational Linguistics Volume 36, Number 3\nFigure 5\nWord alignment precision when the threshold is chosen to achieve IBM Model 4 recall with a\ndifference of ? 0.005. The average relative increase in precision (against the HMM model) is\n10% for IBM Model 4, 11% for B-HMM, and 14% for S-HMM.\nMOSES training script.3 This performs five iterations of IBM Model 1, five iterations of\n"},{"#tail":"\n","@confidence":"0.9895978","#text":"\nFr ? En En ? Fr Es ? En En ? Es Pt ? En En ? Pt\nIBM M4 GDF 35.7 31.2 32.4 31.6 31.4 28.9\nHMM SU 35.9 28.9 32.3 31.6 30.9 31.6\nB-HMM SU 36.0 31.5 32.6 31.7 31.0 32.2\nS-HMM SU 35.5 31.2 31.9 32.5 31.4 32.3\n"},{"#tail":"\n","@confidence":"0.593588181818182","#text":"\nComputational Linguistics Volume 36, Number 3\nAppendix A: Modified E-Step Dual Derivation\nThe modified E step involves a projection step that minimizes the Kullback-Leibler\ndivergence:\nE? : arg min\nq(z|x),?\nKL( q(z|x) ? p?(z|x)) s.t. Eq[f(x, z)] ? bx ? ?; ||?||22 ? 2.\nAssuming the set Qx = { q(z|x) : ??, Eq[f(x, z)] ? bx ? ?; ||?||22 ? 2} is non-empty, the\ncorresponding Lagrangian is max\n?,?,?\nmin\n"}]}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.322651","#tail":"\n","@no":"0","#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.996644","#text":"University of Pennsylvania"},{"#tail":"\n","@confidence":"0.99691","#text":"University of Pennsylvania"}],"author":[{"#tail":"\n","@confidence":"0.998673","#text":"Joao V Graca"},{"#tail":"\n","@confidence":"0.739962","#text":"Kuzman Ganchev"},{"#tail":"\n","@confidence":"0.956684","#text":"Ben Taskar"}],"abstract":{"#tail":"\n","@confidence":"0.997338416666667","#text":"Word-level alignment of bilingual text is a critical resource for a growing variety of tasks. Probabilistic models for word alignment present a fundamental trade-off between richness of captured constraints and correlations versus efficiency and tractability of inference. In this article, we use the Posterior Regularization framework (Grac?a, Ganchev, and Taskar 2007) to incorporate complex constraints into probabilistic models during learning without changing the efficiency of the underlying model. We focus on the simple and tractable hidden Markov model, and present an efficient learning algorithm for incorporating approximate bijectivity and symmetry constraints. Models estimated with these constraints produce a significant boost in performance as measured by both precision and recall of manually annotated alignments for six language pairs. We also report experiments on two different tasks where word alignments are required: phrase-based machine translation and syntax transfer, and show promising improvements over standard methods."},"title":{"#tail":"\n","@confidence":"0.9996385","#text":"Learning Tractable Word Alignment Models with Complex Constraints"},"email":{"#tail":"\n","@confidence":"0.39696","#text":"L2FINESC-ID"}}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"Bannard, Colin and Chris Callison-Burch. 2005. Paraphrasing with bilingual parallel corpora. In ACL ?05: Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 597?604, Morristown, NJ."},"#text":"\n","pages":{"#tail":"\n","#text":"597--604"},"marker":{"#tail":"\n","#text":"Bannard, Callison-Burch, 2005"},"location":{"#tail":"\n","#text":"Morristown, NJ."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"formation Science, 3330 Walnut Street, Philadelphia, PA 19104-6389. E-mail: taskar@cis.upenn.edu. Submission received: 1 August 2009; revised submission received: 24 December 2009; accepted for publication: 10 March 2010. ? 2010 Association for Computational Linguistics Computational Linguistics Volume 36, Number 3 MT system combination (Matusov, Ueffing, and Ney 2006). But their importance has grown far beyond machine translation: for instance, transferring annotations between languages (Yarowsky and Ngai 2001; Hwa et al 2005; Ganchev, Gillenwater, and Taskar 2009); discovery of paraphrases (Bannard and Callison-Burch 2005); and joint unsupervised POS and parser induction across languages (Snyder and Barzilay 2008). IBM Models 1 and 2 and the HMM are simple and tractable probabilistic models, which produce the target sentence one target word at a time by choosing a source word and generating its translation. IBM Models 3, 4, and 5 attempt to capture fertility (the tendency of each source word to generate several target words), resulting in probabilistically deficient, intractable models that require local heuristic search and are difficult to implement and extend. Many researchers use the GIZA++ software package","@endWordPosition":"398","@position":"2897","annotationId":"T1","@startWordPosition":"395","@citStr":"Bannard and Callison-Burch 2005"}},"title":{"#tail":"\n","#text":"Paraphrasing with bilingual parallel corpora."},"booktitle":{"#tail":"\n","#text":"In ACL ?05: Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Colin Bannard"},{"#tail":"\n","#text":"Chris Callison-Burch"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2009"},"rawString":{"#tail":"\n","#text":"Bellare, Kedar, Gregory Druck, and Andrew McCallum. 2009. Alternating projections Grac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints for learning with expectation constraints. In Proceedings of the Twenty-Fifth Conference Annual Conference on Uncertainty in Artificial Intelligence, pages 43?50, Corvallis, OR."},"#text":"\n","pages":{"#tail":"\n","#text":"43--50"},"marker":{"#tail":"\n","#text":"Bellare, Druck, McCallum, 2009"},"location":{"#tail":"\n","#text":"Corvallis, OR."},"title":{"#tail":"\n","#text":"Alternating projections Grac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints for learning with expectation constraints."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Twenty-Fifth Conference Annual Conference on Uncertainty in Artificial Intelligence,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kedar Bellare"},{"#tail":"\n","#text":"Gregory Druck"},{"#tail":"\n","#text":"Andrew McCallum"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"Bertsekas, Dimitri P. 1999. Nonlinear Programming: 2nd Edition. Athena Scientific, Nashua, NH. Brown, Peter F., Stephen A. Della Pietra, Vincent J. Della Pietra, Meredith J."},"#text":"\n","marker":{"#tail":"\n","#text":"Bertsekas, 1999"},"location":{"#tail":"\n","#text":"Nashua, NH."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"urrent setting of ?. ?i ? 0;1 while ||?(?)||2 > ? do2 ??(x, zc) ? ?(x, zc) exp?? f(x,zc );3 q(z | x) ? forwardBackward(??(x, zc));4 ? ? ? + ???(?);5 end6 Algorithm 1: Computing KL(Qx ? p?(z|x)) = min q?Qx KL(q(z|x) ? p?(z|x)) 489 Computational Linguistics Volume 36, Number 3 We optimize the dual objective using the gradient based methods shown in Algorithm 1. Here ? is an optimization precision, ? is a step size chosen with the strong Wolfe?s rule (Nocedal and Wright 1999). Here, ??(?) represents an ascent direction chosen as follows: For inequality constraints, it is the projected gradient (Bertsekas 1999); for equality constraints with slack, we use conjugate gradient (Nocedal and Wright 1999), noting that when ? = 0, the objective is not differentiable. In practice this only happens at the start of optimization and we use a sub-gradient for the first direction. Computing the projection requires an algorithm for inference in the original model, and uses that inference as a subroutine. For HMM word alignments, we need to make several calls to forward?backward in order to choose ?. Setting the optimization precision ? more loosely allows the optimization to terminate more quickly but at a less a","@endWordPosition":"4240","@position":"26555","annotationId":"T2","@startWordPosition":"4239","@citStr":"Bertsekas 1999"}},"title":{"#tail":"\n","#text":"Nonlinear Programming: 2nd Edition. Athena Scientific,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Dimitri P Bertsekas"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"Goldsmith, Jan Hajic, Robert L. Mercer, and Surya Mohanty. 1993a. But dictionaries are data too. In HLT ?93: Proceedings of the Workshop on Human Language Technology, pages 202?205, Morristown, NJ. Brown, Peter F., Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L."},"#text":"\n","pages":{"#tail":"\n","#text":"202--205"},"marker":{"#tail":"\n","#text":"Goldsmith, Mercer, Mohanty, 1993"},"location":{"#tail":"\n","#text":"Morristown, NJ."},"title":{"#tail":"\n","#text":"But dictionaries are data too."},"booktitle":{"#tail":"\n","#text":"In HLT ?93: Proceedings of the Workshop on Human Language Technology,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Jan Hajic Goldsmith"},{"#tail":"\n","#text":"Robert L Mercer"},{"#tail":"\n","#text":"Surya Mohanty"}]}},{"volume":{"#tail":"\n","#text":"19"},"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"Mercer. 1993b. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263?311."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"2"},"marker":{"#tail":"\n","#text":"Mercer, 1993"},"title":{"#tail":"\n","#text":"The mathematics of statistical machine translation: Parameter estimation."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Mercer"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"Chiang, David, Adam Lopez, Nitin Madnani, Christof Monz, Philip Resnik, and Michael Subotin. 2005. The Hiero machine translation system: Extensions, evaluation, and analysis. In Proceedings of the Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 779?786, Vancouver."},"#text":"\n","pages":{"#tail":"\n","#text":"779--786"},"marker":{"#tail":"\n","#text":"Chiang, Lopez, Madnani, Monz, Resnik, Subotin, 2005"},"location":{"#tail":"\n","#text":"Vancouver."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" et al (1993b) introduced a series of probabilistic models (IBM Models 1?5) for statistical machine translation and the concept of ?word-byword? alignment, the correspondence between words in source and target languages. Although no longer competitive as end-to-end translation models, the IBM Models, as well as the hidden Markov model (HMM) of Vogel, Ney, and Tillmann (1996), are still widely used for word alignment. Word alignments are used primarily for extracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn, Och, and Marcu 2003] and rules [Galley et al 2004; Chiang et al 2005]) as well as for ? INESC-ID Lisboa, Spoken Language Systems Lab, R. Alves Redol 9, 1000-029 LISBOA, Portugal. E-mail: joao.graca@l2f.inesc-id.pt. ?? University of Pennsylvania, Department of Computer and Information Science, Levine Hall, 3330 Walnut Street, Philadelphia, PA 19104-6309. E-mail: kuzman@cis.upenn.edu. ? University of Pennsylvania, Department of Computer and Information Science, 3330 Walnut Street, Philadelphia, PA 19104-6389. E-mail: taskar@cis.upenn.edu. Submission received: 1 August 2009; revised submission received: 24 December 2009; accepted for publication: 10 March 2010. ?","@endWordPosition":"268","@position":"1888","annotationId":"T3","@startWordPosition":"265","@citStr":"Chiang et al 2005"}},"title":{"#tail":"\n","#text":"The Hiero machine translation system: Extensions, evaluation, and analysis."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"David Chiang"},{"#tail":"\n","#text":"Adam Lopez"},{"#tail":"\n","#text":"Nitin Madnani"},{"#tail":"\n","#text":"Christof Monz"},{"#tail":"\n","#text":"Philip Resnik"},{"#tail":"\n","#text":"Michael Subotin"}]}},{"volume":{"#tail":"\n","#text":"39"},"#tail":"\n","date":{"#tail":"\n","#text":"1977"},"rawString":{"#tail":"\n","#text":"Dempster, Arthur P., Nan M. Laird, and Donald B. Rubin. 1977. Maximum likelihood from incomplete data via the em algorithm. Royal Statistical Society, Series B, 39(1):1?38."},"journal":{"#tail":"\n","#text":"Royal Statistical Society, Series B,"},"#text":"\n","issue":{"#tail":"\n","#text":"1"},"marker":{"#tail":"\n","#text":"Dempster, Laird, Rubin, 1977"},"title":{"#tail":"\n","#text":"Maximum likelihood from incomplete data via the em algorithm."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Arthur P Dempster"},{"#tail":"\n","#text":"Nan M Laird"},{"#tail":"\n","#text":"Donald B Rubin"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"DeNero, John and Dan Klein. 2007. Tailoring word alignments to syntactic machine translation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 17?24, Prague."},"#text":"\n","pages":{"#tail":"\n","#text":"17--24"},"marker":{"#tail":"\n","#text":"DeNero, Klein, 2007"},"location":{"#tail":"\n","#text":"Prague."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" will help and when they will hinder system performance. In this work we followed a more principled approach that uses Figure 8 Precision/recall curves for the different models after soft union symmetrization. Precision is on the horizontal axis. Left EN-FR, Right PT-ES. 496 Grac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints the knowledge about the posterior distributions of each directional model. We include a point in the final alignment if the average of the posteriors under the two models for that point is above a threshold. This heuristic is called soft union (DeNero and Klein 2007). Figure 8 shows the Precision/Recall curves after symmetrization for the En-Fr corpus. The posterior regularization?trained models still performed better, but the differences get smaller after doing the symmetrization. This should not be very surprising, because the soft union symmetrization can be viewed as an approximation of our symmetry constraint applied only at decode time. Applying the symmetrization to the model with symmetry constraints does not affect performance. 4.5 Analysis In this section we discuss some scenarios in which the constraints make the alignments better, and some sce","@endWordPosition":"7102","@position":"43730","annotationId":"T4","@startWordPosition":"7099","@citStr":"DeNero and Klein 2007"}},"title":{"#tail":"\n","#text":"Tailoring word alignments to syntactic machine translation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"John DeNero"},{"#tail":"\n","#text":"Dan Klein"}]}},{"date":{"#tail":"\n","#text":"2005"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"red edges that are correct. Horizontal axis: average number of transferred edges per sentence. results are based on a corpus of movie subtitles (Tiedemann 2007), and are consequently shorter sentences, whereas the En?Es results are based on a corpus of parliamentary proceedings (Koehn 2005). We see in Figure 10 that for both domains, the models trained using posterior regularization perform better than the baseline model trained using EM. 6. Related Work The idea of introducing constraints over a model to better guide the learning process has appeared before. In the context of word alignment, Deng and Byrne (2005) use a state-duration HMM in order to model word-to-phrase translations. The fertility of each source word is implicitly encoded in the durations of the HMM states. Without any restrictions, likelihood prefers to always use longer phrases and the authors try to control this behavior by multiplying every transition probability by a constant ? > 1. This encourages more transitions and hence shorter phrases. For the task of unsupervised dependency parsing, Smith and Eisner (2006) add a constraint of the form ?the average length of dependencies should be X? to capture the locality of syntax (at le","@endWordPosition":"8586","@position":"53165","annotationId":"T5","@startWordPosition":"8583","@citStr":"Deng and Byrne (2005)"}},"title":{"#tail":"\n","#text":"HMM word and phrase alignment for statistical machine translation."},"#tail":"\n","institution":{"#tail":"\n","#text":"for Computational Linguistics."},"rawString":{"#tail":"\n","#text":"Deng, Yonggang and William Byrne. 2005. HMM word and phrase alignment for statistical machine translation. In HLT ?05: Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 169?176, Morristown, NJ. Association for Computational Linguistics."},"#text":"\n","pages":{"#tail":"\n","#text":"169--176"},"marker":{"#tail":"\n","#text":"Deng, Byrne, 2005"},"publisher":{"#tail":"\n","#text":"Association"},"location":{"#tail":"\n","#text":"Morristown, NJ."},"booktitle":{"#tail":"\n","#text":"In HLT ?05: Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Yonggang Deng"},{"#tail":"\n","#text":"William Byrne"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Fraser, Alexander and Daniel Marcu. 2007. Getting the structure right for word alignment: Leaf. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 51?60, Prague."},"#text":"\n","pages":{"#tail":"\n","#text":"51--60"},"marker":{"#tail":"\n","#text":"Fraser, Marcu, 2007"},"location":{"#tail":"\n","#text":"Prague."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ent thresholds (0..1). Second, with this method we can ignore the null word probabilities, which tend to be poorly estimated. 3. Posterior Regularization Word alignment models in general and the HMM in particular are very gross oversimplifications of the translation process and the optimal likelihood parameters learned often do not correspond to sensible alignments. One solution to this problem is to add more complexity to the model to better reflect the translation process. This is the approach taken by IBM Models 4+ (Brown et al 1993b; Och and Ney 2003), and more recently by the LEAF model (Fraser and Marcu 2007). Unfortunately, these changes make the models probabilistically deficient and intractable, requiring approximations and heuristic learning and inference prone to search errors. Instead, we propose to use a learning framework called Posterior Regularization (Grac?a, Ganchev, and Taskar 2007) that incorporates side information into unsupervised estimation in the form of constraints on the model?s posteriors. The constraints are expressed as inequalities on the expected values under the posterior distribution of user-defined constraint features (not necessarily the same features used by the mode","@endWordPosition":"2991","@position":"19002","annotationId":"T6","@startWordPosition":"2988","@citStr":"Fraser and Marcu 2007"}},"title":{"#tail":"\n","#text":"Getting the structure right for word alignment: Leaf."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Alexander Fraser"},{"#tail":"\n","#text":"Daniel Marcu"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Galley, Michel, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What?s in a translation rule? In HLT-NAACL 2004: Main Proceedings, pages 273?280, Boston, MA."},"#text":"\n","pages":{"#tail":"\n","#text":"273--280"},"marker":{"#tail":"\n","#text":"Galley, Hopkins, Knight, Marcu, 2004"},"location":{"#tail":"\n","#text":"Boston, MA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"minal work of Brown et al (1993b) introduced a series of probabilistic models (IBM Models 1?5) for statistical machine translation and the concept of ?word-byword? alignment, the correspondence between words in source and target languages. Although no longer competitive as end-to-end translation models, the IBM Models, as well as the hidden Markov model (HMM) of Vogel, Ney, and Tillmann (1996), are still widely used for word alignment. Word alignments are used primarily for extracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn, Och, and Marcu 2003] and rules [Galley et al 2004; Chiang et al 2005]) as well as for ? INESC-ID Lisboa, Spoken Language Systems Lab, R. Alves Redol 9, 1000-029 LISBOA, Portugal. E-mail: joao.graca@l2f.inesc-id.pt. ?? University of Pennsylvania, Department of Computer and Information Science, Levine Hall, 3330 Walnut Street, Philadelphia, PA 19104-6309. E-mail: kuzman@cis.upenn.edu. ? University of Pennsylvania, Department of Computer and Information Science, 3330 Walnut Street, Philadelphia, PA 19104-6389. E-mail: taskar@cis.upenn.edu. Submission received: 1 August 2009; revised submission received: 24 December 2009; accepted for publicatio","@endWordPosition":"264","@position":"1869","annotationId":"T7","@startWordPosition":"261","@citStr":"Galley et al 2004"}},"title":{"#tail":"\n","#text":"What?s in a translation rule?"},"booktitle":{"#tail":"\n","#text":"In HLT-NAACL 2004: Main Proceedings,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Michel Galley"},{"#tail":"\n","#text":"Mark Hopkins"},{"#tail":"\n","#text":"Kevin Knight"},{"#tail":"\n","#text":"Daniel Marcu"}]}},{"volume":{"#tail":"\n","#text":"1"},"#tail":"\n","date":{"#tail":"\n","#text":"2009"},"rawString":{"#tail":"\n","#text":"Ganchev, Kuzman, Jennifer Gillenwater, and Ben Taskar. 2009. Dependency grammar induction via bitext projection constraints. In ACL-IJCNLP ?09: Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1, pages 369?377, Morristown, NJ."},"#text":"\n","pages":{"#tail":"\n","#text":"369--377"},"marker":{"#tail":"\n","#text":"Ganchev, Gillenwater, Taskar, 2009"},"location":{"#tail":"\n","#text":"Morristown, NJ."},"title":{"#tail":"\n","#text":"Dependency grammar induction via bitext projection constraints."},"booktitle":{"#tail":"\n","#text":"In ACL-IJCNLP ?09: Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP:"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kuzman Ganchev"},{"#tail":"\n","#text":"Jennifer Gillenwater"},{"#tail":"\n","#text":"Ben Taskar"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2008"},"rawString":{"#tail":"\n","#text":"Ganchev, Kuzman, Joa?o V. Grac?a, and Ben Taskar. 2008. Better alignments = better translations? In Proceedings of ACL-08: HLT, pages 986?993, Columbus, OH."},"#text":"\n","pages":{"#tail":"\n","#text":"986--993"},"marker":{"#tail":"\n","#text":"Ganchev, Graca, Taskar, 2008"},"location":{"#tail":"\n","#text":"Columbus, OH."},"title":{"#tail":"\n","#text":"Better alignments = better translations?"},"booktitle":{"#tail":"\n","#text":"In Proceedings of ACL-08: HLT,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kuzman Ganchev"},{"#tail":"\n","#text":"Joao V Graca"},{"#tail":"\n","#text":"Ben Taskar"}]}},{"date":{"#tail":"\n","#text":"2007"},"editor":{"#tail":"\n","#text":"J. C. Platt, D. Koller, Y. Singer, and S. Roweis, editors,"},"title":{"#tail":"\n","#text":"Expectation maximization and posterior constraints. In"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Grac?a, Joa?o V., Kuzman Ganchev, and Ben Taskar. 2007. Expectation maximization and posterior constraints. In J. C. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems 20. MIT Press, Cambridge, MA, pages 569?576."},"#text":"\n","pages":{"#tail":"\n","#text":"569--576"},"marker":{"#tail":"\n","#text":"Graca, Ganchev, Taskar, 2007"},"publisher":{"#tail":"\n","#text":"MIT Press,"},"location":{"#tail":"\n","#text":"Cambridge, MA,"},"booktitle":{"#tail":"\n","#text":"Advances in Neural Information Processing Systems 20."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Joao V Graca"},{"#tail":"\n","#text":"Kuzman Ganchev"},{"#tail":"\n","#text":"Ben Taskar"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2009"},"rawString":{"#tail":"\n","#text":"Grac?a, Joa?o V., Kuzman Ganchev, and Ben Taskar. 2009. Postcat - posterior constrained alignment toolkit. The Prague Bulletin Of Mathematical Linguistics - Special Issue: Open Source Tools for Machine Translation, 91:27?37."},"#text":"\n","pages":{"#tail":"\n","#text":"91--27"},"marker":{"#tail":"\n","#text":"Graca, Ganchev, Taskar, 2009"},"title":{"#tail":"\n","#text":"Postcat - posterior constrained alignment toolkit. The Prague Bulletin Of Mathematical Linguistics - Special Issue: Open Source Tools for Machine Translation,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Joao V Graca"},{"#tail":"\n","#text":"Kuzman Ganchev"},{"#tail":"\n","#text":"Ben Taskar"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2008"},"rawString":{"#tail":"\n","#text":"Grac?a, Joa?o V., Joana P. Pardal, Lu??sa Coheur, and Diamantino Caseiro. 2008. Building a golden collection of parallel multi-language word alignment. In Proceedings of the Sixth International Language Resources and Evaluation (LREC?08), Marrakech."},"#text":"\n","marker":{"#tail":"\n","#text":"Graca, Pardal, Coheur, Caseiro, 2008"},"location":{"#tail":"\n","#text":"Marrakech."},"title":{"#tail":"\n","#text":"Building a golden collection of parallel multi-language word alignment."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Sixth International Language Resources and Evaluation (LREC?08),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Joao V Graca"},{"#tail":"\n","#text":"Joana P Pardal"},{"#tail":"\n","#text":"Lusa Coheur"},{"#tail":"\n","#text":"Diamantino Caseiro"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Hoang, Hieu, Alexandra Birch, Chris Callison-Burch, Richard Zens, Rwth Aachen, Alexandra Constantin, Marcello Federico, Nicola Bertoldi, Chris Dyer, Brooke Cowan, Wade Shen, Christine Moran, and Ondrej Bojar. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177?180, Prague."},"#text":"\n","pages":{"#tail":"\n","#text":"177--180"},"marker":{"#tail":"\n","#text":"Hoang, Birch, Callison-Burch, Zens, Aachen, Constantin, Federico, Bertoldi, Dyer, Cowan, Shen, Moran, Bojar, 2007"},"location":{"#tail":"\n","#text":"Prague."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" word alignments; (5) build phrase table; (6) tune weights for the phrase table. For more details consult the shared task description.6 To evaluate the quality of the produced alignments, we keep the pipeline unchanged, and use the models described earlier to generate the word alignments in Step 3. For Step 4, we use the soft union symmetrization heuristic. Symmetrization has almost no effect on alignments produced by S-HMM, but we use it for uniformity in the experiments. We tested three values of the threshold (0.2, 0.4, 0.6) which try to capture different tradeoffs 5 The open source Moses (Hoang et al 2007) toolkit from www.statmt.org/moses/. 6 www.statmt.org/wmt08/baseline.html. 498 Grac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints Table 2 BLEU scores for all language pairs. The best threshold was selected according to the development set after the last MERT iteration. Bold denotes the best score. Fr ? En En ? Fr Es ? En En ? Es Pt ? En En ? Pt IBM M4 GDF 35.7 31.2 32.4 31.6 31.4 28.9 HMM SU 35.9 28.9 32.3 31.6 30.9 31.6 B-HMM SU 36.0 31.5 32.6 31.7 31.0 32.2 S-HMM SU 35.5 31.2 31.9 32.5 31.4 32.3 of precision vs. recall, and pick the best according to the translati","@endWordPosition":"7899","@position":"48900","annotationId":"T8","@startWordPosition":"7896","@citStr":"Hoang et al 2007"}},"title":{"#tail":"\n","#text":"Moses: Open source toolkit for statistical machine translation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,"},"@valid":"false","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Hieu Hoang"},{"#tail":"\n","#text":"Alexandra Birch"},{"#tail":"\n","#text":"Chris Callison-Burch"},{"#tail":"\n","#text":"Richard Zens"},{"#tail":"\n","#text":"Rwth Aachen"},{"#tail":"\n","#text":"Alexandra Constantin"},{"#tail":"\n","#text":"Marcello Federico"},{"#tail":"\n","#text":"Nicola Bertoldi"},{"#tail":"\n","#text":"Chris Dyer"},{"#tail":"\n","#text":"Brooke Cowan"},{"#tail":"\n","#text":"Wade Shen"},{"#tail":"\n","#text":"Christine Moran"},{"#tail":"\n","#text":"Ondrej Bojar"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"Hwa, Rebecca, Philip Resnik, Amy Weinberg, Clara Cabezas, and Okan Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Natural Language Engineering, 11:11?311."},"#text":"\n","pages":{"#tail":"\n","#text":"11--11"},"marker":{"#tail":"\n","#text":"Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" kuzman@cis.upenn.edu. ? University of Pennsylvania, Department of Computer and Information Science, 3330 Walnut Street, Philadelphia, PA 19104-6389. E-mail: taskar@cis.upenn.edu. Submission received: 1 August 2009; revised submission received: 24 December 2009; accepted for publication: 10 March 2010. ? 2010 Association for Computational Linguistics Computational Linguistics Volume 36, Number 3 MT system combination (Matusov, Ueffing, and Ney 2006). But their importance has grown far beyond machine translation: for instance, transferring annotations between languages (Yarowsky and Ngai 2001; Hwa et al 2005; Ganchev, Gillenwater, and Taskar 2009); discovery of paraphrases (Bannard and Callison-Burch 2005); and joint unsupervised POS and parser induction across languages (Snyder and Barzilay 2008). IBM Models 1 and 2 and the HMM are simple and tractable probabilistic models, which produce the target sentence one target word at a time by choosing a source word and generating its translation. IBM Models 3, 4, and 5 attempt to capture fertility (the tendency of each source word to generate several target words), resulting in probabilistically deficient, intractable models that require local heuristi","@endWordPosition":"386","@position":"2797","annotationId":"T9","@startWordPosition":"383","@citStr":"Hwa et al 2005"}},"title":{"#tail":"\n","#text":"Bootstrapping parsers via syntactic projection across parallel texts. Natural Language Engineering,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Rebecca Hwa"},{"#tail":"\n","#text":"Philip Resnik"},{"#tail":"\n","#text":"Amy Weinberg"},{"#tail":"\n","#text":"Clara Cabezas"},{"#tail":"\n","#text":"Okan Kolak"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"Koehn, Philipp. 2005. Europarl: A parallel corpus for statistical machine translation. In Machine Translation Summit, 12?15 September, Phuket."},"#text":"\n","marker":{"#tail":"\n","#text":"Koehn, 2005"},"location":{"#tail":"\n","#text":"Phuket."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ength Max Length % Sure % 1-1 En/Fr 447 16/17 30/30 21 98 En/Es 400 29/31 90/99 67 86 En/Pt 60 11/11 20/20 54 91 Pt/Es 60 11/11 20/20 69 92 Pt/Fr 60 11/12 20/20 77 88 Es/Fr 60 11/12 20/20 79 87 are represented as squares without borders. Circles indicate the posterior probability associated with a given link and will be explained latter. We use six manually annotated corpora whose characteristics are summarized in Table 1. The corpora are: the Hansard corpus (Och and Ney 2000) of English/French Canadian Parliamentary proceedings (En-Fr), and the English/Spanish portion of the Europarl corpus (Koehn 2005) where the annotation is from EPPS (Lambert et al 2005) (En-Es) using standard test and development set split. We also used the English/ Portuguese (En-Pt), Portuguese/Spanish (Pt-Es), Portuguese/French (Pt-Fr), and Spanish/French (Es-Fr) portions of the Europarl corpus using annotations described by Grac?a et al (2008), where we split the gold alignments into a dev/test set in a ratio of 40%/60%. Table 1 shows some of the variety of challenges presented by each corpus. For example, En-Es has longer sentences and hence more ambiguity for alignment. Furthermore, it has a smaller percentage of b","@endWordPosition":"1372","@position":"9438","annotationId":"T10","@startWordPosition":"1371","@citStr":"Koehn 2005"},{"#tail":"\n","#text":" for transferring from English to Bulgarian (En?Bg) and from English to Spanish (En?Es). The En?Bg 499 Computational Linguistics Volume 36, Number 3 Figure 10 Edge conservation for cross-lingual grammar induction. Left: En?Bg subtitle corpus; Right: En?Es parliamentary proceedings. Vertical axis: percentage of transferred edges that are correct. Horizontal axis: average number of transferred edges per sentence. results are based on a corpus of movie subtitles (Tiedemann 2007), and are consequently shorter sentences, whereas the En?Es results are based on a corpus of parliamentary proceedings (Koehn 2005). We see in Figure 10 that for both domains, the models trained using posterior regularization perform better than the baseline model trained using EM. 6. Related Work The idea of introducing constraints over a model to better guide the learning process has appeared before. In the context of word alignment, Deng and Byrne (2005) use a state-duration HMM in order to model word-to-phrase translations. The fertility of each source word is implicitly encoded in the durations of the HMM states. Without any restrictions, likelihood prefers to always use longer phrases and the authors try to control ","@endWordPosition":"8532","@position":"52835","annotationId":"T11","@startWordPosition":"8531","@citStr":"Koehn 2005"}]},"title":{"#tail":"\n","#text":"Europarl: A parallel corpus for statistical machine translation."},"booktitle":{"#tail":"\n","#text":"In Machine Translation Summit, 12?15 September,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Philipp Koehn"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Koehn, Philipp, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based Computational Linguistics Volume 36, Number 3 translation. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (NAACL), pages 48?54, Morristown, NJ."},"#text":"\n","pages":{"#tail":"\n","#text":"48--54"},"marker":{"#tail":"\n","#text":"Koehn, Och, Marcu, 2003"},"location":{"#tail":"\n","#text":"Morristown, NJ."},"title":{"#tail":"\n","#text":"Statistical phrase-based Computational Linguistics Volume 36, Number 3 translation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (NAACL),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Philipp Koehn"},{"#tail":"\n","#text":"Franz Josef Och"},{"#tail":"\n","#text":"Daniel Marcu"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Kumar, Shankar and William Byrne. 2002. Minimum Bayes-Risk word alignments of bilingual texts. In Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing, pages 140?147, Philadelphia, PA."},"#text":"\n","pages":{"#tail":"\n","#text":"140--147"},"marker":{"#tail":"\n","#text":"Kumar, Byrne, 2002"},"location":{"#tail":"\n","#text":"Philadelphia, PA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" sentences it needs to spread its probability mass over fewer competing translations. In this case, choosing to align the rare word to all of these words leads to a higher likelihood than correctly linking them or linking them to the special null word, because it increases the likelihood of this sentence without lowering the likelihood of many other sentences. 2.3 Decoding Alignments are normally predicted using the Viterbi algorithm (which selects the single most probable path through the HMM?s lattice). Another possibility that often works better is to use Minimum Bayes-Risk (MBR) decoding (Kumar and Byrne 2002; Liang, Taskar, and Klein 2006; Grac?a, Ganchev, and Taskar 2007). Using this decoding we include an alignment link i ? j if the posterior probability that word i aligns to word j is above some threshold. This allows the accumulation of probability from several low-scoring alignments that agree on one alignment link. The threshold is tuned on some small amount of labeled data?in our case the development set?to minimize some loss. Kumar and Byrne (2002) study different loss functions that incorporate linguistic knowledge, and show significant 486 Grac?a, Ganchev, and Taskar Learning Alignment ","@endWordPosition":"2700","@position":"17143","annotationId":"T12","@startWordPosition":"2697","@citStr":"Kumar and Byrne 2002"}},"title":{"#tail":"\n","#text":"Minimum Bayes-Risk word alignments of bilingual texts."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Shankar Kumar"},{"#tail":"\n","#text":"William Byrne"}]}},{"volume":{"#tail":"\n","#text":"39"},"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"Lambert, Patrik, Adria` De Gispert, Rafael Banchs, and Jose? B. Marino. 2005. Guidelines for word alignment evaluation and manual alignment. Language Resources and Evaluation, 39(4):267?285."},"journal":{"#tail":"\n","#text":"Language Resources and Evaluation,"},"#text":"\n","issue":{"#tail":"\n","#text":"4"},"marker":{"#tail":"\n","#text":"Lambert, De Gispert, Banchs, Marino, 2005"},"title":{"#tail":"\n","#text":"Guidelines for word alignment evaluation and manual alignment."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Patrik Lambert"},{"#tail":"\n","#text":"Adria` De Gispert"},{"#tail":"\n","#text":"Rafael Banchs"},{"#tail":"\n","#text":"Jose B Marino"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2009"},"rawString":{"#tail":"\n","#text":"Liang, Percy, Michael I. Jordan, and Dan Klein. 2009. Learning from measurements in exponential families. In ICML ?09: Proceedings of the 26th Annual International Conference on Machine Learning, pages 641?648, New York, NY."},"#text":"\n","pages":{"#tail":"\n","#text":"641--648"},"marker":{"#tail":"\n","#text":"Liang, Jordan, Klein, 2009"},"location":{"#tail":"\n","#text":"New York, NY."},"title":{"#tail":"\n","#text":"Learning from measurements in exponential families."},"booktitle":{"#tail":"\n","#text":"In ICML ?09: Proceedings of the 26th Annual International Conference on Machine Learning,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Percy Liang"},{"#tail":"\n","#text":"Michael I Jordan"},{"#tail":"\n","#text":"Dan Klein"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Liang, Percy, Ben Taskar, and Dan Klein. 2006. Alignment by agreement. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 104?111, New York, NY."},"#text":"\n","pages":{"#tail":"\n","#text":"104--111"},"marker":{"#tail":"\n","#text":"Liang, Taskar, Klein, 2006"},"location":{"#tail":"\n","#text":"New York, NY."},"title":{"#tail":"\n","#text":"Alignment by agreement."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Percy Liang"},{"#tail":"\n","#text":"Ben Taskar"},{"#tail":"\n","#text":"Dan Klein"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Lopez, Adam and Philip Resnik. 2006. Word-based alignment, phrase-based translation: Whats the link? In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas (AMTA): Visions for the Future of Machine Translation, pages 90?99, Boston, MA."},"#text":"\n","pages":{"#tail":"\n","#text":"90--99"},"marker":{"#tail":"\n","#text":"Lopez, Resnik, 2006"},"location":{"#tail":"\n","#text":"Boston, MA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"for MERT optimization to converge varied from 2 to 28; and the best choice of threshold on the development set did not always correspond to the best on the test set. Contrary to conventional wisdom in the MT community, bigger phrase tables did not always perform better. In 14 out of 18 cases, the threshold picked was 0.4 (medium size phrase tables) and the other four times 0.2 was picked (smaller phrase tables). When we include only high confidence alignments, more phrases are extracted but many of these are erroneous. Potentially this leads to a poor estimate of the phrase probabilities. See Lopez and Resnik (2006) for further discussion. 5.2 Syntax Transfer In this section, we compare the different alignments produced with and without PR based on how well they can be used for transfer of linguistic resources across languages. We used the system proposed by Ganchev, Gillenwater, and Taskar (2009). This system uses a word-aligned corpus and a parser for a resource-rich language (source language) in order to create a parser for a resource-poor language (target language). We consider a parse tree on the source language as a set of dependency edges to be transferred. For each such edge, if both end points a","@endWordPosition":"8210","@position":"50748","annotationId":"T13","@startWordPosition":"8207","@citStr":"Lopez and Resnik (2006)"}},"title":{"#tail":"\n","#text":"Word-based alignment, phrase-based translation: Whats the link?"},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas (AMTA): Visions for the Future of Machine Translation,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Adam Lopez"},{"#tail":"\n","#text":"Philip Resnik"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Mann, G. and A. McCallum. 2007. Simple, robust, scalable semi-supervised learning via expectation regularization. In Proceedings of the 24th International Conference on Machine Learning, page 600, Corvallis, OR."},"#text":"\n","pages":{"#tail":"\n","#text":"600"},"marker":{"#tail":"\n","#text":"Mann, McCallum, 2007"},"location":{"#tail":"\n","#text":"Corvallis, OR."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" of ?, for instance if ? ? 0, even if the data is such that the model already uses too many short edges on average, this value of ? will push for more short edges. By contrast the statements we can make in PR are of the form ?there should be more short edges than long edges?. Such a statement is data-dependent in the sense that if the model satisfies the constraints then we do not need to change it; if it is far from satisfying it we might need to make very dramatic changes. 500 Grac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints PR is closely related to the work of Mann and McCallum (2007, 2008), who concurrently developed the idea of using penalties based on posterior expectations of features to guide semi-supervised learning. They call their method generalized expectation (GE) constraints or alternatively expectation regularization. In the original GE framework, the posteriors of the model on unlabeled data are regularized directly. They train a discriminative model, using conditional likelihood on labeled data and an ?expectation regularization? penalty term on the unlabeled data: arg max ? Llabeled(?) ? ??E[||Ep? [f(x, z) ? b|| 2 2]. (16) Notice that there is no intermedia","@endWordPosition":"8952","@position":"55279","annotationId":"T14","@startWordPosition":"8949","@citStr":"Mann and McCallum (2007"}},"title":{"#tail":"\n","#text":"Simple, robust, scalable semi-supervised learning via expectation regularization."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 24th International Conference on Machine Learning,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"G Mann"},{"#tail":"\n","#text":"A McCallum"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2008"},"rawString":{"#tail":"\n","#text":"Mann, Gideon S. and Andrew McCallum. 2008. Generalized expectation criteria for semi-supervised learning of conditional random fields. In Proceedings of ACL-08: HLT, pages 870?878, Columbus, OH."},"#text":"\n","pages":{"#tail":"\n","#text":"870--878"},"marker":{"#tail":"\n","#text":"Mann, McCallum, 2008"},"location":{"#tail":"\n","#text":"Columbus, OH."},"title":{"#tail":"\n","#text":"Generalized expectation criteria for semi-supervised learning of conditional random fields."},"booktitle":{"#tail":"\n","#text":"In Proceedings of ACL-08: HLT,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Gideon S Mann"},{"#tail":"\n","#text":"Andrew McCallum"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Matusov, Evgeny, Nicola Ueffing, and Hermann Ney. 2006. Computing consensus translation from multiple machine translation systems using enhanced hypotheses alignment. In Proceedings of the EACL, pages 33?40, Cambridge."},"#text":"\n","pages":{"#tail":"\n","#text":"33--40"},"marker":{"#tail":"\n","#text":"Matusov, Ueffing, Ney, 2006"},"location":{"#tail":"\n","#text":"Cambridge."},"title":{"#tail":"\n","#text":"Computing consensus translation from multiple machine translation systems using enhanced hypotheses alignment."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the EACL,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Evgeny Matusov"},{"#tail":"\n","#text":"Nicola Ueffing"},{"#tail":"\n","#text":"Hermann Ney"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"McDonald, Ryan, Koby Crammer, and Fernando Pereira. 2005. Online large-margin training of dependency parsers. In ACL ?05: Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 91?98, Morristown, NJ."},"#text":"\n","pages":{"#tail":"\n","#text":"91--98"},"marker":{"#tail":"\n","#text":"McDonald, Crammer, Pereira, 2005"},"location":{"#tail":"\n","#text":"Morristown, NJ."},"title":{"#tail":"\n","#text":"Online large-margin training of dependency parsers."},"booktitle":{"#tail":"\n","#text":"In ACL ?05: Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Ryan McDonald"},{"#tail":"\n","#text":"Koby Crammer"},{"#tail":"\n","#text":"Fernando Pereira"}]}},{"date":{"#tail":"\n","#text":"1998"},"editor":{"#tail":"\n","#text":"In M. I. Jordan, editor,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"hood : L(?) = ?E[log p?(x | y)] = ?E[log ? z p?(x, z | y)] (2) where ?E[ f (x, y)] = 1N ?N n=1 f (x n, yn) denotes the empirical average of a function f (xn, yn) over the N pairs of sentences {(x1, y1) . . . , (xN, yN )} in the training corpus. Because of the latent alignment variables z, the log-likelihood function for the HMM model is not concave, and the model is fit using the Expectation Maximization (EM) algorithm (Dempster, Laird, and Rubin 1977). EM maximizes L(?) via block-coordinate ascent on a lower bound F(q, ?) using an auxiliary distribution over the latent variables q(z | x, y) (Neal and Hinton 1998): EM Lower Bound : L(?) ? F(q, ?) = ?E [ ? z q(z | x, y) log p?(x, z | y) q(z | x, y) ] (3) 2 For both of these points, see the experimental setup in Section 4.1. 485 Computational Linguistics Volume 36, Number 3 To simplify notation, we will drop the dependence on y and will write p?(x, z | y) as p?(x, z), p?(z | x, y) as p?(z | x) and q(z | x, y) as q(z | x). The alternating E and M steps at iteration t + 1 are given by: E : qt+1(z | x) = arg max q(z|x) F(q, ?t) = arg min q(z|x) KL(q(z | x) || p?t (z | x)) = p?t (z | x) (4) M : ?t+1 = arg max ? F(qt+1, ?) = arg max ? ?E [ ? z qt+1(z | x) log","@endWordPosition":"2142","@position":"14058","annotationId":"T15","@startWordPosition":"2139","@citStr":"Neal and Hinton 1998"}},"title":{"#tail":"\n","#text":"A new view of the EM algorithm that justifies incremental, sparse and other variants."},"#tail":"\n","rawString":{"#tail":"\n","#text":"Neal, Radford M. and Geoffrey E. Hinton. 1998. A new view of the EM algorithm that justifies incremental, sparse and other variants. In M. I. Jordan, editor, Learning in Graphical Models. Kluwer, Amsterdam, pages 355?368."},"#text":"\n","pages":{"#tail":"\n","#text":"355--368"},"marker":{"#tail":"\n","#text":"Neal, Hinton, 1998"},"publisher":{"#tail":"\n","#text":"Kluwer,"},"location":{"#tail":"\n","#text":"Amsterdam,"},"booktitle":{"#tail":"\n","#text":"Learning in Graphical Models."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Radford M Neal"},{"#tail":"\n","#text":"Geoffrey E Hinton"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"Nocedal, Jorge and Stephen J. Wright. 1999. Numerical Optimization. Springer, Berlin."},"#text":"\n","marker":{"#tail":"\n","#text":"Nocedal, Wright, 1999"},"publisher":{"#tail":"\n","#text":"Springer,"},"location":{"#tail":"\n","#text":"Berlin."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"rojection step uses the same inference algorithm (forward?backward for HMMs) to compute the gradient, only modifying the local factors using the current setting of ?. ?i ? 0;1 while ||?(?)||2 > ? do2 ??(x, zc) ? ?(x, zc) exp?? f(x,zc );3 q(z | x) ? forwardBackward(??(x, zc));4 ? ? ? + ???(?);5 end6 Algorithm 1: Computing KL(Qx ? p?(z|x)) = min q?Qx KL(q(z|x) ? p?(z|x)) 489 Computational Linguistics Volume 36, Number 3 We optimize the dual objective using the gradient based methods shown in Algorithm 1. Here ? is an optimization precision, ? is a step size chosen with the strong Wolfe?s rule (Nocedal and Wright 1999). Here, ??(?) represents an ascent direction chosen as follows: For inequality constraints, it is the projected gradient (Bertsekas 1999); for equality constraints with slack, we use conjugate gradient (Nocedal and Wright 1999), noting that when ? = 0, the objective is not differentiable. In practice this only happens at the start of optimization and we use a sub-gradient for the first direction. Computing the projection requires an algorithm for inference in the original model, and uses that inference as a subroutine. For HMM word alignments, we need to make several calls to forward?backward ","@endWordPosition":"4221","@position":"26418","annotationId":"T16","@startWordPosition":"4218","@citStr":"Nocedal and Wright 1999"}},"title":{"#tail":"\n","#text":"Numerical Optimization."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Jorge Nocedal"},{"#tail":"\n","#text":"Stephen J Wright"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Och, Franz Josef and Hermann Ney. 2000. Improved statistical alignment models. In ACL ?00: Proceedings of the 38th Annual Meeting on Association for Computational Linguistics, pages 440?447, Morristown, NJ."},"#text":"\n","pages":{"#tail":"\n","#text":"440--447"},"marker":{"#tail":"\n","#text":"Och, Ney, 2000"},"location":{"#tail":"\n","#text":"Morristown, NJ."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"lish?French, English?Spanish, English?Portuguese, Portuguese?Spanish, Portuguese?French, and Spanish?French. Corpus Sentence Pairs Ave Length Max Length % Sure % 1-1 En/Fr 447 16/17 30/30 21 98 En/Es 400 29/31 90/99 67 86 En/Pt 60 11/11 20/20 54 91 Pt/Es 60 11/11 20/20 69 92 Pt/Fr 60 11/12 20/20 77 88 Es/Fr 60 11/12 20/20 79 87 are represented as squares without borders. Circles indicate the posterior probability associated with a given link and will be explained latter. We use six manually annotated corpora whose characteristics are summarized in Table 1. The corpora are: the Hansard corpus (Och and Ney 2000) of English/French Canadian Parliamentary proceedings (En-Fr), and the English/Spanish portion of the Europarl corpus (Koehn 2005) where the annotation is from EPPS (Lambert et al 2005) (En-Es) using standard test and development set split. We also used the English/ Portuguese (En-Pt), Portuguese/Spanish (Pt-Es), Portuguese/French (Pt-Fr), and Spanish/French (Es-Fr) portions of the Europarl corpus using annotations described by Grac?a et al (2008), where we split the gold alignments into a dev/test set in a ratio of 40%/60%. Table 1 shows some of the variety of challenges presented by each cor","@endWordPosition":"1356","@position":"9308","annotationId":"T17","@startWordPosition":"1353","@citStr":"Och and Ney 2000"}},"title":{"#tail":"\n","#text":"Improved statistical alignment models."},"booktitle":{"#tail":"\n","#text":"In ACL ?00: Proceedings of the 38th Annual Meeting on Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Franz Josef Och"},{"#tail":"\n","#text":"Hermann Ney"}]}},{"volume":{"#tail":"\n","#text":"29"},"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Och, Franz Josef and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19?51."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"1"},"marker":{"#tail":"\n","#text":"Och, Ney, 2003"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"and joint unsupervised POS and parser induction across languages (Snyder and Barzilay 2008). IBM Models 1 and 2 and the HMM are simple and tractable probabilistic models, which produce the target sentence one target word at a time by choosing a source word and generating its translation. IBM Models 3, 4, and 5 attempt to capture fertility (the tendency of each source word to generate several target words), resulting in probabilistically deficient, intractable models that require local heuristic search and are difficult to implement and extend. Many researchers use the GIZA++ software package (Och and Ney 2003) as a black box, selecting IBM Model 4 as a compromise between alignment quality and efficiency. All of the models are asymmetric (switching target and source languages produces drastically different results) and the simpler models (IBM Models 1, 2, and HMM) do not enforce bijectivity (the majority of words translating as a single word). Although there are systematic translation phenomena where one cannot hope to obtain 1-to-1 alignments, we observe that in over 6 different European language pairs the majority of alignments are in fact 1-to-1 (86?98%). This leads to the common practice of post","@endWordPosition":"496","@position":"3516","annotationId":"T18","@startWordPosition":"493","@citStr":"Och and Ney 2003"},{"#tail":"\n","#text":"nglish He walked and French Il est alle?), articles required in one language but optional in the other (e.g., English Cars use gas and Portuguese Os carros usam gasolina), cases where the content is expressed using multiple words in one language and a single word in the other language (e.g., agglutination such as English weapons of mass destruction and German Massenvernichtungswaffen), and expressions translated indirectly. Due to this inherent ambiguity, manual annotations usually distinguish between sure correspondences for unambiguous translations, and possible, for ambiguous translations (Och and Ney 2003). The top row of Figure 1 shows two word alignments between an English?French sentence pair. We use the following notation: the alignment on the left (right) will be referenced as source?target (target?source) and contains source (target) words as rows and target (source) words as columns. Each entry in the matrix corresponds to a source?target word pair, and is the candidate for an alignment link. Sure links are represented as squares with borders, and possible links Figure 1 Posterior marginal distributions for different models for an English to French sentence translation. Left: EN?FR model","@endWordPosition":"1093","@position":"7582","annotationId":"T19","@startWordPosition":"1090","@citStr":"Och and Ney 2003"},{"#tail":"\n","#text":"on vs recall curves, by generating alignments for different thresholds (0..1). Second, with this method we can ignore the null word probabilities, which tend to be poorly estimated. 3. Posterior Regularization Word alignment models in general and the HMM in particular are very gross oversimplifications of the translation process and the optimal likelihood parameters learned often do not correspond to sensible alignments. One solution to this problem is to add more complexity to the model to better reflect the translation process. This is the approach taken by IBM Models 4+ (Brown et al 1993b; Och and Ney 2003), and more recently by the LEAF model (Fraser and Marcu 2007). Unfortunately, these changes make the models probabilistically deficient and intractable, requiring approximations and heuristic learning and inference prone to search errors. Instead, we propose to use a learning framework called Posterior Regularization (Grac?a, Ganchev, and Taskar 2007) that incorporates side information into unsupervised estimation in the form of constraints on the model?s posteriors. The constraints are expressed as inequalities on the expected values under the posterior distribution of user-defined constraint","@endWordPosition":"2980","@position":"18941","annotationId":"T20","@startWordPosition":"2977","@citStr":"Och and Ney 2003"},{"#tail":"\n","#text":"-1 alignment links from 78% to 97.3% for En-Fr (manual annotations have 98.1%); for En-Pt the increase is from 84.7% to 95.8% (manual annotations have 90.8%) (see Section 4.1). 3.4 Symmetry Constraints The directional nature of the generative models used to recover word alignments conflicts with their interpretation as translations. In practice, we see that the choice of which language is source versus target matters and changes the mistakes made by the model (the first row of panels in Figure 1). The standard approach is to train two models independently and then intersect their predictions (Och and Ney 2003). However, we show that it is much better to train two directional models concurrently, coupling their posterior distributions over alignments to approximately agree. Let the directional models be defined as: ??p (??z ) (source?target) and ??p (??z ) (target?source). We suppress dependence on x and y for brevity. Define z to range over the union of all possible 491 Computational Linguistics Volume 36, Number 3 directional alignments ?? Z ???Z . We define a mixture model p(z) = 12 ??p (z) + 12 ??p (z) where ??p (??z ) = 0 and vice versa (i.e., the alignment of one directional model has probabil","@endWordPosition":"4996","@position":"31062","annotationId":"T21","@startWordPosition":"4993","@citStr":"Och and Ney 2003"},{"#tail":"\n","#text":"ed with normal EM vs. trained with PR plus constraints. We also report results for IBM Model 4, because it is often used as the default word alignment model, and can be used as a reference. However, we would like to note that IBM Model 4 is a more complex model, able to capture more structure, albeit at the cost of intractable inference. Because our approach is orthogonal to the base model used, the constraints described here could be applied in principle to IBM Model 4 if exact inference was efficient, hopefully yielding similar improvements. We used a standard implementation of IBM Model 4 (Och and Ney 2003) and because changing the existing code is not trivial, we could not use the same stopping criterion to avoid overfitting and we are not able to produce precision/recall curves. We trained IBM Model 4 using the default configuration of the Figure 4 Precision/Recall curves for different models using 1,000k sentences. Precision on the horizontal axis. Left: Hansard EN-FR direction. Right: EN-PT Portuguese-English direction. 493 Computational Linguistics Volume 36, Number 3 Figure 5 Word alignment precision when the threshold is chosen to achieve IBM Model 4 recall with a difference of ? 0.005. T","@endWordPosition":"6020","@position":"37000","annotationId":"T22","@startWordPosition":"6017","@citStr":"Och and Ney 2003"},{"#tail":"\n","#text":"rds to null. 4.4 Symmetrization As discussed earlier, the word alignment models are asymmetric, whereas most applications require a single alignment for each sentence pair. Typically this is achieved by a symmetrization heuristic that takes two directional alignments and produces a single 495 Computational Linguistics Volume 36, Number 3 Figure 7 Precision and Recall as a function of training data size for En-Fr by common and rare words. Top Left: Common Precision, Top Right: Rare Precision, Bottom: Rare Recall. alignment. For MT the most commonly used heuristic is called grow diagonal final (Och and Ney 2003). This starts with the intersection of the sets of aligned points and adds points around the diagonal that are in the union of the two sets of aligned points. The alignment produced has high recall relative to the intersection and only slightly lower recall than the union. In syntax transfer the intersection heuristic is normally used, because one wants to have high precision links to transfer knowledge between languages. One pitfall of these symmetrization heuristics is that they can obfuscate the link between the original alignment and the ones used for a specific task, making errors more di","@endWordPosition":"6886","@position":"42380","annotationId":"T23","@startWordPosition":"6883","@citStr":"Och and Ney 2003"}]},"title":{"#tail":"\n","#text":"A systematic comparison of various statistical alignment models."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Franz Josef Och"},{"#tail":"\n","#text":"Hermann Ney"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Smith, Noah A. and Jason Eisner. 2006. Annealing structural bias in multilingual weighted grammar induction. In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, pages 569?576, Morristown, NJ."},"#text":"\n","pages":{"#tail":"\n","#text":"569--576"},"marker":{"#tail":"\n","#text":"Smith, Eisner, 2006"},"location":{"#tail":"\n","#text":"Morristown, NJ."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ing constraints over a model to better guide the learning process has appeared before. In the context of word alignment, Deng and Byrne (2005) use a state-duration HMM in order to model word-to-phrase translations. The fertility of each source word is implicitly encoded in the durations of the HMM states. Without any restrictions, likelihood prefers to always use longer phrases and the authors try to control this behavior by multiplying every transition probability by a constant ? > 1. This encourages more transitions and hence shorter phrases. For the task of unsupervised dependency parsing, Smith and Eisner (2006) add a constraint of the form ?the average length of dependencies should be X? to capture the locality of syntax (at least half of the dependencies are between adjacent words), using a scheme they call structural annealing. They modify the model?s distribution over trees p?(y) by a penalty term as: p ? ?(y) ? p?(y)e (? ? e?y length(e)), where length(e) is the surface length of edge e. The factor ? changes from a high value to a lower one so that the preference for short edges (hence a smaller sum) is stronger at the start of training. These two approaches also have the goal of controlling unsu","@endWordPosition":"8661","@position":"53646","annotationId":"T24","@startWordPosition":"8658","@citStr":"Smith and Eisner (2006)"}},"title":{"#tail":"\n","#text":"Annealing structural bias in multilingual weighted grammar induction."},"booktitle":{"#tail":"\n","#text":"In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Noah A Smith"},{"#tail":"\n","#text":"Jason Eisner"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2008"},"rawString":{"#tail":"\n","#text":"Snyder, Benjamin and Regina Barzilay. 2008. Unsupervised multilingual learning for morphological segmentation. In Proceedings of ACL-08: HLT, pages 737?745, Columbus, OH."},"#text":"\n","pages":{"#tail":"\n","#text":"737--745"},"marker":{"#tail":"\n","#text":"Snyder, Barzilay, 2008"},"location":{"#tail":"\n","#text":"Columbus, OH."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"bmission received: 1 August 2009; revised submission received: 24 December 2009; accepted for publication: 10 March 2010. ? 2010 Association for Computational Linguistics Computational Linguistics Volume 36, Number 3 MT system combination (Matusov, Ueffing, and Ney 2006). But their importance has grown far beyond machine translation: for instance, transferring annotations between languages (Yarowsky and Ngai 2001; Hwa et al 2005; Ganchev, Gillenwater, and Taskar 2009); discovery of paraphrases (Bannard and Callison-Burch 2005); and joint unsupervised POS and parser induction across languages (Snyder and Barzilay 2008). IBM Models 1 and 2 and the HMM are simple and tractable probabilistic models, which produce the target sentence one target word at a time by choosing a source word and generating its translation. IBM Models 3, 4, and 5 attempt to capture fertility (the tendency of each source word to generate several target words), resulting in probabilistically deficient, intractable models that require local heuristic search and are difficult to implement and extend. Many researchers use the GIZA++ software package (Och and Ney 2003) as a black box, selecting IBM Model 4 as a compromise between alignment q","@endWordPosition":"411","@position":"2990","annotationId":"T25","@startWordPosition":"408","@citStr":"Snyder and Barzilay 2008"}},"title":{"#tail":"\n","#text":"Unsupervised multilingual learning for morphological segmentation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of ACL-08: HLT,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Benjamin Snyder"},{"#tail":"\n","#text":"Regina Barzilay"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Tiedemann, Jo?rg. 2007. Building a multilingual parallel subtitle corpus. In Proceedings of the 17th Conference on Computational Linguistics in the Netherlands (CLIN 17), Leuven."},"#text":"\n","marker":{"#tail":"\n","#text":"Tiedemann, 2007"},"location":{"#tail":"\n","#text":"Leuven."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"anchev, Gillenwater, and Taskar (2009), we filter alignment links between words with incompatible POS tags. Figure 10 shows our results for transferring from English to Bulgarian (En?Bg) and from English to Spanish (En?Es). The En?Bg 499 Computational Linguistics Volume 36, Number 3 Figure 10 Edge conservation for cross-lingual grammar induction. Left: En?Bg subtitle corpus; Right: En?Es parliamentary proceedings. Vertical axis: percentage of transferred edges that are correct. Horizontal axis: average number of transferred edges per sentence. results are based on a corpus of movie subtitles (Tiedemann 2007), and are consequently shorter sentences, whereas the En?Es results are based on a corpus of parliamentary proceedings (Koehn 2005). We see in Figure 10 that for both domains, the models trained using posterior regularization perform better than the baseline model trained using EM. 6. Related Work The idea of introducing constraints over a model to better guide the learning process has appeared before. In the context of word alignment, Deng and Byrne (2005) use a state-duration HMM in order to model word-to-phrase translations. The fertility of each source word is implicitly encoded in the dur","@endWordPosition":"8513","@position":"52704","annotationId":"T26","@startWordPosition":"8512","@citStr":"Tiedemann 2007"}},"title":{"#tail":"\n","#text":"Building a multilingual parallel subtitle corpus."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 17th Conference on Computational Linguistics in the Netherlands (CLIN 17),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Jorg Tiedemann"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"Vogel, Stephan, Hermann Ney, and Christoph Tillmann. 1996. Hmm-based word alignment in statistical translation. In Proceedings of the 16th Conference on Computational Linguistics, pages 836?841, Morristown, NJ."},"#text":"\n","pages":{"#tail":"\n","#text":"836--841"},"marker":{"#tail":"\n","#text":"Vogel, Ney, Tillmann, 1996"},"location":{"#tail":"\n","#text":"Morristown, NJ."},"title":{"#tail":"\n","#text":"Hmm-based word alignment in statistical translation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 16th Conference on Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Stephan Vogel"},{"#tail":"\n","#text":"Hermann Ney"},{"#tail":"\n","#text":"Christoph Tillmann"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Yarowsky, David and Grace Ngai. 2001. Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora. In Proceedings of the North American Chapter Of The Association For Computational Linguistics, pages 1?8, Morristown, NJ."},"#text":"\n","pages":{"#tail":"\n","#text":"1--8"},"marker":{"#tail":"\n","#text":"Yarowsky, Ngai, 2001"},"location":{"#tail":"\n","#text":"Morristown, NJ."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":", PA 19104-6309. E-mail: kuzman@cis.upenn.edu. ? University of Pennsylvania, Department of Computer and Information Science, 3330 Walnut Street, Philadelphia, PA 19104-6389. E-mail: taskar@cis.upenn.edu. Submission received: 1 August 2009; revised submission received: 24 December 2009; accepted for publication: 10 March 2010. ? 2010 Association for Computational Linguistics Computational Linguistics Volume 36, Number 3 MT system combination (Matusov, Ueffing, and Ney 2006). But their importance has grown far beyond machine translation: for instance, transferring annotations between languages (Yarowsky and Ngai 2001; Hwa et al 2005; Ganchev, Gillenwater, and Taskar 2009); discovery of paraphrases (Bannard and Callison-Burch 2005); and joint unsupervised POS and parser induction across languages (Snyder and Barzilay 2008). IBM Models 1 and 2 and the HMM are simple and tractable probabilistic models, which produce the target sentence one target word at a time by choosing a source word and generating its translation. IBM Models 3, 4, and 5 attempt to capture fertility (the tendency of each source word to generate several target words), resulting in probabilistically deficient, intractable models that requir","@endWordPosition":"382","@position":"2781","annotationId":"T27","@startWordPosition":"379","@citStr":"Yarowsky and Ngai 2001"}},"title":{"#tail":"\n","#text":"Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the North American Chapter Of The Association For Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"David Yarowsky"},{"#tail":"\n","#text":"Grace Ngai"}]}}]}}]}}
