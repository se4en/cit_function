{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","listItem":[{"#tail":"\n","@confidence":"0.463248","#text":"\nthe Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Cliticization\nLexical Rule (Miller and Sag 1993) to operate on those raised elements. Also an analysis treating\nadjunct extraction via lexical rules (van Noord and Bouma 1994) results in an infinite lexicon.\n(~) 1997 Association for Computational Linguistics\n"},{"#tail":"\n","@confidence":"0.6366145","#text":"\n3. Lexical Covariation: Encoding Lexical Rules and their Interaction\nas Definite Relations\n"},{"#tail":"\n","@confidence":"0.9072325","#text":"\nclause predicates:\n1. Lexical rule predicates representing the lexical rules;\n2. Frame predicates specifying the frame for the lexical rule predicates; and\n3. Interaction predicates encoding lexical rule interaction for the natural\n"}],"figure":[{"#tail":"\n","@confidence":"0.705896285714286","#text":"\nMeurers and Minnen Covariation Approach to HPSG Lexical Rules\nsl\n\\] LOC\\] CAT\nLOC\\[CAT\nHEAD\nVAL\nHAVrFbVFOOpsP tlJ\nsu , INDEX \\[VAL (IL 'CONT\nLCOMpS /\\[LOC\\]CONTll NDEX \\[~\\]1 \\[\\]\nt---+\nVFORM pas\\]\nSUBJ / \\[LOC\\] CONT \\[ INDEX \\[\\]\\]/\n/ (\\[LOC ICATI HEAD prep\\[ PFORM\nCOMPS \\[\\] O L CONT\\]INDEX \\[\\]\n"},{"#tail":"\n","@confidence":"0.820766545454545","#text":"\nMeurers and Minnen Covariation Approach to HPSG Lexical Rules\ninput :\noutput :\nFigure 3\nThe compiler setup.\n~ x i c o ~ +\ntranslation\nI of lexical rules\ninto\ndefinite relations\n~ ~ ~ ~ ~ f ~ ~me\ndetermination of\nlexical rule\ninteraction\nword class\n3 specialization of\nlexical rule\ninteraction\npruned\nfinite state / /\ntranslation\n4 of lexical rules\n"},{"#tail":"\n","@confidence":"0.770109375","#text":"\nlist bool val\nAA\nelist \\[HD val\\] + _ a b\nnelist TL list\\]\n\\[c,Y\nFigure 5\nLexical rule 1.\nlex-rule-l(\\[B \\ [y - - \\ ] \\ ] , \\ [~ \\[ bX ~\\] \\ ] )\n"},{"#tail":"\n","@confidence":"0.3476384","#text":"\nMeurers and Minnen Covariation Approach to HPSG Lexical Rules\nRule 1:\nRule 3:\nC\\[Y --\\] ~ C\\[ X Rule 2:\nc r w +\\]\\] \\[c\\[Y t2 LZ \\] TL ~ ~ Rule 4:\n"},{"#tail":"\n","@confidence":"0.2166425","#text":"\nMeurers and Minnen Covariation Approach to HPSG Lexical Rules\nj\\] W -- ). lex_entry( C X i\nZ ,b\nt2\n"},{"#tail":"\n","@confidence":"0.7451441","#text":"\nextended lexical entries\ncall I\n= in teract ion predicates\ncall I\n= lex ica l ru le predicates\ncall \\[\n--- frame predicates\nFigure 19\nSchematic representation f definite clause encoding of lexical rules and their interaction.\n4. Partial Unfolding of Frame Predicates\n"},{"#tail":"\n","@confidence":"0.9831152","#text":"\nMeurers and Minnen Covariation Approach to HPSG Lexical Rules\nextended lexical entries\ncall I\n.~ interaction predicates\ncall unfolding\nc unfolding\nFigure 20\nSchematic representation f the successive unfolding transformation.\nextended lexical entries\ncall I\n,, interaction predicates\nca l l\n,, lexical rule predicates &quot;~ unfolding\n/ call\n.~ frame predicates /\n"}],"author":{"#tail":"\n","@confidence":"0.948942","#text":"\nGuido Minnen\n"},"equation":[{"#tail":"\n","@confidence":"0.6765885","#text":"\ni V - - .V n\nFigure 10\n"},{"#tail":"\n","@confidence":"0.964555733333333","#text":"\nc\\[w -\\]\n\\ [B - \\]1 c I w , ~ \\[:Ex+d\nL t2 LZ 0\nlex_rule_2(\\[/ll BA b-L C\\[W -\\]\\]'E\\]\\[C\\[W +\\]\\]):- frame2(\\[~).\n'ex~'e~,OVC \\[W\nL t2LZI\nw\nlex_rule_4(~ C x\nL taL z\n+\\]\\]\\[ l\\] TL ~ ' [~ C [ YZ ~ ):-frame-3(\\[~'m)'\n(~\\] ,\\[~\\]\\[~\\[X+ _ ]\\]):- frame_4(\\[~I~).\nr frame-2( C Ix ~\\] ' C t l Ltl &quot;Y x ).\nB \\['~ B ~\\]\nframe-3( C rw ~\\] ' c t 2 L t2 uX xW ).\nFigure 12\n"},{"#tail":"\n","@confidence":"0.921422333333333","#text":"\nIA BO IA iBO fra~e~, c \\[X~ 'C X~ ~\nL t2 Lz t2 z\nwo 1\\]\\[;i 1 \\[\\] frame-4( Ct2 zY ~ ' t2 Z yW [.~ ).\n"},{"#tail":"\n","@confidence":"0.8971985","#text":"\nq19\nq2 1 1 3 4 q15 3 4 q20\nq5 4 ~ ) ql 2\nFigure 14\n"},{"#tail":"\n","@confidence":"0.8720634","#text":"\nW m\nlex_entry(I-6~):- q_l( X ~ ,\\[~\\]).\nZ ,b\nt2\nFigure 17\n"},{"#tail":"\n","@confidence":"0.938753142857143","#text":"\nq_l(E\\]~):- lex_rule_l(\\[~,~,\nq_l(\\[~\\]):- lexxule.2(\\[~\\[g/~,\nq_2(\\[~\\]~\\]):- lexn'ule.2(\\[~\\],\\[~),\nq_7(D~\\],\\[-6-~):- lex_rule_3(E\\],\\[~),\nq_14 (\\[~\\],\\[~) :-lex ~-ule _3 (E\\],\\[X~,\nq_14 (\\[/T\\],\\[O~):-lex ~ule _4 (E\\],\\[X~),\nq~2(~\\[~).\nq_3(\\[NNN~.\nq_7(\\[d~\\[~\\]).\nq_14(\\[x~\\],\\[~\\]).\nq_14(\\[-X~,\\[~\\]).\nq_l 9(rA-~,\\[~\\]).\nq_l(E\\]~\\]), q2(E\\]E), q_3(E\\]~, q_7(\\[~\\[~\\]), q_14(\\[~E\\]), q_19(\\[~\\[~\\]).\nFigure 18\n"},{"#tail":"\n","@confidence":"0.870313733333333","#text":"\n\\[B iCq_l(\\[~\\] W , \\ [~)\nt2\n1\\] \\[\\] IN~) q_l/ t2 Z\n\\[\\] IN~)\nq_2(\\[/;;\\] C yX\nt2 Z\n:- lex _rule _1 (17~-I,\\[-X~\\]),\n:- lex_rule_2(E\\],\\[~,\n:- lex _rule22(\\[~\\[~\\]),\n:- l ex_ ru le~3( \\ [~,\nq_2(\\[-~7~ W ,\\[~).\nt2\nt2 z \\[\\]\nB \\[\\]\nq_7\nt2 z \\[\\]\nB \\[\\]\nq_14(\\[X~\\] C \\[W '\\[~\\])&quot;\nL t2 LX\nq_14(FX~l c w I~ .\nx\nt2\nq-,9 c\nt2 Z\nB \\[\\]\nq_14(\\[F~\\] C \\[W ~\\] ,\\[b-~):-lex_rule_3(\\[~\\],\\[~\\]),\nL t2t&quot;\nL t2LZ \\[\\]\nq_l(E\\],\\[~\\]), q_2( \\ [~) , q~3(\\[~,~\\]), q_7(\\[~\\[~\\]), q_14( \\ [~) , q_19(\\[~\\]).\nFigure 22\n"},{"#tail":"\n","@confidence":"0.731793","#text":"\n(C A D1) V -.. V (C A Dk): We compute C A (D1 V ... V Dk), where the r) are assumed\n"}],"subsectionHeader":[{"#tail":"\n","@confidence":"0.987246","#text":"\n2.1 A Formal Setup for HPSG Grammars\n"},{"#tail":"\n","@confidence":"0.998285","#text":"\n2.2 Lexical Rules in HPSG\n"},{"#tail":"\n","@confidence":"0.998513","#text":"\n3.1 Lexical Rules as Definite Relations and the Automatic Specification of Frames\n"},{"#tail":"\n","@confidence":"0.999801","#text":"\n3.2 Determining Global Lexical Rule Interaction\n"},{"#tail":"\n","@confidence":"0.992001","#text":"\n3.3 Word Class Specialization of Lexical Rule Interaction\n"},{"#tail":"\n","@confidence":"0.977652","#text":"\n3.4 Lexical Rule Interaction as Definite Relat ions\n"},{"#tail":"\n","@confidence":"0.9959","#text":"\n5.1 Constraint Propagation\n"},{"#tail":"\n","@confidence":"0.997255","#text":"\n5.2 Dynamic and Static Coroutining\n"},{"#tail":"\n","@confidence":"0.99919","#text":"\n6.1 Time Efficiency\n"},{"#tail":"\n","@confidence":"0.999542","#text":"\n6.2 Space Efficiency\n"},{"#tail":"\n","@confidence":"0.992472","#text":"\n7.1 Off-line Expansion of Lexical Rules\n"},{"#tail":"\n","@confidence":"0.990988","#text":"\n7.2 Lexical Rules as Unary Phrase Structure Rules\n"}],"subsubsectionHeader":[{"#tail":"\n","@confidence":"0.747098","#text":"\n2.2.2 Description-Level Lexical Rules. The DLR approach formalizes lexical rules\n"},{"#tail":"\n","@confidence":"0.745521","#text":"\n2.2.3 Lexical Rule Specification and Framing. An important difference between unary\n"}],"footnote":[{"#tail":"\n","@confidence":"0.931785666666667","#text":"\n/b4home.html\n1 This is, for example, the case for all proposals working with verbal exical entries that raise the\narguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as\n"},{"#tail":"\n","@confidence":"0.800295","#text":"\n2 This is not to say that a special precompilation treatment along those lines would not be profitable for\nphrase structure ules. In fact, such a proposal ismade by Torisawa nd Tsuji (1996).\n"},{"#tail":"\n","@confidence":"0.779105428571429","#text":"\n3 The terminology used in the literature varies. Types are also referred to as sorts, appropriateness\nconditions as feature declarations, and features as attributes. To avoid confusion, we will only use the\nterminology introduced in the text.\n4 This interpretation f the signature is sometimes referred to as closed world (Gerdemann and King\n1994; Gerdemann 1995).\n5 An in-depth discussion including a comparison of both approaches i provided in Calcagno, Meurers,\nand Pollard (in preparation).\n"},{"#tail":"\n","@confidence":"0.935485","#text":"\n1l Manandhar (1995) proposes to unify these two steps by including an update operator in the\n"},{"#tail":"\n","@confidence":"0.9670665","#text":"\n17 We use indexing of predicate names to be able to indicate later on which lexical rule a frame predicate\nbelongs to.\n18 Since in computational systems, in contrast to the general theoretical case, we only need to ensure\ntransfer for the properties actually specified in the lexical entries of a given grammar, some of the\ndistinctions made in the signature can possibly be ignored. One could therefore improve the\ncalculation of frame predicates by taking the base lexical entries into account at this stage of the\n"}],"title":{"#tail":"\n","@confidence":"0.6664755","#text":"\nA Computational Treatment of Lexical Rules\nin HPSG as Covariation in Lexical Entries\nW. Detmar Meurers*\nUniversity of Tiibingen\n"},"@confidence":"0.000000","#tail":"\n","reference":[{"#tail":"\n","@confidence":"0.997611606060606","#text":"\nBriscoe, Ted and Ann Copestake. 1996.\nControlling the application of lexical\nrules. In Proceedings ofthe SIGLEX\nWorkshop on Breadth and Depth of Semantic\nLexicons, Santa Cruz, CA.\nBriscoe, Ted, Ann Copestake, and Valeria\nde Paiva, editors. 1992. Default Inheritance\nWithin UniX'cation-Based Approaches tothe\nLexicon. Cambridge University Press,\nCambridge, UK.\nCalcagno, Mike. 1995. Interpreting lexical\nrules. In Proceedings ofthe Conference on\nFormal Grammar, Barcelona. Also in:\nProceedings of the ACQUILEX II\nWorkshop on Lexical Rules, 1995,\nCambridge, UK.\nCalcagno, Mike, Detmar Meurers, and Carl\nPollard. In preparation. On the nature of\nlexical rules in head-driven phrase\nstructure grammar. Unpublished\nmanuscript, Ohio State University and\nUniversity of T~ibingen.\nCalcagno, Mike and Carl Pollard. 1995.\nLexical rules in HPSG: What are they?\nUnpublished manuscript, Ohio State\nUniversity, Columbus, OH.\nCarpenter, Bob. 1991. The generative power\nof categorial grammars and Head-Driven\nPhrase Structure Grammars with lexical\nrules. Computational Linguistics,\n17(3):301-314.\nCarpenter, Bob and Gerald Penn. 1994.\nALE--The Attribute Logic Engine, User's\n"},{"#tail":"\n","@confidence":"0.992690105691057","#text":"\nComputational Linguistics Volume 23, Number 4\nGuide, Version 2.0.1, December 1994.\nTechnical report, Computational\nLinguistics Program, Philosophy\nDepartment, Carnegie Mellon University,\nPittsburgh, PA.\nCopestake, Ann. 1992. The Representation f\nLexical Semantic Information. Cognitive\nscience research paper CSRP 280,\nUniversity of Sussex, Sussex, UK.\nCopestake, Ann. 1993. The Compleat LKB.\nTechnical report 316, University of\nCambridge Computer Laboratory,\nCambridge, UK.\nD6rre, Jochen and Michael Dorna, editors.\n1993a. Computational Aspects of\nConstraint-Based Linguistic Description I.\nUniversity of Stuttgart, Stuttgart,\nGermany.\nDOrre, Jochen and Michael Dorna. 1993b.\nCUF--A formalism for linguistic\nknowledge representation. I D6rre and\nDorna (1993a).\nDOrre, Jochen and Andreas Eisele. 1991. A\nComprehensive Unification Based\nFormalism. DYANA Deliverable R3.1.B,\nUniversity of Stuttgart, Stuttgart,\nGermany.\nEisele, Andreas and Jochen D6rre. 1990.\nDisjunctive Unification. Technical Report\n124, IBM Wissenschaftliches Zentrum,\nInstitut fiir Wissensbasierte Systeme.\nEmele, Martin. 1994. The typed feature\nstructure representation formalism. In\nProceedings ofthe International Workshop on\nSharable Natural Language Resources, Nara,\nJapan.\nEmele, Martin and R~mi Zajac. 1990. Typed\nunification grammars. In Proceedings ofthe\n13th Conference on Computational Linguistics\n(COLING), Helsinki, Finland.\nFlickinger, Daniel. 1987. Lexical Rules in the\nHierarchical Lexicon. Ph.D. thesis, Stanford\nUniversity, Stanford, CA.\nFlickinger, Daniel, Carl Pollard, and Thomas\nWasow. 1985. Structure-sharing i lexical\nrepresentation. I Proceedings ofthe 23rd\nAnnual Meeting, pages 262-267, Chicago,\nIL. Association for Computational\nLinguistics.\nFrank, Annette. 1994. Verb second by\nunderspecification. In Proceedings of\nKONVENS, Berlin. Springer-Verlag.\nGerdemann, Dale. 1995. Open and closed\nworld types in NLP systems. In\nProceedings ofthe DGfS Fachtagung\nComputerlinguistik, Diisseldorf, Germany.\nGerdemann, Dale and Paul King. 1994. The\ncorrect and efficient implementation f\nappropriateness specifications for typed\nfeature structures. In Proceedings ofthe 15th\nConference on Computational Linguistics\n(COLING), Kyoto, Japan.\nGinsberg, Matthew L., editor. 1987. Readings\nin Nonmonotonic Reasoning. Morgan\nKaufmann.\nG6tz, Thilo. 1994. A Normal Form for\nTyped Feature Structures. Arbeitspapiere\ndes SFB 340 no. 40, University of\nT~ibingen, IBM, Heidelberg, Germany.\nG6tz, Thilo and Detmar Meurers. 1995.\nCompiling HPSG type constraints into\ndefinite clause programs. In Proceedings of\nthe 33rd Annual Meeting, Boston, MA.\nAssociation for Computational\nLinguistics.\nG6tz, Thilo and Detmar Meurers. 1996. The\nimportance of being lazy--Using lazy\nevaluation to process queries to HPSG\ngrammars. In Proceedings ofTALN 96 (Joint\nSession with the Third International\nConference on HPSG), Marseille, France.\nGOtz, Thilo and Detmar Meurers. 1997a.\nThe ConTroll system as large grammar\ndevelopment platform. In Proceedings of\nthe ACL/EACL Post-Conference Workshop on\nComputational Environments for Grammar\nDevelopment and Linguistic Engineering,\nMadrid, Spain.\nG6tz, Thilo and Detmar Meurers. 1997b.\nInterleaving universal principles and\nrelational constraints over typed feature\nlogic. In Proceedings ofthe 35th Annual\nMeeting of the ACL and the 8th Conference of\nthe EACL, Madrid, Spain.\nGriffith, John. 1996. Modularizing contexted\nconstraints. In Proceedings ofthe 16th\nConference on Computational Linguistics\n(COLING), Copenhagen, Denmark.\nHinrichs, Erhard, Detmar Meurers, and\nTsuneko Nakazawa, editors. 1994.\nPartial-VP and Split-NP Topicalization i\nGerman--An HPSG Analysis and its\nImplementation. Number 58.\nHinrichs, Erhard and Tsuneko Nakazawa.\n1989. Flipped out: Aux in German. In\nPapers from the 25th Regional Meeting, pages\n193-202, Chicago. Chicago Linguistic\nSociety.\nHinrichs, Erhard and Tsuneko Nakazawa.\n1994. Partial-VP and split-NP\ntopicalization i German: An HPSG\nanalysis. In Hinrichs, Meurers, and\nNakazawa (1994).\nHinrichs, Erhard and Tsuneko Nakazawa.\n1996. Applying lexical rules under\nsubsumption. In Proceedings ofthe 16th\nConference on Computational Linguistics\n(COLING), pages 543-549, Copenhagen,\nDenmark.\nKathol, Andreas. 1994. Passive without\nlexical rules. In John Nerbonne, Klaus\nNetter, and Carl Pollard, editors, HPSGfor\n"},{"#tail":"\n","@confidence":"0.99907931147541","#text":"\nMeurers and Minnen Covariation Approach to HPSG Lexical Rules\nGerman. CSLI Lecture Notes, Stanford\nUniversity, Stanford, CA.\nKing, Paul. 1989. A Logical Formalism for\nHead-driven Phrase Structure Grammar.\nPh.D. thesis, University of Manchester,\nManchester, UK.\nKing, Paul. 1994. An Expanded Logical\nFormalism for Head-driven Phrase\nStructure Grammar. Arbeitspapiere des\nSonderforschungsbereich 340 no. 59,\nUniversity of Tfibingen, Tfibingen,\nGermany.\nKrieger, Hans-Ulrich and John Nerbonne.\n1992. Feature-based inheritance networks\nfor computational lexicons. In Briscoe,\nCopestake, and de Paiva (1992).\nManandhar, Suresh. 1995. The Update\nOperation in Feature Logic. Unpublished\nManuscript, HCRC at University of\nEdinburgh, UK.\nMarriott, Kim, Lee Naish, and Jean-Louis\nLassez. 1988. Most specific logic\nprograms. In Proceedings of5th International\nConference and Symposium on Logic\nProgramming.\nMartinoviG Miroslav and Tomek\nStrzalkowski. 1992. Comparing two\ngrammar-based generation algorithms: A\ncase study. In Proceedings ofthe 30th\nAnnual Meeting, Newark, DE. Association\nfor Computational Linguistics.\nMaxwell, John and Ronald Kaplan. 1989. An\noverview of disjunctive constraint\nsatisfaction. In Proceedings ofthe\nInternational Workshop on Parsing\nTechnologies, pages 18-27.\nMcCarthy, John and Patrick Hayes. 1969.\nSome philosophical problems from the\nstandpoint of artificial intelligence. In\nMeltzer and Michie (1969). Reprinted in\nGinsberg (1987).\nMeltzer, Bernard and Donald Michie,\neditors. 1969. Machine Intelligence 4.\nEdinburgh University Press, Edinburgh,\nUK.\nMeurers, Detmar. 1994. On implementing\nan HPSG theory: Aspects of the logical\narchitecture, the formalization and the\nimplementation f Head-driven Phrase\nStructure Grammars. In Hinrichs,\nMeurers, and Nakazawa (1994).\nMeurers, Detmar. 1995. Towards a semantics\nfor lexical rules as used in HPSG. In\nProceedings ofthe Conference on Formal\nGrammar, Barcelona. Also in Proceedings of\nthe ACQUILEX II Workshop on Lexical Rules,\n1995, Cambridge, UK.\nMeurers, Detmar and Guido Minnen. 1995.\nA computational treatment of HPSG\nlexical rules as covariation in lexical\nentries. In Proceedings ofthe Fifth\nInternational Workshop on Natural Language\nUnderstanding and Logic Programming,\nLisbon, Portugal.\nMeurers, Detmar and Guido Minnen. 1996.\nOff-line constraint propagation for\nefficient HPSG processing. In Proceedings\nof TALN 96 (Joint Session with the Third\nInternational Conference on HPSG),\nMarseille, France.\nMiller, Philip and Ivan Sag. 1993. French\nClitic Climbing Without Clitics or\nClimbing. Unpublished Manuscript,\nUniversity of Lille and Stanford\nUniversity.\nMinnen, Guido. In preparation. Natural\nLanguage Processing with Constraint-Logic\nGrammars: Grammar Compilation for\nDeclarative Under-determination. Ph D.\nthesis.\nMinnen, Guido, Dale Gerdemann, and Thilo\nGOtz. 1995. Off-line optimization for\nearley-style HPSG processing. In\nProceedings ofthe 7th Conference ofthe EACL,\nDublin, Ireland.\nMinnen, Guido, Dale Gerdemann, and\nErhard Hinrichs. 1996. Direct automated\ninversion of logic grammars. New\nGeneration Computing 14(2):131-168.\nNaish, Lee. 1986. Negation and Control in\nProlog. Springer Verlag, New York.\nO'Keefe, Richard. 1990. The Craft of Prolog.\nMIT Press, Cambridge, MA.\nOliva, Karel. 1994. HPSG lexicon without\nlexical rules. In Proceedings ofthe 15th\nConference on Computational Linguistics\n(COLING), Kyoto, Japan.\nOpalka, Annette. 1995. Statische\nProgrammtransformationen zur\neffizienten Verarbeitung\nconstraintbasierter Grammatiken.\nDiplomarbeit, University of Stuttgart,\nStuttgart, Germany.\nPereira, Fernando and Stuart Shieber. 1987.\nProlog and Natural Language Analysis. CSLI\nLecture Notes. Center for the Study of\nLanguage and Information, Stanford\nUniversity, Stanford, CA.\nPettorossi, Alberto and Maurizio Proietti.\n1994. Transformations of logic programs:\nFoundations and techniques. Journal of\nLogic Programming 19/20:261-320.\nPollard, Carl and Ivan Sag. 1987.\nInformation-based Syntax and Semantics, Vol.\n1. Number 13 of CSLI Lecture Notes.\nCenter for the Study of Language and\nInformation, Stanford University,\nStanford, CA.\nPollard, Carl and Ivan Sag. 1994.\nHead-Driven Phrase Structure Grammar.\nUniversity of Chicago Press, Chicago, IL.\n"},{"#tail":"\n","@confidence":"0.998124916666666","#text":"\nComputational Linguistics Volume 23, Number 4\nRiehemann, Susanne. 1993. Word Formation\nin Lexical Type Hierarchies: A Case Study\nof bar-Adjectives in German. Master's\nthesis, University of Ti~bingen, Tiibingen,\nGermany. Also published as\nSfS-Report-02-93, Seminar fiir\nSprachwissenschaft, University of\nTi~bingen.\nSanfilippo, Antonio. 1995. Lexical\npolymorphism and word disambiguation.\nIn Proceedings ofthe American Associa tion.for\nArti~cial Intelligence (AAAI), Stanford\nUniversity, Stanford, CA.\nShieber, Stuart, Hans Uszkoreit, Fernando\nPereira, Jane Robinson, and Mabry Tyson.\n1983. The formalism and implementation\nof PATR II. In Research on Interactive\nAcquisition and Use of Knowledge. SRI\nInternational, Menlo Park, CA, pages\n39-79.\nTamaki, Hisao and Taisuke Sato. 1984.\nUnfold/Fold transformation f logic\nprograms. In Proceedings ofthe 2nd\nInternational Conference on Logic\nProgramming, Uppsala, Sweden.\nTorisawa, Kentaro and Jun'ichi Tsuji. 1996.\nOff-line raising, dependency analysis and\npartial unification. In Proceedings ofTALN\n96 (Joint Session with the Third International\nConference on HPSG), Marseille, France.\nvan Noord, Gertjan and Gosse Bouma. 1994.\nThe scope of adjuncts and the processing\nof lexical rules. In Proceedings ofthe 15th\nConference on Computational Linguistics\n(COLING), Kyoto, Japan.\n"}],"bodyText":[{"#tail":"\n","@confidence":"0.996715555555556","#text":"\nThis paper proposes anew computational treatment of lexical rules as used in the HPSG frame-\nwork. A compiler is described which translates a set of lexical rules and their interaction into a\ndefinite clause encoding, which is called by the base lexical entries in the lexicon. This way, the\ndisjunctive possibilities arising from lexical rule application are encoded as systematic covariation\nin the specification of lexical entries. The compiler ensures the automatic transfer of properties\nnot changed by a lexical rule. Program transformation techniques are used to advance the en-\ncoding. The final output of the compiler constitutes an efficient computational counterpart of the\nlinguistic generalizations captured by lexical rules and allows on-the-fly application of lexical\nrules.\n"},{"#tail":"\n","@confidence":"0.96470745","#text":"\nIn the paradigm of HPSG, lexical rules have become one of the key mechanisms used\nin current linguistic analysis. Computationally, lexical rules have mainly been dealt\nwith in two ways: On the one hand, lexical rules are used to expand out the full\nlexicon at compile-time. On the other hand, lexical rules are encoded as unary phrase\nstructure rules. Both of these computational treatments of lexical rules, however, have\nsignificant shortcomings with respect o lexical rules as used in HPSG.\nA computational treatment expanding out the lexicon cannot be used for the in-\ncreasing number of HPSG analyses that propose lexical rules that would result in an\ninfinite lexicon. Most current HPSG analyses of Dutch, German, Italian, and French\nfall into that category. 1 Furthermore, since lexical rules in such an approach only serve\nin a precompilation step, the generalizations captured by the lexical rules cannot be\nused at run-time. Finally, all such treatments of lexical rules currently available pre-\nsuppose a fully explicit notation of lexical rule specifications that transfer properties\nnot changed by the lexical rules to the newly created lexical entry. This conflicts with\nthe standard assumption made in HPSG that only the properties changed by a lexical\nrule need be mentioned. As shown in Meurers (1994) this is a well-motivated conven-\ntion since it avoids splitting up lexical rules to transfer the specifications that must be\npreserved for different lexical entries.\n? The authors are listed alphabetically. SFB 340, Kleine Wilhelmstr. 113, D-72074 Tiibingen, Germany.\nemail: {dm,minnen}@sfs.nphil.uni-tuebingen.de URL: http://www.sfs.nphil.uni-tuebingen.de/sfb\n"},{"#tail":"\n","@confidence":"0.986357756756757","#text":"\nComputational Linguistics Volume 23, Number 4\nTreatments of lexical rules as unary phrase structure rules also require their fully\nexplicit specification, which entails the last problem mentioned above. In addition,\ncomputationally treating lexical rules on a par with phrase structure rules fails to\ntake computational advantage of their specific properties. For example, the interaction\nof lexical rules is explored at run-time, even though the possible interaction can be\ndetermined at compile-time given the information available in the lexical rules and\nthe base lexical entries. 2\nBased on the research results reported in Meurers and Minnen (1995, 1996), we\npropose a new computational treatment of lexical rules that overcomes these short-\ncomings and results in a more efficient processing of lexical rules as used in HPSG.\nWe developed a compiler that takes as its input a set of lexical rules, deduces the nec-\nessary transfer of properties not changed by the individual lexical rules, and encodes\nthe set of lexical rules and their interaction i to definite relations constraining lexical\nentries. Each lexical entry is automatically extended with a definite clause encoding of\nthe lexical rule applications which the entry can undergo. The definite clauses thereby\nintroduce what we refer to as systematic covariation in lexical entries.\nDefinite relations are a convenient way of encoding the interaction of lexical rules,\nas they readily support various program transformations to improve the encoding: We\nshow that the definite relations produced by the compiler can be refined by program\ntransformation techniques to increase fficiency. The resulting encoding allows the\nexecution of lexical rules on-the-fly, i.e., coroutined with other constraints at some\ntime after lexical lookup. The computational treatment of lexical rules proposed can\nbe seen as an extension to the principled method discussed by G6tz and Meurers\n(1995, 1996, 1997b) for encoding the main building block of HPSG grammars--the\nimplicative constraints--as logic program.\nThe structure of the paper is as follows: We start with a brief introduction of the\nformal background on which our approach is based in Section 2. We then describe\n(Section 3) how lexical rules and their interaction can be encoded in a definite clause\nencoding that expresses systematic covariation in lexical entries. We show how the\nencoding of lexical rule interaction can be improved by specializing it for different\nword classes and, in Section 4, focus on an improvement of this specialization step\nby means of program transformation techniques. A further improvement relevant to\non-the-fly application of lexical rules is presented in Section 5. In Section 6, we dis-\ncuss implementation results and illustrate the efficiency of the proposed encoding. A\ncomparison with other computational approaches to lexical rules (Section 7) and some\nconcluding remarks (Section 8) end the paper.\n"},{"#tail":"\n","@confidence":"0.998516333333333","#text":"\nIn this section we introduce the formal setup of HPSG grammars that we assume and\ndiscuss two ways to formalize a lexical rule mechanism and their consequences for a\ncomputational treatment.\n"},{"#tail":"\n","@confidence":"0.921700666666667","#text":"\nAn HPSG grammar formally consists of two parts (Pollard and Sag 1994): The signature\ndefines the ontology of linguistic objects, and the theory, i.e., the usually implicative\nconstraints encoding the grammatical principles, describes the subset of those linguistic\n"},{"#tail":"\n","@confidence":"0.975638875","#text":"\nMeurers and Minnen Covariation Approach to HPSG Lexical Rules\nobjects that are grammatical. The constraints constituting the theory are expressions\nof a formal language that define the set of grammatical objects, in the sense that every\ngrammatical object is described by every principle in the theory.\nThe signature consists of the type hierarchy defining which types of objects ex-\nist and the appropriateness conditions pecifying which objects have which features\ndefined on them to represent their properties. 3 A signature is interpreted as follows:\nEvery object is assigned exactly one most specific type, and in case a feature is ap-\npropriate for some object of a certain type, then it is appropriate for all objects of this\ntype. 4\nA logic that provides the formal architecture required by Pollard and Sag (1994)\nwas defined by King (1989, 1994). The formal language of King allows the expression\nof grammatical principles using type assignments to refer to the type of an object\nand path equalities to require the (token) identity of objects. These atomic expressions\ncan be combined using conjunction, disjunction, and negation. The expressions are\ninterpreted by a set-theoretical semantics.\n"},{"#tail":"\n","@confidence":"0.974845826086957","#text":"\nWhile the setup of King provides a clear formal basis for basic HPSG grammars,\nnothing is said about how special inguistic mechanisms like lexical rules fit into this\nformal setup. Two formalizations of lexical rules as used by HPSG linguists have been\nproposed, the meta-level lexical rules (MLRs; Calcagno 1995; Calcagno and Pollard\n1995) and the .description-level l xical rules (DLRs; Meurers 1995). 5\n2.2.1 Meta-Level Lexical Rules. The MLR approach sees lexical rules in the more\ntraditional sense as relations between lexical entries, i.e., descriptions of word objects.\nThe set of lexical entries constituting the lexicon is closed under the application of\nlexical rules, which results in a (possibly infinite) set of lexical entries. In order to be\ngrammatical, every word object occurring in a sentence has to be described by one of\nthe descriptions in this expanded lexicon set. In the MLR setup, lexical rules are thus\nexternal to the rest of the theory, they only serve to provide an expanded lexicon set.\nLicensing grammatical words is then done by this set--the lexical rules play no direct\nrole. Externalizing the lexicon and lexical rule application from the theory in such a\nway has an interesting consequence, namely that the lexical entries serving as input\nto a lexical rule are not tested for grammaticality.\nA computational treatment of lexical rules that expands out the lexicon at compile-\ntime closely resembles the MLR interpretation of lexical rules. The work on MLRs can\ntherefore be seen as providing a semantics for such a computational treatment. It also\nallows a clear view of its restrictions: First, no restrictions on lexical entries serving\nas input to a lexical rule can be enforced that cannot be executed on the basis of\nthe information present in the lexical entry alone, 6and second, grammars including\nlexical rules that, under the MLR formalization, result in an infinite lexicon, can only\n"},{"#tail":"\n","@confidence":"0.907896333333333","#text":"\nlinguistic example. The in-specification of this lexical rule makes use of an append relation to constrain\nthe valence attribute of the auxiliaries erving as its input. In the lexicon, however, the complements of\nan auxiliary are uninstantiated because it raises the arguments of its verbal complement.\n"},{"#tail":"\n","@confidence":"0.607117857142857","#text":"\nComputational Linguistics Volume 23, Number 4\nsimple-word ---* LE1 v . . ? V LEn\nderived-word ~ (\\[IN LRl-in\\] A LRl-out) V . . . V (\\[IN LRm-in\\] A LRm-oUt)\nFigure 1\nThe extended lexicon under the DLR approach.\npartially be dealt with, for example, by using a depth bound on lexical rule application\nto ensure that a finite number of lexical entries is obtained. 7\n"},{"#tail":"\n","@confidence":"0.999737551724138","#text":"\nas relations between word objects. Lexical rules under this approach are part of the\ntheory, just like any other constraint of the grammar, and they relate the word objects\nlicensed by the base lexical entries to another set of well-formed word objects. Thus,\nunder the DLR approach, no new lexical entries are created, but the theory itself is\nextended in order to include lexical rules. One possibility for extending the theory is\nto introduce two subtypes of word, i.e., simple-word and derived-word, and define an\nadditional feature IN with appropriate value word for objects of type derived-word. The\nprinciples encoding the extended lexicon in such an approach are shown in Figure 1.\nEach basic lexical entry is a disjunct LE in an implicative constraint on simple-word.\nThis disjunction thus constitutes the base lexicon. The disjuncts in the constraint on\nderived-word, on the other hand, encode the lexical rules. The in-specification of a\nlexical rule specifies the IN feature, the out-specification, the derived word itself. Note\nthat the value of the IN feature is of type word and thus also has to satisfy either a\nbase lexical entry or an out-specification f a lexical rule. While this introduces the\nrecursion ecessary to permit successive l xical rule application, it also grounds the\nrecursion in a word described by a base lexical entry. Contrary to the MLR setup, the\nDLR formalization therefore requires all words feeding lexical rules to be grammatical\nwith respect o the theory.\nSince lexical rules are expressed in the theory just like any other part of the theory,\nthey are represented in the same way, as unary immediate dominance schemata. 8 This\nconception of lexical rules thus can be understood as underlying the computational\napproach that treats lexical rules as unary phrase structure rules as, for example,\nadopted in the LKB system (Copestake 1992). Both the input and output of a lexical\nrule, i.e., the mother and the daughter of a phrase structure rule, are available during\na generation or parsing process. As a result, in addition to the information present\nin the lexical entry, syntactic information can be accessed to execute the constraints\non the input of a lexical rule. The computational treatment of lexical rules that we\npropose in this paper is essentially a domain-specific refinement of such an approach\nto lexical rules. 9\n"},{"#tail":"\n","@confidence":"0.697312222222222","#text":"\nimmediate dominance schemata nd lexical rules, however, is that immediate dom-\ninance schemata re fully specified in the linguistic theory and can thus be directly\ninterpreted as a relation on objects. Lexical rules, on the other hand, are usually not\n7 This approach is, for example, taken in the ALE system. See Section 7 for more discussion of different\ncomputational pproaches.\n8 Elaborating this analogy, the IN feature of derived words can be understood as the DTRS feature of a\nphrase.\n9 See Section 7 for a more detailed discussion of the relation between our approach and this perspective\non lexical rules.\n"},{"#tail":"\n","@confidence":"0.97901225","#text":"\nA passivization lexical rule.\nwritten as fully specified relations between words, rather, only what is supposed to\nbe changed is specified.\nConsider, for example, the lexical rule in Figure 2, which encodes a passive lexicai\nrule like the one presented by Pollard and Sag (1987, 215) in terms of the setup of\nPollard and Sag (1994, ch. 9). This lexical rule could be used in a grammar of English\nto relate past participle forms of verbs to their passive form2 ?The rule takes the index\nof the least oblique complement of the input and assigns it to the subject of the output.\nThe index that the subject bore in the input is assigned to an optional prepositional\ncomplement in the output.\nOnly the verb form and some indices are specified to be changed, and thus other\ninput properties, like the phonology, the semantics, or the nonlocal specifications, are\npreserved in the output. This is so since the lexical rule in Figure 2 &quot;(like all lexical rules\nin HPSG) preserves all properties of the input not mentioned in the rule.&quot; (Pollard and\nSag \\[1994, 314\\], following Flickinger \\[1987\\]). This idea of preserving properties can be\nconsidered an instance of the well-known frame problem in AI (McCarthy and Hayes\n1969), and we will therefore refer to the specifications left implicit by the linguist as the\nframe specification, or simply frame, of a lexical rule. Not having to represent the frame\nexplicitly not only enables the linguist to express only the relevant hings, but also\nallows a more compact representation f lexical rules where explicit framing would\nrequire the rules to be split up (Meurers 1994).\nOne thus needs to distinguish the lexical rule specification provided by the linguist\nfrom the fully explicit lexical rule relations integrated into the theory. The formalization\nof DLRs provided by Meurers (1995) defines aformal exical rule specification language\nand provides a semantics for that language in two steps: A rewrite system enriches the\nlexical rule specification i to a fully explicit description of the kind shown in Figure 1.\nThis description can then be given the standard set-theoretical interpretation f King\n(1989, 1994). 11\n10 Note that the passivization lexical rule in Figure 2 is only intended to illustrate the mechanism. We do\nnot make the linguistic claim that passives hould be analyzed using such a lexical rule. For space\nreasons, the SYNSEM feature is abbreviated by its first letter. The traditional (First I Rest) list notation is\nused, and the operator ? stands for the append relation in the usual way.\n"},{"#tail":"\n","@confidence":"0.931138714285714","#text":"\nComputational Linguistics Volume 23, Number 4\nThe computational treatment we discuss in the rest of the paper follows this setup\nin that it automatically computes, for each lexical rule specification, the frames neces-\nsary to preserve the properties not changed by it. 12 We will show that the detection\nand specification of frames and the use of program transformation to advance their\nintegration into the lexicon encoding is one of the key ingredients of the covariation\napproach to HPSG lexical rules.\n"},{"#tail":"\n","@confidence":"0.999125","#text":"\nHaving situated the computational pproach presented in this paper as a computa-\ntional treatment of DLRs that emphasizes their domain-specific properties, we now\nturn to the compiler that realizes this approach. We describe four compilation steps\nthat translate a set of lexical rules, as specified by the linguist, and their interaction\ninto definite relations to constrain lexical entries. To give the reader a global idea of\nour approach, we focus on those aspects of the compiler that are crucial to the pre-\nsented conception of lexical rules. The different steps of the compiler are discussed\nwith emphasis on understandabil ity and not on formal details. 13\nFigure 3 shows the overall setup of the compiler. The first compilation step, dis-\ncussed in Section 3.1, translates lexical rules into a definite clause representation a d\nderives, for each lexical rule, a frame predicate that ensures the transfer of properties\nthat remain unchanged. In the second compilation step (Section 3.2), we determine the\npossible interaction of the lexical rules. This results in a finite-state automaton repre-\nsenting global lexical rule interaction, i.e., the interaction of lexical rules irrespective\nof the lexical entries in the lexicon. In the subsequent step of word class specialization\n(Section 3.3) this finite-state automaton is fine-tuned for each of the natural classes\nof lexical entries in the lexicon. In the fourth compilation step (Section 3.4) these au-\ntomata are translated into definite relations and the lexical entries are adapted to call\nthe definite relation corresponding to the automaton fine-tuned for the natural class\nto which they belong.\n"},{"#tail":"\n","@confidence":"0.91264325","#text":"\nWe start by translating each lexical rule into a definite clause predicate, called the\nlexical rdle predicate. The first argument of a lexical rule predicate corresponds to the\nin-specification of the lexical rule and the second argument to its out-specification.\nAssume the signature in Figure 4 on which we base the example throughout the\npaper and suppose the lexical rule specification shown in Figure 5.14 This lexical rule\napplies to base lexical entries that unify 15 wi th the in-specification, i.e., lexical entries\nspecifying B and Y as - . The derived lexical entry licenses word objects with + as the\nvalue of x and Y, and b as that of A.\nThe translation of the lexical rule into a predicate is trivial. The result is displayed\ndescription language.\n12 In order to focus on the computational aspects of the covariation approach, in this paper we will not go\ninto a discussion of the full lexical rule specification language introduced in Meurers (1995). The reader\ninterested in that language and its precise interpretation can find the relevant details in that paper.\n13 A more detailed presentation can be found in Minnen (in preparation).\n14 We use rather abstract lexical rules in the examples to be able to focus on the relevant aspects.\n15 Hinrichs and Nakazawa (1996) show that the question of whether the application criterion of lexical\nrules should be a subsumption ra unification test is an important question deserving of more\nattention. We here assume unification as the application criterion, which formally corresponds tothe\nconjunction ofdescriptions and their conversion to normal form (G6tz 1994). Computationally, a\nsubsumption test could equally well be used in our compiler.\n"},{"#tail":"\n","@confidence":"0.9390518","#text":"\ninteraction into\ndefinite relations\nin Figure 6. Though this predicate represents what was explicitly specified in the lexi-\ncal rule, it does not accomplish exactly what is intended. As discussed in Section 2.2.3,\nfeatures specified in a lexical entry unifying with the in-specification of the lexical rule\nthat are not specified differently in the out-specification of the lexical rule are intended\nto receive the same value on the derived word as on the input: The compiler imple-\nments this by enriching the lexical rule with type specifications and path equalities\nbetween the in- and the out-specification to arrive at an explicit representation of its\nframe.\nThe detection of which additional specifications are intended by the linguist cru-\ncially depends on the interpretation of the signature assumed in HPSG, discussed in\nSection 2.1. This interpretation makes it possible to determine which kind of word\nobjects (by ontological status fully specified) may undergo the rule. A type can always\nbe replaced by a disjunction of its most specific subtypes and the appropriate features\n"},{"#tail":"\n","@confidence":"0.9269556","#text":"\nA sample lexical entry.\nof each type are known. So, on the basis of the signature, we can determine which\n&quot;appropriate&quot; paths the linguist left unspecified in the out-specification f the lexical\nrule. For those appropriate paths not specified in the out-specification, one can then\nadd path equalities between the in- and the out-specifications of the lexical rule to\nensure framing of those path values.\nFrame specification becomes lightly more difficult when one considers type spec-\nifications of those paths in words serving as input to a lexical rule that occur in the\nout-specification f the lexical rule but are not assigned a type value. For example, the\nlexical rule 1 of Figure 6 applies to word objects with tl as their c value and to those\nhaving t2 as their c value. With respect o frame specification this means that there\ncan be lexical entries, such as the one in Figure 7, for which we need to make sure\nthat tl as the value of c gets transferred. 16\nOne would think that the type information tl, which is more specific than that\n16 A linguistic example based on the signature given by Pollard and Sag (1994) would be a lexical rule\nderiving predicative signs from nonpredicative ones, i.e., changing the PRD value of substantive signs\nfrom - to +, much like the lexical rule for NPs given by Pollard and Sag (1994, p. 360, fn. 20). In such\na Predicative Lexical Rule (which we only note as an example and not as a linguistic proposal) the\nsubtype of the head object undergoing the rule as well as the value of the features only appropriate for\nthe subtypes of substantive either is lost or must be specified by a separate rule for each of the subtypes.\n"},{"#tail":"\n","@confidence":"0.961351513513513","#text":"\nMeurers and Minnen Covariation Approach to HPSG Lexical Rules\nb lex lel, \\[:, _,\\]ollx framel\nFigure 8\nLexical rule predicate representing lexical rule 1.\n\\[B o lIB \\ ] c w r frame_l( , ). frame_l( |W tl \\[ ~1\\] Ch\\[W ~\\] L t2LZ\nFigure 9\nDefinition of the frame predicate for lexical rule 1.\ngiven in the output of the lexical rule, can be specified on the out-specification of the\nlexical rule if the specification of c is transferred as a whole (via structure sharing of\nthe value of c). This is not possible, though, since the values of x and Y are specified\nin the out-specification of the lexical rule. The problem seems to be that there is no\nnotion of sharing just the type of an object. However, introducing such type sharing\nwould not actually solve the problem, since one also needs to account for additional\nappropriate features. The subtypes of t have different appropriate features, the values\nof which have to be preserved. In particular, in case the lexical entry has t2 as the\nvalue of c, we need to ensure that the value of the feature z is transferred properly.\nTo ensure that no information is lost as a result of applying a lexical rule, it\nseems to be necessary to split up the lexical rule to make each instance deal with\na specific case. In the above example, this would result in two lexical rules: one for\nwords with tl as their c value and one for those with t2 as their c value. In the\nlatter case, we can also take care of transferring the value of z. However, as discussed\nby Meurers (1994), creating several instances of lexical rules can be avoided. Instead,\nthe disjunctive possibilities introduced by the frame specification are attached as a\nconstraint o a lexical rule. This is accomplished by having each lexical rule predicate\ncall a so-called frame predicate, which can have multiple defining clauses. So for the\nlexical rule 1, the frame specification is taken care of by extending the predicate in\nFigure 6 with a call to a frame predicate, as shown in Figure 8.17\nOn the basis of the lexical rule specification and the signature, the compiler de-\nduces the frame predicates without requiring additional specifications by the linguist.\nThe frame predicate for lexical rule 1 is defined by the two clauses displayed in Fig-\nure 9. The first case applies to lexical entries in which c is specified as tl. We have to\nensure that the value of the feature w is transferred. In the second case, when feature\nc has t2 as its value, we additionally have to ensure that z gets transferred. Note that\nneither clause of the frame predicate needs to specify the features A, X, and Y since\nthese features are changed by lex_rule_l. Furthermore, filling in features of the struc-\nture below z is unnecessary as the value of z is structure shared as a whole. Finally, if\na lexical entry specifies c as t, bothframe_l c auses apply. TM\n"},{"#tail":"\n","@confidence":"0.241296","#text":"\nComputational Linguistics Volume 23, Number 4\n"},{"#tail":"\n","@confidence":"0.958541571428571","#text":"\nFinite-state automaton representing free application.\nSumming up, we distinguish the lexical rule predicates encoding the specification\nof the linguist from the frame predicates taking care of the frame specification. Based\non the signature, the frame predicates are automatically derived from the lexical rule\npredicates and they can have a possibly large number of defining clauses. In Sec-\ntion 4 we will show that the encoding can be advanced in a way that eliminates the\nnondeterminism introduced by the multiply defined frame predicates.\n"},{"#tail":"\n","@confidence":"0.998577096774194","#text":"\nIn the second compilation step, we use the definite clause representation f a set\nof lexical rules, i.e., the lexical rule and the frame predicates, to compute a finite-\nstate automaton representing how the lexical rules interact (irrespective of the lexical\nentries).\nIn general, any lexical rule can apply to the output of another lexical rule, which is\nsometimes referred to as free application. As shown in Figure 10, this can be represented\nas a finite-state automaton that consists of a single state with a cycle from/into this\nstate for all lexical rules. 19 When looking at a specific set of lexical rules though, one\ncan be more specific as to which sequences of lexical rule applications are possible. One\ncan represent this information about he interaction of lexical rules as a more complex\nfinite-state automaton, which can be used to avoid trying lexical rule applications at\nrun-time that are bound to fail. To derive a finite-state automaton representing global\nlexical rule interaction, we first determine which lexical rules can possibly follow which\nother lexical rules in a grammar. The set of follow relationships i obtained by testing\nwhich in-specifications unify with which out-specifications. 2?\nTo illustrate the steps in determining lobal lexical rule interaction, let us add\nthree more lexical rules to the one discussed in Section 3.1. Figure 11 shows the full\nset of four lexical rules.\nFigure 12 shows the definite clause representations of lexical rules 2, 3, and 4 and\nthe frame predicates derived for them. The definite clauses representing lexical rule 1\nand its frame were already given in Figures 8 and 9. The follow relation obtained for\nthe set of four lexical rules is shown in Figure 13, where follow(LR,ListOfLRs) specifies\ncompilation process.\n19 We use the following conventions with respect o finite-state automata to represent lexical rule\ninteraction: The state annotated with an angle bracket represents the initial state. All states (including\nthe initial state) are final states. The labels of the transitions from one state to another are (disjunctions\nof) the lexical rule predicate indices, i.e., the lexical rule names constitute the alphabet of the finite-state\nautomaton.\n20 For the computation of the follow relationships, the specifications of the frame predicates are taken into\naccount. In case the frame relation called by a lexical rule has several defining clauses, the\ngeneralization of the frame possibilities is used.\n"},{"#tail":"\n","@confidence":"0.481875","#text":"\nA set of four lexical rules.\n"},{"#tail":"\n","@confidence":"0.811648","#text":"\nThe definite clause encoding of lexical rules 2, 3, and 4.\n"},{"#tail":"\n","@confidence":"0.976346866666667","#text":"\nfollow(I, \\[2, 3, 4\\]). follow(2, \\[1, 3, 4\\]). follow(3, \\[3, 4\\]). follow(4, \\[\\]).\nFigure 13\nThe follow relation for the four lexical rules of the example.\nthat only the lexical rules in ListOfLRs can possibly be applied to a word resulting\nfrom the application of lexical rule LR.\nOnce the follow relation has been obtained, it can be used to construct an automa-\nton that represents which lexical rule can be applied after which sequence of lexical\nrules. Special care has to be taken in case the same lexical rule can apply several times\nin a sequence. To obtain afinite automaton, such a repetition is encoded as a transition\ncycling back to a state in the lexical rule sequence preceding it.\nIn order to be able (in the following steps) to remove a transition representing\na certain lexical rule application in one sequence without eliminating the lexical rule\napplication from other sequences, every transition, except hose introducing cycles, is\ntaken to lead to a new state. The finite-state automaton in Figure 14 is constructed on\nthe basis of the follow relation of Figure 13.\n"},{"#tail":"\n","@confidence":"0.249225","#text":"\nComputational Linguistics Volume 23, Number 4\n"},{"#tail":"\n","@confidence":"0.970716275862069","#text":"\nFinite-state automaton representing global exical rule interaction.\nThe finite-state automaton representing global lexical rule interaction can be used\nas the backbone of a definite clause encoding of lexical rules and their interaction\n(see Section 3.4). Compared to free application, the finite-state automaton i Figure 14\nlimits the choice of lexical rules that can apply at a certain point. However, there still\nare several places where the choices can be further educed. One possible reduction\nof the above automaton consists of taking into account he propagation ofspecifications\nalong each possible path through the automaton. This corresponds toactually unifying\nthe out-specification f a lexical rule with the in-specification of the following lexical\nrule along each path in the automaton, instead of merely testing for unifiability, which\nwe did to obtain the follow relation. 21 As a result of unifying the out-specification\nof a lexical rule in a path of the finite-state automaton with the in-specification of\nthe following lexical rule, the out-specification f the second rule can become more\nspecific. This is because of the structure sharing between the second lexical rule's in-\nand out-specifications, which stem from the lexical rule and its frame specification.\nThis makes it possible to eliminate some of the transitions that seem to be possible\nwhen judging on the basis of the follow relation alone. 22\nFor example, solely on the basis of the follow relation, we are not able to discover\nthe fact that upon the successive application of lexical rules 1 and 2, neither lexical rule\n1 nor 2 can be applied again. Taking into account he propagation of specifications,\nthe result of the successive application of lexical rule 1 and lexical rule 2 in any order\n(leading to state q7 or q9) bears the value + on features w and Y. This excludes lexical\n21 The reason for first determining the automaton on the basis of the follow relation alone, instead of\ntaking propagation of specifications into account right from the start, is that the follow relations allow\na very simple construction of a finite-state automaton representing lexical rule interaction. Using\nunification right away would significantly complicate the algorithm, in particular for automata\ncontaining cycles.\n22 Note that in the case of transitions belonging to a cycle, only those transitions can be removed that are\nuseless at the first visit and after any traversal of the cycle.\n"},{"#tail":"\n","@confidence":"0.9918707","#text":"\nA lexical entry.\nrules 1 and 2 as possible followers of that sequence since their in-specifications do not\nunify with those values. As a result, the arcs 1(q7, q2) and 2(q9, q3), which are marked\nwith grey dots in Figure 14, can be removed.\nTwo problems remain: First, because of the procedural interpretation of lexical\nrules, duplicate lexical entries can possibly be derived. And second, relative to a spe-\ncific lexical entry, many sequences of lexical rules that are bound to fail are tried any-\nway. We tackle these problems by means of word class specialization, i.e., we prune\nthe automaton with respect o the propagation of specifications belonging to the base\nlexical entries.\n"},{"#tail":"\n","@confidence":"0.979429071428571","#text":"\nIn the third compilation step, the finite-state automaton representing lobal lexical\nrule interaction is fine-tuned for each base lexical entry in the lexicon. The result is\na pruned finite-state automaton. The pruning is done by performing the lexical rule\napplications corresponding to the transitions in the automaton representing lobal\nlexical rule interaction. To ensure termination in case of direct or indirect cycles, we\nuse a subsumption check. If the application of a particular lexical rule with respect\nto a lexical entry fails, we know that the corresponding transition can be pruned for\nthat entry. In case of indirect or direct cycles in the automaton, however, we cannot\nderive all possible lexical entries, as there may be infinitely many. Even though one can\nprune certain transitions even in such cyclic cases, it is possible that certain inapplicable\ntransitions remain in the pruned automaton. However, this is not problematic since the\nlexical rule application corresponding to such a transition will simply fail at run-time.\nConsider the base lexical entry in Figure 15. With respect o this base lexical en-\ntry, we fine-tune the finite-state automaton representing global lexical rule interaction\nby pruning transitions. In the automaton of Figure 14, we can prune the transitions\n{3(q2, q8), 4(q2, q6), 3(q3, q11), 4(q3, ql0), 3(ql, q4), 4(ql, q5)}, because the lexical rules\n3 and 4 can not be applied to a (derived) lexical entry that does not have both w\nand x of value +. As a consequence, the states q8, q15, q11, q18, q4, and q12 are no\nlonger reachable and the following transitions can be eliminated as well: {3(q8,q8),\n4(q8, q15), 3(q11, q11), 4(q11, q18), 3(q4, q4), 4(q4, q12)}. We can also eliminate the tran-\nsitions {4(q7,q13),4(q9, 17)}, because the lexical rule 4 requires the value of z to be\nempty list. Note that the lexical rules 3 and 4 remain applicable in q14 and q16.\nFurthermore, due to the procedural interpretation of lexical rules in a computa-\ntional system (in contrast o the original declarative intention), there can be sequences\nof lexical rule applications that produce identical entries. 23 To avoid having arcs in\nthe pruned automaton leading to such identical entries, we use a tabulation method\n23 Note that the order in which two lexical rules are applied is immaterial as long as both rules modify\nthe value of different features of a lexical entry.\n"},{"#tail":"\n","@confidence":"0.990875707317073","#text":"\nduring word class specialization that keeps track of the feature structures obtained for\neach node. If we find a feature structure for a node qn that is identical to the feature\nstructure corresponding to another node qm, the arc leading to qn or the arc leading\nto qm is discarded. 24In the example, q7 and q9 are such identical nodes. So we can\ndiscard either 2(q2, q7) or 1(q3, q9) and eliminate the arcs from states that then become\nunreachable. Choosing to discard 1(q3, q9), the pruned automaton for the example\nlexical entry looks as displayed in Figure 16. 25\nNote that word class specialization of lexical rule interaction does not influence the\nrepresentation f the lexical rules themselves. Pruning the finite-state automaton rep-\nresenting lobal lexical rule interaction only involves restricting lexical rule interaction\nin relation to the lexical entries in the lexicon.\nThe fine-tuning of the automaton representing lexical rule interaction results in\na finite-state automaton for each lexical entry in the lexicon. However, identical au-\ntomata are obtained for certain groups of lexical entries and, as shown in the next\nsection, each automaton is translated into definite relations only once. We therefore\nautomatically group the lexical entries into the natural classes for which the linguist\nintended a certain sequence of lexical rule applications to be possible. 26 No additional\nhand-specification is required. Moreover, the alternative computational treatment to\nexpand out the full lexicon at compile-time is just as costly and, furthermore, impos-\nsible in case of an infinite lexicon.\nAn interesting aspect of the idea of representing lexical rule interaction for partic-\nular word classes is that this allows a natural encoding of exceptions to lexical rules.\nMore specifically, the linguist specifies exceptions as a special property of either a lex-\nical rule or a lexical entry. During word class specialization, the compiler then deals\nwith such specifications by pruning the corresponding transitions in the finite-state\nautomaton representing global lexical rule interaction for the particular lexical entry\nunder consideration. This results in an encoding of exceptions to a lexical rule in the\ninteraction predicate called by the irregular lexical entries. An advantage of the setup\npresented is that entries that behave according to subregularities will automatically be\ngrouped together again and call the same interaction predicate. The final representa-\n24 In general, there is not always enough information available to determine whether two sequences of\nlexical rule applications produce identical entries. This is because in order to be able to treat recursive\nlexical rules producing infinite lexica, we perform word class specialization of the interaction predicate\ninstead of expanding out the lexicon.\n25 Note that an automaton can be made even more deterministic by unfurling instances of cycles prior to\npruning. In our example, unfurling the direct cycle by replacing 3(q14, q14) with\n{3(q14, q14~), 3(q14 ~, q14~), 4(q14 ~, q19~)} would allow pruning of the cyclic transition 3(q14 ~, q14 ~) and\nthe transition 4(q14, q19). Note, however, that unfurling of the first n instances of a cycle does not\nalways allow pruning of transitions, i.e., reduce nondeterminism.\n26 The pruned finite-state automaton constitutes valuable feedback, as it represents he interaction of the\nset of lexical rules possible for a word class in a succinct and perspicuous manner.\n"},{"#tail":"\n","@confidence":"0.964791333333333","#text":"\nAn extended lexical entry.\ntion of the lexical rules and the lexical entries remains, without a special specification\nof exceptions. 27\n"},{"#tail":"\n","@confidence":"0.998824","#text":"\nIn the fourth compilation step, the finite-state automata produced in the last step are\nencoded in definite clauses, called interaction predicates. The lexical entries belonging\nto a particular natural class all call the interaction predicate ncoding the automaton\nrepresenting lexical rule interaction for that class. Figure 17 shows the extended version\nof the lexical entry of Figure 15. The base lexical entry is fed into the first argument\nof the call to the interaction predicate q_l. For each solution to a call to q_l the value\nof ~ is a derived lexical entry.\nEncoding a finite-state automaton as definite relations is rather straightforward.\nIn fact, one can view the representations as notational variants of one another. Each\ntransition in the automaton is translated into a definite relation in which the corre-\nsponding lexical rule predicate is called, and each final state is encoded by a unit\nclause. Using an accumulator passing technique (O'Keefe 1990), we ensure that upon\nexecution of a call to the interaction predicate q_l a new lexical entry is derived as\nthe result of successive application of a number of lexical rules. Because of the word\nclass specialization step discussed in Section 3.3, the execution avoids trying out many\nlexical rule applications that are guaranteed to fail.\nWe illustrate the encoding with the finite-state automaton of Figure 16. As the\nlexical rules themselves are already translated into a definite clause representation in\nthe first compilation step, the interaction predicates only need to ensure that the right\ncombination of lexical rule predicates i called. The interaction predicate ncoding the\nfinite-state automaton of Figure 16 is shown in Figure 18. 28\nWe now have a first complete ncoding of the lexical rules and their interaction repre-\nsented as covariation i lexical entries. The encoding consists of three types of definite\n"},{"#tail":"\n","@confidence":"0.6581795","#text":"\nclasses of lexical entries in the lexicon.\nThe way these predicates interconnect is represented in Figure 19.\n27 Briscoe and Copestake (1996) argue that semi-productivity of lexical rules, which can be understood as\na generalization of exceptions to lexical rules, can be integrated with our approach by assigning\nprobabilities to the automaton associated with a particular lexical entry.\n28 In order to distinguish the different interaction predicates for the different classes of lexical entries, the\ncompiler indexes the names of the interaction predicates. Since for expository reasons we will only\ndiscuss one kind of lexical entry in this paper, we will not show those indices in the examples given.\n"},{"#tail":"\n","@confidence":"0.754956","#text":"\nThe definite relations representing the pruned finite state automaton of Figure 16.\n"},{"#tail":"\n","@confidence":"0.98807765","#text":"\nThe automata resulting from word class specialization group the lexical entries into\nnatural classes. In case the automata corresponding to two lexical entries are identical,\nthe entries belong to the same natural class. However, each lexical rule application, i.e.,\neach transition in an automaton, calls a frame predicate that can have a large number\nof defining clauses. Intuitively understood, each defining clause of a frame predicate\ncorresponds to a subclass of the class of lexical entries to which a lexical rule can be\napplied. During word class specialization, though, when the finite-state automaton\nrepresenting global lexical rule application is pruned with respect o a particular base\nlexical entry, we know which subclass we are dealing with. For each interaction defini-\ntion we can therefore check which of the flame clauses are applicable and discard the\nnon-applicable ones. We thereby eliminate the redundant nondeterminism resulting\nfrom multiply defined frame predicates.\nThe elimination of redundant nondeterminism is based on Unfold/Fold trans-\nformation techniques (Tamaki and Sato 1984). 29 The unfolding transformation is also\nreferred to as partial execution, for example, by Pereira and Shieber (1987). Intuitively\nunderstood, unfolding comprises the evaluation of a particular literal in the body of\na clause at compile-time. As a result, the literal can be removed from the body of\n29 This improvement of the covariation encoding can also be viewed as an instance of the program\ntransformation technique r ferred to as deletion of clauses with a finitely failed body (Pettorossi and Proietti\n1994).\n"},{"#tail":"\n","@confidence":"0.833960208333334","#text":"\nSchematic representation f the partial unfolding transformation.\nthe clause. Whereas unfolding can be viewed as a symbolic way of going forward in\ncomputation, folding constitutes a symbolic step backwards in computation.\nGiven a lexical entry as in Figure 15, we can discard all frame clauses that presup-\npose tl as the value of c, as discussed in the previous section. To eliminate the frame\npredicates completely, we can successively unfold the frame predicates and the lexical\nrule predicates with respect o the interaction predicates. 3? The successive unfolding\nsteps are schematically represented in Figure 20.\nSuch a transformation, however, would result in the loss of a representation f the\nlexical rule predicates that is independent of a particular word class, but an indepen-\ndent representation of lexical rules constitutes an advantage in space in case lexical\nrules can be applied across word classes. Our compiler therefore performs what can\nbe viewed as &quot;partial&quot; unfolding: it unfolds the frame predicates directly with respect\nto the interaction predicates, as shown in Figure 21.\nOne can also view this transformation assuccessive unfolding of the frame predi-\ncates and the lexical rule predicates with respect o the interaction predicates followed\nby a folding transformation that isolates the original lexical rule predicates. The defi-\nnite clause encoding of the interaction predicates resulting from unfolding the frame\npredicates for the lexical entry of Figure 15 with respect o the interaction predicate of\nFigure 18 is given in Figure 22. The lexical rule predicates called by these interaction\npredicates are defined as in Figures 8 and 12, except hat the frame predicates are no\nlonger called.\n30 Note that it is only possible to eliminate the frame predicates, since they are never called\nindependently of the covariation encoding.\n"},{"#tail":"\n","@confidence":"0.115092","#text":"\nComputational Linguistics Volume 23, Number 4\n"},{"#tail":"\n","@confidence":"0.924637823529412","#text":"\nUnfolding the frame predicates for the example ntry with respect to the interaction predicate.\n5. On-the-f ly Appl icat ion of Lexical Rules\nWe want our compiler to produce an encoding of lexical rules that allows us to execute\nlexical rules on-the-fly, i.e., at some time after lexical lookup. This is advantageous\nbecause postponing the execution of the interaction predicates allows more constraints\non the word to be collected. When the interaction predicate is finally called, as a result\nof syntactic information being present, many of its possible solutions imply fail. The\nsearch tree that would have resulted from pursuing these possibilities at the beginning\nof processing does not have to be explored. 31\nAs it stands, our encoding of lexical rules and their application as covariation in\nlexical entries does not yet support the application of lexical rules on-the-fly. With\nrespect o processing, the extended lexical entry of Figure 17 is problematic because\nbefore execution of the call to q_l, it is not known which information of the base lexical\nentry ends up in a derived lexical entry, i.e., tag ~ is completely uninstantiated. This\nmeans that there is no way of indexing the lexical entries according to what kind of\n31 According to Pollard and Sag (1987) on-the-fly application of lexical rules is also well-suited to playing\na role in a model of language use.\n"},{"#tail":"\n","@confidence":"0.959007","#text":"\nMeurers and Minnen Covariation Approach to HPSG Lexical Rules\nderived entry one is looking for. As a result, it is necessary to execute the call to q_l\nimmediately when the lexical entry is used during processing. Otherwise, there would\nbe no information available to restrict the search-space of a generation or parsing\nprocess.\nFlickinger, Pollard, and Wasow (1985) solve this problem using additional specifi-\ncations: &quot;By providing with each lexical rule a generic class frame which specifies the\ngeneral form and predictable properties of the rule's output, we avoid unnecessary\nwork when the lexical rule applies&quot; (p. 264). In the following, we show that the addi-\ntional specifications on the extended lexical entry needed to guide processing can be\ndeduced automatically.\n"},{"#tail":"\n","@confidence":"0.9997394375","#text":"\nThe intuitive idea behind this improvement of the covariation encoding is to lift into\nthe extended lexical entry the information that is ensured after all sequences of possible\nlexical rule applications for a particular base lexical entry have occurred. Note that this\nis not an unfolding step. Unfolding the interaction predicates with respect o the lexical\nentries basically expands out the lexicon off-line. Instead, what we do is factor out the\ninformation common to all definitions of the called interaction predicate by computing\nthe most specific generalization of these definitions.\nThe most specific generalization does not necessarily provide additional constrain-\ning information. However, usually it is the case that lexical entries resulting from lexical\nrule application differ in very few specifications compared to the number of specifica-\ntions in a base lexical entry. Most of the specifications of a lexical entry are assumed to\nbe passed unchanged via the automatically generated frame specification. Therefore,\nafter lifting the common information into the extended lexical entry, the out-argument\nin many cases contains enough information to permit a postponed execution of the\ninteraction predicate. When C is the common information, and D1, ..., Dk are the\ndefinitions of the interaction predicate called, we use distributivity to factor out C in\n"},{"#tail":"\n","@confidence":"0.996267523809524","#text":"\nto contain no further common factors. Once we have computed c, we use it to make\nthe extended lexical entry more specific. This technique closely resembles the off-line\nconstraint propagation technique described by Marriott, Naish, and Lassez (1988). The\nreader is referred to Meurers and Minnen (1996) for a more detailed iscussion of our\nuse of constraint propagation. 32\nWe illustrate the result of constraint propagation with our example grammar. Since\nthe running example of this paper was kept small, for expository reasons, by only\nincluding features that do get changed by one of the lexical rules (which violates\nthe empirical observation mentioned above), the full set of lexical rules would not\nprovide a good example. Let us therefore assume that only the lexical rules 1 and 2\nof Figure 11 are given. We then only obtain seven of the clauses of Figure 22: those\ncalling lex_rule_l or lex_rule_2, as well as the unit clauses for q_l, q_2, q3, and q_7.\nApplying constraint propagation to the extended lexical entry of Figure 17 yields the\nresult shown in Figure 23. The information common to all solutions to the interaction\ncall is lifted up into the lexical entry and becomes available upon lexical lookup.\n32 In certain cases an extension ofthe constraint language with named isjunctions orcontexted\nconstraints (Maxwell and Kaplan 1989; Eisele and D6rre 1990; Griffith 1996) can be used to circumvent\nconstraint propagation. Encoding the disjunctive possibilities for lexical rule application i this way,\ninstead of with definite clause attachments, makes all relevant lexical information available at lexical\nlookup. For analyses proposing infinite lexica, though, adefinite clause ncoding of disjunctive\npossibilities i still necessary and constraint propagation is indispensable forefficient processing.\n"},{"#tail":"\n","@confidence":"0.999453409090909","#text":"\nEven though we see on-the-fly application as a prerequisite of a computational treat-\nment of lexical rules, it is important o note that a postponed evaluation of lexical\nrule application is not always profitable. For example, in the case of generation, un-\nderspecification f the head of a construction can lead to massive nondeterminism or\neven nontermination when not enough restricting information is available to generate\nits complements (Martinovi4 and Strzalkowski 1992; Minnen, Gerdemann, and G6tz\n1995). Criteria to determine when it is most profitable to execute calls to an interaction\npredicate are required.\nOne possibility is to annotate the lexical rule encoding with such criteria by means\nof delay statements, as, for example, suggested by van Noord and Bouma (1994). While\nwe consider this kind of control facility (Naish \\[1986\\] and references therein) to be, in\ngeneral, indispensable for efficient processing, it also has disadvantages that make it\ndesirable to search for alternative or additional mechanisms: Delay statements presup-\npose the procedural annotation of an otherwise declarative specification. Substantial\ncomputational expertise is required to provide restrictions on the instantiation status\nof a goal, which must be fulfilled before the goal can be executed. Furthermore, the\ncomputational bookkeeping necessary for the delaying mechanism is very expensive.\nAn interesting alternative, therefore, is to automatically determine certain control prob-\nlems and deal with them in an off-line fashion along the lines of Minnen, Gerdemann,\nand G6tz (1995) and Minnen, Gerdemann, and Hinrichs (1996). They describe the\nuse of a dataflow analysis for an off-line improvement of grammars that determines\nautomatically when a particular goal in a clause can best be executed.\n"},{"#tail":"\n","@confidence":"0.999498181818182","#text":"\nThe computational treatment of lexical rules as covariation in lexical entries was im-\nplemented in Prolog by the authors in cooperation with Dieter Martini for the ConTroll\nsystem (Gerdemann and King 1994; G6tz and Meurers 1997a). We tested the covaria-\ntion approach with a complex grammar implementing an HPSG analysis covering the\nso-called aux-flip phenomenon, and partial-VP topicalization i the three clause types\nof German (Hinrichs, Meurers, and Nakazawa 1994). This test grammar includes eight\nlexical rules; some serve syntactic purposes, like the Partial-VP Topicalization Lexical\nRule, others are of morphological nature as, for example, an inflectional lexical rule\nthat relates nonfinite verbs to their finite form. Our compiler distinguished seven word\nclasses. Some nouns and most verbal exical entries fed lexical rules, and a single base\nlexical entry resulted in up to 12 derivations.\n"},{"#tail":"\n","@confidence":"0.99921","#text":"\nTo evaluate the time efficiency of the covariation encoding, we compared the parse\ntimes for our test grammar with three different computational encodings of the lexicon:\n"},{"#tail":"\n","@confidence":"0.9779616","#text":"\nMeurers and Minnen Covariation Approach to HPSG Lexical Rules\nthe expanded out lexicon, the basic covariation encoding, and the covariation encoding\nimproved by constraint propagation. 33\nAs discussed in Section 5.1, the parsing times with a covariation lexicon without\nconstraint propagation suffer significantly from the lack of information directly avail-\nable upon lexical ookup. For the test grammar, the resulting extended search-space of\nparsing with the basic covariation encoding leads to a performance that is, on average,\n18 times slower than that with the expanded out lexicon.\nThe use of constraint propagation, however, makes it possible to exploit he covari-\nation encoding of lexical rule application such that it results in an increase in speed.\nParsing with the test grammar using the constraint propagated covariation lexicon is,\non average, 25 percent faster than the performance with the expanded out lexicon.\nThe representation f lexical information in a constraint propagated covariation lex-\nicon makes the maximum information available at lexical lookup while requiring a\nminimum number of nondeterministic choices to obtain this information.\nSumming up, the relation between parsing times with the expanded out (EXP),\nthe covariation (COV), and the constraint propagated covariation (IMP) lexicon for\nthe test grammar can be represented asIMP : EXP : COV = 0.75 : 1 : 18. With respect\nto our test grammar, the constraint propagated covariation lexicon thus is the fastest\nlexical encoding.\n"},{"#tail":"\n","@confidence":"0.988324724137931","#text":"\nBesides the effect of requiring a minimum of nondeterministic choices and thereby\nreducing the number of resolution steps to increase time efficiency, the covariation\nencoding of lexical rules can result in an additional speedup since it reduces the space\nrequirements of large grammars.\nA comparison of space efficiency between an expanded out and a covariation lex-\nicon needs to compare two different encodings. The expanded out lexicon consists\nsolely of lexical entries, whereas the covariation lexicon is made up of three differ-\nent data structures: the extended base lexical entries, the interaction predicates, and\nthe lexical rule predicates. We focus on a qualitative valuation of space efficiency,\nrather than on providing results for the test grammar, since the space efficiency of\nthe covariation encoding relative to the expanded out lexicon is dependent on several\nproperties of the grammar: the number of lexical entries in the lexicon that can un-\ndergo lexical rule application, the size of the lexical entries, and the number of lexical\nentries belonging to a word class.\nSince only base lexical entries that feed lexical rules are modified by the lexical\nrule compiler, the covariation encoding naturally only results in space savings for\nthose lexical entries to which lexical rules apply.\nThe space efficiency is dependent on the size of the lexical entries since in the\ncovariation encoding much of the lexical information that is specified in a base lexical\nentry is not duplicated in the lexical entries that can be derived from it, as is the case\nfor an expanded lexicon. Thus, the more information represented in a base lexical\nentry, the greater the space saving achieved by the covariation encoding. In lexically\noriented grammar formalisms like HPSG, the lexical entries are highly information\nrich. A covariation treatment of HPSG lexica therefore can be particularly profitable.\nThe number of lexical entries belonging to a word class is relevant since the inter-\naction predicates are identical for all lexical entries belonging to the same word class.\n33 The lexicon of the test grammar can be expanded out off-line since the recursive Complement\nExtraction Lexical Rule applies only to full verbs, i.e, lexical entries with a complement list of finite\nlength. As a result, the grammar does not have an infinite lexicon.\n"},{"#tail":"\n","@confidence":"0.9650955","#text":"\nComputational Linguistics Volume 23, Number 4\nThis means that the more lexical entries in a word class, the greater the saving in\nspace. The covariation approach therefore is particularly attractive for grammars with\na large lexicon.\n"},{"#tail":"\n","@confidence":"0.99835575","#text":"\nThe powerful mechanism of lexical rules (Carpenter 1991) has been used in many\nnatural language processing systems. In this section we briefly discuss some of the\nmore prominent approaches and compare them with the treatment proposed in this\npaper.\n"},{"#tail":"\n","@confidence":"0.998799428571428","#text":"\nA common computational treatment of lexical rules adopted, for example, in the ALE\nsystem (Carpenter and Penn 1994) consists of computing the transitive closure of the\nbase lexical entries under lexical rule application at compile-time. While this provides\na front-end to include lexical rules in the grammars, it has the disadvantage that the\ngeneralizations captured by lexical rules are not used for computation. We mentioned\nin Section 2.2 that eliminating lexical rules in a precompilation step makes it impossible\nto process lexical rules or lexical entries that impose constraints that can only be\nproperly executed once information from syntactic processing is available. A related\nproblem is that for analyses resulting in infinite lexica, the number of lexical rule\napplications needs to be limited. In the ALE system, for example, a depth bound can\nbe specified for this purpose. Finally, as shown in Section 6, using an expanded out\nlexicon can be less time and space efficient han using a lexicon encoding that makes\ncomputational use of generalizations over lexical information, as, for example, the\ncovariation encoding.\n"},{"#tail":"\n","@confidence":"0.978196090909091","#text":"\nAnother common approach to lexical rules is to encode them as unary phrase structure\nrules. This approach is taken, for example, in LKB (Copestake 1992) where lexical rules\nare introduced on a par with phrase structure rules and the parser makes no distinction\nbetween lexical and nonlexical rules (Copestake 1993, 31). A similar method is included\nin PATR-II (Shieber et al 1983) and can be used to encode lexical rules as binary\nrelations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or the\nTFS system (Emele and Zajac 1990; Emele 1994). The covariation approach described\nin this paper can be viewed as a domain-specific refinement of such a treatment of\nlexical rules.\nThe encoding of lexical rules used in the covariation approach is related to the\nwork of van Noord and Bouma (1994), who describe the hand-encoding of a single\nlexical rule as definite relations and show how these relations can be used to constrain\na lexical entry. The covariation approach builds on this proposal and extends it in\nthree ways: First, the approach shows how to detect and encode the interaction of a\nset of lexical rules. Second, it provides a way to automatically obtain a definite clause\nencoding of lexical rules and their interaction. Finally, it automatically derives the\nframe specification for lexical rules such that, following standard HPSG practice, only\nthe information changed in a lexical rule needs to be specified.\n7.3 Alternative Ways to Express Lexical Generalizations\nLexical rules have not gone unchallenged as a mechanism for expressing eneraliza-\ntions over lexical information. In a number of proposals, lexical generalizations are\ncaptured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992;\n"},{"#tail":"\n","@confidence":"0.9550506","#text":"\nMeurers and Minnen Covariation Approach to HPSG Lexical Rules\nRiehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995). The lexical\nentries are only partially specified, and various specializations are encoded via the\ntype hierarchy, definite clause attachments, or a macro hierarchy.\nThese approaches seem to propose a completely different way to capture lexical\ngeneralizations. It is therefore interesting that the covariation lexical rule compiler\nproduces a lexicon encoding that, basically, uses an underspecification representation:\nThe resulting definite clause representation after constraint propagation represents the\ncommon information in the base lexical entry, and uses a definite clause attachment\nto encode the different specializations.\n"},{"#tail":"\n","@confidence":"0.998813352941176","#text":"\nWe presented a new computational treatment of HPSG lexical rules by describing a\ncompiler that translates a set of lexical rules as specifed by a linguist into definite\nrelations, which are used to constrain lexical entries. The frame of a lexical rule and\nlexical rule interaction is automatically determined and the interaction is represented\nas a finite-state automaton. The automaton allows us to encode lexical rule interaction\nwithout actually having to apply lexical rules a possibly infinite number of times.\nWord classes relevant o lexical rule application are automatically detected and the\ncorresponding finite-state automata re refined in order to avoid lexical rule applica-\ntions that are guaranteed to fail. The refined automata re encoded as definite relations\nand each base lexical entry is extended to call the relation corresponding to its class.\nFinally, the encoding of lexical rules and their interaction is advanced using constraint\npropagation to allow coroutining of its execution with other grammar constraints. This\nreduces the number of nondeterministic choices related to lexical lookup, and, more\nimportantly, allows syntactic information to be used to ensure termination of the co-\nvariation encoding of lexical rules. Finally, we discussed implementation results and\nillustrated the improvement in time and space efficiency resulting from the covariation\nencoding.\n"},{"#tail":"\n","@confidence":"0.931657666666667","#text":"\nThe research reported here was supported\nby Teilprojekt B4 &quot;From Constraints o\nRules: Efficient Compilation of HPSG\nGrammars&quot; of SFB 340 &quot;Sprachtheoretische\nGrundlagen f~ir die Computerlinguistik&quot; of\nthe Deutsche Forschungsgemeinschaft. The\nauthors wish to thank Thilo G6tz and Dale\nGerdemann, Erhard Hinrichs, Paul King,\nSuresh Manandhar, Dieter Martini, Bill\nRounds, and the anonymous reviewers. Of\ncourse, the authors are responsible for all\nremaining errors.\n"},{"#tail":"\n","@confidence":"0.538464333333333","#text":"\nSome of the above papers can be obtained\nelectronically through the URL provided on\nthe first page.\n"}],"#text":"\n","affiliation":{"#tail":"\n","@confidence":"0.975098","#text":"\nUniversity of Tiibingen\n"},"sectionHeader":[{"#tail":"\n","@confidence":"0.993778","@genericHeader":"abstract","#text":"\n1. Introduction\n"},{"#tail":"\n","@confidence":"0.978191","@genericHeader":"keywords","#text":"\n2. Background\n"},{"#tail":"\n","@confidence":"0.778279","@genericHeader":"introduction","#text":"\n6 The Partial-VP Topicalization Lexical Rule proposed by Hinrichs and Nakazawa (1994, 10) is a\n"},{"#tail":"\n","@confidence":"0.973793","@genericHeader":"method","#text":"\n6. Efficiency Evaluation\n"},{"#tail":"\n","@confidence":"0.864929","@genericHeader":"related work","#text":"\n7. Related Work\n"},{"#tail":"\n","@confidence":"0.620423","@genericHeader":"conclusions","#text":"\n8. Summary\n"},{"#tail":"\n","@confidence":"0.964338","@genericHeader":"acknowledgments","#text":"\nAcknowledgments\n"},{"#tail":"\n","@confidence":"0.98527","@genericHeader":"references","#text":"\nReferences\n"}],"page":[{"#tail":"\n","@confidence":"0.998697","#text":"\n544\n"},{"#tail":"\n","@confidence":"0.997233","#text":"\n545\n"},{"#tail":"\n","@confidence":"0.96415","#text":"\n546\n"},{"#tail":"\n","@confidence":"0.999209","#text":"\n547\n"},{"#tail":"\n","@confidence":"0.993139","#text":"\n548\n"},{"#tail":"\n","@confidence":"0.996992","#text":"\n549\n"},{"#tail":"\n","@confidence":"0.962364","#text":"\n550\n"},{"#tail":"\n","@confidence":"0.99228","#text":"\n551\n"},{"#tail":"\n","@confidence":"0.988044","#text":"\n552\n"},{"#tail":"\n","@confidence":"0.99609","#text":"\n553\n"},{"#tail":"\n","@confidence":"0.991137","#text":"\n554\n"},{"#tail":"\n","@confidence":"0.95511","#text":"\n555\n"},{"#tail":"\n","@confidence":"0.98833","#text":"\n556\n"},{"#tail":"\n","@confidence":"0.981326","#text":"\n557\n"},{"#tail":"\n","@confidence":"0.863747","#text":"\n558\n"},{"#tail":"\n","@confidence":"0.868887","#text":"\n559\n"},{"#tail":"\n","@confidence":"0.956589","#text":"\n560\n"},{"#tail":"\n","@confidence":"0.997003","#text":"\n561\n"},{"#tail":"\n","@confidence":"0.979531","#text":"\n562\n"},{"#tail":"\n","@confidence":"0.991074","#text":"\n563\n"},{"#tail":"\n","@confidence":"0.993029","#text":"\n564\n"},{"#tail":"\n","@confidence":"0.970819","#text":"\n565\n"},{"#tail":"\n","@confidence":"0.969902","#text":"\n566\n"},{"#tail":"\n","@confidence":"0.94134","#text":"\n567\n"},{"#tail":"\n","@confidence":"0.997703","#text":"\n568\n"}],"category":{"#tail":"\n","@confidence":"0.162925","#text":"\nMeurers and Minnen Covariation Approach to HPSG Lexical Rules\n"},"figureCaption":[{"#tail":"\n","@confidence":"0.495606","#text":"\nFigure 2\n"},{"#tail":"\n","@confidence":"0.630712","#text":"\nFigure 6\nDefinite clause representation f lexical rule 1.\nword\\[C tl\\]\nFigure 7\n"},{"#tail":"\n","@confidence":"0.248155","#text":"\nFigure 11\n"},{"#tail":"\n","@confidence":"0.263396","#text":"\nFigure 15\n"},{"#tail":"\n","@confidence":"0.658215","#text":"\nFigure 21\n"}],"table":[{"#tail":"\n","@confidence":"0.632825","#text":"\nComputational Linguistics Volume 23, Number 4\nT\nt\\[w bool 1 val \\] x bool|\nt, t2\\[z list\\]\nFigure 4\nAn example signature.\n"},{"#tail":"\n","@confidence":"0.417573166666667","#text":"\nComputational Linguistics Volume 23, Number 4\n3\n1 2 3 ~,.,~ 4\nq3\nFigure 16\nPruned finite state automaton representing lexical rule interaction for a lexical entry.\n"},{"#tail":"\n","@confidence":"0.225554","#text":"\nComputational Linguistics Volume 23, Number 4\n"},{"#tail":"\n","@confidence":"0.9727312","#text":"\nComputational Linguistics Volume 23, Number 4\n- 1\\] Lct2\\[zB\\]j c x_\nt2Lz \\[\\](a'b)JJ\nFigure 23\nAn entry suitable for on-the-fly application (lexical rules 1 and 2 only).\n"}]}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.682988","#tail":"\n","@no":"0","#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.947809","#text":"University of Tiibingen"},{"#tail":"\n","@confidence":"0.859976","#text":"University of Tiibingen"}],"author":[{"#tail":"\n","@confidence":"0.941755","#text":"W Detmar Meurers"},{"#tail":"\n","@confidence":"0.994412","#text":"Guido Minnen"}],"abstract":{"#tail":"\n","@confidence":"0.985300777777778","#text":"This paper proposes anew computational treatment of lexical rules as used in the HPSG framework. A compiler is described which translates a set of lexical rules and their interaction into a definite clause encoding, which is called by the base lexical entries in the lexicon. This way, the disjunctive possibilities arising from lexical rule application are encoded as systematic covariation in the specification of lexical entries. The compiler ensures the automatic transfer of properties not changed by a lexical rule. Program transformation techniques are used to advance the encoding. The final output of the compiler constitutes an efficient computational counterpart of the linguistic generalizations captured by lexical rules and allows on-the-fly application of lexical rules."},"title":{"#tail":"\n","@confidence":"0.9988005","#text":"A Computational Treatment of Lexical Rules in HPSG as Covariation in Lexical Entries"}}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"Briscoe, Ted and Ann Copestake. 1996. Controlling the application of lexical rules. In Proceedings ofthe SIGLEX Workshop on Breadth and Depth of Semantic Lexicons, Santa Cruz, CA."},"#text":"\n","marker":{"#tail":"\n","#text":"Briscoe, Copestake, 1996"},"location":{"#tail":"\n","#text":"Santa Cruz, CA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ate ncoding the finite-state automaton of Figure 16 is shown in Figure 18. 28 We now have a first complete ncoding of the lexical rules and their interaction repre- sented as covariation i lexical entries. The encoding consists of three types of definite clause predicates: 1. Lexical rule predicates representing the lexical rules; 2. Frame predicates specifying the frame for the lexical rule predicates; and 3. Interaction predicates encoding lexical rule interaction for the natural classes of lexical entries in the lexicon. The way these predicates interconnect is represented in Figure 19. 27 Briscoe and Copestake (1996) argue that semi-productivity of lexical rules, which can be understood as a generalization of exceptions to lexical rules, can be integrated with our approach by assigning probabilities to the automaton associated with a particular lexical entry. 28 In order to distinguish the different interaction predicates for the different classes of lexical entries, the compiler indexes the names of the interaction predicates. Since for expository reasons we will only discuss one kind of lexical entry in this paper, we will not show those indices in the examples given. 557 Computational Linguistics Volum","@endWordPosition":"7388","@position":"45361","annotationId":"T1","@startWordPosition":"7385","@citStr":"Briscoe and Copestake (1996)"}},"title":{"#tail":"\n","#text":"Controlling the application of lexical rules."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe SIGLEX Workshop on Breadth and Depth of Semantic Lexicons,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Ted Briscoe"},{"#tail":"\n","#text":"Ann Copestake"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1992"},"editor":{"#tail":"\n","#text":"Briscoe, Ted, Ann Copestake, and Valeria de Paiva, editors."},"rawString":{"#tail":"\n","#text":"Briscoe, Ted, Ann Copestake, and Valeria de Paiva, editors. 1992. Default Inheritance Within UniX'cation-Based Approaches tothe Lexicon. Cambridge University Press, Cambridge, UK."},"#text":"\n","marker":{"#tail":"\n","#text":"1992"},"publisher":{"#tail":"\n","#text":"Cambridge University Press,"},"location":{"#tail":"\n","#text":"Cambridge, UK."},"title":{"#tail":"\n","#text":"Default Inheritance Within UniX'cation-Based Approaches tothe Lexicon."},"@valid":"true"},{"date":{"#tail":"\n","#text":"1995"},"note":{"#tail":"\n","#text":"Unpublished manuscript,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"es using type assignments to refer to the type of an object and path equalities to require the (token) identity of objects. These atomic expressions can be combined using conjunction, disjunction, and negation. The expressions are interpreted by a set-theoretical semantics. 2.2 Lexical Rules in HPSG While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special inguistic mechanisms like lexical rules fit into this formal setup. Two formalizations of lexical rules as used by HPSG linguists have been proposed, the meta-level lexical rules (MLRs; Calcagno 1995; Calcagno and Pollard 1995) and the .description-level l xical rules (DLRs; Meurers 1995). 5 2.2.1 Meta-Level Lexical Rules. The MLR approach sees lexical rules in the more traditional sense as relations between lexical entries, i.e., descriptions of word objects. The set of lexical entries constituting the lexicon is closed under the application of lexical rules, which results in a (possibly infinite) set of lexical entries. In order to be grammatical, every word object occurring in a sentence has to be described by one of the descriptions in this expanded lexicon set. In the MLR setup, lexi","@endWordPosition":"1286","@position":"8399","annotationId":"T2","@startWordPosition":"1285","@citStr":"Calcagno 1995"}},"title":{"#tail":"\n","#text":"Interpreting lexical rules."},"#tail":"\n","institution":{"#tail":"\n","#text":"Ohio State University and University of T~ibingen."},"rawString":{"#tail":"\n","#text":"Calcagno, Mike. 1995. Interpreting lexical rules. In Proceedings ofthe Conference on Formal Grammar, Barcelona. Also in: Proceedings of the ACQUILEX II Workshop on Lexical Rules, 1995, Cambridge, UK. Calcagno, Mike, Detmar Meurers, and Carl Pollard. In preparation. On the nature of lexical rules in head-driven phrase structure grammar. Unpublished manuscript, Ohio State University and University of T~ibingen."},"#text":"\n","marker":{"#tail":"\n","#text":"Calcagno, 1995"},"location":{"#tail":"\n","#text":"Cambridge, UK. Calcagno, Mike, Detmar Meurers, and"},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe Conference"},"@valid":"false","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Mike Calcagno"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"note":{"#tail":"\n","#text":"Unpublished manuscript,"},"institution":{"#tail":"\n","#text":"Ohio State University,"},"rawString":{"#tail":"\n","#text":"Calcagno, Mike and Carl Pollard. 1995. Lexical rules in HPSG: What are they? Unpublished manuscript, Ohio State University, Columbus, OH."},"#text":"\n","marker":{"#tail":"\n","#text":"Calcagno, Pollard, 1995"},"location":{"#tail":"\n","#text":"Columbus, OH."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ssignments to refer to the type of an object and path equalities to require the (token) identity of objects. These atomic expressions can be combined using conjunction, disjunction, and negation. The expressions are interpreted by a set-theoretical semantics. 2.2 Lexical Rules in HPSG While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special inguistic mechanisms like lexical rules fit into this formal setup. Two formalizations of lexical rules as used by HPSG linguists have been proposed, the meta-level lexical rules (MLRs; Calcagno 1995; Calcagno and Pollard 1995) and the .description-level l xical rules (DLRs; Meurers 1995). 5 2.2.1 Meta-Level Lexical Rules. The MLR approach sees lexical rules in the more traditional sense as relations between lexical entries, i.e., descriptions of word objects. The set of lexical entries constituting the lexicon is closed under the application of lexical rules, which results in a (possibly infinite) set of lexical entries. In order to be grammatical, every word object occurring in a sentence has to be described by one of the descriptions in this expanded lexicon set. In the MLR setup, lexical rules are thus external ","@endWordPosition":"1290","@position":"8427","annotationId":"T3","@startWordPosition":"1287","@citStr":"Calcagno and Pollard 1995"}},"title":{"#tail":"\n","#text":"Lexical rules in HPSG: What are they?"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Mike Calcagno"},{"#tail":"\n","#text":"Carl Pollard"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1991"},"rawString":{"#tail":"\n","#text":"Carpenter, Bob. 1991. The generative power of categorial grammars and Head-Driven Phrase Structure Grammars with lexical rules. Computational Linguistics, 17(3):301-314."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","pages":{"#tail":"\n","#text":"17--3"},"marker":{"#tail":"\n","#text":"Carpenter, 1991"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"s belonging to the same word class. 33 The lexicon of the test grammar can be expanded out off-line since the recursive Complement Extraction Lexical Rule applies only to full verbs, i.e, lexical entries with a complement list of finite length. As a result, the grammar does not have an infinite lexicon. 563 Computational Linguistics Volume 23, Number 4 This means that the more lexical entries in a word class, the greater the saving in space. The covariation approach therefore is particularly attractive for grammars with a large lexicon. 7. Related Work The powerful mechanism of lexical rules (Carpenter 1991) has been used in many natural language processing systems. In this section we briefly discuss some of the more prominent approaches and compare them with the treatment proposed in this paper. 7.1 Off-line Expansion of Lexical Rules A common computational treatment of lexical rules adopted, for example, in the ALE system (Carpenter and Penn 1994) consists of computing the transitive closure of the base lexical entries under lexical rule application at compile-time. While this provides a front-end to include lexical rules in the grammars, it has the disadvantage that the generalizations capture","@endWordPosition":"10257","@position":"63978","annotationId":"T4","@startWordPosition":"10256","@citStr":"Carpenter 1991"}},"title":{"#tail":"\n","#text":"The generative power of categorial grammars and Head-Driven Phrase Structure Grammars with lexical rules."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Bob Carpenter"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Carpenter, Bob and Gerald Penn. 1994."},"#text":"\n","marker":{"#tail":"\n","#text":"Carpenter, Penn, 1994"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"me 23, Number 4 This means that the more lexical entries in a word class, the greater the saving in space. The covariation approach therefore is particularly attractive for grammars with a large lexicon. 7. Related Work The powerful mechanism of lexical rules (Carpenter 1991) has been used in many natural language processing systems. In this section we briefly discuss some of the more prominent approaches and compare them with the treatment proposed in this paper. 7.1 Off-line Expansion of Lexical Rules A common computational treatment of lexical rules adopted, for example, in the ALE system (Carpenter and Penn 1994) consists of computing the transitive closure of the base lexical entries under lexical rule application at compile-time. While this provides a front-end to include lexical rules in the grammars, it has the disadvantage that the generalizations captured by lexical rules are not used for computation. We mentioned in Section 2.2 that eliminating lexical rules in a precompilation step makes it impossible to process lexical rules or lexical entries that impose constraints that can only be properly executed once information from syntactic processing is available. A related problem is that for analy","@endWordPosition":"10312","@position":"64326","annotationId":"T5","@startWordPosition":"10309","@citStr":"Carpenter and Penn 1994"}},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Bob Carpenter"},{"#tail":"\n","#text":"Gerald Penn"}]}},{"tech":{"#tail":"\n","#text":"Technical report,"},"date":{"#tail":"\n","#text":"1994"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"German, Italian, and French fall into that category. 1 Furthermore, since lexical rules in such an approach only serve in a precompilation step, the generalizations captured by the lexical rules cannot be used at run-time. Finally, all such treatments of lexical rules currently available pre- suppose a fully explicit notation of lexical rule specifications that transfer properties not changed by the lexical rules to the newly created lexical entry. This conflicts with the standard assumption made in HPSG that only the properties changed by a lexical rule need be mentioned. As shown in Meurers (1994) this is a well-motivated conven- tion since it avoids splitting up lexical rules to transfer the specifications that must be preserved for different lexical entries. ? The authors are listed alphabetically. SFB 340, Kleine Wilhelmstr. 113, D-72074 Tiibingen, Germany. email: {dm,minnen}@sfs.nphil.uni-tuebingen.de URL: http://www.sfs.nphil.uni-tuebingen.de/sfb /b4home.html 1 This is, for example, the case for all proposals working with verbal exical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction ","@endWordPosition":"352","@position":"2289","annotationId":"T6","@startWordPosition":"352","@citStr":"(1994)"},{"#tail":"\n","#text":" the sense that every grammatical object is described by every principle in the theory. The signature consists of the type hierarchy defining which types of objects ex- ist and the appropriateness conditions pecifying which objects have which features defined on them to represent their properties. 3 A signature is interpreted as follows: Every object is assigned exactly one most specific type, and in case a feature is ap- propriate for some object of a certain type, then it is appropriate for all objects of this type. 4 A logic that provides the formal architecture required by Pollard and Sag (1994) was defined by King (1989, 1994). The formal language of King allows the expression of grammatical principles using type assignments to refer to the type of an object and path equalities to require the (token) identity of objects. These atomic expressions can be combined using conjunction, disjunction, and negation. The expressions are interpreted by a set-theoretical semantics. 2.2 Lexical Rules in HPSG While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special inguistic mechanisms like lexical rules fit into this formal setup. Two formal","@endWordPosition":"1174","@position":"7678","annotationId":"T7","@startWordPosition":"1174","@citStr":"(1994)"},{"#tail":"\n","#text":"nfinite lexicon, can only 3 The terminology used in the literature varies. Types are also referred to as sorts, appropriateness conditions as feature declarations, and features as attributes. To avoid confusion, we will only use the terminology introduced in the text. 4 This interpretation f the signature is sometimes referred to as closed world (Gerdemann and King 1994; Gerdemann 1995). 5 An in-depth discussion including a comparison of both approaches i provided in Calcagno, Meurers, and Pollard (in preparation). 6 The Partial-VP Topicalization Lexical Rule proposed by Hinrichs and Nakazawa (1994, 10) is a linguistic example. The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries erving as its input. In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement. 545 Computational Linguistics Volume 23, Number 4 simple-word ---* LE1 v . . ? V LEn derived-word ~ (\\[IN LRl-in\\] A LRl-out) V . . . V (\\[IN LRm-in\\] A LRm-oUt) Figure 1 The extended lexicon under the DLR approach. partially be dealt with, for example, by using a depth bound on lexical rul","@endWordPosition":"1637","@position":"10605","annotationId":"T8","@startWordPosition":"1636","@citStr":"(1994, 10)"},{"#tail":"\n","#text":"plicit framing would require the rules to be split up (Meurers 1994). One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory. The formalization of DLRs provided by Meurers (1995) defines aformal exical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification i to a fully explicit description of the kind shown in Figure 1. This description can then be given the standard set-theoretical interpretation f King (1989, 1994). 11 10 Note that the passivization lexical rule in Figure 2 is only intended to illustrate the mechanism. We do not make the linguistic claim that passives hould be analyzed using such a lexical rule. For space reasons, the SYNSEM feature is abbreviated by its first letter. The traditional (First I Rest) list notation is used, and the operator ? stands for the append relation in the usual way. 1l Manandhar (1995) proposes to unify these two steps by including an update operator in the 547 Computational Linguistics Volume 23, Number 4 The computational treatment we discuss in the rest of the p","@endWordPosition":"2673","@position":"16912","annotationId":"T9","@startWordPosition":"2672","@citStr":"(1989, 1994)"},{"#tail":"\n","#text":"s serving as input to a lexical rule that occur in the out-specification f the lexical rule but are not assigned a type value. For example, the lexical rule 1 of Figure 6 applies to word objects with tl as their c value and to those having t2 as their c value. With respect o frame specification this means that there can be lexical entries, such as the one in Figure 7, for which we need to make sure that tl as the value of c gets transferred. 16 One would think that the type information tl, which is more specific than that 16 A linguistic example based on the signature given by Pollard and Sag (1994) would be a lexical rule deriving predicative signs from nonpredicative ones, i.e., changing the PRD value of substantive signs from - to +, much like the lexical rule for NPs given by Pollard and Sag (1994, p. 360, fn. 20). In such a Predicative Lexical Rule (which we only note as an example and not as a linguistic proposal) the subtype of the head object undergoing the rule as well as the value of the features only appropriate for the subtypes of substantive either is lost or must be specified by a separate rule for each of the subtypes. 550 Meurers and Minnen Covariation Approach to HPSG Le","@endWordPosition":"3909","@position":"24380","annotationId":"T10","@startWordPosition":"3909","@citStr":"(1994)"},{"#tail":"\n","#text":"ch have to be preserved. In particular, in case the lexical entry has t2 as the value of c, we need to ensure that the value of the feature z is transferred properly. To ensure that no information is lost as a result of applying a lexical rule, it seems to be necessary to split up the lexical rule to make each instance deal with a specific case. In the above example, this would result in two lexical rules: one for words with tl as their c value and one for those with t2 as their c value. In the latter case, we can also take care of transferring the value of z. However, as discussed by Meurers (1994), creating several instances of lexical rules can be avoided. Instead, the disjunctive possibilities introduced by the frame specification are attached as a constraint o a lexical rule. This is accomplished by having each lexical rule predicate call a so-called frame predicate, which can have multiple defining clauses. So for the lexical rule 1, the frame specification is taken care of by extending the predicate in Figure 6 with a call to a frame predicate, as shown in Figure 8.17 On the basis of the lexical rule specification and the signature, the compiler de- duces the frame predicates with","@endWordPosition":"4290","@position":"26449","annotationId":"T11","@startWordPosition":"4290","@citStr":"(1994)"},{"#tail":"\n","#text":"pplication is not always profitable. For example, in the case of generation, un- derspecification f the head of a construction can lead to massive nondeterminism or even nontermination when not enough restricting information is available to generate its complements (Martinovi4 and Strzalkowski 1992; Minnen, Gerdemann, and G6tz 1995). Criteria to determine when it is most profitable to execute calls to an interaction predicate are required. One possibility is to annotate the lexical rule encoding with such criteria by means of delay statements, as, for example, suggested by van Noord and Bouma (1994). While we consider this kind of control facility (Naish \\[1986\\] and references therein) to be, in general, indispensable for efficient processing, it also has disadvantages that make it desirable to search for alternative or additional mechanisms: Delay statements presup- pose the procedural annotation of an otherwise declarative specification. Substantial computational expertise is required to provide restrictions on the instantiation status of a goal, which must be fulfilled before the goal can be executed. Furthermore, the computational bookkeeping necessary for the delaying mechanism is ","@endWordPosition":"9287","@position":"57626","annotationId":"T12","@startWordPosition":"9287","@citStr":"(1994)"},{"#tail":"\n","#text":"phrase structure rules and the parser makes no distinction between lexical and nonlexical rules (Copestake 1993, 31). A similar method is included in PATR-II (Shieber et al 1983) and can be used to encode lexical rules as binary relations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or the TFS system (Emele and Zajac 1990; Emele 1994). The covariation approach described in this paper can be viewed as a domain-specific refinement of such a treatment of lexical rules. The encoding of lexical rules used in the covariation approach is related to the work of van Noord and Bouma (1994), who describe the hand-encoding of a single lexical rule as definite relations and show how these relations can be used to constrain a lexical entry. The covariation approach builds on this proposal and extends it in three ways: First, the approach shows how to detect and encode the interaction of a set of lexical rules. Second, it provides a way to automatically obtain a definite clause encoding of lexical rules and their interaction. Finally, it automatically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexi","@endWordPosition":"10615","@position":"66205","annotationId":"T13","@startWordPosition":"10615","@citStr":"(1994)"}]},"title":{"#tail":"\n","#text":"ALE--The Attribute Logic Engine, User's Computational Linguistics Volume 23,"},"volume":{"#tail":"\n","#text":"4"},"#tail":"\n","institution":{"#tail":"\n","#text":"Computational Linguistics Program, Philosophy Department, Carnegie Mellon University,"},"rawString":{"#tail":"\n","#text":"ALE--The Attribute Logic Engine, User's Computational Linguistics Volume 23, Number 4 Guide, Version 2.0.1, December 1994. Technical report, Computational Linguistics Program, Philosophy Department, Carnegie Mellon University, Pittsburgh, PA."},"journal":{"#tail":"\n","#text":"Number"},"#text":"\n","marker":{"#tail":"\n","#text":"1994"},"location":{"#tail":"\n","#text":"Pittsburgh, PA."},"@valid":"true"},{"#tail":"\n","date":{"#tail":"\n","#text":"1992"},"institution":{"#tail":"\n","#text":"University of Sussex,"},"rawString":{"#tail":"\n","#text":"Copestake, Ann. 1992. The Representation f Lexical Semantic Information. Cognitive science research paper CSRP 280, University of Sussex, Sussex, UK."},"#text":"\n","marker":{"#tail":"\n","#text":"Copestake, 1992"},"location":{"#tail":"\n","#text":"Sussex, UK."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" application, it also grounds the recursion in a word described by a base lexical entry. Contrary to the MLR setup, the DLR formalization therefore requires all words feeding lexical rules to be grammatical with respect o the theory. Since lexical rules are expressed in the theory just like any other part of the theory, they are represented in the same way, as unary immediate dominance schemata. 8 This conception of lexical rules thus can be understood as underlying the computational approach that treats lexical rules as unary phrase structure rules as, for example, adopted in the LKB system (Copestake 1992). Both the input and output of a lexical rule, i.e., the mother and the daughter of a phrase structure rule, are available during a generation or parsing process. As a result, in addition to the information present in the lexical entry, syntactic information can be accessed to execute the constraints on the input of a lexical rule. The computational treatment of lexical rules that we propose in this paper is essentially a domain-specific refinement of such an approach to lexical rules. 9 2.2.3 Lexical Rule Specification and Framing. An important difference between unary immediate dominance sch","@endWordPosition":"2068","@position":"13247","annotationId":"T14","@startWordPosition":"2067","@citStr":"Copestake 1992"},{"#tail":"\n","#text":"lting in infinite lexica, the number of lexical rule applications needs to be limited. In the ALE system, for example, a depth bound can be specified for this purpose. Finally, as shown in Section 6, using an expanded out lexicon can be less time and space efficient han using a lexicon encoding that makes computational use of generalizations over lexical information, as, for example, the covariation encoding. 7.2 Lexical Rules as Unary Phrase Structure Rules Another common approach to lexical rules is to encode them as unary phrase structure rules. This approach is taken, for example, in LKB (Copestake 1992) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules (Copestake 1993, 31). A similar method is included in PATR-II (Shieber et al 1983) and can be used to encode lexical rules as binary relations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or the TFS system (Emele and Zajac 1990; Emele 1994). The covariation approach described in this paper can be viewed as a domain-specific refinement of such a treatment of lexical rules. The encoding of lexical rules used in the covariation appro","@endWordPosition":"10503","@position":"65549","annotationId":"T15","@startWordPosition":"10502","@citStr":"Copestake 1992"}]},"title":{"#tail":"\n","#text":"The Representation f Lexical Semantic Information. Cognitive science research paper CSRP 280,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Ann Copestake"}}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Technical report 316,"},"date":{"#tail":"\n","#text":"1993"},"institution":{"#tail":"\n","#text":"University of Cambridge Computer Laboratory,"},"rawString":{"#tail":"\n","#text":"Copestake, Ann. 1993. The Compleat LKB. Technical report 316, University of Cambridge Computer Laboratory, Cambridge, UK."},"#text":"\n","marker":{"#tail":"\n","#text":"Copestake, 1993"},"location":{"#tail":"\n","#text":"Cambridge, UK."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"pose. Finally, as shown in Section 6, using an expanded out lexicon can be less time and space efficient han using a lexicon encoding that makes computational use of generalizations over lexical information, as, for example, the covariation encoding. 7.2 Lexical Rules as Unary Phrase Structure Rules Another common approach to lexical rules is to encode them as unary phrase structure rules. This approach is taken, for example, in LKB (Copestake 1992) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules (Copestake 1993, 31). A similar method is included in PATR-II (Shieber et al 1983) and can be used to encode lexical rules as binary relations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or the TFS system (Emele and Zajac 1990; Emele 1994). The covariation approach described in this paper can be viewed as a domain-specific refinement of such a treatment of lexical rules. The encoding of lexical rules used in the covariation approach is related to the work of van Noord and Bouma (1994), who describe the hand-encoding of a single lexical rule as definite relations and show how these relati","@endWordPosition":"10528","@position":"65710","annotationId":"T16","@startWordPosition":"10527","@citStr":"Copestake 1993"}},"title":{"#tail":"\n","#text":"The Compleat LKB."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Ann Copestake"}}},{"#tail":"\n","editor":{"#tail":"\n","#text":"D6rre, Jochen and Michael Dorna, editors."},"rawString":{"#tail":"\n","#text":"D6rre, Jochen and Michael Dorna, editors. 1993a. Computational Aspects of Constraint-Based Linguistic Description I. University of Stuttgart, Stuttgart, Germany."},"#text":"\n","marker":{"#tail":"\n"},"location":{"#tail":"\n","#text":"Stuttgart, Germany."},"booktitle":{"#tail":"\n","#text":"1993a. Computational Aspects of Constraint-Based Linguistic Description I. University of Stuttgart,"},"@valid":"false"},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"DOrre, Jochen and Michael Dorna. 1993b."},"#text":"\n","marker":{"#tail":"\n","#text":"DOrre, Dorna, 1993"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Jochen DOrre"},{"#tail":"\n","#text":"Michael Dorna"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"CUF--A formalism for linguistic knowledge representation. I  D6rre and Dorna (1993a)."},"#text":"\n","marker":{"#tail":"\n","#text":"1993"},"title":{"#tail":"\n","#text":"CUF--A formalism for linguistic knowledge representation. I D6rre and Dorna"},"@valid":"true"},{"#tail":"\n","date":{"#tail":"\n","#text":"1991"},"institution":{"#tail":"\n","#text":"University of Stuttgart,"},"rawString":{"#tail":"\n","#text":"DOrre, Jochen and Andreas Eisele. 1991. A Comprehensive Unification Based Formalism. DYANA Deliverable R3.1.B, University of Stuttgart, Stuttgart, Germany."},"#text":"\n","marker":{"#tail":"\n","#text":"DOrre, Eisele, 1991"},"location":{"#tail":"\n","#text":"Stuttgart, Germany."},"title":{"#tail":"\n","#text":"A Comprehensive Unification Based Formalism. DYANA Deliverable R3.1.B,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Jochen DOrre"},{"#tail":"\n","#text":"Andreas Eisele"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Technical Report 124,"},"date":{"#tail":"\n","#text":"1990"},"institution":{"#tail":"\n","#text":"IBM Wissenschaftliches Zentrum, Institut fiir Wissensbasierte Systeme."},"rawString":{"#tail":"\n","#text":"Eisele, Andreas and Jochen D6rre. 1990. Disjunctive Unification. Technical Report 124, IBM Wissenschaftliches Zentrum, Institut fiir Wissensbasierte Systeme."},"#text":"\n","marker":{"#tail":"\n","#text":"Eisele, D6rre, 1990"},"title":{"#tail":"\n","#text":"Disjunctive Unification."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Andreas Eisele"},{"#tail":"\n","#text":"Jochen D6rre"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Emele, Martin. 1994. The typed feature structure representation formalism. In Proceedings ofthe International Workshop on Sharable Natural Language Resources, Nara, Japan."},"#text":"\n","marker":{"#tail":"\n","#text":"Emele, 1994"},"location":{"#tail":"\n","#text":"Nara, Japan."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"g. 7.2 Lexical Rules as Unary Phrase Structure Rules Another common approach to lexical rules is to encode them as unary phrase structure rules. This approach is taken, for example, in LKB (Copestake 1992) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules (Copestake 1993, 31). A similar method is included in PATR-II (Shieber et al 1983) and can be used to encode lexical rules as binary relations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or the TFS system (Emele and Zajac 1990; Emele 1994). The covariation approach described in this paper can be viewed as a domain-specific refinement of such a treatment of lexical rules. The encoding of lexical rules used in the covariation approach is related to the work of van Noord and Bouma (1994), who describe the hand-encoding of a single lexical rule as definite relations and show how these relations can be used to constrain a lexical entry. The covariation approach builds on this proposal and extends it in three ways: First, the approach shows how to detect and encode the interaction of a set of lexical rules. Second, it provides a way ","@endWordPosition":"10573","@position":"65955","annotationId":"T17","@startWordPosition":"10572","@citStr":"Emele 1994"}},"title":{"#tail":"\n","#text":"The typed feature structure representation formalism."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe International Workshop on Sharable Natural Language Resources,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Martin Emele"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1990"},"rawString":{"#tail":"\n","#text":"Emele, Martin and R~mi Zajac. 1990. Typed unification grammars. In Proceedings ofthe 13th Conference on Computational Linguistics (COLING), Helsinki, Finland."},"#text":"\n","marker":{"#tail":"\n","#text":"Emele, Zajac, 1990"},"location":{"#tail":"\n","#text":"Helsinki, Finland."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"he covariation encoding. 7.2 Lexical Rules as Unary Phrase Structure Rules Another common approach to lexical rules is to encode them as unary phrase structure rules. This approach is taken, for example, in LKB (Copestake 1992) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules (Copestake 1993, 31). A similar method is included in PATR-II (Shieber et al 1983) and can be used to encode lexical rules as binary relations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or the TFS system (Emele and Zajac 1990; Emele 1994). The covariation approach described in this paper can be viewed as a domain-specific refinement of such a treatment of lexical rules. The encoding of lexical rules used in the covariation approach is related to the work of van Noord and Bouma (1994), who describe the hand-encoding of a single lexical rule as definite relations and show how these relations can be used to constrain a lexical entry. The covariation approach builds on this proposal and extends it in three ways: First, the approach shows how to detect and encode the interaction of a set of lexical rules. Second, it pr","@endWordPosition":"10571","@position":"65942","annotationId":"T18","@startWordPosition":"10568","@citStr":"Emele and Zajac 1990"}},"title":{"#tail":"\n","#text":"Typed unification grammars."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe 13th Conference on Computational Linguistics (COLING),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Martin Emele"},{"#tail":"\n","#text":"Rmi Zajac"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1987"},"institution":{"#tail":"\n","#text":"Stanford University,"},"rawString":{"#tail":"\n","#text":"Flickinger, Daniel. 1987. Lexical Rules in the Hierarchical Lexicon. Ph.D. thesis, Stanford University, Stanford, CA."},"#text":"\n","marker":{"#tail":"\n","#text":"Flickinger, 1987"},"location":{"#tail":"\n","#text":"Stanford, CA."},"booktitle":{"#tail":"\n","#text":"Lexical Rules in the Hierarchical Lexicon. Ph.D. thesis,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Daniel Flickinger"}}},{"date":{"#tail":"\n","#text":"1985"},"title":{"#tail":"\n","#text":"Structure-sharing i lexical representation."},"#tail":"\n","institution":{"#tail":"\n","#text":"Computational Linguistics."},"rawString":{"#tail":"\n","#text":"Flickinger, Daniel, Carl Pollard, and Thomas Wasow. 1985. Structure-sharing i  lexical representation. I  Proceedings ofthe 23rd Annual Meeting, pages 262-267, Chicago, IL. Association for Computational Linguistics."},"#text":"\n","pages":{"#tail":"\n","#text":"262--267"},"marker":{"#tail":"\n","#text":"Flickinger, Pollard, Wasow, 1985"},"publisher":{"#tail":"\n","#text":"Association for"},"location":{"#tail":"\n","#text":"Chicago, IL."},"booktitle":{"#tail":"\n","#text":"I Proceedings ofthe 23rd Annual Meeting,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Daniel Flickinger"},{"#tail":"\n","#text":"Carl Pollard"},{"#tail":"\n","#text":"Thomas Wasow"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Frank, Annette. 1994. Verb second by underspecification. In Proceedings of KONVENS, Berlin. Springer-Verlag."},"#text":"\n","marker":{"#tail":"\n","#text":"Frank, 1994"},"publisher":{"#tail":"\n","#text":"Springer-Verlag."},"location":{"#tail":"\n","#text":"Berlin."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"action. Finally, it automatically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexical rule needs to be specified. 7.3 Alternative Ways to Express Lexical Generalizations Lexical rules have not gone unchallenged as a mechanism for expressing eneraliza- tions over lexical information. In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; 564 Meurers and Minnen Covariation Approach to HPSG Lexical Rules Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995). The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy. These approaches seem to propose a completely different way to capture lexical generalizations. It is therefore interesting that the covariation lexical rule compiler produces a lexicon encoding that, basically, uses an underspecification representation: The resulting definite clause representation after constraint propagation represents the common information in the base lexical entry, and uses a d","@endWordPosition":"10773","@position":"67248","annotationId":"T19","@startWordPosition":"10772","@citStr":"Frank 1994"}},"title":{"#tail":"\n","#text":"Verb second by underspecification."},"booktitle":{"#tail":"\n","#text":"In Proceedings of KONVENS,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Annette Frank"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"rawString":{"#tail":"\n","#text":"Gerdemann, Dale. 1995. Open and closed world types in NLP systems. In Proceedings ofthe DGfS Fachtagung Computerlinguistik, Diisseldorf, Germany."},"#text":"\n","marker":{"#tail":"\n","#text":"Gerdemann, 1995"},"location":{"#tail":"\n","#text":"Diisseldorf, Germany."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"nput to a lexical rule can be enforced that cannot be executed on the basis of the information present in the lexical entry alone, 6and second, grammars including lexical rules that, under the MLR formalization, result in an infinite lexicon, can only 3 The terminology used in the literature varies. Types are also referred to as sorts, appropriateness conditions as feature declarations, and features as attributes. To avoid confusion, we will only use the terminology introduced in the text. 4 This interpretation f the signature is sometimes referred to as closed world (Gerdemann and King 1994; Gerdemann 1995). 5 An in-depth discussion including a comparison of both approaches i provided in Calcagno, Meurers, and Pollard (in preparation). 6 The Partial-VP Topicalization Lexical Rule proposed by Hinrichs and Nakazawa (1994, 10) is a linguistic example. The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries erving as its input. In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement. 545 Computational Linguistics Volume 23, Number 4 simple-word ---* LE1","@endWordPosition":"1605","@position":"10384","annotationId":"T20","@startWordPosition":"1604","@citStr":"Gerdemann 1995"}},"title":{"#tail":"\n","#text":"Open and closed world types in NLP systems."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe DGfS Fachtagung Computerlinguistik,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Dale Gerdemann"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Gerdemann, Dale and Paul King. 1994. The correct and efficient implementation f appropriateness specifications for typed feature structures. In Proceedings ofthe 15th Conference on Computational Linguistics (COLING), Kyoto, Japan."},"#text":"\n","marker":{"#tail":"\n","#text":"Gerdemann, King, 1994"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ical entries serving as input to a lexical rule can be enforced that cannot be executed on the basis of the information present in the lexical entry alone, 6and second, grammars including lexical rules that, under the MLR formalization, result in an infinite lexicon, can only 3 The terminology used in the literature varies. Types are also referred to as sorts, appropriateness conditions as feature declarations, and features as attributes. To avoid confusion, we will only use the terminology introduced in the text. 4 This interpretation f the signature is sometimes referred to as closed world (Gerdemann and King 1994; Gerdemann 1995). 5 An in-depth discussion including a comparison of both approaches i provided in Calcagno, Meurers, and Pollard (in preparation). 6 The Partial-VP Topicalization Lexical Rule proposed by Hinrichs and Nakazawa (1994, 10) is a linguistic example. The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries erving as its input. In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement. 545 Computational Linguistics Volume 23, Number 4 sim","@endWordPosition":"1603","@position":"10367","annotationId":"T21","@startWordPosition":"1600","@citStr":"Gerdemann and King 1994"},{"#tail":"\n","#text":"alternative, therefore, is to automatically determine certain control prob- lems and deal with them in an off-line fashion along the lines of Minnen, Gerdemann, and G6tz (1995) and Minnen, Gerdemann, and Hinrichs (1996). They describe the use of a dataflow analysis for an off-line improvement of grammars that determines automatically when a particular goal in a clause can best be executed. 6. Efficiency Evaluation The computational treatment of lexical rules as covariation in lexical entries was im- plemented in Prolog by the authors in cooperation with Dieter Martini for the ConTroll system (Gerdemann and King 1994; G6tz and Meurers 1997a). We tested the covaria- tion approach with a complex grammar implementing an HPSG analysis covering the so-called aux-flip phenomenon, and partial-VP topicalization i the three clause types of German (Hinrichs, Meurers, and Nakazawa 1994). This test grammar includes eight lexical rules; some serve syntactic purposes, like the Partial-VP Topicalization Lexical Rule, others are of morphological nature as, for example, an inflectional lexical rule that relates nonfinite verbs to their finite form. Our compiler distinguished seven word classes. Some nouns and most verbal ","@endWordPosition":"9470","@position":"58880","annotationId":"T22","@startWordPosition":"9467","@citStr":"Gerdemann and King 1994"}]},"title":{"#tail":"\n","#text":"The correct and efficient implementation f appropriateness specifications for typed feature structures."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe 15th Conference on Computational Linguistics (COLING), Kyoto,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Dale Gerdemann"},{"#tail":"\n","#text":"Paul King"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1987"},"editor":{"#tail":"\n","#text":"Ginsberg, Matthew L., editor."},"rawString":{"#tail":"\n","#text":"Ginsberg, Matthew L., editor. 1987. Readings in Nonmonotonic Reasoning. Morgan Kaufmann."},"#text":"\n","marker":{"#tail":"\n","#text":"1987"},"publisher":{"#tail":"\n","#text":"Morgan Kaufmann."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"lexical rules. 546 Meurers and Minnen Covariation Approach to HPSG Lexical Rules sl \\] LOC\\] CAT LOC\\[CAT HEAD VAL HAVrFbVFOOpsP tlJ su , INDEX \\[VAL (IL 'CONT LCOMpS /\\[LOC\\]CONTll NDEX \\[~\\]1 \\[\\] t---+ VFORM pas\\] SUBJ / \\[LOC\\] CONT \\[ INDEX \\[\\]\\]/ / (\\[LOC ICATI HEAD prep\\[ PFORM COMPS \\[\\] O L CONT\\]INDEX \\[\\] Figure 2 A passivization lexical rule. written as fully specified relations between words, rather, only what is supposed to be changed is specified. Consider, for example, the lexical rule in Figure 2, which encodes a passive lexicai rule like the one presented by Pollard and Sag (1987, 215) in terms of the setup of Pollard and Sag (1994, ch. 9). This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form2 ?The rule takes the index of the least oblique complement of the input and assigns it to the subject of the output. The index that the subject bore in the input is assigned to an optional prepositional complement in the output. Only the verb form and some indices are specified to be changed, and thus other input properties, like the phonology, the semantics, or the nonlocal specifications, are preserved in the output. T","@endWordPosition":"2363","@position":"15036","annotationId":"T23","@startWordPosition":"2362","@citStr":"(1987, 215)"},{"#tail":"\n","#text":"global lexical rule application is pruned with respect o a particular base lexical entry, we know which subclass we are dealing with. For each interaction defini- tion we can therefore check which of the flame clauses are applicable and discard the non-applicable ones. We thereby eliminate the redundant nondeterminism resulting from multiply defined frame predicates. The elimination of redundant nondeterminism is based on Unfold/Fold trans- formation techniques (Tamaki and Sato 1984). 29 The unfolding transformation is also referred to as partial execution, for example, by Pereira and Shieber (1987). Intuitively understood, unfolding comprises the evaluation of a particular literal in the body of a clause at compile-time. As a result, the literal can be removed from the body of 29 This improvement of the covariation encoding can also be viewed as an instance of the program transformation technique r ferred to as deletion of clauses with a finitely failed body (Pettorossi and Proietti 1994). 558 Meurers and Minnen Covariation Approach to HPSG Lexical Rules extended lexical entries call I .~ interaction predicates call unfolding c unfolding Figure 20 Schematic representation f the successi","@endWordPosition":"7755","@position":"47972","annotationId":"T24","@startWordPosition":"7755","@citStr":"(1987)"},{"#tail":"\n","#text":"of processing does not have to be explored. 31 As it stands, our encoding of lexical rules and their application as covariation in lexical entries does not yet support the application of lexical rules on-the-fly. With respect o processing, the extended lexical entry of Figure 17 is problematic because before execution of the call to q_l, it is not known which information of the base lexical entry ends up in a derived lexical entry, i.e., tag ~ is completely uninstantiated. This means that there is no way of indexing the lexical entries according to what kind of 31 According to Pollard and Sag (1987) on-the-fly application of lexical rules is also well-suited to playing a role in a model of language use. 560 Meurers and Minnen Covariation Approach to HPSG Lexical Rules derived entry one is looking for. As a result, it is necessary to execute the call to q_l immediately when the lexical entry is used during processing. Otherwise, there would be no information available to restrict the search-space of a generation or parsing process. Flickinger, Pollard, and Wasow (1985) solve this problem using additional specifi- cations: &quot;By providing with each lexical rule a generic class frame which sp","@endWordPosition":"8479","@position":"52437","annotationId":"T25","@startWordPosition":"8479","@citStr":"(1987)"}]},"booktitle":{"#tail":"\n","#text":"Readings in Nonmonotonic Reasoning."},"@valid":"true"},{"volume":{"#tail":"\n","#text":"340"},"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"institution":{"#tail":"\n","#text":"University of T~ibingen,"},"rawString":{"#tail":"\n","#text":"G6tz, Thilo. 1994. A Normal Form for Typed Feature Structures. Arbeitspapiere des SFB 340 no. 40, University of T~ibingen, IBM, Heidelberg, Germany."},"journal":{"#tail":"\n","#text":"Arbeitspapiere des SFB"},"#text":"\n","marker":{"#tail":"\n","#text":"G6tz, 1994"},"location":{"#tail":"\n","#text":"IBM, Heidelberg, Germany."},"title":{"#tail":"\n","#text":"A Normal Form for Typed Feature Structures."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Thilo G6tz"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"institution":{"#tail":"\n","#text":"for Computational Linguistics."},"rawString":{"#tail":"\n","#text":"G6tz, Thilo and Detmar Meurers. 1995. Compiling HPSG type constraints into definite clause programs. In Proceedings of the 33rd Annual Meeting, Boston, MA. Association for Computational Linguistics."},"#text":"\n","marker":{"#tail":"\n","#text":"G6tz, Meurers, 1995"},"publisher":{"#tail":"\n","#text":"Association"},"location":{"#tail":"\n","#text":"Boston, MA."},"title":{"#tail":"\n","#text":"Compiling HPSG type constraints into definite clause programs."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 33rd Annual Meeting,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Thilo G6tz"},{"#tail":"\n","#text":"Detmar Meurers"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"G6tz, Thilo and Detmar Meurers. 1996. The importance of being lazy--Using lazy evaluation to process queries to HPSG grammars. In Proceedings ofTALN 96 (Joint Session with the Third International Conference on HPSG), Marseille, France."},"#text":"\n","marker":{"#tail":"\n","#text":"G6tz, Meurers, 1996"},"location":{"#tail":"\n","#text":"Marseille, France."},"title":{"#tail":"\n","#text":"The importance of being lazy--Using lazy evaluation to process queries to HPSG grammars."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofTALN 96 (Joint Session with the Third International Conference on HPSG),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Thilo G6tz"},{"#tail":"\n","#text":"Detmar Meurers"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"GOtz, Thilo and Detmar Meurers. 1997a. The ConTroll system as large grammar development platform. In Proceedings of the ACL/EACL Post-Conference Workshop on Computational Environments for Grammar Development and Linguistic Engineering, Madrid, Spain."},"#text":"\n","marker":{"#tail":"\n","#text":"GOtz, Meurers, 1997"},"location":{"#tail":"\n","#text":"Madrid,"},"title":{"#tail":"\n","#text":"The ConTroll system as large grammar development platform."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the ACL/EACL Post-Conference Workshop on Computational Environments for Grammar Development and Linguistic Engineering,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Thilo GOtz"},{"#tail":"\n","#text":"Detmar Meurers"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"G6tz, Thilo and Detmar Meurers. 1997b. Interleaving universal principles and relational constraints over typed feature logic. In Proceedings ofthe 35th Annual Meeting of the ACL and the 8th Conference of the EACL, Madrid, Spain."},"#text":"\n","marker":{"#tail":"\n","#text":"G6tz, Meurers, 1997"},"location":{"#tail":"\n","#text":"Madrid,"},"title":{"#tail":"\n","#text":"Interleaving universal principles and relational constraints over typed feature logic."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe 35th Annual Meeting of the ACL and the 8th Conference of the EACL,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Thilo G6tz"},{"#tail":"\n","#text":"Detmar Meurers"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"Griffith, John. 1996. Modularizing contexted constraints. In Proceedings ofthe 16th Conference on Computational Linguistics (COLING), Copenhagen, Denmark."},"#text":"\n","marker":{"#tail":"\n","#text":"Griffith, 1996"},"location":{"#tail":"\n","#text":"Copenhagen, Denmark."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" rules 1 and 2 of Figure 11 are given. We then only obtain seven of the clauses of Figure 22: those calling lex_rule_l or lex_rule_2, as well as the unit clauses for q_l, q_2, q3, and q_7. Applying constraint propagation to the extended lexical entry of Figure 17 yields the result shown in Figure 23. The information common to all solutions to the interaction call is lifted up into the lexical entry and becomes available upon lexical lookup. 32 In certain cases an extension ofthe constraint language with named isjunctions orcontexted constraints (Maxwell and Kaplan 1989; Eisele and D6rre 1990; Griffith 1996) can be used to circumvent constraint propagation. Encoding the disjunctive possibilities for lexical rule application i this way, instead of with definite clause attachments, makes all relevant lexical information available at lexical lookup. For analyses proposing infinite lexica, though, adefinite clause ncoding of disjunctive possibilities i still necessary and constraint propagation is indispensable forefficient processing. 561 Computational Linguistics Volume 23, Number 4 - 1\\] Lct2\\[zB\\]j c x_ t2Lz \\[\\](a'b)JJ Figure 23 An entry suitable for on-the-fly application (lexical rules 1 and 2","@endWordPosition":"9078","@position":"56200","annotationId":"T26","@startWordPosition":"9077","@citStr":"Griffith 1996"}},"title":{"#tail":"\n","#text":"Modularizing contexted constraints."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe 16th Conference on Computational Linguistics (COLING),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"John Griffith"}}},{"volume":{"#tail":"\n","#text":"58"},"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"editor":{"#tail":"\n","#text":"Hinrichs, Erhard, Detmar Meurers, and Tsuneko Nakazawa, editors."},"rawString":{"#tail":"\n","#text":"Hinrichs, Erhard, Detmar Meurers, and Tsuneko Nakazawa, editors. 1994. Partial-VP and Split-NP Topicalization i German--An HPSG Analysis and its Implementation. Number 58."},"journal":{"#tail":"\n","#text":"Number"},"#text":"\n","marker":{"#tail":"\n","#text":"1994"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"German, Italian, and French fall into that category. 1 Furthermore, since lexical rules in such an approach only serve in a precompilation step, the generalizations captured by the lexical rules cannot be used at run-time. Finally, all such treatments of lexical rules currently available pre- suppose a fully explicit notation of lexical rule specifications that transfer properties not changed by the lexical rules to the newly created lexical entry. This conflicts with the standard assumption made in HPSG that only the properties changed by a lexical rule need be mentioned. As shown in Meurers (1994) this is a well-motivated conven- tion since it avoids splitting up lexical rules to transfer the specifications that must be preserved for different lexical entries. ? The authors are listed alphabetically. SFB 340, Kleine Wilhelmstr. 113, D-72074 Tiibingen, Germany. email: {dm,minnen}@sfs.nphil.uni-tuebingen.de URL: http://www.sfs.nphil.uni-tuebingen.de/sfb /b4home.html 1 This is, for example, the case for all proposals working with verbal exical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction ","@endWordPosition":"352","@position":"2289","annotationId":"T27","@startWordPosition":"352","@citStr":"(1994)"},{"#tail":"\n","#text":" the sense that every grammatical object is described by every principle in the theory. The signature consists of the type hierarchy defining which types of objects ex- ist and the appropriateness conditions pecifying which objects have which features defined on them to represent their properties. 3 A signature is interpreted as follows: Every object is assigned exactly one most specific type, and in case a feature is ap- propriate for some object of a certain type, then it is appropriate for all objects of this type. 4 A logic that provides the formal architecture required by Pollard and Sag (1994) was defined by King (1989, 1994). The formal language of King allows the expression of grammatical principles using type assignments to refer to the type of an object and path equalities to require the (token) identity of objects. These atomic expressions can be combined using conjunction, disjunction, and negation. The expressions are interpreted by a set-theoretical semantics. 2.2 Lexical Rules in HPSG While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special inguistic mechanisms like lexical rules fit into this formal setup. Two formal","@endWordPosition":"1174","@position":"7678","annotationId":"T28","@startWordPosition":"1174","@citStr":"(1994)"},{"#tail":"\n","#text":"nfinite lexicon, can only 3 The terminology used in the literature varies. Types are also referred to as sorts, appropriateness conditions as feature declarations, and features as attributes. To avoid confusion, we will only use the terminology introduced in the text. 4 This interpretation f the signature is sometimes referred to as closed world (Gerdemann and King 1994; Gerdemann 1995). 5 An in-depth discussion including a comparison of both approaches i provided in Calcagno, Meurers, and Pollard (in preparation). 6 The Partial-VP Topicalization Lexical Rule proposed by Hinrichs and Nakazawa (1994, 10) is a linguistic example. The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries erving as its input. In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement. 545 Computational Linguistics Volume 23, Number 4 simple-word ---* LE1 v . . ? V LEn derived-word ~ (\\[IN LRl-in\\] A LRl-out) V . . . V (\\[IN LRm-in\\] A LRm-oUt) Figure 1 The extended lexicon under the DLR approach. partially be dealt with, for example, by using a depth bound on lexical rul","@endWordPosition":"1637","@position":"10605","annotationId":"T29","@startWordPosition":"1636","@citStr":"(1994, 10)"},{"#tail":"\n","#text":"plicit framing would require the rules to be split up (Meurers 1994). One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory. The formalization of DLRs provided by Meurers (1995) defines aformal exical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification i to a fully explicit description of the kind shown in Figure 1. This description can then be given the standard set-theoretical interpretation f King (1989, 1994). 11 10 Note that the passivization lexical rule in Figure 2 is only intended to illustrate the mechanism. We do not make the linguistic claim that passives hould be analyzed using such a lexical rule. For space reasons, the SYNSEM feature is abbreviated by its first letter. The traditional (First I Rest) list notation is used, and the operator ? stands for the append relation in the usual way. 1l Manandhar (1995) proposes to unify these two steps by including an update operator in the 547 Computational Linguistics Volume 23, Number 4 The computational treatment we discuss in the rest of the p","@endWordPosition":"2673","@position":"16912","annotationId":"T30","@startWordPosition":"2672","@citStr":"(1989, 1994)"},{"#tail":"\n","#text":"s serving as input to a lexical rule that occur in the out-specification f the lexical rule but are not assigned a type value. For example, the lexical rule 1 of Figure 6 applies to word objects with tl as their c value and to those having t2 as their c value. With respect o frame specification this means that there can be lexical entries, such as the one in Figure 7, for which we need to make sure that tl as the value of c gets transferred. 16 One would think that the type information tl, which is more specific than that 16 A linguistic example based on the signature given by Pollard and Sag (1994) would be a lexical rule deriving predicative signs from nonpredicative ones, i.e., changing the PRD value of substantive signs from - to +, much like the lexical rule for NPs given by Pollard and Sag (1994, p. 360, fn. 20). In such a Predicative Lexical Rule (which we only note as an example and not as a linguistic proposal) the subtype of the head object undergoing the rule as well as the value of the features only appropriate for the subtypes of substantive either is lost or must be specified by a separate rule for each of the subtypes. 550 Meurers and Minnen Covariation Approach to HPSG Le","@endWordPosition":"3909","@position":"24380","annotationId":"T31","@startWordPosition":"3909","@citStr":"(1994)"},{"#tail":"\n","#text":"ch have to be preserved. In particular, in case the lexical entry has t2 as the value of c, we need to ensure that the value of the feature z is transferred properly. To ensure that no information is lost as a result of applying a lexical rule, it seems to be necessary to split up the lexical rule to make each instance deal with a specific case. In the above example, this would result in two lexical rules: one for words with tl as their c value and one for those with t2 as their c value. In the latter case, we can also take care of transferring the value of z. However, as discussed by Meurers (1994), creating several instances of lexical rules can be avoided. Instead, the disjunctive possibilities introduced by the frame specification are attached as a constraint o a lexical rule. This is accomplished by having each lexical rule predicate call a so-called frame predicate, which can have multiple defining clauses. So for the lexical rule 1, the frame specification is taken care of by extending the predicate in Figure 6 with a call to a frame predicate, as shown in Figure 8.17 On the basis of the lexical rule specification and the signature, the compiler de- duces the frame predicates with","@endWordPosition":"4290","@position":"26449","annotationId":"T32","@startWordPosition":"4290","@citStr":"(1994)"},{"#tail":"\n","#text":"pplication is not always profitable. For example, in the case of generation, un- derspecification f the head of a construction can lead to massive nondeterminism or even nontermination when not enough restricting information is available to generate its complements (Martinovi4 and Strzalkowski 1992; Minnen, Gerdemann, and G6tz 1995). Criteria to determine when it is most profitable to execute calls to an interaction predicate are required. One possibility is to annotate the lexical rule encoding with such criteria by means of delay statements, as, for example, suggested by van Noord and Bouma (1994). While we consider this kind of control facility (Naish \\[1986\\] and references therein) to be, in general, indispensable for efficient processing, it also has disadvantages that make it desirable to search for alternative or additional mechanisms: Delay statements presup- pose the procedural annotation of an otherwise declarative specification. Substantial computational expertise is required to provide restrictions on the instantiation status of a goal, which must be fulfilled before the goal can be executed. Furthermore, the computational bookkeeping necessary for the delaying mechanism is ","@endWordPosition":"9287","@position":"57626","annotationId":"T33","@startWordPosition":"9287","@citStr":"(1994)"},{"#tail":"\n","#text":"phrase structure rules and the parser makes no distinction between lexical and nonlexical rules (Copestake 1993, 31). A similar method is included in PATR-II (Shieber et al 1983) and can be used to encode lexical rules as binary relations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or the TFS system (Emele and Zajac 1990; Emele 1994). The covariation approach described in this paper can be viewed as a domain-specific refinement of such a treatment of lexical rules. The encoding of lexical rules used in the covariation approach is related to the work of van Noord and Bouma (1994), who describe the hand-encoding of a single lexical rule as definite relations and show how these relations can be used to constrain a lexical entry. The covariation approach builds on this proposal and extends it in three ways: First, the approach shows how to detect and encode the interaction of a set of lexical rules. Second, it provides a way to automatically obtain a definite clause encoding of lexical rules and their interaction. Finally, it automatically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexi","@endWordPosition":"10615","@position":"66205","annotationId":"T34","@startWordPosition":"10615","@citStr":"(1994)"}]},"title":{"#tail":"\n","#text":"Partial-VP and Split-NP Topicalization i German--An HPSG Analysis and its Implementation."},"@valid":"true"},{"date":{"#tail":"\n","#text":"1989"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"nly the properties changed by a lexical rule need be mentioned. As shown in Meurers (1994) this is a well-motivated conven- tion since it avoids splitting up lexical rules to transfer the specifications that must be preserved for different lexical entries. ? The authors are listed alphabetically. SFB 340, Kleine Wilhelmstr. 113, D-72074 Tiibingen, Germany. email: {dm,minnen}@sfs.nphil.uni-tuebingen.de URL: http://www.sfs.nphil.uni-tuebingen.de/sfb /b4home.html 1 This is, for example, the case for all proposals working with verbal exical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements. Also an analysis treating adjunct extraction via lexical rules (van Noord and Bouma 1994) results in an infinite lexicon. (~) 1997 Association for Computational Linguistics Computational Linguistics Volume 23, Number 4 Treatments of lexical rules as unary phrase structure rules also require their fully explicit specification, which entails the last problem mentioned above. In addition, computat","@endWordPosition":"423","@position":"2826","annotationId":"T35","@startWordPosition":"420","@citStr":"Hinrichs and Nakazawa 1989"}},"title":{"#tail":"\n","#text":"Flipped out: Aux in German."},"#tail":"\n","rawString":{"#tail":"\n","#text":"Hinrichs, Erhard and Tsuneko Nakazawa. 1989. Flipped out: Aux in German. In Papers from the 25th Regional Meeting, pages 193-202, Chicago. Chicago Linguistic Society."},"#text":"\n","pages":{"#tail":"\n","#text":"193--202"},"marker":{"#tail":"\n","#text":"Hinrichs, Nakazawa, 1989"},"publisher":{"#tail":"\n","#text":"Chicago Linguistic Society."},"location":{"#tail":"\n","#text":"Chicago."},"booktitle":{"#tail":"\n","#text":"In Papers from the 25th Regional Meeting,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Erhard Hinrichs"},{"#tail":"\n","#text":"Tsuneko Nakazawa"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Hinrichs, Erhard and Tsuneko Nakazawa. 1994. Partial-VP and split-NP topicalization i German: An HPSG analysis. In Hinrichs, Meurers, and Nakazawa (1994)."},"#text":"\n","marker":{"#tail":"\n","#text":"Hinrichs, Nakazawa, 1994"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"zation, result in an infinite lexicon, can only 3 The terminology used in the literature varies. Types are also referred to as sorts, appropriateness conditions as feature declarations, and features as attributes. To avoid confusion, we will only use the terminology introduced in the text. 4 This interpretation f the signature is sometimes referred to as closed world (Gerdemann and King 1994; Gerdemann 1995). 5 An in-depth discussion including a comparison of both approaches i provided in Calcagno, Meurers, and Pollard (in preparation). 6 The Partial-VP Topicalization Lexical Rule proposed by Hinrichs and Nakazawa (1994, 10) is a linguistic example. The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries erving as its input. In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement. 545 Computational Linguistics Volume 23, Number 4 simple-word ---* LE1 v . . ? V LEn derived-word ~ (\\[IN LRl-in\\] A LRl-out) V . . . V (\\[IN LRm-in\\] A LRm-oUt) Figure 1 The extended lexicon under the DLR approach. partially be dealt with, for example, by using a depth bound on lexica","@endWordPosition":"1636","@position":"10600","annotationId":"T36","@startWordPosition":"1633","@citStr":"Hinrichs and Nakazawa (1994"}},"title":{"#tail":"\n","#text":"Partial-VP and split-NP topicalization i German: An HPSG analysis."},"booktitle":{"#tail":"\n","#text":"In Hinrichs, Meurers, and Nakazawa"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Erhard Hinrichs"},{"#tail":"\n","#text":"Tsuneko Nakazawa"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"Hinrichs, Erhard and Tsuneko Nakazawa. 1996. Applying lexical rules under subsumption. In Proceedings ofthe 16th Conference on Computational Linguistics (COLING), pages 543-549, Copenhagen, Denmark."},"#text":"\n","pages":{"#tail":"\n","#text":"543--549"},"marker":{"#tail":"\n","#text":"Hinrichs, Nakazawa, 1996"},"location":{"#tail":"\n","#text":"Copenhagen, Denmark."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"nslation of the lexical rule into a predicate is trivial. The result is displayed description language. 12 In order to focus on the computational aspects of the covariation approach, in this paper we will not go into a discussion of the full lexical rule specification language introduced in Meurers (1995). The reader interested in that language and its precise interpretation can find the relevant details in that paper. 13 A more detailed presentation can be found in Minnen (in preparation). 14 We use rather abstract lexical rules in the examples to be able to focus on the relevant aspects. 15 Hinrichs and Nakazawa (1996) show that the question of whether the application criterion of lexical rules should be a subsumption ra unification test is an important question deserving of more attention. We here assume unification as the application criterion, which formally corresponds tothe conjunction ofdescriptions and their conversion to normal form (G6tz 1994). Computationally, a subsumption test could equally well be used in our compiler. 548 Meurers and Minnen Covariation Approach to HPSG Lexical Rules input : output : Figure 3 The compiler setup. ~ x i c o ~ + translation I of lexical rules into definite relatio","@endWordPosition":"3340","@position":"21038","annotationId":"T37","@startWordPosition":"3337","@citStr":"Hinrichs and Nakazawa (1996)"}},"title":{"#tail":"\n","#text":"Applying lexical rules under subsumption."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe 16th Conference on Computational Linguistics (COLING),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Erhard Hinrichs"},{"#tail":"\n","#text":"Tsuneko Nakazawa"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"editor":{"#tail":"\n","#text":"John Nerbonne, Klaus Netter, and Carl Pollard, editors,"},"rawString":{"#tail":"\n","#text":"Kathol, Andreas. 1994. Passive without lexical rules. In John Nerbonne, Klaus Netter, and Carl Pollard, editors, HPSGfor Meurers and Minnen Covariation Approach to HPSG Lexical Rules German. CSLI Lecture Notes, Stanford University, Stanford, CA."},"#text":"\n","marker":{"#tail":"\n","#text":"Kathol, 1994"},"location":{"#tail":"\n","#text":"Stanford University, Stanford, CA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" a set of lexical rules. Second, it provides a way to automatically obtain a definite clause encoding of lexical rules and their interaction. Finally, it automatically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexical rule needs to be specified. 7.3 Alternative Ways to Express Lexical Generalizations Lexical rules have not gone unchallenged as a mechanism for expressing eneraliza- tions over lexical information. In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; 564 Meurers and Minnen Covariation Approach to HPSG Lexical Rules Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995). The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy. These approaches seem to propose a completely different way to capture lexical generalizations. It is therefore interesting that the covariation lexical rule compiler produces a lexicon encoding that, basically, uses an underspecification representation: The resulting ","@endWordPosition":"10753","@position":"67115","annotationId":"T38","@startWordPosition":"10752","@citStr":"Kathol 1994"}},"title":{"#tail":"\n","#text":"Passive without lexical rules. In"},"booktitle":{"#tail":"\n","#text":"HPSGfor Meurers and Minnen Covariation Approach to HPSG Lexical Rules German. CSLI Lecture Notes,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Andreas Kathol"}}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Ph.D. thesis,"},"date":{"#tail":"\n","#text":"1989"},"institution":{"#tail":"\n","#text":"University of Manchester,"},"rawString":{"#tail":"\n","#text":"King, Paul. 1989. A Logical Formalism for Head-driven Phrase Structure Grammar. Ph.D. thesis, University of Manchester, Manchester, UK."},"#text":"\n","marker":{"#tail":"\n","#text":"King, 1989"},"location":{"#tail":"\n","#text":"Manchester, UK."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"grammatical object is described by every principle in the theory. The signature consists of the type hierarchy defining which types of objects ex- ist and the appropriateness conditions pecifying which objects have which features defined on them to represent their properties. 3 A signature is interpreted as follows: Every object is assigned exactly one most specific type, and in case a feature is ap- propriate for some object of a certain type, then it is appropriate for all objects of this type. 4 A logic that provides the formal architecture required by Pollard and Sag (1994) was defined by King (1989, 1994). The formal language of King allows the expression of grammatical principles using type assignments to refer to the type of an object and path equalities to require the (token) identity of objects. These atomic expressions can be combined using conjunction, disjunction, and negation. The expressions are interpreted by a set-theoretical semantics. 2.2 Lexical Rules in HPSG While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special inguistic mechanisms like lexical rules fit into this formal setup. Two formalizations of lexical rules ","@endWordPosition":"1179","@position":"7704","annotationId":"T39","@startWordPosition":"1178","@citStr":"King (1989"},{"#tail":"\n","#text":"re explicit framing would require the rules to be split up (Meurers 1994). One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory. The formalization of DLRs provided by Meurers (1995) defines aformal exical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification i to a fully explicit description of the kind shown in Figure 1. This description can then be given the standard set-theoretical interpretation f King (1989, 1994). 11 10 Note that the passivization lexical rule in Figure 2 is only intended to illustrate the mechanism. We do not make the linguistic claim that passives hould be analyzed using such a lexical rule. For space reasons, the SYNSEM feature is abbreviated by its first letter. The traditional (First I Rest) list notation is used, and the operator ? stands for the append relation in the usual way. 1l Manandhar (1995) proposes to unify these two steps by including an update operator in the 547 Computational Linguistics Volume 23, Number 4 The computational treatment we discuss in the rest o","@endWordPosition":"2672","@position":"16905","annotationId":"T40","@startWordPosition":"2671","@citStr":"King (1989"}]},"title":{"#tail":"\n","#text":"A Logical Formalism for Head-driven Phrase Structure Grammar."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Paul King"}}},{"date":{"#tail":"\n","#text":"1994"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"erving as input to a lexical rule can be enforced that cannot be executed on the basis of the information present in the lexical entry alone, 6and second, grammars including lexical rules that, under the MLR formalization, result in an infinite lexicon, can only 3 The terminology used in the literature varies. Types are also referred to as sorts, appropriateness conditions as feature declarations, and features as attributes. To avoid confusion, we will only use the terminology introduced in the text. 4 This interpretation f the signature is sometimes referred to as closed world (Gerdemann and King 1994; Gerdemann 1995). 5 An in-depth discussion including a comparison of both approaches i provided in Calcagno, Meurers, and Pollard (in preparation). 6 The Partial-VP Topicalization Lexical Rule proposed by Hinrichs and Nakazawa (1994, 10) is a linguistic example. The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries erving as its input. In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement. 545 Computational Linguistics Volume 23, Number 4 sim","@endWordPosition":"1603","@position":"10367","annotationId":"T41","@startWordPosition":"1602","@citStr":"King 1994"},{"#tail":"\n","#text":"herefore, is to automatically determine certain control prob- lems and deal with them in an off-line fashion along the lines of Minnen, Gerdemann, and G6tz (1995) and Minnen, Gerdemann, and Hinrichs (1996). They describe the use of a dataflow analysis for an off-line improvement of grammars that determines automatically when a particular goal in a clause can best be executed. 6. Efficiency Evaluation The computational treatment of lexical rules as covariation in lexical entries was im- plemented in Prolog by the authors in cooperation with Dieter Martini for the ConTroll system (Gerdemann and King 1994; G6tz and Meurers 1997a). We tested the covaria- tion approach with a complex grammar implementing an HPSG analysis covering the so-called aux-flip phenomenon, and partial-VP topicalization i the three clause types of German (Hinrichs, Meurers, and Nakazawa 1994). This test grammar includes eight lexical rules; some serve syntactic purposes, like the Partial-VP Topicalization Lexical Rule, others are of morphological nature as, for example, an inflectional lexical rule that relates nonfinite verbs to their finite form. Our compiler distinguished seven word classes. Some nouns and most verbal ","@endWordPosition":"9470","@position":"58880","annotationId":"T42","@startWordPosition":"9469","@citStr":"King 1994"}]},"title":{"#tail":"\n","#text":"An Expanded Logical Formalism for Head-driven Phrase Structure Grammar."},"volume":{"#tail":"\n","#text":"340"},"#tail":"\n","institution":{"#tail":"\n","#text":"University of Tfibingen,"},"rawString":{"#tail":"\n","#text":"King, Paul. 1994. An Expanded Logical Formalism for Head-driven Phrase Structure Grammar. Arbeitspapiere des Sonderforschungsbereich 340 no. 59, University of Tfibingen, Tfibingen, Germany."},"journal":{"#tail":"\n","#text":"Arbeitspapiere des Sonderforschungsbereich"},"#text":"\n","marker":{"#tail":"\n","#text":"King, 1994"},"location":{"#tail":"\n","#text":"Tfibingen, Germany."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Paul King"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1992"},"rawString":{"#tail":"\n","#text":"Krieger, Hans-Ulrich and John Nerbonne. 1992. Feature-based inheritance networks for computational lexicons. In Briscoe, Copestake, and de Paiva (1992)."},"#text":"\n","marker":{"#tail":"\n","#text":"Krieger, Nerbonne, 1992"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ical rules. Second, it provides a way to automatically obtain a definite clause encoding of lexical rules and their interaction. Finally, it automatically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexical rule needs to be specified. 7.3 Alternative Ways to Express Lexical Generalizations Lexical rules have not gone unchallenged as a mechanism for expressing eneraliza- tions over lexical information. In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; 564 Meurers and Minnen Covariation Approach to HPSG Lexical Rules Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995). The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy. These approaches seem to propose a completely different way to capture lexical generalizations. It is therefore interesting that the covariation lexical rule compiler produces a lexicon encoding that, basically, uses an underspecification representation: The resulting definite clause representat","@endWordPosition":"10757","@position":"67142","annotationId":"T43","@startWordPosition":"10754","@citStr":"Krieger and Nerbonne 1992"}},"title":{"#tail":"\n","#text":"Feature-based inheritance networks for computational lexicons."},"booktitle":{"#tail":"\n","#text":"In Briscoe, Copestake, and de Paiva"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Hans-Ulrich Krieger"},{"#tail":"\n","#text":"John Nerbonne"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Unpublished Manuscript,"},"date":{"#tail":"\n","#text":"1995"},"institution":{"#tail":"\n","#text":"HCRC at University of Edinburgh, UK."},"rawString":{"#tail":"\n","#text":"Manandhar, Suresh. 1995. The Update Operation in Feature Logic. Unpublished Manuscript, HCRC at University of Edinburgh, UK."},"#text":"\n","marker":{"#tail":"\n","#text":"Manandhar, 1995"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ches the lexical rule specification i to a fully explicit description of the kind shown in Figure 1. This description can then be given the standard set-theoretical interpretation f King (1989, 1994). 11 10 Note that the passivization lexical rule in Figure 2 is only intended to illustrate the mechanism. We do not make the linguistic claim that passives hould be analyzed using such a lexical rule. For space reasons, the SYNSEM feature is abbreviated by its first letter. The traditional (First I Rest) list notation is used, and the operator ? stands for the append relation in the usual way. 1l Manandhar (1995) proposes to unify these two steps by including an update operator in the 547 Computational Linguistics Volume 23, Number 4 The computational treatment we discuss in the rest of the paper follows this setup in that it automatically computes, for each lexical rule specification, the frames neces- sary to preserve the properties not changed by it. 12 We will show that the detection and specification of frames and the use of program transformation to advance their integration into the lexicon encoding is one of the key ingredients of the covariation approach to HPSG lexical rules. 3. Lexical Cova","@endWordPosition":"2745","@position":"17329","annotationId":"T44","@startWordPosition":"2744","@citStr":"Manandhar (1995)"}},"title":{"#tail":"\n","#text":"The Update Operation in Feature Logic."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Suresh Manandhar"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1988"},"rawString":{"#tail":"\n","#text":"Marriott, Kim, Lee Naish, and Jean-Louis Lassez. 1988. Most specific logic programs. In Proceedings of5th International Conference and Symposium on Logic Programming."},"#text":"\n","marker":{"#tail":"\n","#text":"Marriott, Naish, Lassez, 1988"},"title":{"#tail":"\n","#text":"Most specific logic programs."},"booktitle":{"#tail":"\n","#text":"In Proceedings of5th International Conference and Symposium on Logic Programming."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kim Marriott"},{"#tail":"\n","#text":"Lee Naish"},{"#tail":"\n","#text":"Jean-Louis Lassez"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1992"},"institution":{"#tail":"\n","#text":"for Computational Linguistics."},"rawString":{"#tail":"\n","#text":"MartinoviG Miroslav and Tomek Strzalkowski. 1992. Comparing two grammar-based generation algorithms: A case study. In Proceedings ofthe 30th Annual Meeting, Newark, DE. Association for Computational Linguistics."},"#text":"\n","marker":{"#tail":"\n","#text":"Miroslav, Strzalkowski, 1992"},"publisher":{"#tail":"\n","#text":"Association"},"location":{"#tail":"\n","#text":"Newark, DE."},"title":{"#tail":"\n","#text":"Comparing two grammar-based generation algorithms: A case study."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe 30th Annual Meeting,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"MartinoviG Miroslav"},{"#tail":"\n","#text":"Tomek Strzalkowski"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1989"},"rawString":{"#tail":"\n","#text":"Maxwell, John and Ronald Kaplan. 1989. An overview of disjunctive constraint satisfaction. In Proceedings ofthe International Workshop on Parsing Technologies, pages 18-27."},"#text":"\n","pages":{"#tail":"\n","#text":"18--27"},"marker":{"#tail":"\n","#text":"Maxwell, Kaplan, 1989"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"e. Let us therefore assume that only the lexical rules 1 and 2 of Figure 11 are given. We then only obtain seven of the clauses of Figure 22: those calling lex_rule_l or lex_rule_2, as well as the unit clauses for q_l, q_2, q3, and q_7. Applying constraint propagation to the extended lexical entry of Figure 17 yields the result shown in Figure 23. The information common to all solutions to the interaction call is lifted up into the lexical entry and becomes available upon lexical lookup. 32 In certain cases an extension ofthe constraint language with named isjunctions orcontexted constraints (Maxwell and Kaplan 1989; Eisele and D6rre 1990; Griffith 1996) can be used to circumvent constraint propagation. Encoding the disjunctive possibilities for lexical rule application i this way, instead of with definite clause attachments, makes all relevant lexical information available at lexical lookup. For analyses proposing infinite lexica, though, adefinite clause ncoding of disjunctive possibilities i still necessary and constraint propagation is indispensable forefficient processing. 561 Computational Linguistics Volume 23, Number 4 - 1\\] Lct2\\[zB\\]j c x_ t2Lz \\[\\](a'b)JJ Figure 23 An entry suitable for on-the","@endWordPosition":"9072","@position":"56161","annotationId":"T45","@startWordPosition":"9069","@citStr":"Maxwell and Kaplan 1989"}},"title":{"#tail":"\n","#text":"An overview of disjunctive constraint satisfaction."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe International Workshop on Parsing Technologies,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"John Maxwell"},{"#tail":"\n","#text":"Ronald Kaplan"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1969"},"rawString":{"#tail":"\n","#text":"McCarthy, John and Patrick Hayes. 1969."},"#text":"\n","marker":{"#tail":"\n","#text":"McCarthy, Hayes, 1969"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ubject bore in the input is assigned to an optional prepositional complement in the output. Only the verb form and some indices are specified to be changed, and thus other input properties, like the phonology, the semantics, or the nonlocal specifications, are preserved in the output. This is so since the lexical rule in Figure 2 &quot;(like all lexical rules in HPSG) preserves all properties of the input not mentioned in the rule.&quot; (Pollard and Sag \\[1994, 314\\], following Flickinger \\[1987\\]). This idea of preserving properties can be considered an instance of the well-known frame problem in AI (McCarthy and Hayes 1969), and we will therefore refer to the specifications left implicit by the linguist as the frame specification, or simply frame, of a lexical rule. Not having to represent the frame explicitly not only enables the linguist to express only the relevant hings, but also allows a more compact representation f lexical rules where explicit framing would require the rules to be split up (Meurers 1994). One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory. The formalization of DLRs provided by Meur","@endWordPosition":"2525","@position":"15973","annotationId":"T46","@startWordPosition":"2522","@citStr":"McCarthy and Hayes 1969"}},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"John McCarthy"},{"#tail":"\n","#text":"Patrick Hayes"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1969"},"note":{"#tail":"\n","#text":"Reprinted in Ginsberg"},"rawString":{"#tail":"\n","#text":"Some philosophical problems from the standpoint of artificial intelligence. In Meltzer and Michie (1969). Reprinted in Ginsberg (1987)."},"#text":"\n","marker":{"#tail":"\n","#text":"1969"},"title":{"#tail":"\n","#text":"Some philosophical problems from the standpoint of artificial intelligence."},"booktitle":{"#tail":"\n","#text":"In Meltzer and Michie"},"@valid":"true"},{"volume":{"#tail":"\n","#text":"4"},"#tail":"\n","date":{"#tail":"\n","#text":"1969"},"rawString":{"#tail":"\n","#text":"Meltzer, Bernard and Donald Michie, editors. 1969. Machine Intelligence 4. Edinburgh University Press, Edinburgh, UK."},"journal":{"#tail":"\n","#text":"Machine Intelligence"},"#text":"\n","marker":{"#tail":"\n","#text":"Meltzer, Michie, editors, 1969"},"publisher":{"#tail":"\n","#text":"Edinburgh University Press,"},"location":{"#tail":"\n","#text":"Edinburgh, UK."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Bernard Meltzer"},{"#tail":"\n","#text":"Donald Michie"},{"#tail":"\n","#text":"editors"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Meurers, Detmar. 1994. On implementing an HPSG theory: Aspects of the logical architecture, the formalization and the implementation f Head-driven Phrase Structure Grammars. In Hinrichs, Meurers, and Nakazawa (1994)."},"#text":"\n","marker":{"#tail":"\n","#text":"Meurers, 1994"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" Dutch, German, Italian, and French fall into that category. 1 Furthermore, since lexical rules in such an approach only serve in a precompilation step, the generalizations captured by the lexical rules cannot be used at run-time. Finally, all such treatments of lexical rules currently available pre- suppose a fully explicit notation of lexical rule specifications that transfer properties not changed by the lexical rules to the newly created lexical entry. This conflicts with the standard assumption made in HPSG that only the properties changed by a lexical rule need be mentioned. As shown in Meurers (1994) this is a well-motivated conven- tion since it avoids splitting up lexical rules to transfer the specifications that must be preserved for different lexical entries. ? The authors are listed alphabetically. SFB 340, Kleine Wilhelmstr. 113, D-72074 Tiibingen, Germany. email: {dm,minnen}@sfs.nphil.uni-tuebingen.de URL: http://www.sfs.nphil.uni-tuebingen.de/sfb /b4home.html 1 This is, for example, the case for all proposals working with verbal exical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction ","@endWordPosition":"352","@position":"2289","annotationId":"T47","@startWordPosition":"351","@citStr":"Meurers (1994)"},{"#tail":"\n","#text":"t mentioned in the rule.&quot; (Pollard and Sag \\[1994, 314\\], following Flickinger \\[1987\\]). This idea of preserving properties can be considered an instance of the well-known frame problem in AI (McCarthy and Hayes 1969), and we will therefore refer to the specifications left implicit by the linguist as the frame specification, or simply frame, of a lexical rule. Not having to represent the frame explicitly not only enables the linguist to express only the relevant hings, but also allows a more compact representation f lexical rules where explicit framing would require the rules to be split up (Meurers 1994). One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory. The formalization of DLRs provided by Meurers (1995) defines aformal exical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification i to a fully explicit description of the kind shown in Figure 1. This description can then be given the standard set-theoretical interpretation f King (1989, 1994). 11 10 Note that the passivization lexical rule in Figu","@endWordPosition":"2590","@position":"16368","annotationId":"T48","@startWordPosition":"2589","@citStr":"Meurers 1994"},{"#tail":"\n","#text":"s of which have to be preserved. In particular, in case the lexical entry has t2 as the value of c, we need to ensure that the value of the feature z is transferred properly. To ensure that no information is lost as a result of applying a lexical rule, it seems to be necessary to split up the lexical rule to make each instance deal with a specific case. In the above example, this would result in two lexical rules: one for words with tl as their c value and one for those with t2 as their c value. In the latter case, we can also take care of transferring the value of z. However, as discussed by Meurers (1994), creating several instances of lexical rules can be avoided. Instead, the disjunctive possibilities introduced by the frame specification are attached as a constraint o a lexical rule. This is accomplished by having each lexical rule predicate call a so-called frame predicate, which can have multiple defining clauses. So for the lexical rule 1, the frame specification is taken care of by extending the predicate in Figure 6 with a call to a frame predicate, as shown in Figure 8.17 On the basis of the lexical rule specification and the signature, the compiler de- duces the frame predicates with","@endWordPosition":"4290","@position":"26449","annotationId":"T49","@startWordPosition":"4289","@citStr":"Meurers (1994)"}]},"title":{"#tail":"\n","#text":"On implementing an HPSG theory: Aspects of the logical architecture, the formalization and the implementation f Head-driven Phrase Structure Grammars."},"booktitle":{"#tail":"\n","#text":"In Hinrichs, Meurers, and Nakazawa"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Detmar Meurers"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"rawString":{"#tail":"\n","#text":"Meurers, Detmar. 1995. Towards a semantics for lexical rules as used in HPSG. In Proceedings ofthe Conference on Formal Grammar, Barcelona. Also in Proceedings of the ACQUILEX II Workshop on Lexical Rules, 1995, Cambridge, UK."},"#text":"\n","marker":{"#tail":"\n","#text":"Meurers, 1995"},"location":{"#tail":"\n","#text":"Cambridge, UK."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"in lexical entries. Definite relations are a convenient way of encoding the interaction of lexical rules, as they readily support various program transformations to improve the encoding: We show that the definite relations produced by the compiler can be refined by program transformation techniques to increase fficiency. The resulting encoding allows the execution of lexical rules on-the-fly, i.e., coroutined with other constraints at some time after lexical lookup. The computational treatment of lexical rules proposed can be seen as an extension to the principled method discussed by G6tz and Meurers (1995, 1996, 1997b) for encoding the main building block of HPSG grammars--the implicative constraints--as logic program. The structure of the paper is as follows: We start with a brief introduction of the formal background on which our approach is based in Section 2. We then describe (Section 3) how lexical rules and their interaction can be encoded in a definite clause encoding that expresses systematic covariation in lexical entries. We show how the encoding of lexical rule interaction can be improved by specializing it for different word classes and, in Section 4, focus on an improvement of thi","@endWordPosition":"774","@position":"5146","annotationId":"T50","@startWordPosition":"773","@citStr":"Meurers (1995"},{"#tail":"\n","#text":" the (token) identity of objects. These atomic expressions can be combined using conjunction, disjunction, and negation. The expressions are interpreted by a set-theoretical semantics. 2.2 Lexical Rules in HPSG While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special inguistic mechanisms like lexical rules fit into this formal setup. Two formalizations of lexical rules as used by HPSG linguists have been proposed, the meta-level lexical rules (MLRs; Calcagno 1995; Calcagno and Pollard 1995) and the .description-level l xical rules (DLRs; Meurers 1995). 5 2.2.1 Meta-Level Lexical Rules. The MLR approach sees lexical rules in the more traditional sense as relations between lexical entries, i.e., descriptions of word objects. The set of lexical entries constituting the lexicon is closed under the application of lexical rules, which results in a (possibly infinite) set of lexical entries. In order to be grammatical, every word object occurring in a sentence has to be described by one of the descriptions in this expanded lexicon set. In the MLR setup, lexical rules are thus external to the rest of the theory, they only serve to provide an expan","@endWordPosition":"1299","@position":"8489","annotationId":"T51","@startWordPosition":"1298","@citStr":"Meurers 1995"},{"#tail":"\n","#text":"969), and we will therefore refer to the specifications left implicit by the linguist as the frame specification, or simply frame, of a lexical rule. Not having to represent the frame explicitly not only enables the linguist to express only the relevant hings, but also allows a more compact representation f lexical rules where explicit framing would require the rules to be split up (Meurers 1994). One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory. The formalization of DLRs provided by Meurers (1995) defines aformal exical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification i to a fully explicit description of the kind shown in Figure 1. This description can then be given the standard set-theoretical interpretation f King (1989, 1994). 11 10 Note that the passivization lexical rule in Figure 2 is only intended to illustrate the mechanism. We do not make the linguistic claim that passives hould be analyzed using such a lexical rule. For space reasons, the SYNSEM feature is abbreviated by its first let","@endWordPosition":"2622","@position":"16583","annotationId":"T52","@startWordPosition":"2621","@citStr":"Meurers (1995)"},{"#tail":"\n","#text":" suppose the lexical rule specification shown in Figure 5.14 This lexical rule applies to base lexical entries that unify 15 wi th the in-specification, i.e., lexical entries specifying B and Y as - . The derived lexical entry licenses word objects with + as the value of x and Y, and b as that of A. The translation of the lexical rule into a predicate is trivial. The result is displayed description language. 12 In order to focus on the computational aspects of the covariation approach, in this paper we will not go into a discussion of the full lexical rule specification language introduced in Meurers (1995). The reader interested in that language and its precise interpretation can find the relevant details in that paper. 13 A more detailed presentation can be found in Minnen (in preparation). 14 We use rather abstract lexical rules in the examples to be able to focus on the relevant aspects. 15 Hinrichs and Nakazawa (1996) show that the question of whether the application criterion of lexical rules should be a subsumption ra unification test is an important question deserving of more attention. We here assume unification as the application criterion, which formally corresponds tothe conjunction ","@endWordPosition":"3286","@position":"20716","annotationId":"T53","@startWordPosition":"3285","@citStr":"Meurers (1995)"}]},"title":{"#tail":"\n","#text":"Towards a semantics for lexical rules as used in HPSG."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe Conference on Formal Grammar, Barcelona. Also in Proceedings of the ACQUILEX II Workshop on Lexical Rules,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Detmar Meurers"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"rawString":{"#tail":"\n","#text":"Meurers, Detmar and Guido Minnen. 1995. A computational treatment of HPSG lexical rules as covariation in lexical entries. In Proceedings ofthe Fifth International Workshop on Natural Language Understanding and Logic Programming, Lisbon, Portugal."},"#text":"\n","marker":{"#tail":"\n","#text":"Meurers, Minnen, 1995"},"location":{"#tail":"\n","#text":"Lisbon, Portugal."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ume 23, Number 4 Treatments of lexical rules as unary phrase structure rules also require their fully explicit specification, which entails the last problem mentioned above. In addition, computationally treating lexical rules on a par with phrase structure rules fails to take computational advantage of their specific properties. For example, the interaction of lexical rules is explored at run-time, even though the possible interaction can be determined at compile-time given the information available in the lexical rules and the base lexical entries. 2 Based on the research results reported in Meurers and Minnen (1995, 1996), we propose a new computational treatment of lexical rules that overcomes these short- comings and results in a more efficient processing of lexical rules as used in HPSG. We developed a compiler that takes as its input a set of lexical rules, deduces the nec- essary transfer of properties not changed by the individual lexical rules, and encodes the set of lexical rules and their interaction i to definite relations constraining lexical entries. Each lexical entry is automatically extended with a definite clause encoding of the lexical rule applications which the entry can undergo. The ","@endWordPosition":"576","@position":"3855","annotationId":"T54","@startWordPosition":"573","@citStr":"Meurers and Minnen (1995"}},"title":{"#tail":"\n","#text":"A computational treatment of HPSG lexical rules as covariation in lexical entries."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe Fifth International Workshop on Natural Language Understanding and Logic Programming,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Detmar Meurers"},{"#tail":"\n","#text":"Guido Minnen"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"Meurers, Detmar and Guido Minnen. 1996. Off-line constraint propagation for efficient HPSG processing. In Proceedings of TALN 96 (Joint Session with the Third International Conference on HPSG), Marseille, France."},"#text":"\n","marker":{"#tail":"\n","#text":"Meurers, Minnen, 1996"},"location":{"#tail":"\n","#text":"Marseille, France."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" contains enough information to permit a postponed execution of the interaction predicate. When C is the common information, and D1, ..., Dk are the definitions of the interaction predicate called, we use distributivity to factor out C in (C A D1) V -.. V (C A Dk): We compute C A (D1 V ... V Dk), where the r) are assumed to contain no further common factors. Once we have computed c, we use it to make the extended lexical entry more specific. This technique closely resembles the off-line constraint propagation technique described by Marriott, Naish, and Lassez (1988). The reader is referred to Meurers and Minnen (1996) for a more detailed iscussion of our use of constraint propagation. 32 We illustrate the result of constraint propagation with our example grammar. Since the running example of this paper was kept small, for expository reasons, by only including features that do get changed by one of the lexical rules (which violates the empirical observation mentioned above), the full set of lexical rules would not provide a good example. Let us therefore assume that only the lexical rules 1 and 2 of Figure 11 are given. We then only obtain seven of the clauses of Figure 22: those calling lex_rule_l or lex_r","@endWordPosition":"8899","@position":"55113","annotationId":"T55","@startWordPosition":"8896","@citStr":"Meurers and Minnen (1996)"}},"title":{"#tail":"\n","#text":"Off-line constraint propagation for efficient HPSG processing."},"booktitle":{"#tail":"\n","#text":"In Proceedings of TALN 96 (Joint Session with the Third International Conference on HPSG),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Detmar Meurers"},{"#tail":"\n","#text":"Guido Minnen"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"institution":{"#tail":"\n","#text":"University of Lille and Stanford University."},"rawString":{"#tail":"\n","#text":"Miller, Philip and Ivan Sag. 1993. French Clitic Climbing Without Clitics or Climbing. Unpublished Manuscript, University of Lille and Stanford University. Minnen, Guido. In preparation. Natural Language Processing with Constraint-Logic Grammars: Grammar Compilation for Declarative Under-determination. Ph D. thesis."},"#text":"\n","marker":{"#tail":"\n","#text":"Miller, Sag, 1993"},"location":{"#tail":"\n","#text":"Minnen, Guido."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"to transfer the specifications that must be preserved for different lexical entries. ? The authors are listed alphabetically. SFB 340, Kleine Wilhelmstr. 113, D-72074 Tiibingen, Germany. email: {dm,minnen}@sfs.nphil.uni-tuebingen.de URL: http://www.sfs.nphil.uni-tuebingen.de/sfb /b4home.html 1 This is, for example, the case for all proposals working with verbal exical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements. Also an analysis treating adjunct extraction via lexical rules (van Noord and Bouma 1994) results in an infinite lexicon. (~) 1997 Association for Computational Linguistics Computational Linguistics Volume 23, Number 4 Treatments of lexical rules as unary phrase structure rules also require their fully explicit specification, which entails the last problem mentioned above. In addition, computationally treating lexical rules on a par with phrase structure rules fails to take computational advantage of their specific properties. For example, the interaction ","@endWordPosition":"449","@position":"2991","annotationId":"T56","@startWordPosition":"446","@citStr":"Miller and Sag 1993"}},"title":{"#tail":"\n","#text":"French Clitic Climbing Without Clitics or Climbing. Unpublished Manuscript,"},"booktitle":{"#tail":"\n","#text":"In preparation. Natural Language Processing with Constraint-Logic Grammars: Grammar Compilation for Declarative Under-determination. Ph D. thesis."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Philip Miller"},{"#tail":"\n","#text":"Ivan Sag"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"rawString":{"#tail":"\n","#text":"Minnen, Guido, Dale Gerdemann, and Thilo GOtz. 1995. Off-line optimization for earley-style HPSG processing. In Proceedings ofthe 7th Conference ofthe EACL, Dublin, Ireland."},"#text":"\n","marker":{"#tail":"\n","#text":"Minnen, Gerdemann, GOtz, 1995"},"location":{"#tail":"\n","#text":"Dublin, Ireland."},"title":{"#tail":"\n","#text":"Off-line optimization for earley-style HPSG processing."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe 7th Conference ofthe EACL,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Guido Minnen"},{"#tail":"\n","#text":"Dale Gerdemann"},{"#tail":"\n","#text":"Thilo GOtz"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"Minnen, Guido, Dale Gerdemann, and Erhard Hinrichs. 1996. Direct automated inversion of logic grammars. New Generation Computing 14(2):131-168."},"journal":{"#tail":"\n","#text":"New Generation Computing"},"#text":"\n","pages":{"#tail":"\n","#text":"14--2"},"marker":{"#tail":"\n","#text":"Minnen, Gerdemann, Hinrichs, 1996"},"title":{"#tail":"\n","#text":"Direct automated inversion of logic grammars."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Guido Minnen"},{"#tail":"\n","#text":"Dale Gerdemann"},{"#tail":"\n","#text":"Erhard Hinrichs"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1986"},"rawString":{"#tail":"\n","#text":"Naish, Lee. 1986. Negation and Control in Prolog. Springer Verlag, New York."},"#text":"\n","marker":{"#tail":"\n","#text":"Naish, 1986"},"publisher":{"#tail":"\n","#text":"Springer Verlag,"},"location":{"#tail":"\n","#text":"New York."},"title":{"#tail":"\n","#text":"Negation and Control in Prolog."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Lee Naish"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1990"},"rawString":{"#tail":"\n","#text":"O'Keefe, Richard. 1990. The Craft of Prolog. MIT Press, Cambridge, MA."},"#text":"\n","marker":{"#tail":"\n","#text":"O'Keefe, 1990"},"publisher":{"#tail":"\n","#text":"MIT Press,"},"location":{"#tail":"\n","#text":"Cambridge, MA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" the lexical entry of Figure 15. The base lexical entry is fed into the first argument of the call to the interaction predicate q_l. For each solution to a call to q_l the value of ~ is a derived lexical entry. Encoding a finite-state automaton as definite relations is rather straightforward. In fact, one can view the representations as notational variants of one another. Each transition in the automaton is translated into a definite relation in which the corre- sponding lexical rule predicate is called, and each final state is encoded by a unit clause. Using an accumulator passing technique (O'Keefe 1990), we ensure that upon execution of a call to the interaction predicate q_l a new lexical entry is derived as the result of successive application of a number of lexical rules. Because of the word class specialization step discussed in Section 3.3, the execution avoids trying out many lexical rule applications that are guaranteed to fail. We illustrate the encoding with the finite-state automaton of Figure 16. As the lexical rules themselves are already translated into a definite clause representation in the first compilation step, the interaction predicates only need to ensure that the right c","@endWordPosition":"7187","@position":"44063","annotationId":"T57","@startWordPosition":"7186","@citStr":"O'Keefe 1990"}},"title":{"#tail":"\n","#text":"The Craft of Prolog."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Richard O'Keefe"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Oliva, Karel. 1994. HPSG lexicon without lexical rules. In Proceedings ofthe 15th Conference on Computational Linguistics (COLING), Kyoto, Japan."},"#text":"\n","marker":{"#tail":"\n","#text":"Oliva, 1994"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" their interaction. Finally, it automatically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexical rule needs to be specified. 7.3 Alternative Ways to Express Lexical Generalizations Lexical rules have not gone unchallenged as a mechanism for expressing eneraliza- tions over lexical information. In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; 564 Meurers and Minnen Covariation Approach to HPSG Lexical Rules Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995). The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy. These approaches seem to propose a completely different way to capture lexical generalizations. It is therefore interesting that the covariation lexical rule compiler produces a lexicon encoding that, basically, uses an underspecification representation: The resulting definite clause representation after constraint propagation represents the common information in the base lexical entry, ","@endWordPosition":"10771","@position":"67236","annotationId":"T58","@startWordPosition":"10770","@citStr":"Oliva 1994"}},"title":{"#tail":"\n","#text":"HPSG lexicon without lexical rules."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe 15th Conference on Computational Linguistics (COLING), Kyoto,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Karel Oliva"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"institution":{"#tail":"\n","#text":"University of Stuttgart,"},"rawString":{"#tail":"\n","#text":"Opalka, Annette. 1995. Statische Programmtransformationen zur effizienten Verarbeitung constraintbasierter Grammatiken. Diplomarbeit, University of Stuttgart, Stuttgart, Germany."},"#text":"\n","marker":{"#tail":"\n","#text":"Opalka, 1995"},"location":{"#tail":"\n","#text":"Stuttgart, Germany."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"lly, it automatically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexical rule needs to be specified. 7.3 Alternative Ways to Express Lexical Generalizations Lexical rules have not gone unchallenged as a mechanism for expressing eneraliza- tions over lexical information. In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; 564 Meurers and Minnen Covariation Approach to HPSG Lexical Rules Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995). The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy. These approaches seem to propose a completely different way to capture lexical generalizations. It is therefore interesting that the covariation lexical rule compiler produces a lexicon encoding that, basically, uses an underspecification representation: The resulting definite clause representation after constraint propagation represents the common information in the base lexical entry, and uses a definite claus","@endWordPosition":"10775","@position":"67261","annotationId":"T59","@startWordPosition":"10774","@citStr":"Opalka 1995"}},"title":{"#tail":"\n","#text":"Statische Programmtransformationen zur effizienten Verarbeitung constraintbasierter Grammatiken. Diplomarbeit,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Annette Opalka"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1987"},"rawString":{"#tail":"\n","#text":"Pereira, Fernando and Stuart Shieber. 1987. Prolog and Natural Language Analysis. CSLI Lecture Notes. Center for the Study of Language and Information, Stanford University, Stanford, CA."},"#text":"\n","marker":{"#tail":"\n","#text":"Pereira, Shieber, 1987"},"location":{"#tail":"\n","#text":"Stanford University, Stanford, CA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"omaton representing global lexical rule application is pruned with respect o a particular base lexical entry, we know which subclass we are dealing with. For each interaction defini- tion we can therefore check which of the flame clauses are applicable and discard the non-applicable ones. We thereby eliminate the redundant nondeterminism resulting from multiply defined frame predicates. The elimination of redundant nondeterminism is based on Unfold/Fold trans- formation techniques (Tamaki and Sato 1984). 29 The unfolding transformation is also referred to as partial execution, for example, by Pereira and Shieber (1987). Intuitively understood, unfolding comprises the evaluation of a particular literal in the body of a clause at compile-time. As a result, the literal can be removed from the body of 29 This improvement of the covariation encoding can also be viewed as an instance of the program transformation technique r ferred to as deletion of clauses with a finitely failed body (Pettorossi and Proietti 1994). 558 Meurers and Minnen Covariation Approach to HPSG Lexical Rules extended lexical entries call I .~ interaction predicates call unfolding c unfolding Figure 20 Schematic representation f the successi","@endWordPosition":"7755","@position":"47972","annotationId":"T60","@startWordPosition":"7752","@citStr":"Pereira and Shieber (1987)"}},"title":{"#tail":"\n","#text":"Prolog and Natural Language Analysis. CSLI Lecture Notes. Center for the Study of Language and Information,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Fernando Pereira"},{"#tail":"\n","#text":"Stuart Shieber"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Pettorossi, Alberto and Maurizio Proietti. 1994. Transformations of logic programs: Foundations and techniques. Journal of Logic Programming 19/20:261-320."},"journal":{"#tail":"\n","#text":"Journal of Logic Programming"},"#text":"\n","pages":{"#tail":"\n","#text":"19--20"},"marker":{"#tail":"\n","#text":"Pettorossi, Proietti, 1994"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"limination of redundant nondeterminism is based on Unfold/Fold trans- formation techniques (Tamaki and Sato 1984). 29 The unfolding transformation is also referred to as partial execution, for example, by Pereira and Shieber (1987). Intuitively understood, unfolding comprises the evaluation of a particular literal in the body of a clause at compile-time. As a result, the literal can be removed from the body of 29 This improvement of the covariation encoding can also be viewed as an instance of the program transformation technique r ferred to as deletion of clauses with a finitely failed body (Pettorossi and Proietti 1994). 558 Meurers and Minnen Covariation Approach to HPSG Lexical Rules extended lexical entries call I .~ interaction predicates call unfolding c unfolding Figure 20 Schematic representation f the successive unfolding transformation. extended lexical entries call I ,, interaction predicates ca l l ,, lexical rule predicates &quot;~ unfolding / call .~ frame predicates / Figure 21 Schematic representation f the partial unfolding transformation. the clause. Whereas unfolding can be viewed as a symbolic way of going forward in computation, folding constitutes a symbolic step backwards in computation. Giv","@endWordPosition":"7820","@position":"48370","annotationId":"T61","@startWordPosition":"7817","@citStr":"Pettorossi and Proietti 1994"}},"title":{"#tail":"\n","#text":"Transformations of logic programs: Foundations and techniques."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Alberto Pettorossi"},{"#tail":"\n","#text":"Maurizio Proietti"}]}},{"volume":{"#tail":"\n","#text":"1"},"#tail":"\n","date":{"#tail":"\n","#text":"1987"},"rawString":{"#tail":"\n","#text":"Pollard, Carl and Ivan Sag. 1987. Information-based Syntax and Semantics, Vol. 1. Number 13 of CSLI Lecture Notes. Center for the Study of Language and Information, Stanford University, Stanford, CA."},"journal":{"#tail":"\n","#text":"Information-based Syntax and Semantics,"},"#text":"\n","marker":{"#tail":"\n","#text":"Pollard, Sag, 1987"},"location":{"#tail":"\n","#text":"Stanford University, Stanford, CA."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" perspective on lexical rules. 546 Meurers and Minnen Covariation Approach to HPSG Lexical Rules sl \\] LOC\\] CAT LOC\\[CAT HEAD VAL HAVrFbVFOOpsP tlJ su , INDEX \\[VAL (IL 'CONT LCOMpS /\\[LOC\\]CONTll NDEX \\[~\\]1 \\[\\] t---+ VFORM pas\\] SUBJ / \\[LOC\\] CONT \\[ INDEX \\[\\]\\]/ / (\\[LOC ICATI HEAD prep\\[ PFORM COMPS \\[\\] O L CONT\\]INDEX \\[\\] Figure 2 A passivization lexical rule. written as fully specified relations between words, rather, only what is supposed to be changed is specified. Consider, for example, the lexical rule in Figure 2, which encodes a passive lexicai rule like the one presented by Pollard and Sag (1987, 215) in terms of the setup of Pollard and Sag (1994, ch. 9). This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form2 ?The rule takes the index of the least oblique complement of the input and assigns it to the subject of the output. The index that the subject bore in the input is assigned to an optional prepositional complement in the output. Only the verb form and some indices are specified to be changed, and thus other input properties, like the phonology, the semantics, or the nonlocal specifications, are preserved in the out","@endWordPosition":"2362","@position":"15030","annotationId":"T62","@startWordPosition":"2359","@citStr":"Pollard and Sag (1987"},{"#tail":"\n","#text":"t the beginning of processing does not have to be explored. 31 As it stands, our encoding of lexical rules and their application as covariation in lexical entries does not yet support the application of lexical rules on-the-fly. With respect o processing, the extended lexical entry of Figure 17 is problematic because before execution of the call to q_l, it is not known which information of the base lexical entry ends up in a derived lexical entry, i.e., tag ~ is completely uninstantiated. This means that there is no way of indexing the lexical entries according to what kind of 31 According to Pollard and Sag (1987) on-the-fly application of lexical rules is also well-suited to playing a role in a model of language use. 560 Meurers and Minnen Covariation Approach to HPSG Lexical Rules derived entry one is looking for. As a result, it is necessary to execute the call to q_l immediately when the lexical entry is used during processing. Otherwise, there would be no information available to restrict the search-space of a generation or parsing process. Flickinger, Pollard, and Wasow (1985) solve this problem using additional specifi- cations: &quot;By providing with each lexical rule a generic class frame which sp","@endWordPosition":"8479","@position":"52437","annotationId":"T63","@startWordPosition":"8476","@citStr":"Pollard and Sag (1987)"}]},"title":{"#tail":"\n","#text":"of CSLI Lecture Notes. Center for the Study of Language and Information,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Carl Pollard"},{"#tail":"\n","#text":"Ivan Sag"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Pollard, Carl and Ivan Sag. 1994. Head-Driven Phrase Structure Grammar. University of Chicago Press, Chicago, IL."},"#text":"\n","marker":{"#tail":"\n","#text":"Pollard, Sag, 1994"},"publisher":{"#tail":"\n","#text":"University of Chicago Press,"},"location":{"#tail":"\n","#text":"Chicago, IL."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"l-motivated conven- tion since it avoids splitting up lexical rules to transfer the specifications that must be preserved for different lexical entries. ? The authors are listed alphabetically. SFB 340, Kleine Wilhelmstr. 113, D-72074 Tiibingen, Germany. email: {dm,minnen}@sfs.nphil.uni-tuebingen.de URL: http://www.sfs.nphil.uni-tuebingen.de/sfb /b4home.html 1 This is, for example, the case for all proposals working with verbal exical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements. Also an analysis treating adjunct extraction via lexical rules (van Noord and Bouma 1994) results in an infinite lexicon. (~) 1997 Association for Computational Linguistics Computational Linguistics Volume 23, Number 4 Treatments of lexical rules as unary phrase structure rules also require their fully explicit specification, which entails the last problem mentioned above. In addition, computationally treating lexical rules on a par with phrase structure rules fails to take computational ad","@endWordPosition":"439","@position":"2924","annotationId":"T64","@startWordPosition":"436","@citStr":"Pollard and Sag 1994"},{"#tail":"\n","#text":" to on-the-fly application of lexical rules is presented in Section 5. In Section 6, we dis- cuss implementation results and illustrate the efficiency of the proposed encoding. A comparison with other computational approaches to lexical rules (Section 7) and some concluding remarks (Section 8) end the paper. 2. Background In this section we introduce the formal setup of HPSG grammars that we assume and discuss two ways to formalize a lexical rule mechanism and their consequences for a computational treatment. 2.1 A Formal Setup for HPSG Grammars An HPSG grammar formally consists of two parts (Pollard and Sag 1994): The signature defines the ontology of linguistic objects, and the theory, i.e., the usually implicative constraints encoding the grammatical principles, describes the subset of those linguistic 2 This is not to say that a special precompilation treatment along those lines would not be profitable for phrase structure ules. In fact, such a proposal ismade by Torisawa nd Tsuji (1996). 544 Meurers and Minnen Covariation Approach to HPSG Lexical Rules objects that are grammatical. The constraints constituting the theory are expressions of a formal language that define the set of grammatical objec","@endWordPosition":"982","@position":"6466","annotationId":"T65","@startWordPosition":"979","@citStr":"Pollard and Sag 1994"},{"#tail":"\n","#text":" Covariation Approach to HPSG Lexical Rules sl \\] LOC\\] CAT LOC\\[CAT HEAD VAL HAVrFbVFOOpsP tlJ su , INDEX \\[VAL (IL 'CONT LCOMpS /\\[LOC\\]CONTll NDEX \\[~\\]1 \\[\\] t---+ VFORM pas\\] SUBJ / \\[LOC\\] CONT \\[ INDEX \\[\\]\\]/ / (\\[LOC ICATI HEAD prep\\[ PFORM COMPS \\[\\] O L CONT\\]INDEX \\[\\] Figure 2 A passivization lexical rule. written as fully specified relations between words, rather, only what is supposed to be changed is specified. Consider, for example, the lexical rule in Figure 2, which encodes a passive lexicai rule like the one presented by Pollard and Sag (1987, 215) in terms of the setup of Pollard and Sag (1994, ch. 9). This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form2 ?The rule takes the index of the least oblique complement of the input and assigns it to the subject of the output. The index that the subject bore in the input is assigned to an optional prepositional complement in the output. Only the verb form and some indices are specified to be changed, and thus other input properties, like the phonology, the semantics, or the nonlocal specifications, are preserved in the output. This is so since the lexical rule in Figure 2 &quot;(","@endWordPosition":"2373","@position":"15083","annotationId":"T66","@startWordPosition":"2370","@citStr":"Pollard and Sag (1994"},{"#tail":"\n","#text":"se paths in words serving as input to a lexical rule that occur in the out-specification f the lexical rule but are not assigned a type value. For example, the lexical rule 1 of Figure 6 applies to word objects with tl as their c value and to those having t2 as their c value. With respect o frame specification this means that there can be lexical entries, such as the one in Figure 7, for which we need to make sure that tl as the value of c gets transferred. 16 One would think that the type information tl, which is more specific than that 16 A linguistic example based on the signature given by Pollard and Sag (1994) would be a lexical rule deriving predicative signs from nonpredicative ones, i.e., changing the PRD value of substantive signs from - to +, much like the lexical rule for NPs given by Pollard and Sag (1994, p. 360, fn. 20). In such a Predicative Lexical Rule (which we only note as an example and not as a linguistic proposal) the subtype of the head object undergoing the rule as well as the value of the features only appropriate for the subtypes of substantive either is lost or must be specified by a separate rule for each of the subtypes. 550 Meurers and Minnen Covariation Approach to HPSG Le","@endWordPosition":"3909","@position":"24380","annotationId":"T67","@startWordPosition":"3906","@citStr":"Pollard and Sag (1994)"}]},"title":{"#tail":"\n","#text":"Head-Driven Phrase Structure Grammar."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Carl Pollard"},{"#tail":"\n","#text":"Ivan Sag"}]}},{"volume":{"#tail":"\n","#text":"23"},"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"institution":{"#tail":"\n","#text":"Computational Linguistics"},"rawString":{"#tail":"\n","#text":"Computational Linguistics Volume 23, Number 4 Riehemann, Susanne. 1993. Word Formation in Lexical Type Hierarchies: A Case Study of bar-Adjectives in German. Master's thesis, University of Ti~bingen, Tiibingen, Germany. Also published as SfS-Report-02-93, Seminar fiir Sprachwissenschaft, University of Ti~bingen."},"#text":"\n","marker":{"#tail":"\n","#text":"Riehemann, 1993"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"exical rules and their interaction. Finally, it automatically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexical rule needs to be specified. 7.3 Alternative Ways to Express Lexical Generalizations Lexical rules have not gone unchallenged as a mechanism for expressing eneraliza- tions over lexical information. In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; 564 Meurers and Minnen Covariation Approach to HPSG Lexical Rules Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995). The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy. These approaches seem to propose a completely different way to capture lexical generalizations. It is therefore interesting that the covariation lexical rule compiler produces a lexicon encoding that, basically, uses an underspecification representation: The resulting definite clause representation after constraint propagation represents the common information in the base lex","@endWordPosition":"10769","@position":"67224","annotationId":"T68","@startWordPosition":"10768","@citStr":"Riehemann 1993"}},"title":{"#tail":"\n","#text":"Word Formation in Lexical Type Hierarchies: A Case Study of bar-Adjectives in German. Master's thesis,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Susanne Riehemann"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"institution":{"#tail":"\n","#text":"Stanford University,"},"rawString":{"#tail":"\n","#text":"Sanfilippo, Antonio. 1995. Lexical polymorphism and word disambiguation. In Proceedings ofthe American Associa tion.for Arti~cial Intelligence (AAAI), Stanford University, Stanford, CA."},"#text":"\n","marker":{"#tail":"\n","#text":"Sanfilippo, 1995"},"location":{"#tail":"\n","#text":"Stanford, CA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"atically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexical rule needs to be specified. 7.3 Alternative Ways to Express Lexical Generalizations Lexical rules have not gone unchallenged as a mechanism for expressing eneraliza- tions over lexical information. In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; 564 Meurers and Minnen Covariation Approach to HPSG Lexical Rules Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995). The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy. These approaches seem to propose a completely different way to capture lexical generalizations. It is therefore interesting that the covariation lexical rule compiler produces a lexicon encoding that, basically, uses an underspecification representation: The resulting definite clause representation after constraint propagation represents the common information in the base lexical entry, and uses a definite clause attachment to en","@endWordPosition":"10777","@position":"67279","annotationId":"T69","@startWordPosition":"10776","@citStr":"Sanfilippo 1995"}},"title":{"#tail":"\n","#text":"Lexical polymorphism and word disambiguation."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe American Associa tion.for Arti~cial Intelligence (AAAI),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Antonio Sanfilippo"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1983"},"rawString":{"#tail":"\n","#text":"Shieber, Stuart, Hans Uszkoreit, Fernando Pereira, Jane Robinson, and Mabry Tyson. 1983. The formalism and implementation of PATR II. In Research on Interactive Acquisition and Use of Knowledge. SRI International, Menlo Park, CA, pages 39-79."},"#text":"\n","pages":{"#tail":"\n","#text":"39--79"},"marker":{"#tail":"\n","#text":"Shieber, Uszkoreit, Pereira, Robinson, Tyson, 1983"},"location":{"#tail":"\n","#text":"Menlo Park, CA,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"xicon can be less time and space efficient han using a lexicon encoding that makes computational use of generalizations over lexical information, as, for example, the covariation encoding. 7.2 Lexical Rules as Unary Phrase Structure Rules Another common approach to lexical rules is to encode them as unary phrase structure rules. This approach is taken, for example, in LKB (Copestake 1992) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules (Copestake 1993, 31). A similar method is included in PATR-II (Shieber et al 1983) and can be used to encode lexical rules as binary relations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or the TFS system (Emele and Zajac 1990; Emele 1994). The covariation approach described in this paper can be viewed as a domain-specific refinement of such a treatment of lexical rules. The encoding of lexical rules used in the covariation approach is related to the work of van Noord and Bouma (1994), who describe the hand-encoding of a single lexical rule as definite relations and show how these relations can be used to constrain a lexical entry. The covariation appro","@endWordPosition":"10540","@position":"65777","annotationId":"T70","@startWordPosition":"10537","@citStr":"Shieber et al 1983"}},"title":{"#tail":"\n","#text":"The formalism and implementation of PATR II."},"booktitle":{"#tail":"\n","#text":"In Research on Interactive Acquisition and Use of Knowledge. SRI International,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Stuart Shieber"},{"#tail":"\n","#text":"Hans Uszkoreit"},{"#tail":"\n","#text":"Fernando Pereira"},{"#tail":"\n","#text":"Jane Robinson"},{"#tail":"\n","#text":"Mabry Tyson"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1984"},"rawString":{"#tail":"\n","#text":"Tamaki, Hisao and Taisuke Sato. 1984. Unfold/Fold transformation f logic programs. In Proceedings ofthe 2nd International Conference on Logic Programming, Uppsala, Sweden."},"#text":"\n","marker":{"#tail":"\n","#text":"Tamaki, Sato, 1984"},"location":{"#tail":"\n","#text":"Uppsala, Sweden."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"tries to which a lexical rule can be applied. During word class specialization, though, when the finite-state automaton representing global lexical rule application is pruned with respect o a particular base lexical entry, we know which subclass we are dealing with. For each interaction defini- tion we can therefore check which of the flame clauses are applicable and discard the non-applicable ones. We thereby eliminate the redundant nondeterminism resulting from multiply defined frame predicates. The elimination of redundant nondeterminism is based on Unfold/Fold trans- formation techniques (Tamaki and Sato 1984). 29 The unfolding transformation is also referred to as partial execution, for example, by Pereira and Shieber (1987). Intuitively understood, unfolding comprises the evaluation of a particular literal in the body of a clause at compile-time. As a result, the literal can be removed from the body of 29 This improvement of the covariation encoding can also be viewed as an instance of the program transformation technique r ferred to as deletion of clauses with a finitely failed body (Pettorossi and Proietti 1994). 558 Meurers and Minnen Covariation Approach to HPSG Lexical Rules extended lexical","@endWordPosition":"7737","@position":"47854","annotationId":"T71","@startWordPosition":"7734","@citStr":"Tamaki and Sato 1984"}},"title":{"#tail":"\n","#text":"Unfold/Fold transformation f logic programs."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe 2nd International Conference on Logic Programming,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Hisao Tamaki"},{"#tail":"\n","#text":"Taisuke Sato"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"Torisawa, Kentaro and Jun'ichi Tsuji. 1996. Off-line raising, dependency analysis and partial unification. In Proceedings ofTALN 96 (Joint Session with the Third International Conference on HPSG), Marseille, France."},"#text":"\n","marker":{"#tail":"\n","#text":"Torisawa, Tsuji, 1996"},"location":{"#tail":"\n","#text":"Marseille, France."},"title":{"#tail":"\n","#text":"Off-line raising, dependency analysis and partial unification."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofTALN 96 (Joint Session with the Third International Conference on HPSG),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kentaro Torisawa"},{"#tail":"\n","#text":"Jun'ichi Tsuji"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"van Noord, Gertjan and Gosse Bouma. 1994. The scope of adjuncts and the processing of lexical rules. In Proceedings ofthe 15th Conference on Computational Linguistics (COLING), Kyoto, Japan. Some of the above papers can be obtained electronically through the URL provided on the first page."},"#text":"\n","pages":{"#tail":"\n","#text":"page."},"marker":{"#tail":"\n","#text":"van Noord, Bouma, 1994"},"title":{"#tail":"\n","#text":"The scope of adjuncts and the processing of lexical rules."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe 15th Conference on Computational Linguistics (COLING), Kyoto,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Gertjan van Noord"},{"#tail":"\n","#text":"Gosse Bouma"}]}}]}}]}}
