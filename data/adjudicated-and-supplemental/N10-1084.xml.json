{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","figure":[{"#tail":"\n","@confidence":"0.47486425","#text":"\nOriginal phrase Paraphrases\nthe end of this year later this year\nthe end of the year\nyear end\na number of people some of my colleagues\ndifferences\nthe European peoples party\nthe PPE group\n"},{"#tail":"\n","@confidence":"0.821653625","#text":"\nW<c><n> = (WL\n<c>\n<n>,WR\n<c>\n<n>), where WL\n<c>\n<n> is\ncomposed by <c>OUTLeft concatenated with <n-\n"},{"#tail":"\n","@confidence":"0.966176555555556","#text":"\nINPUT: S, P, P ?, n,maxC\nOUTPUT: the acceptability of paraphrase P ?\nchecked by (n, maxC)\nFOR each context size C from 1 to maxC\nGET a context window pair WCn\nIF O(WCn ) is zero THEN\nOUTPUT paraphrase P ? fails\nEND FOR\nOUTPUT paraphrase P ? passes\n"},{"#tail":"\n","@confidence":"0.853995944444444","#text":"\nN-\ngram\nContext Accuracy Precision Recall F-measure\nSize (%) (%) (%) (%)\n2-\ngram\n1 62.0 62.1 98.0 76.0\n3-\ngram\n1 62.5 65.1 84.2 73.4\n2 67.3 72.9 74.4 73.6\n4-\ngram\n1 58.5 71.3 54.5 61.8\n2 53.2 84.7 29.3 43.5\n3 51.8 89.6 24.4 38.3\n5-\ngram\n"},{"#tail":"\n","@confidence":"0.842758666666667","#text":"\nN-\ngram\nContext Accuracy Precision Recall F-measure\nSize (%) (%) (%) (%)\n2-\ngram\n1 68.0 67.7 91.9 78.0\n3-\ngram\n1 67.3 70.9 79.3 74.9\n2 69.5 77.7 70.7 74.0\n4-\ngram\n1 59.5 75.6 50.4 60.5\n2 53.8 88.6 28.5 43.1\n3 52.0 92.2 24.0 38.1\n5-\ngram\n"}],"author":[{"#tail":"\n","@confidence":"0.421107","#text":"\nLos Angeles, California, June 2010. c?2010 Association for Computational Linguistics\n"},{"#tail":"\n","@confidence":"0.964724","#text":"\nChing-Yun Chang\n"},{"#tail":"\n","@confidence":"0.975749","#text":"\nStephen Clark\n"}],"subsectionHeader":[{"#tail":"\n","@confidence":"0.906943","#text":"\n2.1 Synonym Substitution\n"},{"#tail":"\n","@confidence":"0.997362","#text":"\n2.2 Syntactic Transformations\n"},{"#tail":"\n","@confidence":"0.995671","#text":"\n2.3 Semantic Transformations\n"},{"#tail":"\n","@confidence":"0.997356","#text":"\n3.1 Paraphrase Dictionary\n"},{"#tail":"\n","@confidence":"0.999623","#text":"\n3.2 Google N-gram Data\n"},{"#tail":"\n","@confidence":"0.999191","#text":"\n3.3 Paraphrase Judgement Corpus\n"},{"#tail":"\n","@confidence":"0.972005","#text":"\n4.1 Google N-gram Method\n"},{"#tail":"\n","@confidence":"0.998064","#text":"\n4.2 Syntactic Filter\n"},{"#tail":"\n","@confidence":"0.911589","#text":"\n4.3 Results\n"},{"#tail":"\n","@confidence":"0.997773","#text":"\n5.1 Data Embedding Procedure\n"},{"#tail":"\n","@confidence":"0.998294","#text":"\n5.2 Data Extracting Procedure\n"}],"footnote":{"#tail":"\n","@confidence":"0.734619666666667","#text":"\n1The observer may also be a computer program, designed to\ndetect statistical anomalies in the image representation which\nmay indicate the presence of hidden information.\n"},"title":[{"#tail":"\n","@confidence":"0.703208","#text":"\nHuman Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 591?599,\n"},{"#tail":"\n","@confidence":"0.867767","#text":"\nLinguistic Steganography Using Automatically Generated Paraphrases\n"}],"@confidence":"0.000003","#tail":"\n","reference":{"#tail":"\n","@confidence":"0.998048696078431","#text":"\nMikhail J. Atallah, Craig J. McDonough, Victor Raskin,\nand Sergei Nirenburg. 2001a. Natural language pro-\ncessing for information assurance and security: an\noverview and implementations. In Proceedings of the\n2000 workshop on New security paradigms, pages 51?\n65, Ballycotton, County Cork, Ireland.\nMikhail J. Atallah, Victor Raskin, Michael C. Crogan,\nChristian Hempelmann, Florian Kerschbaum, Dina\nMohamed, and Sanket Naik. 2001b. Natural lan-\nguage watermarking: design, analysis, and a proof-\nof-concept implementation. In Proceedings of the 4th\nInternational Information Hiding Workshop, volume\n2137, pages 185?199, Pittsburgh, Pennsylvania.\nMikhail J. Atallah, Victor Raskin, Christian F. Hempel-\nmann, Mercan Karahan, Umut Topkara, Katrina E.\nTriezenberg, and Radu Sion. 2002. Natural language\nwatermarking and tamperproofing. In Proceedings of\nthe 5th International Information Hiding Workshop,\npages 196?212, Noordwijkerhout, The Netherlands.\nRegina Barzilay and Kathleen R. McKeown. 2001. Ex-\ntracting paraphrases from a parallel corpus. In Pro-\nceedings of the 39th ACL, pages 50?57, Toulouse.\nRichard Bergmair. 2007. A comprehensive bibliogra-\nphy of linguistic steganography. In Proceedings of the\nSPIE Conference on Security, Steganography, and Wa-\ntermarking of Multimedia Contents, volume 6505.\nShane Bergsma, Dekang Lin, and Randy Goebel. 2009.\nWeb-scale n-gram models for lexical disambiguation.\nIn Proceedings of the 21st International Joint Con-\nference on Artifical Intelligence, pages 1507?1512,\nPasadena, CA.\nIgor A. Bolshakov. 2004. A method of linguistic\nsteganography based on coladdressally-verified syn-\nonym. In Information Hiding: 6th International Work-\nshop, volume 3200, pages 180?191, Toronto, Canada.\nChris Callison-Burch. 2008. Syntactic constraints on\nparaphrases extracted from parallel corpora. In Pro-\nceedings of the EMNLP Conference, pages 196?205,\nHonolulu, Hawaii.\nMark Chapman and George I. Davida. 1997. Hiding the\nhidden: A software system for concealing ciphertext\nas innocuous text. In Proceedings of the First Interna-\ntional Conference on Information and Communication\nSecurity, volume 1334, pages 335?345, Beijing.\nStephen Clark and James R. Curran. 2007. Wide-\ncoverage efficient statistical parsing with CCG and\nlog-linear models. Comp. Ling., 33(4):493?552.\nJessica Fridrich. 2009. Steganography in Digital Media:\nPrinciples, Algorithms, and Applications. Cambridge\nUniversity Press, first edition.\nYuling Liu, Xingming Sun, and Yong Wu. 2005. A nat-\nural language watermarking based on Chinese syntax.\nIn Advances in Natural Computation, volume 3612,\npages 958?961, Changsha, China.\nMitchell P. Marcus, Beatrice Santorini, and Mary A.\nMarcinkiewicz. 1993. Building a large annotated cor-\npus of English: the Penn Treebank. Computational\nLinguistics, 19:313?330.\nHasan M. Meral, Emre Sevinc, Ersin Unkar, Bulent\nSankur, A. Sumru Ozsoy, and Tunga Gungor. 2007.\nSyntactic tools for text watermarking. In Proceed-\nings of the SPIE Conference on Security, Steganogra-\nphy, and Watermarking of Multimedia Contents, vol-\nume 6505, San Jose, CA.\nBrian Murphy and Carl Vogel. 2007. The syntax of con-\ncealment: reliable methods for plain text information\nhiding. In Proceedings of the SPIE Conference on Se-\ncurity, Steganography, and Watermarking of Multime-\ndia Contents, volume 6505, San Jose, CA.\nBrian Murphy. 2001. Syntactic information hiding in\nplain text. Masters Thesis. Trinity College Dublin.\nLip Y. Por, Ang T. Fong, and B. Delina. 2008.\nWhitesteg: a new scheme in information hiding using\ntext steganography. WSEAS Transactions on Comput-\ners, 7:735?745.\nCuneyt M. Taskiran, Mercan Topkara, and Edward J.\nDelp. 2006. Attacks on linguistic steganography sys-\ntems using text analysis. In Proceedings of the SPIE\nConference on Security, Steganography, and Water-\nmarking of Multimedia Contents, volume 6072, pages\n97?105, San Jose, CA.\nMercan Topkara, Cuneyt M. Taskiran, and Edward J.\nDelp. 2005. Natural language watermarking.\nIn Proceedings of the SPIE Conference on Secu-\nrity, Steganography, and Watermarking of Multimedia\nContents, volume 5681, pages 441?452, San Jose, CA.\nMercan Topkara, Umut Topkara, and Mikhail J. Atallah.\n2006a. Words are not enough: sentence level natural\nlanguage watermarking. In Proceedings of the ACM\nWorkshop on Content Protection and Security, pages\n37?46, Santa Barbara, CA.\nUmut Topkara, Mercan Topkara, and Mikhail J. Atal-\nlah. 2006b. The hiding virtues of ambiguity: quan-\ntifiably resilient watermarking of natural language text\nthrough synonym substitutions. In Proceedings of the\n8th Workshop on Multimedia and Security, pages 164?\n174, Geneva, Switzerland.\nM. Olga Vybornova and Benoit Macq. 2007. A\nmethod of text watermarking using presuppositions.\nIn Proceedings of the SPIE Conference on Secu-\nrity, Steganography, and Watermarking of Multimedia\nContents, volume 6505, San Jose, CA.\n"},"bodyText":[{"#tail":"\n","@confidence":"0.9995094375","#text":"\nThis paper describes a method for checking\nthe acceptability of paraphrases in context.\nWe use the Google n-gram data and a CCG\nparser to certify the paraphrasing grammati-\ncality and fluency. We collect a corpus of hu-\nman judgements to evaluate our system. The\nultimate goal of our work is to integrate text\nparaphrasing into a Linguistic Steganography\nsystem, by using paraphrases to hide informa-\ntion in a cover text. We propose automati-\ncally generated paraphrases as a new and use-\nful source of transformations for Linguistic\nSteganography, and show that our method for\nchecking paraphrases is effective at maintain-\ning a high level of imperceptibility, which is\ncrucial for effective steganography.\n"},{"#tail":"\n","@confidence":"0.99714026","#text":"\nSteganography is concerned with hiding informa-\ntion in some cover medium, by manipulating prop-\nerties of the medium in such a way that the hidden\ninformation is not easily detectable by an observer\n(Fridrich, 2009). The covert communication is such\nthat the very act of communication is to be kept se-\ncret from outside observers. A related area is Wa-\ntermarking, in which modifications are made to a\ncover medium in order to identify it, for example for\nthe purposes of copyright. Here the changes may\nbe known to an observer, and the task is to make\nthe changes in such a way that the watermark cannot\neasily be removed.\nThere is a large literature on image steganogra-\nphy and watermarking, in which images are mod-\nified to encode a hidden message or watermark.\nImage stegosystems exploit the redundancy in an\nimage representation together with limitations of\nthe human visual system. For example, a stan-\ndard image stegosystem uses the least-significant-bit\n(LSB) substitution technique. Since the difference\nbetween 11111111 and 11111110 in the value for\nred/green/blue intensity is likely to be undetectable\nby the human eye, the LSB can be used to hide infor-\nmation other than colour, without being perceptable\nby a human observer.1\nA key question for any steganography system is\nthe choice of cover medium. Given the ubiqui-\ntous nature of natural languages and electronic text,\ntext is an obvious medium to consider. However,\nthe literature on Linguistic Steganography, in which\nlinguistic properties of a text are modified to hide\ninformation, is small compared with other media\n(Bergmair, 2007). The likely reason is that it is\neasier to make changes to images and other non-\nlinguistic media which are undetectable by an ob-\nserver. Language has the property that even small\nlocal changes to a text, e.g. replacing a word by a\nword with similar meaning, may result in text which\nis anomalous at the document level, or anomalous\nwith respect to the state of the world. Hence find-\ning linguistic transformations which can be applied\nreliably and often is a challenging problem for Lin-\nguistic Steganography.\nIn this paper we focus on steganography rather\nthan watermarking, since we are interested in the re-\nquirement that any changes to a text be impercep-\ntible to an observer. Figure 1 shows the Linguistic\nSteganography framework. First, some secret mes-\nsage, represented as a sequence of bits, is hidden in a\n"},{"#tail":"\n","@confidence":"0.99569653030303","#text":"\ncover text using the embedding algorithm, resulting\nin the stego text.2 Next, the stego text passes the hu-\nman observer, who is happy for innocuous messages\nto pass between the sender and receiver, but will ex-\namine the text for any suspicious looking content.\nOnce the stego text reaches the receiver, the hidden\nmessage is recovered using the extracting algorithm.\nThere is a fundamental tradeoff in all steganogra-\nphy systems, and one that is especially apparent in\nthe Linguistic Steganography framework: the trade-\noff between imperceptibility and payload. Payload\nis the number of bits that can be encoded per unit\nof cover medium, for example per sentence in the\nlinguistic case. The tradeoff arises because any at-\ntempt to hide additional information in the cover\ntext, through the application of more linguistic trans-\nformations, is likely to increase the chances of rais-\ning the suspicions of the observer, by introducing\nanomalies into the text.\nThe key elements of a Linguistic Steganography\nsystem are the linguistic transformation and the em-\nbedding method. In this paper we focus on the lin-\nguistic transformation. Section 5 describes a pos-\nsible embedding method for our framework, and\nfor readers unfamiliar with linguistic steganography\nshows how linguistic transformations can be used to\nembed hidden bits in text.\nSection 2 describes some of the previous transfor-\nmations used in Linguistic Steganography. Note that\nwe are concerned with transformations which are\n2The message may have been encrypted initially also, as in\nthe figure, but this is not important in this paper; the key point\nis that the hidden message is a sequence of bits.\nlinguistic in nature, rather than dealing with superfi-\ncial properties of the text, e.g. the amount of white\nspace between words (Por et al, 2008). Our pro-\nposed method is based on the automatically acquired\nparaphrase dictionary described in Callison-Burch\n(2008), in which the application of paraphrases from\nthe dictionary encodes secret bits. One advantage\nof the dictionary is that it has wide coverage, be-\ning automatically extracted; however, a disadvan-\ntage is that it contains many paraphrases which are\neither inappropriate, or only appropriate in certain\ncontexts. Since we require any changes to be im-\nperceptible to a human observer, it is crucial to our\nsystem that any uses of paraphrasing are grammati-\ncal and retain the meaning of the original cover text.\nIn order to test the grammaticality and meaning\npreserving nature of a paraphrase, we employ a sim-\nple technique based on checking whether the con-\ntexts containing the paraphrase are in the Google n-\ngram corpus. This technique is based on the sim-\nple hypothesis that, if the paraphrase in context has\nbeen used many times before on the web, then it is\nan appropriate use. We test our n-gram-based sys-\ntem against some human judgements of the gram-\nmaticality of paraphrases in context. We find that\nusing larger contexts leads to a high precision sys-\ntem (100% when using 5-grams), but at the cost of\na reduced recall. This precision-recall tradeoff re-\nflects the inherent tradeoff between imperceptibility\nand payload in a Linguistic Steganography system.\nWe also experiment with a CCG parser (Clark and\nCurran, 2007), requiring that the contexts surround-\ning the original phrase and paraphrase are assigned\n"},{"#tail":"\n","@confidence":"0.984938555555556","#text":"\nthe same CCG lexical categories by the parser. This\nmethod increases the precision of the Google n-gram\ncheck with a slight loss in recall.\nA contribution of this paper is to advertise the Lin-\nguistic Steganography problem to the ACL commu-\nnity. The requirement that any linguistic transfor-\nmation maintain the grammaticality and meaning of\nthe cover text makes the problem a strong test for\nexisting NLP technology.\n"},{"#tail":"\n","@confidence":"0.999752470588235","#text":"\nThe simplest and most straightforward subliminal\nmodification of text is to substitute selected words\nwith their synonyms. The first lexical substitu-\ntion method was proposed by Chapman and Davida\n(1997). Later works, such as Atallah et al (2001a),\nBolshakov (2004), Taskiran et al (2006) and Top-\nkara et al (2006b), further made use of part-of-\nspeech taggers and electronic dictionaries, such as\nWordNet and VerbNet, to increase the robustness of\nthe method. Taskiran et al (2006) attempt to use\ncontext by prioritizing the alternatives using an n-\ngram language model; that is, rather than randomly\nchoose an option from the synonym set, the system\nrelies on the language model to select the synonym.\nTopkara et al (2005) and Topkara et al (2006b) re-\nport an average embedding capacity of 0.67 bits per\nsentence for the synonym substitution method.\n"},{"#tail":"\n","@confidence":"0.999703130434783","#text":"\nThe second and the most widely used manipulations\nfor linguistic steganography are syntactic transfor-\nmations. This method is based on the fact that a sen-\ntence can be transformed into more than one seman-\ntically equivalent syntactic structure, using trans-\nformations such as passivization, topicalization and\nclefting. The first syntactic transformation method is\npresented by Atallah et al (2001a). Later, Atallah et\nal. (2001b) embedded information in the tree struc-\nture of the text by adjusting the structural proper-\nties of intermediate representations of sentences. In\nother words, instead of performing lexical substitu-\ntion directly to the text, the secret message is embed-\nded into syntactic parse trees of the sentences. Liu\net al (2005), Meral et al (2007), Murphy (2001),\nMurphy and Vogel (2007) and Topkara et al (2006a)\nall belong to the syntactic transformation category.\nAfter embedding the secret message, modified deep\nstructure forms are converted into the surface struc-\nture format via language generation tools. Atallah et\nal. (2001b) and Topkara et al (2006a) attained the\nembedding capacity of 0.5 bits per sentence with the\nsyntactic transformation method.\n"},{"#tail":"\n","@confidence":"0.998601866666667","#text":"\nThe semantic transformation method is the most so-\nphisticated approach for linguistic steganography,\nand perhaps impractical given the current state-of-\nthe-art for NLP technology. It requires some sophis-\nticated tools and knowledge to model natural lan-\nguage semantics. Atallah et al (2002) used seman-\ntic transformations and embed information in text-\nmeaning representation (TMR) trees of the text by\neither pruning, grafting or substituting the tree struc-\nture with information available from ontological se-\nmantic resources. Vybornova and Macq (2007)\naimed to embed information by exploiting the lin-\nguistic phenomenon of presupposition, with the idea\nthat some presuppositional information can be re-\nmoved without changing the meaning of a sentence.\n"},{"#tail":"\n","@confidence":"0.99942275","#text":"\nThe cover text used for our experiments consists of\nnewspaper sentences from Section 00 of the Penn\nTreebank (Marcus et al, 1993). Hence we require\npossible paraphrases for phrases that occur in Sec-\ntion 00. The paraphrase dictionary that we use\nwas generated for us by Chris Callison-Burch, using\nthe technique described in Callison-Burch (2008),\nwhich exploits a parallel corpus and methods devel-\noped for statistical machine translation.\nTable 1 gives summary statistics of the paraphrase\ndictionary and its coverage on Section 00 of the\nPenn Treebank. The length of the extracted n-gram\nphrases ranges from unigrams to five-grams. The\ncoverage figure gives the percentage of sentences\nwhich have at least one phrase in the dictionary. The\ncoverage is important for us because it determines\nthe payload capacity of the embedding method de-\nscribed in Section 5.\nTable 2 lists some examples 5-gram phrases and\nparaphrases from the dictionary. The format of the\n"},{"#tail":"\n","@confidence":"0.961284666666667","#text":"\ntionary\ndictionary is a mapping from phrases to sets of pos-\nsible paraphrases. Each paraphrase also has a prob-\nability, based on a statistical machine translation\nmodel, but we do not use that feature here. The ex-\namples show that, while some of the paraphrases are\nof a high quality, some are not. For example, dif-\nferences is unlikely to be a suitable paraphrase for\na number of people in any context. Moreover, there\nare some ?phrase, paraphrase? pairs which are only\nsuitable in particular contexts. For example, year\nend is an unsuitable paraphrase for the end of this\nyear in the sentence The chart compares the gold\nprice at the end of last year with the end of this year.\nBarzilay and McKeown (2001) also note that the ap-\nplicability of paraphrases is strongly influenced by\ncontext. Section 4 describes our method for deter-\nmining if a paraphrase is suitable in a given context.\n"},{"#tail":"\n","@confidence":"0.9309135","#text":"\nThe Google n-gram data was collected by Google\nResearch for statistical language modelling, and has\nbeen used for many tasks such as lexical disam-\nbiguation (Bergsma et al, 2009), and contains En-\nglish n-grams and their observed frequency counts,\nfor counts of at least 40. The striking feature of\n"},{"#tail":"\n","@confidence":"0.998703857142857","#text":"\nthe n-gram corpus is the large number of n-grams\nand the size of the counts, since the counts were ex-\ntracted from over 1 trillion word tokens of English\ntext on publicly accessible Web pages collected in\nJanuary 2006. For example, the 5-gram phrase the\npart that you were has a count of 103. The com-\npressed data is around 24 GB on disk.\n"},{"#tail":"\n","@confidence":"0.994734551724138","#text":"\nThe focus of the paper is to develop an automatic\nsystem for checking the grammaticality and flu-\nency of paraphrases in context. In order to evaluate\nthe system, we collected some human judgements,\nbased on 70 sentences from Section 00 of the Penn\nTreebank. For each sentence, we took every phrase\nin the sentence which is in the dictionary, and for\neach paraphrase of that phrase, replaced the phrase\nwith the paraphrase to create an instance. This pro-\ncedure resulted in 500 cases of paraphrases in con-\ntext.\nEach case was then evaluated by a human judge,\nusing a web-based annotation system that we devel-\noped. The judges were asked to judge each case on\ntwo dimensions: a) whether the paraphrase is gram-\nmatical in context; and b) whether the paraphrase\nretains the meaning of the original phrase given the\ncontext. Figure 2 gives a screen shot of the annota-\ntion system.\n50 of the 500 cases were judged by two judges, in\norder to obtain some indication of whether the gram-\nmaticality and meaning retention judgements are vi-\nable; the rest were judged by one annotator. (The\n500 instances were randomly distributed among 10\nnative speakers, each being given 55 instances to\njudge.) For the meaning retention check, only 34 out\nof the 50 cases received the same judgement. One\nreason for the low agreement may be that, for 11 of\nthe 16 disagreement cases, we were asking annota-\n"},{"#tail":"\n","@confidence":"0.99873525","#text":"\ntors to judge the meaning retention of paraphrases\nwhich had been judged to be ungrammatical in con-\ntext, which may not be a meaningful task. For the\ngrammatical check, 42 out of the 50 cases received\nthe same judgement, a much higher level of agree-\nment.\nSince the meaning retention judgements were un-\nreliable, we used only the grammatical judgements\nto evaluate our system. Hence we are interested\nin evaluating whether our n-gram and parser-based\nsystems can determine if a paraphrase is grammat-\nical in context. Meaning retention is important for\nthe imperceptibility requirement, but grammatical-\nity is even more so, since ungrammatical sentences\nwill be easy for an observer to spot. However, we\nrecognise that only testing for grammaticality does\nnot fully test the imperceptibility properties of the\nsystem, only part of it.\nFor the 8 cases which received different judge-\nments on grammaticality, the second author of this\npaper made the definitive judgement, which resulted\nin a test set of 308 paraphrases judged as grammat-\nical in context, and 192 paraphrases judged as un-\ngrammatical in context.\n"},{"#tail":"\n","@confidence":"0.99959225","#text":"\nThe main idea for testing the use of paraphrases is\nto check if the various contextual n-grams appear\nin the Google n-gram data, or were already in the\noriginal sentence (before paraphrasing). Let us first\ndefine some notation to be used in describing the\nmethod. The leftmost and rightmost <m> words in\nthe phrase/paraphrase are represented as <m>INLeft\nand <m>INRight, respectively. Words at the left and\nright side of the substituted phrase are defined as\n<c>OUTLeft and <c>OUTRight, where <c> is an\ninteger which indicates the number of words rep-\nresented. Also, we define a context window pair\n"},{"#tail":"\n","@confidence":"0.952016333333333","#text":"\nc>INLeft, and WR<c><n> is composed by <n-c>INRight\nconcatenated with <c>OUTRight. Figure 3 gives an\nexample of the context window pairs W 13 and W\n"},{"#tail":"\n","@confidence":"0.979086666666667","#text":"\nthe sentence Soviets said that it is too early to say\nwhether that will happen where the phrase too early\nto is being considered in context.\n"},{"#tail":"\n","@confidence":"0.99611744","#text":"\nWe define a google-count function G(). This func-\ntion takes a context window pair W<c><n> as input and\noutputs a frequency count pair of W<c><n> recorded in\nthe Google n-gram data. If a context window cannot\nbe found in the Google n-gram data, the frequency\ncount of that window is zero. Also, we define a bi-\nnary occurrence function O(). It is used to deter-\nmine whether a context window pair can be passed\nas acceptable. The input of this function is W<c><n>.\nThe function outputs one if either both WL<c><n> and\nWR<c><n> already occurred in the original sentence\n(before paraphrasing) or if the frequency counts out-\nput by G(W<c><n>) are both greater than zero.\nThe two major components in our method are the\nparaphrase dictionary and the Google n-gram data.\nOnce a phrase P in the cover sentence S is matched\nwith that in the paraphrase dictionary, we test the use\nof its paraphrase P ? by the following method. This\nmethod takes into account maximum C contextual\nwords at both sides of the target phrase, and uses\nGoogle n-gram data as a check, where n = 2, 3, 4 or\n5, and maxC = 1 to n? 1. Each pair of (n, maxC)\nprovides a separate check, by considering both left\nand right contexts for these values.\nFigure 4 describes the procedure for checking the\n"},{"#tail":"\n","@confidence":"0.981823217391304","#text":"\nacceptability of paraphrasing phrase P with P ? in\na given sentence S, given the n-gram size and the\nmaximum considered context size maxC. For ex-\nample, we want to check the acceptability of the\nparaphrase in context shown in Figure 3 by using\ngoogle tri-gram data (n = 3) and taking maximum\ncontext size equal to two into consideration (maxC\n= 2). The procedure starts from taking context size\nC equal to one into account, namely checking the\noccurrence of W 13 . If the paraphrase P\n? passes the\ncurrent test, in the next iteration it will be tested by\ntaking one more context word into account, namely\nW 23 . However, If the paraphrase P\n? fails the current\n(n, C) check the checking procedure will terminate\nand report that the paraphrase fails. In contrast, if\nthe paraphrase passes all the (n, C) checks where\nC = 1 to maxC, the procedure determines the para-\nphrase as acceptable. What is happening is that an n-\ngram window is effectively being shifted across the\nparaphrase boundary to include different amounts of\ncontext and paraphrase.\n"},{"#tail":"\n","@confidence":"0.996590888888889","#text":"\nIn order to improve the grammaticality checking, we\nuse a parser as an addition to the basic Google n-\ngram method. We use the Clark and Curran (2007)\nCCG parser to analyse the sentence before and af-\nter paraphrasing. Combinatory Categorial Grammar\n(CCG) is a lexicalised grammar formalism, in which\nCCG lexical categories ? typically expressing sub-\ncategorisation information ? are assigned to each\nword in a sentence. The grammatical check works\nby checking if the words in the sentence outside of\nthe phrase and paraphrase receive the same lexical\ncategories before and after paraphrasing. If there is\nany change in lexical category assignment to these\nwords then the paraphrase is judged ungrammati-\ncal. Hence the grammar check is at the word, rather\nthan derivation, level; however, CCG lexical cate-\ngories contain a large amount of syntactic informa-\ntion which this method is able to exploit.\n"},{"#tail":"\n","@confidence":"0.967145","#text":"\nThe test corpus described in Section 3.3 was split\ninto development and test data: 100 instances for\ndevelopment and 400 for testing. The development\ndata was used for preliminary experiments. For the\ntest data, 246 of the examples (61.5%) had been\n"},{"#tail":"\n","@confidence":"0.997425292682927","#text":"\njudged as grammatical, and 154 (38.5%) had been\njudged as ungrammatical by the annotators.\nThe performance of the system is evaluated us-\ning accuracy, precision, recall and balanced F-\nmeasure. Accuracy is the percentage of correct\njudgements over all grammatical and ungrammati-\ncal paraphrases. Precision is the percentage of para-\nphrases judged grammatical by the system which are\njudged grammatical by the human judges, and recall\nis the percentage of paraphrases judged grammatical\nby human judges which are also judged grammatical\nby the system. Precision and recall are relevant in\nour setting because high precision implies high im-\nperceptibility, since grammatical phrases in context\nare less likely to be viewed as suspicious by the ob-\nserver; whereas high recall maximises the payload\n(given the dictionary), since high recall implies that\nphrases are being paraphrased where possible (and\nhence embedding as much information as possible).\nAn accuracy baseline is obtained by always re-\nturning the majority class, in this case always judg-\ning the paraphrase grammatical, which gives an ac-\ncuracy of 61.5%. Table 3 gives the performance\nwhen only the CCG parser is used for checking gram-\nmaticality. As far as steganography is concerned, the\nprecision is low, since over 30% of the paraphrases\nused are ungrammatical, which is likely to raise the\nsuspicions of the observer.\nTable 4 gives the results for the Google n-gram\nmethod, for various n-gram and context sizes. As the\nn-gram size increases ? meaning that a larger part\nof the context is used ? the accuracy falls below\nthat of the baseline. However, from a steganogra-\nphy aspect, accuracy is not useful, since the trade-\noff between precision and recall is more relevant.\nAs expected, with larger n-grams checking the left\nand right contexts, the precision increases, reaching\n100% for the 5-grams. Hence, as far as grammati-\ncality judgements are concerned, the imperceptibil-\nity requirement is completely satisified. However,\nthe large drop in recall means that the imperceptibil-\n"},{"#tail":"\n","@confidence":"0.994050833333333","#text":"\nity is achieved at the cost of a reduced payload, since\nmany of the grammatical paraphrases that could be\nused to embed information are being discarded.\nTable 5 shows the results for the Google n-gram\nmethod followed by the parser check; that is, if the\nGoogle n-gram method judges the paraphrase to be\ngrammatical, then it is passed to the CCG parser for\nan additional check. Adding the parser generally\nincreases the precision with a slight loss in recall.\nWhich settings are best to use in practice would de-\npend on how the steganography user wished to trade\noff imperceptibility for payload.\n"},{"#tail":"\n","@confidence":"0.994679833333334","#text":"\nIn this section, we propose a linguistic hiding\nmethod which can be integrated with an automatic\nparaphrasing system. It needs a large paraphrase\ndictionary to determine modifiable phrases and pro-\nvide available paraphrases. The embedding capacity\nof the proposed linguistic stegosystem relies on the\nnumber of paraphrasable sentences in the cover text.\nIf every sentence in the cover text is paraphrasable,\nthe system can have the maximum embedding ca-\npacity equal to 1 bit per sentence which is compara-\nble to other linguistic steganography methods using\nsyntactic transformations and synonym substitution.\n"},{"#tail":"\n","@confidence":"0.99965308","#text":"\nFirst the sentences in a cover text T are identi-\nfied using a sentence segmentation algorithm, giv-\ning N sentences s1, s2,. . . , sN . The paraphrasabil-\nity of each sentence is then checked using our au-\ntomatic method. If a sentence contains at least one\nparaphrasable phrase, we call the sentence a para-\nphrasable sentence or a non-paraphrasable sen-\ntence otherwise. Let D be the maximum number of\nsentence boundaries between two subsequent para-\nphrasable sentences in T. Thus, for every D sen-\ntences within a cover text T, there will be at least\none paraphrasable sentence. Let every unit of D sen-\ntences serve as one embedding unit in which a single\nsecret bit can be embedded. If we want to embed\n0 in an embedding unit, we transform all the para-\nphrasable sentences in this embedding unit to non-\nparaphrasable sentences (assuming certain proper-\nties of the dictionary; see end of this section for dis-\ncussion). If we want to embed 1, we leave the em-\nbedding unit without any modifications.\nFigure 5 demonstrates the embedding of the se-\ncret bitstring 101 in a cover text containing nine sen-\ntences t1, t2,. . . , t9 defined by a sentence segmenta-\ntion algorithm. First, t1, t3, t4, t7 and t9 are de-\ntermined as paraphrasable sentences and thus D, the\n"},{"#tail":"\n","@confidence":"0.99426680952381","#text":"\nsize of an embedding unit, is 3. Next, we segment\nthe cover text into three embedding units u1, u2 and\nu3, each of which contains three sentences. Since\nwe want to embed secret bits 101 in u1, u2 and u3 re-\nspectively, the embedding unit u2 should contain no\nparaphrasable sentence. That is, the paraphrasable\nphrase in t4 should be replaced by its paraphrase.\nFinally, the stego text is output and sent along with\nthe private key D to the other party. A private key is\nknown only to the parties that exchange messages.\nIn order for this method to work, we require cer-\ntain properties of the paraphrase dictionary. For ex-\nample, it is crucial that, once a phrase has been para-\nphrased, it does not produce another phrase that can\nbe paraphrased. This can be achieved by simply\nrequiring that any paraphrase ?on the RHS? of the\ndictionary does not also appear as a phrase on the\nLHS. In fact, this is not so unnatural for the Callison-\nBurch dictionary, which consists of phrases mapped\nto sets of paraphrases, many of which only appear\non one side.\n"},{"#tail":"\n","@confidence":"0.908942761904762","#text":"\nFor extracting the secret data, first, the stego text\nT ? undergoes sentence segmentation, and N defined\nsentences s?1, s\n?\n2,. . . , s\n?\nN are obtained. According\nto the private key D, every D sentences are treated\nas an information unit, and in each unit we check\nthe occurrence of paraphrasable sentences making\nuse of our paraphrasing method. If an information\nunit contains at least one paraphrasable sentence,\nthis information unit implies the embedding of 1.\nIn contrast, if none of the sentences in the informa-\ntion unit are paraphrasable, it implies the embedding\nof 0. Hence, in order to recover the hidden mes-\nsage, the receiver requires the sentence segmentation\nalgorithm, the paraphrase dictionary, the automatic\nprogram determining grammaticality of paraphrases\nin context, and the secret key D. The extraction pro-\ncess essentially reverses the embedding method.\n"},{"#tail":"\n","@confidence":"0.99967362962963","#text":"\nThe contributions of this paper are to develop an\nautomatic system for checking the grammaticality\nand fluency of paraphrases in context, and the pro-\nposal of using paraphrases as a suitable transfor-\nmation for Linguistic Steganography. An advan-\ntage of our proposed method is that it is somewhat\nlanguage and domain independent, requiring only a\nparaphrase dictionary and a Google n-gram corpus,\nboth of which are likely to be available for a range\nof languages in the future.\nThere are various practical issues in the applica-\ntion of Linguistic Steganography systems that we\nhave chosen to ignore. For example, we have not\ndiscussed the choice of cover text. If a newspaper ar-\nticle were chosen as the cover text, then any changes\ncould be easily found in practice by comparing the\nstego text with the original article, which is likely\nto be readily available. Another interesting ques-\ntion that we have not addressed is whether some lan-\nguages are better suited to Linguistic Steganography\nthan others, or whether some languages are better\nsuited to particular linguistic transformations than\nothers. Finally, we have only evaluated our gram-\nmatical checker and not the steganography system\nitself (other than giving an indication of the likely\npayload). How best to evaluate the imperceptibility\nof such a system we leave to future work.\n"},{"#tail":"\n","@confidence":"0.87330275","#text":"\nWe would like to thank Chris Callison-Burch for pro-\nviding the paraphrase dictionary, Katja Markert, Stephen\nPulman, Laura Rimell, and the anonymous reviewers for\nuseful comments. Ching-Yun Chang was funded by an\n"}],"#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.971905","#text":"\nUniversity of Cambridge\nComputer Laboratory\n"},{"#tail":"\n","@confidence":"0.9782225","#text":"\nUniversity of Cambridge\nComputer Laboratory\n"},{"#tail":"\n","@confidence":"0.556798","#text":"\nOxford University Clarendon scholarship.\n"}],"sectionHeader":[{"#tail":"\n","@confidence":"0.989452","@genericHeader":"abstract","#text":"\nAbstract\n"},{"#tail":"\n","@confidence":"0.998204","@genericHeader":"keywords","#text":"\n1 Introduction\n"},{"#tail":"\n","@confidence":"0.979254","@genericHeader":"introduction","#text":"\n2 Previous Work\n"},{"#tail":"\n","@confidence":"0.975213","@genericHeader":"method","#text":"\n3 Data Resources\n"},{"#tail":"\n","@confidence":"0.882952","@genericHeader":"method","#text":"\n4 Proposed Method and Experiments\n"},{"#tail":"\n","@confidence":"0.953372","@genericHeader":"method","#text":"\n3 in\n"},{"#tail":"\n","@confidence":"0.869652","@genericHeader":"method","#text":"\n5 Possible embedding method\n"},{"#tail":"\n","@confidence":"0.99884","@genericHeader":"conclusions","#text":"\n6 Conclusions\n"},{"#tail":"\n","@confidence":"0.944087","@genericHeader":"acknowledgments","#text":"\nAcknowledgements\n"},{"#tail":"\n","@confidence":"0.975803","@genericHeader":"references","#text":"\nReferences\n"}],"tableCaption":[{"#tail":"\n","@confidence":"0.946806","#text":"\nTable 1: Statistics for the paraphrase dictionary\n"},{"#tail":"\n","@confidence":"0.879338","#text":"\nTable 2: Example phrases and paraphrases from the dic-\n"},{"#tail":"\n","@confidence":"0.995688","#text":"\nTable 3: Grammar check using CCG parser\n"},{"#tail":"\n","@confidence":"0.99746","#text":"\nTable 4: Performance of google n-gram method\n"},{"#tail":"\n","@confidence":"0.939528","#text":"\nTable 5: Performance of google n-gram method with the\nCCG parser filter\n"}],"page":[{"#tail":"\n","@confidence":"0.997179","#text":"\n591\n"},{"#tail":"\n","@confidence":"0.995153","#text":"\n592\n"},{"#tail":"\n","@confidence":"0.999356","#text":"\n593\n"},{"#tail":"\n","@confidence":"0.991707","#text":"\n594\n"},{"#tail":"\n","@confidence":"0.813954","#text":"\n2\n"},{"#tail":"\n","@confidence":"0.990287","#text":"\n595\n"},{"#tail":"\n","@confidence":"0.988043","#text":"\n596\n"},{"#tail":"\n","@confidence":"0.99624","#text":"\n597\n"},{"#tail":"\n","@confidence":"0.99292","#text":"\n598\n"},{"#tail":"\n","@confidence":"0.998658","#text":"\n599\n"}],"figureCaption":[{"#tail":"\n","@confidence":"0.999431","#text":"\nFigure 1: The Linguistic Steganography framework\n"},{"#tail":"\n","@confidence":"0.975749","#text":"\nFigure 2: The web-based annotation system\n"},{"#tail":"\n","@confidence":"0.982579","#text":"\nFigure 3: An example of the context window pair\n"},{"#tail":"\n","@confidence":"0.999888","#text":"\nFigure 4: Procedure for checking acceptability\n"},{"#tail":"\n","@confidence":"0.8269965","#text":"\nFigure 5: Embedding secret bits in a cover text using sen-\ntence segmentation method\n"}],"table":[{"#tail":"\n","@confidence":"0.999093428571429","#text":"\nN-gram Number of Coverage on\nphrases section 00 (%)\nUnigrams 5,856 99\nBigrams 13,473 96\nTrigrams 6,574 65\nFour-grams 1,604 40\nFive-grams 295 10\n"},{"#tail":"\n","@confidence":"0.994532666666667","#text":"\nAcc% P% R% F%\nbaseline 61.5 61.5 100.0 76.2\nparser 68.3 67.4 93.9 78.4\n"},{"#tail":"\n","@confidence":"0.79129675","#text":"\n1 54.8 85.0 32.1 46.6\n2 43.5 95.5 8.5 15.7\n3 41.0 100.0 4.1 7.8\n4 41.0 100.0 4.1 7.8\n"},{"#tail":"\n","@confidence":"0.81174725","#text":"\n1 53.8 86.8 29.3 43.8\n2 43.3 95.2 8.1 15.0\n3 41.0 100.0 4.1 7.8\n4 41.0 100.0 4.1 7.8\n"}],"email":[{"#tail":"\n","@confidence":"0.958008","#text":"\nChing-Yun.Chang@cl.cam.ac.uk\n"},{"#tail":"\n","@confidence":"0.97926","#text":"\nStephen.Clark@cl.cam.ac.uk\n"}]}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.231210","#tail":"\n","@no":"0","#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.9997675","#text":"University of Cambridge Computer Laboratory"},{"#tail":"\n","@confidence":"0.9998485","#text":"University of Cambridge Computer Laboratory"}],"author":[{"#tail":"\n","@confidence":"0.99663","#text":"Ching-Yun Chang"},{"#tail":"\n","@confidence":"0.934795","#text":"Stephen Clark"}],"abstract":{"#tail":"\n","@confidence":"0.998978588235294","#text":"This paper describes a method for checking the acceptability of paraphrases in context. We use the Google n-gram data and a CCG parser to certify the paraphrasing grammaticality and fluency. We collect a corpus of human judgements to evaluate our system. The ultimate goal of our work is to integrate text paraphrasing into a Linguistic Steganography system, by using paraphrases to hide information in a cover text. We propose automatically generated paraphrases as a new and useful source of transformations for Linguistic Steganography, and show that our method for checking paraphrases is effective at maintaining a high level of imperceptibility, which is crucial for effective steganography."},"title":[{"#tail":"\n","@confidence":"0.842598333333333","#text":"Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 591?599, Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics Linguistic Steganography Using Automatically Generated Paraphrases"},{"#tail":"\n","@confidence":"0.374997","#text":"Ching-Yun.Chang@cl.cam.ac.uk"}],"email":{"#tail":"\n","@confidence":"0.841725","#text":"Stephen.Clark@cl.cam.ac.uk"}}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Mikhail J. Atallah, Craig J. McDonough, Victor Raskin, and Sergei Nirenburg. 2001a. Natural language processing for information assurance and security: an overview and implementations. In Proceedings of the 2000 workshop on New security paradigms, pages 51? 65, Ballycotton, County Cork, Ireland."},"#text":"\n","pages":{"#tail":"\n","#text":"51--65"},"marker":{"#tail":"\n","#text":"Atallah, McDonough, Raskin, Nirenburg, 2001"},"location":{"#tail":"\n","#text":"Ballycotton, County Cork, Ireland."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"on of the Google n-gram check with a slight loss in recall. A contribution of this paper is to advertise the Linguistic Steganography problem to the ACL community. The requirement that any linguistic transformation maintain the grammaticality and meaning of the cover text makes the problem a strong test for existing NLP technology. 2 Previous Work 2.1 Synonym Substitution The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms. The first lexical substitution method was proposed by Chapman and Davida (1997). Later works, such as Atallah et al (2001a), Bolshakov (2004), Taskiran et al (2006) and Topkara et al (2006b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method. Taskiran et al (2006) attempt to use context by prioritizing the alternatives using an ngram language model; that is, rather than randomly choose an option from the synonym set, the system relies on the language model to select the synonym. Topkara et al (2005) and Topkara et al (2006b) report an average embedding capacity of 0.67 bits per sentence for the synonym substitution method.","@endWordPosition":"1251","@position":"7803","annotationId":"T1","@startWordPosition":"1248","@citStr":"Atallah et al (2001"},{"#tail":"\n","#text":") embedded information in the tree structure of the text by adjusting the structural properties of intermediate representations of sentences. In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences. Liu et al (2005), Meral et al (2007), Murphy (2001), Murphy and Vogel (2007) and Topkara et al (2006a) all belong to the syntactic transformation category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology. It requires some sophisticated tools and knowledge to model natural language semantics. Atallah et al (2002) used semantic transformations and embed information in textmeaning representation (TMR) trees of the text by either pruning, grafting or substituting the tr","@endWordPosition":"1516","@position":"9479","annotationId":"T2","@startWordPosition":"1513","@citStr":"Atallah et al. (2001"}]},"title":{"#tail":"\n","#text":"Natural language processing for information assurance and security: an overview and implementations."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 2000 workshop on New security paradigms,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Mikhail J Atallah"},{"#tail":"\n","#text":"Craig J McDonough"},{"#tail":"\n","#text":"Victor Raskin"},{"#tail":"\n","#text":"Sergei Nirenburg"}]}},{"date":{"#tail":"\n","#text":"2001"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"on of the Google n-gram check with a slight loss in recall. A contribution of this paper is to advertise the Linguistic Steganography problem to the ACL community. The requirement that any linguistic transformation maintain the grammaticality and meaning of the cover text makes the problem a strong test for existing NLP technology. 2 Previous Work 2.1 Synonym Substitution The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms. The first lexical substitution method was proposed by Chapman and Davida (1997). Later works, such as Atallah et al (2001a), Bolshakov (2004), Taskiran et al (2006) and Topkara et al (2006b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method. Taskiran et al (2006) attempt to use context by prioritizing the alternatives using an ngram language model; that is, rather than randomly choose an option from the synonym set, the system relies on the language model to select the synonym. Topkara et al (2005) and Topkara et al (2006b) report an average embedding capacity of 0.67 bits per sentence for the synonym substitution method.","@endWordPosition":"1251","@position":"7803","annotationId":"T3","@startWordPosition":"1248","@citStr":"Atallah et al (2001"},{"#tail":"\n","#text":") embedded information in the tree structure of the text by adjusting the structural properties of intermediate representations of sentences. In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences. Liu et al (2005), Meral et al (2007), Murphy (2001), Murphy and Vogel (2007) and Topkara et al (2006a) all belong to the syntactic transformation category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology. It requires some sophisticated tools and knowledge to model natural language semantics. Atallah et al (2002) used semantic transformations and embed information in textmeaning representation (TMR) trees of the text by either pruning, grafting or substituting the tr","@endWordPosition":"1516","@position":"9479","annotationId":"T4","@startWordPosition":"1513","@citStr":"Atallah et al. (2001"}]},"title":{"#tail":"\n","#text":"Natural language watermarking: design, analysis, and a proofof-concept implementation."},"volume":{"#tail":"\n","#text":"2137"},"#tail":"\n","institution":{"#tail":"\n","#text":"Mercan Karahan, Umut Topkara, Katrina E."},"rawString":{"#tail":"\n","#text":"Mikhail J. Atallah, Victor Raskin, Michael C. Crogan, Christian Hempelmann, Florian Kerschbaum, Dina Mohamed, and Sanket Naik. 2001b. Natural language watermarking: design, analysis, and a proofof-concept implementation. In Proceedings of the 4th International Information Hiding Workshop, volume 2137, pages 185?199, Pittsburgh, Pennsylvania. Mikhail J. Atallah, Victor Raskin, Christian F. Hempelmann, Mercan Karahan, Umut Topkara, Katrina E."},"#text":"\n","pages":{"#tail":"\n","#text":"185--199"},"marker":{"#tail":"\n","#text":"Atallah, Raskin, Crogan, Hempelmann, Kerschbaum, Mohamed, Naik, 2001"},"location":{"#tail":"\n","#text":"Pittsburgh, Pennsylvania. Mikhail"},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 4th International Information Hiding Workshop,"},"@valid":"false","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Mikhail J Atallah"},{"#tail":"\n","#text":"Victor Raskin"},{"#tail":"\n","#text":"Michael C Crogan"},{"#tail":"\n","#text":"Christian Hempelmann"},{"#tail":"\n","#text":"Florian Kerschbaum"},{"#tail":"\n","#text":"Dina Mohamed"},{"#tail":"\n","#text":"Sanket Naik"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Triezenberg, and Radu Sion. 2002. Natural language watermarking and tamperproofing. In Proceedings of the 5th International Information Hiding Workshop, pages 196?212, Noordwijkerhout, The Netherlands."},"#text":"\n","pages":{"#tail":"\n","#text":"196--212"},"marker":{"#tail":"\n","#text":"Triezenberg, Sion, 2002"},"location":{"#tail":"\n","#text":"Noordwijkerhout, The Netherlands."},"title":{"#tail":"\n","#text":"Natural language watermarking and tamperproofing."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 5th International Information Hiding Workshop,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Triezenberg"},{"#tail":"\n","#text":"Radu Sion"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Regina Barzilay and Kathleen R. McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proceedings of the 39th ACL, pages 50?57, Toulouse."},"#text":"\n","pages":{"#tail":"\n","#text":"50--57"},"marker":{"#tail":"\n","#text":"Barzilay, McKeown, 2001"},"location":{"#tail":"\n","#text":"Toulouse."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":". Each paraphrase also has a probability, based on a statistical machine translation model, but we do not use that feature here. The examples show that, while some of the paraphrases are of a high quality, some are not. For example, differences is unlikely to be a suitable paraphrase for a number of people in any context. Moreover, there are some ?phrase, paraphrase? pairs which are only suitable in particular contexts. For example, year end is an unsuitable paraphrase for the end of this year in the sentence The chart compares the gold price at the end of last year with the end of this year. Barzilay and McKeown (2001) also note that the applicability of paraphrases is strongly influenced by context. Section 4 describes our method for determining if a paraphrase is suitable in a given context. 3.2 Google N-gram Data The Google n-gram data was collected by Google Research for statistical language modelling, and has been used for many tasks such as lexical disambiguation (Bergsma et al, 2009), and contains English n-grams and their observed frequency counts, for counts of at least 40. The striking feature of Figure 2: The web-based annotation system the n-gram corpus is the large number of n-grams and the siz","@endWordPosition":"2007","@position":"12524","annotationId":"T5","@startWordPosition":"2004","@citStr":"Barzilay and McKeown (2001)"}},"title":{"#tail":"\n","#text":"Extracting paraphrases from a parallel corpus."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 39th ACL,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Regina Barzilay"},{"#tail":"\n","#text":"Kathleen R McKeown"}]}},{"volume":{"#tail":"\n","#text":"volume"},"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Richard Bergmair. 2007. A comprehensive bibliography of linguistic steganography. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 6505."},"#text":"\n","pages":{"#tail":"\n","#text":"6505"},"marker":{"#tail":"\n","#text":"Bergmair, 2007"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"que. Since the difference between 11111111 and 11111110 in the value for red/green/blue intensity is likely to be undetectable by the human eye, the LSB can be used to hide information other than colour, without being perceptable by a human observer.1 A key question for any steganography system is the choice of cover medium. Given the ubiquitous nature of natural languages and electronic text, text is an obvious medium to consider. However, the literature on Linguistic Steganography, in which linguistic properties of a text are modified to hide information, is small compared with other media (Bergmair, 2007). The likely reason is that it is easier to make changes to images and other nonlinguistic media which are undetectable by an observer. Language has the property that even small local changes to a text, e.g. replacing a word by a word with similar meaning, may result in text which is anomalous at the document level, or anomalous with respect to the state of the world. Hence finding linguistic transformations which can be applied reliably and often is a challenging problem for Linguistic Steganography. In this paper we focus on steganography rather than watermarking, since we are interested in ","@endWordPosition":"425","@position":"2754","annotationId":"T6","@startWordPosition":"424","@citStr":"Bergmair, 2007"}},"title":{"#tail":"\n","#text":"A comprehensive bibliography of linguistic steganography."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Richard Bergmair"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2009"},"rawString":{"#tail":"\n","#text":"Shane Bergsma, Dekang Lin, and Randy Goebel. 2009. Web-scale n-gram models for lexical disambiguation."},"#text":"\n","marker":{"#tail":"\n","#text":"Bergsma, Lin, Goebel, 2009"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"only suitable in particular contexts. For example, year end is an unsuitable paraphrase for the end of this year in the sentence The chart compares the gold price at the end of last year with the end of this year. Barzilay and McKeown (2001) also note that the applicability of paraphrases is strongly influenced by context. Section 4 describes our method for determining if a paraphrase is suitable in a given context. 3.2 Google N-gram Data The Google n-gram data was collected by Google Research for statistical language modelling, and has been used for many tasks such as lexical disambiguation (Bergsma et al, 2009), and contains English n-grams and their observed frequency counts, for counts of at least 40. The striking feature of Figure 2: The web-based annotation system the n-gram corpus is the large number of n-grams and the size of the counts, since the counts were extracted from over 1 trillion word tokens of English text on publicly accessible Web pages collected in January 2006. For example, the 5-gram phrase the part that you were has a count of 103. The compressed data is around 24 GB on disk. 3.3 Paraphrase Judgement Corpus The focus of the paper is to develop an automatic system for checking ","@endWordPosition":"2070","@position":"12903","annotationId":"T7","@startWordPosition":"2067","@citStr":"Bergsma et al, 2009"}},"title":{"#tail":"\n","#text":"Web-scale n-gram models for lexical disambiguation."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Shane Bergsma"},{"#tail":"\n","#text":"Dekang Lin"},{"#tail":"\n","#text":"Randy Goebel"}]}},{"#tail":"\n","rawString":{"#tail":"\n","#text":"In Proceedings of the 21st International Joint Conference on Artifical Intelligence, pages 1507?1512, Pasadena, CA."},"#text":"\n","pages":{"#tail":"\n","#text":"1507--1512"},"marker":{"#tail":"\n"},"location":{"#tail":"\n","#text":"Pasadena, CA."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 21st International Joint Conference on Artifical Intelligence,"},"@valid":"false"},{"date":{"#tail":"\n","#text":"2004"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" check with a slight loss in recall. A contribution of this paper is to advertise the Linguistic Steganography problem to the ACL community. The requirement that any linguistic transformation maintain the grammaticality and meaning of the cover text makes the problem a strong test for existing NLP technology. 2 Previous Work 2.1 Synonym Substitution The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms. The first lexical substitution method was proposed by Chapman and Davida (1997). Later works, such as Atallah et al (2001a), Bolshakov (2004), Taskiran et al (2006) and Topkara et al (2006b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method. Taskiran et al (2006) attempt to use context by prioritizing the alternatives using an ngram language model; that is, rather than randomly choose an option from the synonym set, the system relies on the language model to select the synonym. Topkara et al (2005) and Topkara et al (2006b) report an average embedding capacity of 0.67 bits per sentence for the synonym substitution method. 2.2 Syntactic Trans","@endWordPosition":"1253","@position":"7823","annotationId":"T8","@startWordPosition":"1252","@citStr":"Bolshakov (2004)"}},"title":{"#tail":"\n","#text":"A method of linguistic steganography based on coladdressally-verified synonym."},"volume":{"#tail":"\n","#text":"3200"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Igor A. Bolshakov. 2004. A method of linguistic steganography based on coladdressally-verified synonym. In Information Hiding: 6th International Workshop, volume 3200, pages 180?191, Toronto, Canada."},"#text":"\n","pages":{"#tail":"\n","#text":"180--191"},"marker":{"#tail":"\n","#text":"Bolshakov, 2004"},"location":{"#tail":"\n","#text":"Toronto, Canada."},"booktitle":{"#tail":"\n","#text":"In Information Hiding: 6th International Workshop,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Igor A Bolshakov"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2008"},"rawString":{"#tail":"\n","#text":"Chris Callison-Burch. 2008. Syntactic constraints on paraphrases extracted from parallel corpora. In Proceedings of the EMNLP Conference, pages 196?205, Honolulu, Hawaii."},"#text":"\n","pages":{"#tail":"\n","#text":"196--205"},"marker":{"#tail":"\n","#text":"Callison-Burch, 2008"},"location":{"#tail":"\n","#text":"Honolulu, Hawaii."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"sed to embed hidden bits in text. Section 2 describes some of the previous transformations used in Linguistic Steganography. Note that we are concerned with transformations which are 2The message may have been encrypted initially also, as in the figure, but this is not important in this paper; the key point is that the hidden message is a sequence of bits. linguistic in nature, rather than dealing with superficial properties of the text, e.g. the amount of white space between words (Por et al, 2008). Our proposed method is based on the automatically acquired paraphrase dictionary described in Callison-Burch (2008), in which the application of paraphrases from the dictionary encodes secret bits. One advantage of the dictionary is that it has wide coverage, being automatically extracted; however, a disadvantage is that it contains many paraphrases which are either inappropriate, or only appropriate in certain contexts. Since we require any changes to be imperceptible to a human observer, it is crucial to our system that any uses of paraphrasing are grammatical and retain the meaning of the original cover text. In order to test the grammaticality and meaning preserving nature of a paraphrase, we employ a ","@endWordPosition":"905","@position":"5696","annotationId":"T9","@startWordPosition":"904","@citStr":"Callison-Burch (2008)"},{"#tail":"\n","#text":"sources. Vybornova and Macq (2007) aimed to embed information by exploiting the linguistic phenomenon of presupposition, with the idea that some presuppositional information can be removed without changing the meaning of a sentence. 3 Data Resources 3.1 Paraphrase Dictionary The cover text used for our experiments consists of newspaper sentences from Section 00 of the Penn Treebank (Marcus et al, 1993). Hence we require possible paraphrases for phrases that occur in Section 00. The paraphrase dictionary that we use was generated for us by Chris Callison-Burch, using the technique described in Callison-Burch (2008), which exploits a parallel corpus and methods developed for statistical machine translation. Table 1 gives summary statistics of the paraphrase dictionary and its coverage on Section 00 of the Penn Treebank. The length of the extracted n-gram phrases ranges from unigrams to five-grams. The coverage figure gives the percentage of sentences which have at least one phrase in the dictionary. The coverage is important for us because it determines the payload capacity of the embedding method described in Section 5. Table 2 lists some examples 5-gram phrases and paraphrases from the dictionary. The ","@endWordPosition":"1709","@position":"10768","annotationId":"T10","@startWordPosition":"1708","@citStr":"Callison-Burch (2008)"}]},"title":{"#tail":"\n","#text":"Syntactic constraints on paraphrases extracted from parallel corpora."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the EMNLP Conference,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Chris Callison-Burch"}}},{"date":{"#tail":"\n","#text":"1997"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"by the parser. This method increases the precision of the Google n-gram check with a slight loss in recall. A contribution of this paper is to advertise the Linguistic Steganography problem to the ACL community. The requirement that any linguistic transformation maintain the grammaticality and meaning of the cover text makes the problem a strong test for existing NLP technology. 2 Previous Work 2.1 Synonym Substitution The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms. The first lexical substitution method was proposed by Chapman and Davida (1997). Later works, such as Atallah et al (2001a), Bolshakov (2004), Taskiran et al (2006) and Topkara et al (2006b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method. Taskiran et al (2006) attempt to use context by prioritizing the alternatives using an ngram language model; that is, rather than randomly choose an option from the synonym set, the system relies on the language model to select the synonym. Topkara et al (2005) and Topkara et al (2006b) report an average embedding capacity of 0.67 bits per sen","@endWordPosition":"1243","@position":"7761","annotationId":"T11","@startWordPosition":"1240","@citStr":"Chapman and Davida (1997)"}},"title":{"#tail":"\n","#text":"Hiding the hidden: A software system for concealing ciphertext as innocuous text."},"volume":{"#tail":"\n","#text":"1334"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Mark Chapman and George I. Davida. 1997. Hiding the hidden: A software system for concealing ciphertext as innocuous text. In Proceedings of the First International Conference on Information and Communication Security, volume 1334, pages 335?345, Beijing."},"#text":"\n","pages":{"#tail":"\n","#text":"335--345"},"marker":{"#tail":"\n","#text":"Chapman, Davida, 1997"},"location":{"#tail":"\n","#text":"Beijing."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the First International Conference on Information and Communication Security,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Mark Chapman"},{"#tail":"\n","#text":"George I Davida"}]}},{"volume":{"#tail":"\n","#text":"33"},"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Stephen Clark and James R. Curran. 2007. Widecoverage efficient statistical parsing with CCG and log-linear models. Comp. Ling., 33(4):493?552."},"journal":{"#tail":"\n","#text":"Comp. Ling.,"},"#text":"\n","issue":{"#tail":"\n","#text":"4"},"marker":{"#tail":"\n","#text":"Clark, Curran, 2007"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"e Google ngram corpus. This technique is based on the simple hypothesis that, if the paraphrase in context has been used many times before on the web, then it is an appropriate use. We test our n-gram-based system against some human judgements of the grammaticality of paraphrases in context. We find that using larger contexts leads to a high precision system (100% when using 5-grams), but at the cost of a reduced recall. This precision-recall tradeoff reflects the inherent tradeoff between imperceptibility and payload in a Linguistic Steganography system. We also experiment with a CCG parser (Clark and Curran, 2007), requiring that the contexts surrounding the original phrase and paraphrase are assigned 592 the same CCG lexical categories by the parser. This method increases the precision of the Google n-gram check with a slight loss in recall. A contribution of this paper is to advertise the Linguistic Steganography problem to the ACL community. The requirement that any linguistic transformation maintain the grammaticality and meaning of the cover text makes the problem a strong test for existing NLP technology. 2 Previous Work 2.1 Synonym Substitution The simplest and most straightforward subliminal mo","@endWordPosition":"1125","@position":"7010","annotationId":"T12","@startWordPosition":"1122","@citStr":"Clark and Curran, 2007"},{"#tail":"\n","#text":"ccount, namely W 23 . However, If the paraphrase P ? fails the current (n, C) check the checking procedure will terminate and report that the paraphrase fails. In contrast, if the paraphrase passes all the (n, C) checks where C = 1 to maxC, the procedure determines the paraphrase as acceptable. What is happening is that an ngram window is effectively being shifted across the paraphrase boundary to include different amounts of context and paraphrase. 4.2 Syntactic Filter In order to improve the grammaticality checking, we use a parser as an addition to the basic Google ngram method. We use the Clark and Curran (2007) CCG parser to analyse the sentence before and after paraphrasing. Combinatory Categorial Grammar (CCG) is a lexicalised grammar formalism, in which CCG lexical categories ? typically expressing subcategorisation information ? are assigned to each word in a sentence. The grammatical check works by checking if the words in the sentence outside of the phrase and paraphrase receive the same lexical categories before and after paraphrasing. If there is any change in lexical category assignment to these words then the paraphrase is judged ungrammatical. Hence the grammar check is at the word, rathe","@endWordPosition":"3272","@position":"19773","annotationId":"T13","@startWordPosition":"3269","@citStr":"Clark and Curran (2007)"}]},"title":{"#tail":"\n","#text":"Widecoverage efficient statistical parsing with CCG and log-linear models."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Stephen Clark"},{"#tail":"\n","#text":"James R Curran"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2009"},"note":{"#tail":"\n","#text":"first edition."},"rawString":{"#tail":"\n","#text":"Jessica Fridrich. 2009. Steganography in Digital Media: Principles, Algorithms, and Applications. Cambridge University Press, first edition."},"#text":"\n","marker":{"#tail":"\n","#text":"Fridrich, 2009"},"publisher":{"#tail":"\n","#text":"Cambridge University Press,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"phrasing into a Linguistic Steganography system, by using paraphrases to hide information in a cover text. We propose automatically generated paraphrases as a new and useful source of transformations for Linguistic Steganography, and show that our method for checking paraphrases is effective at maintaining a high level of imperceptibility, which is crucial for effective steganography. 1 Introduction Steganography is concerned with hiding information in some cover medium, by manipulating properties of the medium in such a way that the hidden information is not easily detectable by an observer (Fridrich, 2009). The covert communication is such that the very act of communication is to be kept secret from outside observers. A related area is Watermarking, in which modifications are made to a cover medium in order to identify it, for example for the purposes of copyright. Here the changes may be known to an observer, and the task is to make the changes in such a way that the watermark cannot easily be removed. There is a large literature on image steganography and watermarking, in which images are modified to encode a hidden message or watermark. Image stegosystems exploit the redundancy in an image r","@endWordPosition":"198","@position":"1373","annotationId":"T14","@startWordPosition":"197","@citStr":"Fridrich, 2009"}},"title":{"#tail":"\n","#text":"Steganography in Digital Media: Principles, Algorithms, and Applications."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Jessica Fridrich"}}},{"date":{"#tail":"\n","#text":"2005"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" based on the fact that a sentence can be transformed into more than one semantically equivalent syntactic structure, using transformations such as passivization, topicalization and clefting. The first syntactic transformation method is presented by Atallah et al (2001a). Later, Atallah et al. (2001b) embedded information in the tree structure of the text by adjusting the structural properties of intermediate representations of sentences. In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences. Liu et al (2005), Meral et al (2007), Murphy (2001), Murphy and Vogel (2007) and Topkara et al (2006a) all belong to the syntactic transformation category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the curr","@endWordPosition":"1469","@position":"9174","annotationId":"T15","@startWordPosition":"1466","@citStr":"Liu et al (2005)"}},"title":{"#tail":"\n","#text":"A natural language watermarking based on Chinese syntax."},"volume":{"#tail":"\n","#text":"3612"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Yuling Liu, Xingming Sun, and Yong Wu. 2005. A natural language watermarking based on Chinese syntax. In Advances in Natural Computation, volume 3612, pages 958?961, Changsha, China. Mitchell P. Marcus, Beatrice Santorini, and Mary A."},"#text":"\n","pages":{"#tail":"\n","#text":"958--961"},"marker":{"#tail":"\n","#text":"Liu, Sun, Wu, 2005"},"location":{"#tail":"\n","#text":"Changsha, China. Mitchell"},"booktitle":{"#tail":"\n","#text":"In Advances in Natural Computation,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Yuling Liu"},{"#tail":"\n","#text":"Xingming Sun"},{"#tail":"\n","#text":"Yong Wu"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"Marcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics, 19:313?330."},"#text":"\n","marker":{"#tail":"\n","#text":"Marcinkiewicz, 1993"},"title":{"#tail":"\n","#text":"Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Marcinkiewicz"}}},{"date":{"#tail":"\n","#text":"2007"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" that a sentence can be transformed into more than one semantically equivalent syntactic structure, using transformations such as passivization, topicalization and clefting. The first syntactic transformation method is presented by Atallah et al (2001a). Later, Atallah et al. (2001b) embedded information in the tree structure of the text by adjusting the structural properties of intermediate representations of sentences. In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences. Liu et al (2005), Meral et al (2007), Murphy (2001), Murphy and Vogel (2007) and Topkara et al (2006a) all belong to the syntactic transformation category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art ","@endWordPosition":"1473","@position":"9194","annotationId":"T16","@startWordPosition":"1470","@citStr":"Meral et al (2007)"}},"title":{"#tail":"\n","#text":"Syntactic tools for text watermarking."},"volume":{"#tail":"\n","#text":"volume"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Hasan M. Meral, Emre Sevinc, Ersin Unkar, Bulent Sankur, A. Sumru Ozsoy, and Tunga Gungor. 2007. Syntactic tools for text watermarking. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 6505, San Jose, CA."},"#text":"\n","pages":{"#tail":"\n","#text":"6505"},"marker":{"#tail":"\n","#text":"Meral, Sevinc, Unkar, Sankur, Ozsoy, Gungor, 2007"},"location":{"#tail":"\n","#text":"San Jose, CA."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Hasan M Meral"},{"#tail":"\n","#text":"Emre Sevinc"},{"#tail":"\n","#text":"Ersin Unkar"},{"#tail":"\n","#text":"Bulent Sankur"},{"#tail":"\n","#text":"A Sumru Ozsoy"},{"#tail":"\n","#text":"Tunga Gungor"}]}},{"date":{"#tail":"\n","#text":"2007"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" into more than one semantically equivalent syntactic structure, using transformations such as passivization, topicalization and clefting. The first syntactic transformation method is presented by Atallah et al (2001a). Later, Atallah et al. (2001b) embedded information in the tree structure of the text by adjusting the structural properties of intermediate representations of sentences. In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences. Liu et al (2005), Meral et al (2007), Murphy (2001), Murphy and Vogel (2007) and Topkara et al (2006a) all belong to the syntactic transformation category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology. It requires some sop","@endWordPosition":"1479","@position":"9234","annotationId":"T17","@startWordPosition":"1476","@citStr":"Murphy and Vogel (2007)"}},"title":{"#tail":"\n","#text":"The syntax of concealment: reliable methods for plain text information hiding."},"volume":{"#tail":"\n","#text":"volume"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Brian Murphy and Carl Vogel. 2007. The syntax of concealment: reliable methods for plain text information hiding. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 6505, San Jose, CA."},"#text":"\n","pages":{"#tail":"\n","#text":"6505"},"marker":{"#tail":"\n","#text":"Murphy, Vogel, 2007"},"location":{"#tail":"\n","#text":"San Jose, CA."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Brian Murphy"},{"#tail":"\n","#text":"Carl Vogel"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Brian Murphy. 2001. Syntactic information hiding in plain text. Masters Thesis. Trinity College Dublin."},"#text":"\n","marker":{"#tail":"\n","#text":"Murphy, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" be transformed into more than one semantically equivalent syntactic structure, using transformations such as passivization, topicalization and clefting. The first syntactic transformation method is presented by Atallah et al (2001a). Later, Atallah et al. (2001b) embedded information in the tree structure of the text by adjusting the structural properties of intermediate representations of sentences. In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences. Liu et al (2005), Meral et al (2007), Murphy (2001), Murphy and Vogel (2007) and Topkara et al (2006a) all belong to the syntactic transformation category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technol","@endWordPosition":"1475","@position":"9209","annotationId":"T18","@startWordPosition":"1474","@citStr":"Murphy (2001)"}},"title":{"#tail":"\n","#text":"Syntactic information hiding in plain text. Masters Thesis. Trinity College Dublin."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Brian Murphy"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2008"},"rawString":{"#tail":"\n","#text":"Lip Y. Por, Ang T. Fong, and B. Delina. 2008. Whitesteg: a new scheme in information hiding using text steganography. WSEAS Transactions on Computers, 7:735?745. Cuneyt M. Taskiran, Mercan Topkara, and Edward J."},"journal":{"#tail":"\n","#text":"WSEAS Transactions on Computers, 7:735?745. Cuneyt"},"#text":"\n","marker":{"#tail":"\n","#text":"Por, Fong, Delina, 2008"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ramework, and for readers unfamiliar with linguistic steganography shows how linguistic transformations can be used to embed hidden bits in text. Section 2 describes some of the previous transformations used in Linguistic Steganography. Note that we are concerned with transformations which are 2The message may have been encrypted initially also, as in the figure, but this is not important in this paper; the key point is that the hidden message is a sequence of bits. linguistic in nature, rather than dealing with superficial properties of the text, e.g. the amount of white space between words (Por et al, 2008). Our proposed method is based on the automatically acquired paraphrase dictionary described in Callison-Burch (2008), in which the application of paraphrases from the dictionary encodes secret bits. One advantage of the dictionary is that it has wide coverage, being automatically extracted; however, a disadvantage is that it contains many paraphrases which are either inappropriate, or only appropriate in certain contexts. Since we require any changes to be imperceptible to a human observer, it is crucial to our system that any uses of paraphrasing are grammatical and retain the meaning of the","@endWordPosition":"889","@position":"5579","annotationId":"T19","@startWordPosition":"886","@citStr":"Por et al, 2008"}},"title":{"#tail":"\n","#text":"Whitesteg: a new scheme in information hiding using text steganography."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Lip Y Por"},{"#tail":"\n","#text":"Ang T Fong"},{"#tail":"\n","#text":"B Delina"}]}},{"volume":{"#tail":"\n","#text":"6072"},"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Delp. 2006. Attacks on linguistic steganography systems using text analysis. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 6072, pages 97?105, San Jose, CA. Mercan Topkara, Cuneyt M. Taskiran, and Edward J."},"#text":"\n","pages":{"#tail":"\n","#text":"97--105"},"marker":{"#tail":"\n","#text":"Delp, 2006"},"location":{"#tail":"\n","#text":"San"},"title":{"#tail":"\n","#text":"Attacks on linguistic steganography systems using text analysis."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Delp"}}},{"volume":{"#tail":"\n","#text":"5681"},"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"Delp. 2005. Natural language watermarking. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 5681, pages 441?452, San Jose, CA."},"#text":"\n","pages":{"#tail":"\n","#text":"441--452"},"marker":{"#tail":"\n","#text":"Delp, 2005"},"location":{"#tail":"\n","#text":"San Jose, CA."},"title":{"#tail":"\n","#text":"Natural language watermarking."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Delp"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Mercan Topkara, Umut Topkara, and Mikhail J. Atallah. 2006a. Words are not enough: sentence level natural language watermarking. In Proceedings of the ACM Workshop on Content Protection and Security, pages 37?46, Santa Barbara, CA."},"#text":"\n","pages":{"#tail":"\n","#text":"37--46"},"marker":{"#tail":"\n","#text":"Topkara, Topkara, Atallah, 2006"},"location":{"#tail":"\n","#text":"Santa Barbara, CA."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ibution of this paper is to advertise the Linguistic Steganography problem to the ACL community. The requirement that any linguistic transformation maintain the grammaticality and meaning of the cover text makes the problem a strong test for existing NLP technology. 2 Previous Work 2.1 Synonym Substitution The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms. The first lexical substitution method was proposed by Chapman and Davida (1997). Later works, such as Atallah et al (2001a), Bolshakov (2004), Taskiran et al (2006) and Topkara et al (2006b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method. Taskiran et al (2006) attempt to use context by prioritizing the alternatives using an ngram language model; that is, rather than randomly choose an option from the synonym set, the system relies on the language model to select the synonym. Topkara et al (2005) and Topkara et al (2006b) report an average embedding capacity of 0.67 bits per sentence for the synonym substitution method. 2.2 Syntactic Transformations The second and the most widely used ","@endWordPosition":"1263","@position":"7870","annotationId":"T20","@startWordPosition":"1259","@citStr":"Topkara et al (2006"},{"#tail":"\n","#text":"ally equivalent syntactic structure, using transformations such as passivization, topicalization and clefting. The first syntactic transformation method is presented by Atallah et al (2001a). Later, Atallah et al. (2001b) embedded information in the tree structure of the text by adjusting the structural properties of intermediate representations of sentences. In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences. Liu et al (2005), Meral et al (2007), Murphy (2001), Murphy and Vogel (2007) and Topkara et al (2006a) all belong to the syntactic transformation category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology. It requires some sophisticated tools and kno","@endWordPosition":"1484","@position":"9258","annotationId":"T21","@startWordPosition":"1481","@citStr":"Topkara et al (2006"}]},"title":{"#tail":"\n","#text":"Words are not enough: sentence level natural language watermarking."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the ACM Workshop on Content Protection and Security,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Mercan Topkara"},{"#tail":"\n","#text":"Umut Topkara"},{"#tail":"\n","#text":"Mikhail J Atallah"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Umut Topkara, Mercan Topkara, and Mikhail J. Atallah. 2006b. The hiding virtues of ambiguity: quantifiably resilient watermarking of natural language text through synonym substitutions. In Proceedings of the 8th Workshop on Multimedia and Security, pages 164? 174, Geneva, Switzerland."},"#text":"\n","pages":{"#tail":"\n","#text":"164--174"},"marker":{"#tail":"\n","#text":"Topkara, Topkara, Atallah, 2006"},"location":{"#tail":"\n","#text":"Geneva, Switzerland."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ibution of this paper is to advertise the Linguistic Steganography problem to the ACL community. The requirement that any linguistic transformation maintain the grammaticality and meaning of the cover text makes the problem a strong test for existing NLP technology. 2 Previous Work 2.1 Synonym Substitution The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms. The first lexical substitution method was proposed by Chapman and Davida (1997). Later works, such as Atallah et al (2001a), Bolshakov (2004), Taskiran et al (2006) and Topkara et al (2006b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method. Taskiran et al (2006) attempt to use context by prioritizing the alternatives using an ngram language model; that is, rather than randomly choose an option from the synonym set, the system relies on the language model to select the synonym. Topkara et al (2005) and Topkara et al (2006b) report an average embedding capacity of 0.67 bits per sentence for the synonym substitution method. 2.2 Syntactic Transformations The second and the most widely used ","@endWordPosition":"1263","@position":"7870","annotationId":"T22","@startWordPosition":"1259","@citStr":"Topkara et al (2006"},{"#tail":"\n","#text":"ally equivalent syntactic structure, using transformations such as passivization, topicalization and clefting. The first syntactic transformation method is presented by Atallah et al (2001a). Later, Atallah et al. (2001b) embedded information in the tree structure of the text by adjusting the structural properties of intermediate representations of sentences. In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences. Liu et al (2005), Meral et al (2007), Murphy (2001), Murphy and Vogel (2007) and Topkara et al (2006a) all belong to the syntactic transformation category. After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools. Atallah et al. (2001b) and Topkara et al (2006a) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology. It requires some sophisticated tools and kno","@endWordPosition":"1484","@position":"9258","annotationId":"T23","@startWordPosition":"1481","@citStr":"Topkara et al (2006"}]},"title":{"#tail":"\n","#text":"The hiding virtues of ambiguity: quantifiably resilient watermarking of natural language text through synonym substitutions."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 8th Workshop on Multimedia and Security,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Umut Topkara"},{"#tail":"\n","#text":"Mercan Topkara"},{"#tail":"\n","#text":"Mikhail J Atallah"}]}},{"date":{"#tail":"\n","#text":"2007"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"sentence with the syntactic transformation method. 2.3 Semantic Transformations The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology. It requires some sophisticated tools and knowledge to model natural language semantics. Atallah et al (2002) used semantic transformations and embed information in textmeaning representation (TMR) trees of the text by either pruning, grafting or substituting the tree structure with information available from ontological semantic resources. Vybornova and Macq (2007) aimed to embed information by exploiting the linguistic phenomenon of presupposition, with the idea that some presuppositional information can be removed without changing the meaning of a sentence. 3 Data Resources 3.1 Paraphrase Dictionary The cover text used for our experiments consists of newspaper sentences from Section 00 of the Penn Treebank (Marcus et al, 1993). Hence we require possible paraphrases for phrases that occur in Section 00. The paraphrase dictionary that we use was generated for us by Chris Callison-Burch, using the technique described in Callison-Burch (2008), which explo","@endWordPosition":"1618","@position":"10181","annotationId":"T24","@startWordPosition":"1615","@citStr":"Vybornova and Macq (2007)"}},"title":{"#tail":"\n","#text":"A method of text watermarking using presuppositions."},"volume":{"#tail":"\n","#text":"volume"},"#tail":"\n","rawString":{"#tail":"\n","#text":"M. Olga Vybornova and Benoit Macq. 2007. A method of text watermarking using presuppositions. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 6505, San Jose, CA."},"#text":"\n","pages":{"#tail":"\n","#text":"6505"},"marker":{"#tail":"\n","#text":"Vybornova, Macq, 2007"},"location":{"#tail":"\n","#text":"San Jose, CA."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"M Olga Vybornova"},{"#tail":"\n","#text":"Benoit Macq"}]}}]}}]}}
