{"algorithms":{"#text":"\n","@version":"110505","algorithm":{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"1988"},"rawString":{"#tail":"\n","#text":"K. Church 1988. A stochastic parts program and noun phrase parser for unrestricted text. In Proceedings of the Second Conference on Applied Natural Language Processing, pages 136-143."},"#text":"\n","pages":{"#tail":"\n","#text":"136--143"},"marker":{"#tail":"\n","#text":"Church, 1988"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"on tree software. Indeed, the results we obtain could perhaps be improved by using more sophisticated decision-tree approaches such as the adaptiveresampling described in (Weiss et al, 1999). The features that we use to train the decision tree are intended to capture the characteristics of names. We specify a total of ten features for each unknown word. These identify two features of the unknown word itself as well as two features for each of the two preceding and two following words. The first feature represents the part of speech of the word. We use an in-house statistical tagger (based on (Church, 1988)) to tag the text in which the unknown word occurs. The tag set used is a simplified version of the tags used in the machinereadable version of the Oxford Advanced Learners Dictionary (OALD). The tag set contains just one tag to identify nouns. The second feature provides more informative tagging for specific parts of speech (these are referred to as 'detailed tags' (DETAG)). This tagset consists of the nine tags listed in Table 1. All parts of speech apart from noun and punctuation tags are assigned the tag 'OTHER'. All punctuation tags are assigned the tag 'BOUNDARY'. Words identified as nou","@endWordPosition":"1345","@position":"8199","annotationId":"T1","@startWordPosition":"1344","@citStr":"Church, 1988"}},"title":{"#tail":"\n","#text":"A stochastic parts program and noun phrase parser for unrestricted text."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Second Conference on Applied Natural Language Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"K Church"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"D. Elworthy. 1998. Language identification with confidence limits. In Proceedings of the 6th Workshop on Very large Corpora."},"#text":"\n","marker":{"#tail":"\n","#text":"Elworthy, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" of differing categories. Some immediately obvious domains where unknown words are frequent include e-mail messages, internet chat rooms, data typed in by call centre operators, etc. To deal with these issues we propose a multicomponent architecture where individual components specialize in identifying one particular type of 173 unknown word. For example, the misspelling identifier will specialize in identifying misspellings, the abbreviation component will specialize in identifying abbreviations, etc. Each component will return a confidence measure of the reliability of its prediction, c.f. (Elworthy, 1998). The results from each component are evaluated to determine the final category of the word. There are several advantages to this approach. Firstly, the system can take advantage of existing research. For example, the name recognition module can make use of the considerable research that exists on name recognition, e.g. (McDonald, 1996), (Mani et al., 1996). Secondly, individual components can be replaced when improved models are available, without affecting other parts of the system. Thirdly, this approach is compatible with incorporating multiple components of the same type to improve perfor","@endWordPosition":"738","@position":"4487","annotationId":"T2","@startWordPosition":"737","@citStr":"Elworthy, 1998"}},"title":{"#tail":"\n","#text":"Language identification with confidence limits."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 6th Workshop on Very large Corpora."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"D Elworthy"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1992"},"rawString":{"#tail":"\n","#text":"T. Vosse. 1992. Detecting and correcting morphosyntactic errors in real texts. In Proceedings of the 3rd Conference on Applied Natural Language Processing, pages 111-118."},"#text":"\n","pages":{"#tail":"\n","#text":"111--118"},"marker":{"#tail":"\n","#text":"Vosse, 1992"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" additions, deletions, substitutions, or reversals of letters, or the exclusion of punctuation such as hyphenation or spacing. Like the definition of 'unknown word', the definition of a misspelling is also relative to a particular NLP system. Like the name identifier, we make use of a decision tree to capture the characteristics of misspellings. The features we use are derived from previous research, including our own previous research on misspelling identification. An abridged list of the features that are used in the training data is listed in Table 2 and discussed below. Corpus frequency: (Vosse, 1992) differentiates between misspellings and neologisms (new words) in terms of their frequency. His algorithm classifies unknown words that appear infrequently as misspellings, and those that appear more frequently as neologisms. Our corpus frequency variable specifies the frequency of each unknown word in a 2.6 million word corpus of business news closed captions. Word Length: (Agirre et al., 1998) note that their predictions for the correct spelling of misspelled words are more accurate for words longer than four characters, and much less accurate for shorter words. This observation can also be","@endWordPosition":"1863","@position":"11253","annotationId":"T3","@startWordPosition":"1862","@citStr":"Vosse, 1992"},{"#tail":"\n","#text":"tiating the different types of unknown words. For example, research on spelling error detection and correction for the most part assumes that all unknown words are misspellings and makes no attempt to identify other types of unknown words, e.g. (Elmi and Evens, 1998). Naturally, these are not appropriate comparisons for the work reported here. However, as is evident from the discussion above, previous spelling research does provide an important role in suggesting productive features to include in the decision tree. Research that is more similar in goal to that outlined in this paper is Vosse (Vosse, 1992). Vosse uses a simple algorithm to identify three classes of unknown words: misspellings, neologisms, and names. Capitalization is his sole means of identifying names. However, capitalization information is not available in closed captions. Hence, his system would be ineffective on the closed caption domain with which we are working. (Granger, 1983) uses expectations generated by scripts to analyze unknown words. The drawback of his system is that it lacks portability since it incorporates scripts that make use of world knowledge of the situation being described; in this case, naval ship-to-sh","@endWordPosition":"4377","@position":"26903","annotationId":"T4","@startWordPosition":"4376","@citStr":"Vosse, 1992"}]},"title":{"#tail":"\n","#text":"Detecting and correcting morphosyntactic errors in real texts."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 3rd Conference on Applied Natural Language Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"T Vosse"}}}]}}}}
