ceptualize its task as consisting of two distinct phases. In the first phase, the sentence-plan-generator 2The meaning of the human ratings and RankBoost scores in Figure 2 are discussed below. (SPG) generates a potentially large sample of possible sentence plans for a given text-plan input. In the second phase, the sentence-plan-ranker (SPR) ranks the sample sentence plans, and then selects the top-ranked output to input to the surface realizer. Our primary contribution is a method for training the SPR. The SPR uses rules automatically learned from training data, using techniques similar to (Collins, 2000; Freund et al., 1998). Our method for training a sentence planner is unique in neither depending on hand-crafted rules, nor on the existence of a text or speech corpus in the domain of the sentence planner obtained from the interaction of a human with a system or another human. We show that the trained SPR learns to select a sentence plan whose rating on average is only 5% worse than the top human-ranked sentence plan. In the remainder of the paper, section 2 describes the sentence planning task in more detail. We then describe the sentence plan generator (SPG) in section 3, the sentence plan
 be in a relation of synonymy or hyperonymy (rather than being identical). SOFT-MERGE-GENERAL. Same as MERGE-GENERAL, except that the verbs need only to be in a relation of synonymy or hyperonymy. CONJUNCTION. This is standard conjunction with conjunction reduction. RELATIVE-CLAUSE. This includes participial adjuncts to nouns. ADJECTIVE. This transforms a predicative use of an adjective into an adnominal construction. PERIOD. Joins two complete clauses with a period. These operations are not domain-specific and are similar to those of previous aggregation components (Rambow and Korelsky,1992; Shaw, 1998; Danlos, 2000), although the various MERGE operations are, to our knowledge, novel in this form. The result of applying the operations is a sentence plan tree (or sp-tree for short), which is a binary tree with leaves labeled by all the elementary speech acts Sp−trees with associated DSyntSs * Sentence Planner * 0 SPG !fin !fin !fin . . SPR !fin . !fin Dialog System RealPro Realizer Rule Sample first argument Sample second argument Result MERGE You are leaving from Newark. You are leaving at 5 You are leaving at 5 from Newark MERGE-GENERAL What time would you like to You are leaving from Newa
 with the root node. This DSyntS can be sent to RealPro, which returns a sentence (or several sentences, if the DSyntS contains period nodes). The SPG is designed in such a way that if a DSyntS is associated with the root node, it is a valid structure which can be realized. imp−confirm(dest−city) imp−confirm(orig−city) Figure 5: Alternative 0 Sentence Plan Tree Figure 2 shows some of the realizations of alternative sentence plans generated by our SPG for utterance Sys3The sp-tree is inspired by (Lavoie and Rambow, 1998). The representations used by Danlos (2000), Gardent and Webber (1998), or Stone and Doran (1997) are similar, but do not (always) explicitly represent the clause combining operations as labeled nodes. period imp−confirm(orig−city) imp−confirm(dest−city) Figure 6: Alternative 5 Sentence Plan Tree Figure 7: Alternative 8 Sentence Plan Tree tem5 in Dialog D1. Sp-trees for alternatives 0, 5 and 8 are in Figures 5, 6 and 7. For example, consider the sp-tree in Figure 7. Node soft-merge-general merges an implicit-confirmations of the destination city and the origin city. The row labelled SOFT-MERGE in Figure 4 shows the result of applying the soft-merge operation when Args 1 and 2 are implicit
g was the feedback for that example. 4.3 Features Used by RankBoost Rankboost, like other machine learning programs of the boosting family, can handle a very large number of features. Therefore, instead of carefully choosing a small number of features by hand which may be useful, we generated a very large number of features and let RankBoost choose the relevant ones. In total, we used 3,291 features in training the SPR. Features were discovered from the actual sentence plan trees that the SPG generated through the feature derivation process described below, in a manner similar to that used by Collins (2000). The motivation for the features was to capture declaratively decisions made by the randomized SPG. We avoided features specific to particular text plans by discarding those that occurred fewer than 10 times. Features are derived from two sources: the sp-trees and the DSyntSs associated with the root nodes of sptrees. The feature names are prefixed with “sp-” or “dsynt-” depending on the source. There are two types of features: local and global. Local features record structural configurations local to a particular node, i.e., that can be described with respect to a single node (such as its an
ems that might identify particular discourse contexts, most of the learned rules utilize general properties of the sp-tree and the DSyntS. This is probably partly due to the fact that we eliminated features that appeared fewer than 10 times in the training data, but also partly due to the fact that boosting algorithms in general appear to be resistant to overfitting the data (Freund et al., 1998). 6 Related Work Previous work in sentence planning in the natural language generation (NLG) community uses hand-written rules to approximate the distribution of linguistic phenomena in a corpus (see (Shaw, 1998) for a recent example with further references). This approach is difficult to scale due to the nonrobustness of rules and unexpected interactions (Hovy and Wanner, 1996), and it is difficult to develop new applications quickly. Presumably, this is the reason why dialog systems to date have not used this kind of sentence planning. Most dialog systems today use template-based generation. The template outputs are typically concatenated to produce a turn realizing all the communicative goals. It is hard to achieve high quality output by concatenating the template-based output for individual commun
