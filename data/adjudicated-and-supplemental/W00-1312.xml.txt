or term translation? (Section 8) ? How much does performance d grade due to omissions from the bilingual dictionary and how does performance vary with size of such a dictionary? (Sections 8-9) All experiments were performed using a common baseline, an HMM-based (mono- lingual) indexing and retrieval engine. In order to design controlled experiments for the questions above, the IR system was run without sophisticated query expansion techniques. Our experiments are based on the Chinese materials of TREC-5 and TREC-6 and the Spanish materials of TREC-4. 2 HMM for Mono-Lingual Retrieval Following Miller et al, 1999, the IR system ranks documents according to the probability that a document D is relevant given the query Q, P(D is R IQ). Using Bayes Rule, and the fact that P(Q) is constant for a given query, and our initial assumption of a uniform a priori 95 probability that a document is relevant, ranking documents according to P(Q\[D is R) is the same as ranking them according to P(D is RIQ). The approach therefore estimates the probability that a query Q is generated, given the document D is relevant. (A glossary of symbols used appears below.) We use x to represent the language (e.g. English) for whi
ments according to P(Q\[D is R) is the same as ranking them according to P(D is RIQ). The approach therefore estimates the probability that a query Q is generated, given the document D is relevant. (A glossary of symbols used appears below.) We use x to represent the language (e.g. English) for which retrieval is carried out. According to that model of monolingual retrieval, it can be shown that p(Q \[ D is R) = I I (aP(W \[ Gx) + (1- a)e(w ID)), W inQ where W's are query words in Q. Miller et al estimated probabilities as follows: * The transition probability a is 0.7 using the EM algorithm (Rabiner, 1989) on the TREC4 ad-hoc query set. number of occurrences of W in C x ? e0e IGx)= length of Cx which is the general language probability for word W in language x. number of occurrences of W in D ? e (WlD) = length of D In principle, any large corpus Cx that is representative of language x can be used in computing the general language probabilities. In practice, the collection to be searched is used for that purpose. The length of a Q a query English query a document a document in foreign language y document is relevant a word an English corpus a corpus in language x QX D Dr D isR W Gx Cx Wx BL an 
t an English- Chinese lexicon. That is, for each English word e, we associate it with a list of Chinese words cl, c2, ... Cm together with non-zero translation probabilities P( elc~). The resulting English-Chinese l xicon has 80,000 English words. On average, each English word has 2.3 Chinese translations. For Spanish, we downloaded a bilingual English-Spanish lexicon from the Internet (http://www.activa.arrakis.es) containing around 22,000 English words (16,000 English stems) and processed it similarly. Each English word has around 1.5 translations on average. A co- occurrence based stemmer (Xu and Croft, 1998) was used to stem Spanish words. One difference from the treatment of Chinese is to include the English word as one of its own translations in addition to its Spanish translations in the lexicon. This is useful for translating proper nouns, which often have identical spellings in English and Spanish but are routinely excluded from a lexicon. One problem is the segmentation f Chinese text, since Chinese has no spaces between words. In these initial experiments, we relied on a simple sub-string matching algorithm to extract words from Chinese text. To extract words from a string of Chinese chara
 as well as its components. For example, the Chinese word for &quot;particle physics&quot; as well as the Chinese words for &quot;particle&quot; and &quot;physics&quot; will be extracted. This seems desirable because it ensures the retrieval algorithm will match both the compound words as well as their components. The above algorithm was used in processing Chinese documents and Chinese queries. English data from the 2 GB of TREC disks l&2 was used to estimate P(WlG,..ngti~h), the general language probabilities for English words. The evaluation metric used in this study is the average precision using the trec_eval program (Voorhees and Harman, 1997). Mono-lingual retrieval results (using the Chinese and Spanish queries) provided our baseline, with the HMM retrieval system (Miller et al 1999). 1 Clearly, this is not correct; however, it simplified implementation. 97 5 Retrieval Results Table 2 reports average precision for mono- lingual retrieval, average precision for cross- lingual, and the relative performance ratio of cross-lingual retrieval to mono-lingual. Relative performance of cross-lingual IR varies between 67% and 84% of mono-lingual IR. Trec6 Chinese queries have a somewhat higher relative performance than Trec5 Chinese querie
ted. This seems desirable because it ensures the retrieval algorithm will match both the compound words as well as their components. The above algorithm was used in processing Chinese documents and Chinese queries. English data from the 2 GB of TREC disks l&2 was used to estimate P(WlG,..ngti~h), the general language probabilities for English words. The evaluation metric used in this study is the average precision using the trec_eval program (Voorhees and Harman, 1997). Mono-lingual retrieval results (using the Chinese and Spanish queries) provided our baseline, with the HMM retrieval system (Miller et al 1999). 1 Clearly, this is not correct; however, it simplified implementation. 97 5 Retrieval Results Table 2 reports average precision for mono- lingual retrieval, average precision for cross- lingual, and the relative performance ratio of cross-lingual retrieval to mono-lingual. Relative performance of cross-lingual IR varies between 67% and 84% of mono-lingual IR. Trec6 Chinese queries have a somewhat higher relative performance than Trec5 Chinese queries. Longer queries have higher elative performance than short queries in general. Overall, cross-lingual performance using our HMM retrieval model
slations (potentially the more common terms) more credit in retrieval, even though such terms hould potentially be given less credit if they are more common. Also, a document matching different translations ofone term in the original query may be ranked higher than a document that matches translations ofdifferent terms in the original query. That is, a document that contains terms at, a2 and a3 may be ranked higher than a document which contains terms at and bl. However, the second ocument is more likely to be relevant since correct translations of the query terms are more likely to co-occur (Ballesteros and Croft, 1998). A second method is to structure the translated query, separating the translations for one term from translations for other terms. This approach limits how much credit he retrieval algorithm can give to a single term in the original query and prevents the translations ofone or a few terms from swamping the whole query. There are several variations of such a method (Ballesteros and Croft, 1998; Pirkola, 1998; Hull 1997). One such method is to treat different translations ofthe same term as synonyms. Ballesteros, for example, used the INQUERY (Callan et al 1995) synonym operator to group transl
document which contains terms at and bl. However, the second ocument is more likely to be relevant since correct translations of the query terms are more likely to co-occur (Ballesteros and Croft, 1998). A second method is to structure the translated query, separating the translations for one term from translations for other terms. This approach limits how much credit he retrieval algorithm can give to a single term in the original query and prevents the translations ofone or a few terms from swamping the whole query. There are several variations of such a method (Ballesteros and Croft, 1998; Pirkola, 1998; Hull 1997). One such method is to treat different translations ofthe same term as synonyms. Ballesteros, for example, used the INQUERY (Callan et al 1995) synonym operator to group translations ofdifferent query terms. However, if a term has two translations inthe target language, it will treat hem as equal even though one of them is more likely to be the correct translation than the other. By contrast, our HMM approach supports translation probabilities. The synonym approach is equivalent to changing all non-zero translation probabilities P(W~\[ Wy)'s to 1 in our retrieyal function. Even es
contains terms at and bl. However, the second ocument is more likely to be relevant since correct translations of the query terms are more likely to co-occur (Ballesteros and Croft, 1998). A second method is to structure the translated query, separating the translations for one term from translations for other terms. This approach limits how much credit he retrieval algorithm can give to a single term in the original query and prevents the translations ofone or a few terms from swamping the whole query. There are several variations of such a method (Ballesteros and Croft, 1998; Pirkola, 1998; Hull 1997). One such method is to treat different translations ofthe same term as synonyms. Ballesteros, for example, used the INQUERY (Callan et al 1995) synonym operator to group translations ofdifferent query terms. However, if a term has two translations inthe target language, it will treat hem as equal even though one of them is more likely to be the correct translation than the other. By contrast, our HMM approach supports translation probabilities. The synonym approach is equivalent to changing all non-zero translation probabilities P(W~\[ Wy)'s to 1 in our retrieyal function. Even estimating uni
re likely to co-occur (Ballesteros and Croft, 1998). A second method is to structure the translated query, separating the translations for one term from translations for other terms. This approach limits how much credit he retrieval algorithm can give to a single term in the original query and prevents the translations ofone or a few terms from swamping the whole query. There are several variations of such a method (Ballesteros and Croft, 1998; Pirkola, 1998; Hull 1997). One such method is to treat different translations ofthe same term as synonyms. Ballesteros, for example, used the INQUERY (Callan et al 1995) synonym operator to group translations ofdifferent query terms. However, if a term has two translations inthe target language, it will treat hem as equal even though one of them is more likely to be the correct translation than the other. By contrast, our HMM approach supports translation probabilities. The synonym approach is equivalent to changing all non-zero translation probabilities P(W~\[ Wy)'s to 1 in our retrieyal function. Even estimating uniform translation probabilities gives higher weights to unambiguous translations and lower weights to highly ambiguous translations. 98 These int
medium, Trec6C- medium and Trec4S queries. That is, for each English query term, a native Chinese or Spanish speaker scanned the list of translations in the bilingual exicon and kept one translation deemed to be the best for the English term and discarded the rest. If none of the translations was correct, the first one was chosen. The results in Table 4 show that manual disambiguation improves performance by 17% on Trec5C, 4% on Trec4S, but not at all on Trec6C. Furthermore, the improvement on Trec5C appears to be caused by big improvements for a small number of queries. The one-sided t-test (Hull, 1993) at significance level 0.05 indicated that the improvement on Trec5C is not statistically significant. It seems urprising that disambiguation does not help at all for Trec6C. We found that many terms have more than one valid translation. For example, the word &quot;flood&quot; (as in &quot;flood control&quot;) has 4 valid Chinese translations. Using all of them achieves the desirable ffect of query expansion. It appears that for Trec6C, the benefit of disambiguation is cancelled by choosing only one of several alternatives, discarding those other good translations. If multiple correct Query sets Trec5C-medium Tre
 Size Figure 1 Impact of lexicon size on cross-lingual IR performance We categorized the missing terms and found that most of them are proper nouns (especially locations and person ames), highly technical terms, or numbers. Such words understandably do not normally appear in traditional lexicons. Translation of numbers can be solved using simple rules. Transliteration, a technique that guesses the likely translations of a word based on pronunciation, can be readily used in translating proper nouns. Another technique is automatic discovery of translations from parallel or non-parallel corpora (Fung and Mckeown, 1997). Since traditional lexicons are more or less static repositories of knowledge, techniques that discover translation from newly published materials can supplement them with corpus-specific vocabularies. 100 10 Using a Parallel Corpus In this section we estimate translation probabilities from a parallel corpus rather than assuming uniform likelihood as in section 4. A Hong Kong News corpus obtained from the Linguistic Data Consortium has 9,769 news stories in Chinese with English translations. It has 3.4 million English words. Since the documents are not exact ranslations of each other, occasio
rmance, the parallel corpus is not large enough nor diverse nough for reliable stimation of the translation probabilities. In fact, many words do not appear in the corpus at all. With a larger and better parallel corpus, more weight should be given to the probability estimates from the corpus. Trec5 - Trec6- medium medium P_lexicon 0.2449 0.3872 13=0.3 0.2557 0.3980 13=0.5 0.2605 0.4021 13=0.7 0.2658 0.4035 P_corpus 0.2293 0.2971 Table 6: Performance with different values of 13. All scores are average precision. 11 Related Work Other studies which view IR as a query generation process include Maron and Kuhns, 1960; Hiemstra nd Kraaij, 1999; Ponte and Croft, 1998; Miller et al 1999. Our work has focused on cross-lingual retrieval. Many approaches tocross-lingual IR have been published. One common approach is using Machine Translation (MT) to translate the queries to the language of the documents or translate documents othe language of the queries (Gey et al 1999; Oard, 1998). For most languages, there are no MT systems at all. Our focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual exicon. (D
or diverse nough for reliable stimation of the translation probabilities. In fact, many words do not appear in the corpus at all. With a larger and better parallel corpus, more weight should be given to the probability estimates from the corpus. Trec5 - Trec6- medium medium P_lexicon 0.2449 0.3872 13=0.3 0.2557 0.3980 13=0.5 0.2605 0.4021 13=0.7 0.2658 0.4035 P_corpus 0.2293 0.2971 Table 6: Performance with different values of 13. All scores are average precision. 11 Related Work Other studies which view IR as a query generation process include Maron and Kuhns, 1960; Hiemstra nd Kraaij, 1999; Ponte and Croft, 1998; Miller et al 1999. Our work has focused on cross-lingual retrieval. Many approaches tocross-lingual IR have been published. One common approach is using Machine Translation (MT) to translate the queries to the language of the documents or translate documents othe language of the queries (Gey et al 1999; Oard, 1998). For most languages, there are no MT systems at all. Our focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual exicon. (Davis and Ogden, 1997; Ballesteros and Croft, 1997
liable stimation of the translation probabilities. In fact, many words do not appear in the corpus at all. With a larger and better parallel corpus, more weight should be given to the probability estimates from the corpus. Trec5 - Trec6- medium medium P_lexicon 0.2449 0.3872 13=0.3 0.2557 0.3980 13=0.5 0.2605 0.4021 13=0.7 0.2658 0.4035 P_corpus 0.2293 0.2971 Table 6: Performance with different values of 13. All scores are average precision. 11 Related Work Other studies which view IR as a query generation process include Maron and Kuhns, 1960; Hiemstra nd Kraaij, 1999; Ponte and Croft, 1998; Miller et al 1999. Our work has focused on cross-lingual retrieval. Many approaches tocross-lingual IR have been published. One common approach is using Machine Translation (MT) to translate the queries to the language of the documents or translate documents othe language of the queries (Gey et al 1999; Oard, 1998). For most languages, there are no MT systems at all. Our focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual exicon. (Davis and Ogden, 1997; Ballesteros and Croft, 1997; Hull and Grefenst
.2605 0.4021 13=0.7 0.2658 0.4035 P_corpus 0.2293 0.2971 Table 6: Performance with different values of 13. All scores are average precision. 11 Related Work Other studies which view IR as a query generation process include Maron and Kuhns, 1960; Hiemstra nd Kraaij, 1999; Ponte and Croft, 1998; Miller et al 1999. Our work has focused on cross-lingual retrieval. Many approaches tocross-lingual IR have been published. One common approach is using Machine Translation (MT) to translate the queries to the language of the documents or translate documents othe language of the queries (Gey et al 1999; Oard, 1998). For most languages, there are no MT systems at all. Our focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual exicon. (Davis and Ogden, 1997; Ballesteros and Croft, 1997; Hull and Grefenstette, 1996). While word sense disambiguation has been a central topic in previous tudies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable. Other studies on the value of disambiguation for c
0; Hiemstra nd Kraaij, 1999; Ponte and Croft, 1998; Miller et al 1999. Our work has focused on cross-lingual retrieval. Many approaches tocross-lingual IR have been published. One common approach is using Machine Translation (MT) to translate the queries to the language of the documents or translate documents othe language of the queries (Gey et al 1999; Oard, 1998). For most languages, there are no MT systems at all. Our focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual exicon. (Davis and Ogden, 1997; Ballesteros and Croft, 1997; Hull and Grefenstette, 1996). While word sense disambiguation has been a central topic in previous tudies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable. Other studies on the value of disambiguation for cross-lingual IR include Hiernstra nd de Jong, 1999; Hull, 1997. Sanderson, 1994 studied the issue of disarnbiguation for mono-lingual IR. 101 The third approach to cross-lingual retrieval is to map queries and documents o some intermediate r presentatio
1999; Ponte and Croft, 1998; Miller et al 1999. Our work has focused on cross-lingual retrieval. Many approaches tocross-lingual IR have been published. One common approach is using Machine Translation (MT) to translate the queries to the language of the documents or translate documents othe language of the queries (Gey et al 1999; Oard, 1998). For most languages, there are no MT systems at all. Our focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual exicon. (Davis and Ogden, 1997; Ballesteros and Croft, 1997; Hull and Grefenstette, 1996). While word sense disambiguation has been a central topic in previous tudies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable. Other studies on the value of disambiguation for cross-lingual IR include Hiernstra nd de Jong, 1999; Hull, 1997. Sanderson, 1994 studied the issue of disarnbiguation for mono-lingual IR. 101 The third approach to cross-lingual retrieval is to map queries and documents o some intermediate r presentation, e.g latent semantic indexi
Miller et al 1999. Our work has focused on cross-lingual retrieval. Many approaches tocross-lingual IR have been published. One common approach is using Machine Translation (MT) to translate the queries to the language of the documents or translate documents othe language of the queries (Gey et al 1999; Oard, 1998). For most languages, there are no MT systems at all. Our focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual exicon. (Davis and Ogden, 1997; Ballesteros and Croft, 1997; Hull and Grefenstette, 1996). While word sense disambiguation has been a central topic in previous tudies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable. Other studies on the value of disambiguation for cross-lingual IR include Hiernstra nd de Jong, 1999; Hull, 1997. Sanderson, 1994 studied the issue of disarnbiguation for mono-lingual IR. 101 The third approach to cross-lingual retrieval is to map queries and documents o some intermediate r presentation, e.g latent semantic indexing (LSI) (Littman et al 1998),
. Our focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual exicon. (Davis and Ogden, 1997; Ballesteros and Croft, 1997; Hull and Grefenstette, 1996). While word sense disambiguation has been a central topic in previous tudies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable. Other studies on the value of disambiguation for cross-lingual IR include Hiernstra nd de Jong, 1999; Hull, 1997. Sanderson, 1994 studied the issue of disarnbiguation for mono-lingual IR. 101 The third approach to cross-lingual retrieval is to map queries and documents o some intermediate r presentation, e.g latent semantic indexing (LSI) (Littman et al 1998), or the General Vector space model (GVSM), (Carbonell et al 1997). We believe our approach is computationally ess costly than (LSI and GVSM) and assumes less resources (WordNet in Diekema et al, 1999). 12 Conclusions and Future Work We proposed an approach to cross-lingual IR based on hidden Markov models, where the system estimates the probability
is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual exicon. (Davis and Ogden, 1997; Ballesteros and Croft, 1997; Hull and Grefenstette, 1996). While word sense disambiguation has been a central topic in previous tudies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable. Other studies on the value of disambiguation for cross-lingual IR include Hiernstra nd de Jong, 1999; Hull, 1997. Sanderson, 1994 studied the issue of disarnbiguation for mono-lingual IR. 101 The third approach to cross-lingual retrieval is to map queries and documents o some intermediate r presentation, e.g latent semantic indexing (LSI) (Littman et al 1998), or the General Vector space model (GVSM), (Carbonell et al 1997). We believe our approach is computationally ess costly than (LSI and GVSM) and assumes less resources (WordNet in Diekema et al, 1999). 12 Conclusions and Future Work We proposed an approach to cross-lingual IR based on hidden Markov models, where the system estimates the probability that a query in 
 central topic in previous tudies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable. Other studies on the value of disambiguation for cross-lingual IR include Hiernstra nd de Jong, 1999; Hull, 1997. Sanderson, 1994 studied the issue of disarnbiguation for mono-lingual IR. 101 The third approach to cross-lingual retrieval is to map queries and documents o some intermediate r presentation, e.g latent semantic indexing (LSI) (Littman et al 1998), or the General Vector space model (GVSM), (Carbonell et al 1997). We believe our approach is computationally ess costly than (LSI and GVSM) and assumes less resources (WordNet in Diekema et al, 1999). 12 Conclusions and Future Work We proposed an approach to cross-lingual IR based on hidden Markov models, where the system estimates the probability that a query in one language could be generated from a document in another language. Experiments using the TREC5 and TREC6 Chinese test sets and the TREC4 Spanish test set show the following: ? Our retrieval model can reduce the performance d gradation due to translation ambiguity This had been a major limiting f
