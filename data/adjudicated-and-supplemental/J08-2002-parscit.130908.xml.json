{"algorithms":{"#text":"\n","@version":"110505","algorithm":{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Collins, Michael. 2000. Discriminative reranking for natural language parsing. In Proceedings of ICML, pages 175\u2013182, Stanford, CA."},"#text":"\n","pages":{"#tail":"\n","#text":"175--182"},"marker":{"#tail":"\n","#text":"Collins, 2000"},"location":{"#tail":"\n","#text":"Stanford, CA."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"s that if too many dependencies are encoded, the model will over-fit the training data and will not generalize well. We propose a model which circumvents these two dangers and achieves significant performance gains over a similar local model that does not add any dependency arcs among the random variables. To tackle the efficiency problem, we adopt dynamic programming and re-ranking algorithms. To avoid overfitting we encode only a small set of linguistically motivated dependencies in features over sets of the random variables. Our re-ranking approach, like the approach to parse re-ranking of Collins (2000), employs a simpler model\u2014a local semantic role labeling algorithm\u2014as a first pass to generate a set of n likely complete assignments of labels to all parse tree nodes. The joint model is restricted to these n assignments and does not have to search the exponentially large space of all possible joint labelings. 2. Related Work There has been a substantial amount of work on automatic semantic role labeling, starting with the statistical model of Gildea and Jurafsky (2002). Researchers have worked on defining new useful features, and different system architectures and models. Here we review the ","@endWordPosition":"1319","@position":"8342","annotationId":"T1","@startWordPosition":"1318","@citStr":"Collins (2000)"},{"#tail":"\n","#text":"n nodes is 2n. This number can run into the hundreds of billions for a normal-sized tree. For argument labeling, the number of possible assignments is ≈ 20m, if m is the number of arguments of a verb (typically between 2 and 5), and 20 is the approximate number of possible labels if considering both core and modifying arguments. Training a model which has such a huge number of classes is infeasible if the model does not factorize due to strong independence assumptions. Therefore, in order to be able to incorporate long-range dependencies in our models, we chose to adopt a re-ranking approach (Collins 2000), which selects from likely assignments generated by a model which makes stronger independence assumptions. We utilize the top n assignments of our local semantic role labeling model PSRL to generate likely assignments. As can be seen from Figure 8(a), for relatively small values of n, our 177 Computational Linguistics Volume 34, Number 2 re-ranking approach does not present a serious bottleneck to performance. We used a value of n = 10 for training. In Figure 8(a) we can see that if we could pick, using an oracle, the best assignment out of the top 10 assignments according to the local model,","@endWordPosition":"8000","@position":"49767","annotationId":"T2","@startWordPosition":"7999","@citStr":"Collins 2000"},{"#tail":"\n","#text":"frames near the bottom of the top n for large n. Because the re-ranking model is trained on relatively 181 Computational Linguistics Volume 34, Number 2 few good argument frames, it cannot easily rule out very bad frames. It makes sense then to incorporate the local model into our final score. Our final score is given by: PSRL(LJt,v) = (PsRL(LJt,v))α PrSRL(LJt,v) where α is a tunable parameter determining the amount of influence the local score has on the final score (we found α = 1.0 to work best). Such interpolation with a score from a first-pass model was also used for parse re-ranking in (Collins 2000). Given this score, at test time we choose among the top n local assignments L1,. . . , Ln according to: argmaxL∈L1,...,Ln α logPsRL(LJt,v) + logPrSRL(LJt,v) (4) 5.4 Joint Model Results We compare the performance of joint re-ranking models and local models. We used n = 10 joint assignments for training re-ranking models, and n = 15 for testing. The weight α of the local model was set to 1. Using different numbers of joint assignments in training and testing is in general not ideal, but due to memory requirements, we could not experiment with larger values of n for training. Figure 10 shows the","@endWordPosition":"10103","@position":"62588","annotationId":"T3","@startWordPosition":"10102","@citStr":"Collins 2000"}]},"title":{"#tail":"\n","#text":"Discriminative reranking for natural language parsing."},"booktitle":{"#tail":"\n","#text":"In Proceedings of ICML,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Michael Collins"}}},{"volume":{"#tail":"\n","#text":"28"},"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Gildea, Daniel and Daniel Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3):245\u2013288."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"3"},"marker":{"#tail":"\n","#text":"Gildea, Jurafsky, 2002"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" motivated dependencies in features over sets of the random variables. Our re-ranking approach, like the approach to parse re-ranking of Collins (2000), employs a simpler model\u2014a local semantic role labeling algorithm\u2014as a first pass to generate a set of n likely complete assignments of labels to all parse tree nodes. The joint model is restricted to these n assignments and does not have to search the exponentially large space of all possible joint labelings. 2. Related Work There has been a substantial amount of work on automatic semantic role labeling, starting with the statistical model of Gildea and Jurafsky (2002). Researchers have worked on defining new useful features, and different system architectures and models. Here we review the work most closely related to ours, concentrating on methods for incorporating joint information and for increasing robustness to parser error. 2 That is, it defines a conditional distribution of labels of all nodes given the parse tree. 163 Computational Linguistics Volume 34, Number 2 2.1 Methods for Incorporating Joint Information Gildea and Jurafsky (2002) propose a method to model global dependencies by including a probability distribution over multi-sets of semantic","@endWordPosition":"1399","@position":"8817","annotationId":"T4","@startWordPosition":"1396","@citStr":"Gildea and Jurafsky (2002)"},{"#tail":"\n","#text":"information extraction (McCallum, Freitag, and Pereira 2000). Notice that here the previous two nodes classified are not in general the previous two nodes assigned non-NONE labels. If a linear order on all nodes is imposed, then the previous two nodes classified most likely bear the label NONE. Language model lattice re-scoring: Re-scoring of an N-best lattice with a trigram language model over semantic role label sequences. The target predicate is also part of the sequence. These ways of incorporating joint information resulted in small gains over a baseline system using only the features of Gildea and Jurafsky (2002). The performance gain due to joint information over a system using all features was not reported. The joint information captured by this model is limited by the n-gram Markov assumption of the language model over labels. In our work, we improve the modeling of joint dependencies by looking at longer-distance context, by defining richer features over the sequence of labels and input features, and by estimating the model parameters discriminatively. A system which can integrate longer-distance dependencies is that of Punyakanok et al. (2004) and Punyakanok, Roth, and Yih (2005). The idea is to ","@endWordPosition":"1888","@position":"11878","annotationId":"T5","@startWordPosition":"1885","@citStr":"Gildea and Jurafsky (2002)"},{"#tail":"\n","#text":"ly of the labels of other nodes. In defining our models, we use the standard separation of the task of semantic role labeling into identification and classification phases. Formally, let L denote a mapping of the nodes in a tree t to a label set of semantic roles (including NONE) with respect to a predicate v. Let Id(L) be the mapping which collapses L\u2019s non-NONE values into ARG. 5 The regular expressions look for phrases containing pronouns with part-of-speech tags WDT, WRB, WP, or WP$ (Xavier Carreras, personal communication). 171 Computational Linguistics Volume 34, Number 2 Then, like the Gildea and Jurafsky (2002) system, we decompose the probability of a labeling L into probabilities according to an identification model PID and a classification model PCLS. PSRL(L|t, v) = PID(Id(L)|t, v)PCLS(L|t, v, Id(L)) (1) This decomposition does not encode any independence assumptions, but is a useful way of thinking about the problem. Our local models for semantic role labeling use this decomposition. We use the same features for local identification and classification models, but use the decomposition for efficiency of training. The identification models are trained to classify each node in a parse tree as ARG o","@endWordPosition":"5502","@position":"34468","annotationId":"T6","@startWordPosition":"5499","@citStr":"Gildea and Jurafsky (2002)"},{"#tail":"\n","#text":"the identification stage in testing and can find the exact labeling of the complete parse tree, which is the maximizer of Equation (1). We use log-linear models for multi-class classification for the local models. Because they produce probability distributions, identification and classification models can be chained in a principled way, as in Equation (1). The baseline features we used for the local identification and classification models are outlined in Figure 3. These features are a subset of the features used in previous work. The standard features at the top of the figure were defined by Gildea and Jurafsky (2002), and the rest are other useful lexical and structural features identified in more recent work (Surdeanu et al. 2003; Pradhan et al. 2004; Xue and Palmer 2004). We also incorporated several novel features which we describe next. Figure 3 Baseline features. 172 Toutanova, Haghighi, and Manning A Global Joint Model for SRL Figure 4 Example of displaced arguments. 4.1 Additional Features for Displaced Constituents We found that a large source of errors for ARG0 and ARG1 stemmed from cases such as those illustrated in Figure 4, where arguments were dislocated by raising or control verbs. Here, the","@endWordPosition":"5739","@position":"35931","annotationId":"T7","@startWordPosition":"5736","@citStr":"Gildea and Jurafsky (2002)"},{"#tail":"\n","#text":"cular, the likelihood of an assignment according to the joint model with local features will differ from the likelihood of the same assignment according to the local model only in the denominator (the partition function). The joint model sums over 179 Computational Linguistics Volume 34, Number 2 a few likely assignments in the denominator, whereas the local model sums over all assignments; also, the joint model does not treat the decomposition into identification and classification models in exactly the same way as the local model. Whole Label Sequence Features. As observed in previous work (Gildea and Jurafsky 2002; Pradhan et al. 2004), including information about the set or sequence of labels assigned to argument nodes should be very helpful for disambiguation. For example, including such information will make the model less likely to pick multiple nodes to fill the same role or to come up with a labeling that does not contain an obligatory argument. We added a whole label sequence feature template that extracts the labels of all argument nodes, and preserves information about the position of the predicate. Two templates for whole label sequences were added: one having the predicate voice only, and an","@endWordPosition":"8971","@position":"55511","annotationId":"T8","@startWordPosition":"8968","@citStr":"Gildea and Jurafsky 2002"}]},"title":{"#tail":"\n","#text":"Automatic labeling of semantic roles."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Daniel Gildea"},{"#tail":"\n","#text":"Daniel Jurafsky"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Punyakanok, Vasin, Dan Roth, Wen-tau Yih, Dav Zimak, and Yuancheng Tu. 2004. Semantic role labeling via generalized inference over classifiers. In Proceedings of CoNLL, pages 130\u2013133, Boston, MA."},"#text":"\n","pages":{"#tail":"\n","#text":"130--133"},"marker":{"#tail":"\n","#text":"Punyakanok, Roth, Yih, Zimak, Tu, 2004"},"location":{"#tail":"\n","#text":"Boston, MA."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"s over a baseline system using only the features of Gildea and Jurafsky (2002). The performance gain due to joint information over a system using all features was not reported. The joint information captured by this model is limited by the n-gram Markov assumption of the language model over labels. In our work, we improve the modeling of joint dependencies by looking at longer-distance context, by defining richer features over the sequence of labels and input features, and by estimating the model parameters discriminatively. A system which can integrate longer-distance dependencies is that of Punyakanok et al. (2004) and Punyakanok, Roth, and Yih (2005). The idea is to build a semantic role labeling system that is based on local classifiers but also uses a global component that ensures that several linguistically motivated global constraints on argument frames are satisfied. The constraints are categorical and specified by hand. For example, one global constraint is that the argument phrases cannot overlap\u2014that is, if a node is labeled with a non-NONE label, all of its descendants have to be labeled NONE. The proposed framework is integer linear programming (ILP), which makes it possible to find the most ","@endWordPosition":"1972","@position":"12424","annotationId":"T9","@startWordPosition":"1969","@citStr":"Punyakanok et al. (2004)"},{"#tail":"\n","#text":"syntactic chunks and one based on labeling parse tree nodes. Our work differs from that work in that our constraints are not categorical (either satisfied or not), but are rather statistical preferences, and that they are learned automatically based on features specified by the knowledge engineer. On the other hand, we solve the search/estimation problem through re-ranking and n-best search only approximately, not exactly. So far we have mainly discussed systems which label nodes in a parse tree. Many systems that only use shallow syntactic information have also been presented (Hacioglu 2004; Punyakanok et al. 2004); using full syntactic parse information was not allowed in the CoNLL 2004 shared task on Semantic Role Labeling and description of such systems can be found in (Carreras and M`arquez 2004). Most systems which use only shallow syntactic information represent the input sentence as a sequence of tokens (words or phrases), which they label with a BIO tagging representation (beginning, inside, and outside argument labels) (Hacioglu 2004). Limited joint information is used by such systems, provided as a fixed size context of tags on previous tokens; for example, a length five window is used in the ","@endWordPosition":"2235","@position":"14082","annotationId":"T10","@startWordPosition":"2232","@citStr":"Punyakanok et al. 2004"},{"#tail":"\n","#text":"el li of each parse tree node ni as shown below in Equation (2). P� SRL(L|t,v) _ � PID(Id(li)|t, v) � PCLS(li|t, v,Id(li)) (2) ni∈t ni∈t A problem with this approach is that a maximizing labeling of the nodes could possibly violate the constraint that argument nodes should not overlap with each other. Therefore, to produce a consistent set of arguments with local classifiers, we must have a way of enforcing the non-overlapping constraint. When labeling parse tree nodes, previous work has either used greedy algorithms to find a non-overlapping assignment, or the general-purpose ILP approach of Punyakanok et al. (2004). For labeling chunks an exact algorithm based on shortest paths was proposed in Punyakanok and Roth (2001). Its complexity is quadratic in the length of the sentence. Here we describe a faster exact dynamic programming algorithm to find the most likely non-overlapping (consistent) labeling of all nodes in the parse tree, according to a product of probabilities from local models, as in Equation (2). For simplicity, we describe the dynamic program for the case where only two classes are possible: ARG and NONE. The generalization to more classes is straightforward. Intuitively, the algorithm is ","@endWordPosition":"6400","@position":"39932","annotationId":"T11","@startWordPosition":"6397","@citStr":"Punyakanok et al. (2004)"},{"#tail":"\n","#text":"mproves the overall performance mainly by improving the performance on 176 Toutanova, Haghighi, and Manning A Global Joint Model for SRL CORE arguments, through increasing recall and precision by looking at wider sentence context. 4.3 On Split Constituents As discussed in Section 3, multiple constituents can be part of the same semantic argument as specified by Propbank. An automatic system that has to recover such information needs to have a way of indicating when multiple constituents labeled with the same semantic role are a part of the same argument. Some researchers (Pradhan et al. 2004; Punyakanok et al. 2004) have chosen to make labels of the form C-ARGX distinct argument labels that become additional classes in a multi-class constituent classifier. These C-ARGX are used to indicate continuing arguments as illustrated in the two trees in Figure 2. We chose to not introduce additional labels of this form, because they might unnecessarily fragment the training data. Our automatic classifiers label constituents with one of the core or modifier semantic role labels, and a simple post-processing rule is applied to the output of the system to determine which constituents that are labeled the same are to","@endWordPosition":"7585","@position":"47203","annotationId":"T12","@startWordPosition":"7582","@citStr":"Punyakanok et al. 2004"}]},"title":{"#tail":"\n","#text":"Semantic role labeling via generalized inference over classifiers."},"booktitle":{"#tail":"\n","#text":"In Proceedings of CoNLL,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Vasin Punyakanok"},{"#tail":"\n","#text":"Dan Roth"},{"#tail":"\n","#text":"Wen-tau Yih"},{"#tail":"\n","#text":"Dav Zimak"},{"#tail":"\n","#text":"Yuancheng Tu"}]}}]}}}}
