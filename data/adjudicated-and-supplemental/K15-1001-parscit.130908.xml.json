{"algorithms":{"#text":"\n","@version":"110505","algorithm":{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Michael Collins. 2002. Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms. In EMNLP, Philadelphia, PA."},"#text":"\n","marker":{"#tail":"\n","#text":"Collins, 2002"},"location":{"#tail":"\n","#text":"Philadelphia, PA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" + α VIDT,K T T t=1 √DT T T t=1 + 2||w∗||R�2 ln 1 δ . � 8 ln 2 + Rkw∗k T . δ The generalization bound tells us how far the expected average regret E[REGT] (or average risk, in terms of Cesa-Bianchi et al. (2004)) is from the average regret that we actually observe in a specific instantiation of the algorithm. Generalization for Online-to-Batch Conversion. In practice, perceptron-type algorithms are often applied in a batch learning scenario, i.e., the algorithm is applied for K epochs to a training sample of size T and then used for prediction on an unseen test set (Freund and Schapire, 1999; Collins, 2002). The difference to the online learning scenario is that we treat the multi-epoch algorithm as an empirical risk minimizer that selects a final weight vector wT,K whose expected loss on unseen data we would like to bound. We assume that the algorithm is fed with a sequence of examples x1, ... , xT, and at each epoch k = 1, ... , K it makes a prediction yt,k. The correct label is y∗t . For k = 1, ... , K and t = 1, ... , T, let `t,k = U(xt, y∗t ) − U(xt, yt,k), and denote by Δt,k and ξt,k the distance at epoch k for example t, and the slack at epoch k for example t, respectively. Finally, we de","@endWordPosition":"3275","@position":"19487","annotationId":"T1","@startWordPosition":"3274","@citStr":"Collins, 2002"}},"title":{"#tail":"\n","#text":"Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms."},"booktitle":{"#tail":"\n","#text":"In EMNLP,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Michael Collins"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Birch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In ACL, Prague, Czech Republic."},"#text":"\n","marker":{"#tail":"\n","#text":"Koehn, Hoang, Birch, Callison-Birch, Federico, Bertoldi, Cowan, Shen, 2007"},"location":{"#tail":"\n","#text":"Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"e terms) and the variance caused by the finite sample (the third term in the theorem). The result follows directly from McDiarmid\u2019s concentration inequality. 4 Experiments We used the LIG corpus3 which consists of 10,881 tuples of French-English post-edits (Potet et al., 2012). The corpus is a subset of the newscommentary dataset provided at WMT4 and contains input French sentences, MT outputs, postedited outputs and English references. To prepare SMT outputs for post-editing, the creators of the corpus used their own WMT10 system (Potet et al., 2010), based on the Moses phrase-based decoder (Koehn et al., 2007) with dense features. We replicated a similar Moses system using the same monolingual and parallel data: a 5-gram language model was estimated with the KenLM toolkit (Heafield, 2011) on news.en data (48.65M sentences, 1.13B tokens), pre-processed with the tools from the cdec toolkit (Dyer et al., 2010). perceptron cycling theorem (Block and Levin, 1970; Gelfand et al., 2010) should suffice to show a similar bound. 3http://www-clips.imag.fr/geod/User/marion.potet/ index.php?page=download 4http://statmt.org/wmt10/translation-task.html 5 regret 0.90 0.80 0.70 0.60 0.50 0.40 0.30 0.20 0.10 0.00 α ","@endWordPosition":"3566","@position":"21088","annotationId":"T2","@startWordPosition":"3563","@citStr":"Koehn et al., 2007"}},"title":{"#tail":"\n","#text":"Moses: Open source toolkit for statistical machine translation."},"booktitle":{"#tail":"\n","#text":"In ACL,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Philipp Koehn"},{"#tail":"\n","#text":"Hieu Hoang"},{"#tail":"\n","#text":"Alexandra Birch"},{"#tail":"\n","#text":"Chris Callison-Birch"},{"#tail":"\n","#text":"Marcello Federico"},{"#tail":"\n","#text":"Nicola Bertoldi"},{"#tail":"\n","#text":"Brooke Cowan"},{"#tail":"\n","#text":"Wade Shen"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In NAACL, Edmonton, Canada."},"#text":"\n","marker":{"#tail":"\n","#text":"Och, 2003"},"location":{"#tail":"\n","#text":"Edmonton, Canada."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"formative feedback corresponds to improvements under standard evaluation metrics such as lowercased and tokenized TER, and that learning from weak and strong feedback leads to convergence in TER on test data. For this experiment, the post-edit data from the LIG corpus were randomly split into 3 subsets: PE-train (6,881 sentences), PE-dev, and PE-test (2,000 sentences each). PE-train was used for our online learning experiments. PE-test was held out for testing the algorithms\u2019 progress on unseen data. PE-dev was used to obtain w* to define the utility model. This was done by MERT optimization (Och, 2003) towards post-edits under the TER target metric. Note that the goal of our experi6 % strictly α-informative local 39.46% filtered 47.73% hope 83.30% Table 2: α-informativeness of surrogacy modes. ments is not to improve SMT performance over any algorithm that has access to full information to compute w*. Rather, we want to show that learning from weak feedback leads to convergence in regret with respect to the optimal model, albeit at a slower rate than learning from strong feedback. The feedback data in this experiment were generated by searching the n-best list for translations that are α-in","@endWordPosition":"4196","@position":"24924","annotationId":"T3","@startWordPosition":"4195","@citStr":"Och, 2003"}},"title":{"#tail":"\n","#text":"Minimum error rate training in statistical machine translation."},"booktitle":{"#tail":"\n","#text":"In NAACL,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Franz Josef Och"}}}]}}}}
