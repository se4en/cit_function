{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","note":{"#tail":"\n","@confidence":"0.1917535","#text":"\nProceedings of the ACL Workshop on Computational Approaches to Semitic Languages, pages 63?70,\nAnn Arbor, June 2005. c?2005 Association for Computational Linguistics\n"},"listItem":[{"#tail":"\n","@confidence":"0.533029333333333","#text":"\nduring all lookups and processing: (1) ? ,?\n, and\n(2)\n"},{"#tail":"\n","@confidence":"0.983088545454545","#text":"\n1. the mention type: person (PER), organiza-\ntion (ORG), location (LOC), geopolitical en-\ntity (GPE), facility (FAC), vehicle (VEH), and\nweapon (WEA)\n2. the mention level (named, nominal, pronominal,\nor premodifier)\n3. the mention class (generic, specific, negatively\nquantified, etc.)\n4. the mention sub-type, which is a sub-category\nof the mention type (ACE, 2004) (e.g. OrgGov-\nernmental, FacilityPath, etc.).\n"},{"#tail":"\n","@confidence":"0.210162","#text":"\n(office). After segmentation, the sentence becomes:\n+ I. J?\n"}],"figure":[{"#tail":"\n","@confidence":"0.978372238095238","#text":"\nword match 97.8% correct segmentation.\nSEP/epsilon\na/A#\nepsilon/#\na/epsilon\na/epsilon\nb/epsilon\nb/B\nUNK/epsilon\nc/C\nb/epsilon\nc/BC\ne/+E\nepsilon/+\nd/epsilon\nd/epsilon\nepsilon/epsilon\nb/AB#\nb/A#B#\ne/+DE\nc/epsilon d/BCD e/+D+E\n"},{"#tail":"\n","@confidence":"0.911825125","#text":"\nH. Qj?? ?\n??A\nJ\n??@ I. J?\n??? Q\n??? @ ?J??\n@\n Y? (transla-\n"},{"#tail":"\n","@confidence":"0.959684","#text":"\n??A\nJ\n??@ I. J?\n???\n(to-the-office the-politic to-the-party) and\n?\nG.\nQm?'@ I. J?\n? (office the-party?s) segmented as\nH. Qk + ?\n\n@ + ? + ?\n??A\nJ\n? + ?\n\n"}],"author":{"#tail":"\n","@confidence":"0.673816","#text":"\nImed Zitouni, Jeff Sorensen, Xiaoqiang Luo, Radu Florian\n"},"equation":[{"#tail":"\n","@confidence":"0.4614535","#text":"\n\n@Q?@\n for woman, but ZA\n?  for\n"},{"#tail":"\n","@confidence":"0.864152666666667","#text":"\n\n@ , @\n ,\n\n@ ,\n\n"},{"#tail":"\n","@confidence":"0.781572066666667","#text":"\n? + ?\n\n@ + ? + Q?? + ?\n\n@ + ?J? + ?\n+ @\n Y?\n.H. Qk + ?\n\n@ + ? + ?\n??A\nJ\n? + ?\n\n@\n"},{"#tail":"\n","@confidence":"0.784047285714286","#text":"\n\n@ + ?\n(for the) and ?\n??A\nJ\n? + ?\n\n"},{"#tail":"\n","@confidence":"0.727163","#text":"\n??A\nJ\n"},{"#tail":"\n","@confidence":"0.997537","#text":"\nPL(L = 1|e, m) ? maxmk?e P?L(L = 1|e, mk, m), (1)\n"},{"#tail":"\n","@confidence":"0.99924675","#text":"\nPS(S = 1|e1, e2, ? ? ? , et, m) ?\n1 ? max\n1?i?t\nPL(L = 1|ei, m) (2)\n"}],"subsectionHeader":[{"#tail":"\n","@confidence":"0.997981","#text":"\n3.1 Bootstrapping\n"},{"#tail":"\n","@confidence":"0.999143","#text":"\n3.2 Preprocessing of Arabic Treebank Data\n"},{"#tail":"\n","@confidence":"0.984907","#text":"\n4.1 System Description\n"},{"#tail":"\n","@confidence":"0.992238","#text":"\n4.2 Stem n-gram Features\n"},{"#tail":"\n","@confidence":"0.998169","#text":"\n5.1 Arabic Stem Match Feature\n"},{"#tail":"\n","@confidence":"0.965981","#text":"\n6.1 Data\n"},{"#tail":"\n","@confidence":"0.99932","#text":"\n6.2 Mention Detection\n"},{"#tail":"\n","@confidence":"0.996862","#text":"\n6.3 Coreference Resolution\n"}],"footnote":{"#tail":"\n","@confidence":"0.941484","#text":"\n4The difference in performance is not statistically sig-\n"},"construct":{"#tail":"\n","@confidence":"0.7570905","#text":"\nsuffix ( A ? + ?\n?kAK. + ? + ?).\n"},"title":{"#tail":"\n","@confidence":"0.4776905","#text":"\nThe Impact of Morphological Stemming on Arabic Mention\nDetection and Coreference Resolution\n"},"@confidence":"0.000000","#tail":"\n","reference":{"#tail":"\n","@confidence":"0.999745826086956","#text":"\nPeter F. Abbou and Ernest N. McCarus, editors. 1983.\nElementary modern standard Arabic. Cambridge Univer-\nsity Press.\nACE. 2004. Automatic content extraction.\nhttp://www.ldc.upenn.edu/Projects/ACE/.\nJoan Aliprand, Julie Allen, Joe Becker, Mark Davis,\nMichael Everson, Asmus Freytag, John Jenkins, Mike\nKsar, Rick McGowan, Eric Muller, Lisa Moore, Michel\nSuignard, and Ken Whistler. 2004. The unicode stan-\ndard. http://www.unicode.org/.\nA. Berger, S. Della Pietra, and V. Della Pietra. 1996. A\nmaximum entropy approach to natural language process-\ning. Computational Linguistics, 22(1):39?71.\nD. M. Bikel, S. Miller, R. Schwartz, and R. Weischedel.\n1997. Nymble: a high-performance learning name-finder.\nIn Proceedings of ANLP-97, pages 194?201.\nA. Borthwick. 1999. A Maximum Entropy Approach to\nNamed Entity Recognition. Ph.D. thesis, New York Uni-\nversity.\nEgyptian Demographic Center. 2000.\nhttp://www.frcu.eun.eg/www/homepage/cdc/cdc.htm.\nAitao Chen and Fredic Gey. 2002. Building an arabic\nstemmer for information retrieval. In Proceedings of the\nEleventh Text REtrieval Conference (TREC 2002), Na-\ntional Institute of Standards and Technology, November.\nS. F. Chen and J. Goodman. 1998. An empirical study\nof smoothing techinques for language modeling. Techni-\ncal Report TR-10-98, Center for Research in Comput-\ning Technology, Harvard University, Cambridge, Mas-\nsachusettes, August.\nR. Florian, H. Hassan, A. Ittycheriah, H. Jing, N. Kamb-\nhatla, X. Luo, N Nicolov, and S Roukos. 2004. A statisti-\ncal model for multilingual entity detection and tracking.\nIn Proceedings of HLT-NAACL 2004, pages 1?8.\nY.-S. Lee, K. Papineni, S. Roukos, O. Emam, and H. Has-\nsan. 2003. Language model based Arabic word segmen-\ntation. In Proceedings of the ACL?03, pages 399?406.\nXiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, Nanda\nKambhatla, and Salim Roukos. 2004. A mention-\nsynchronous coreference resolution algorithm based on\nthe bell tree. In Proc. of ACL?04.\nA. Mikheev, M. Moens, and C. Grover. 1999. Named\nentity recognition without gazetteers. In Proceedings of\nEACL?99.\nS. Miller, M. Crystal, H. Fox, L. Ramshaw, R. Schwarz,\nR. Stone, and R. Weischedel. 1998. Bbn: Description of\nthe SIFT system as used for MUC-7. In MUC-7.\nV. Ng and C. Cardie. 2002. Improving machine learning\napproaches to coreference resolution. In Proceedings of\nthe ACL?02, pages 104?111.\nNIST. 2004. Proceedings of ace evaluation and pi meet-\ning 2004 workshop. Alexandria, VA, September. NIST.\nW. M. Soon, H. T. Ng, and C. Y. Lim. 2001. A ma-\nchine learning approach to coreference resolution of noun\nphrases. Computational Linguistics, 27(4):521?544.\nR. Sproat, C. Shih, W. Gale, and N. Chang. 1996. A\nstochastic finite-state word-segmentation algorithm for\nChinese. Computational Linguistics, 22(3).\nM. Tayli and A. Al-Salamah. 1990. Building bilingual\nmicrocomputer systems. Communications of the ACM,\n33(5):495?505.\nJ. Wightwick and M. Gaafar. 1998. Arabic Verbs and\nEssentials of Grammar. Passport Books.\nJ. Xu, A. Fraser, and R. Weischedel. 2001. Trec2001\ncross-lingual retrieval at bbn. In TREC 2001, Gaithers-\nburg: NIST.\nJ. Xu, A. Fraser, and R. Weischedel. 2002. Empirical\nstudies in strategies for arabic information retrieval. In\nSIGIR 2002, Tampere, Finland.\n"},"bodyText":[{"#tail":"\n","@confidence":"0.999536904761905","#text":"\nArabic presents an interesting challenge to\nnatural language processing, being a highly\ninflected and agglutinative language. In\nparticular, this paper presents an in-depth\ninvestigation of the entity detection and\nrecognition (EDR) task for Arabic. We\nstart by highlighting why segmentation is\na necessary prerequisite for EDR, continue\nby presenting a finite-state statistical seg-\nmenter, and then examine how the result-\ning segments can be better included into\na mention detection system and an entity\nrecognition system; both systems are statis-\ntical, build around the maximum entropy\nprinciple. Experiments on a clearly stated\npartition of the ACE 2004 data show that\nstem-based features can significantly im-\nprove the performance of the EDT system\nby 2 absolute F-measure points. The sys-\ntem presented here had a competitive per-\nformance in the ACE 2004 evaluation.\n"},{"#tail":"\n","@confidence":"0.992019528301887","#text":"\nInformation extraction is a crucial step toward un-\nderstanding and processing language. One goal of\ninformation extraction tasks is to identify important\nconceptual information in a discourse. These tasks\nhave applications in summarization, information re-\ntrieval (one can get al hits for Washington/person\nand not the ones for Washington/state or Washing-\nton/city), data mining, question answering, language\nunderstanding, etc.\nIn this paper we focus on the Entity Detection and\nRecognition task (EDR) for Arabic as described in\nACE 2004 framework (ACE, 2004). The EDR has\nclose ties to the named entity recognition (NER) and\ncoreference resolution tasks, which have been the fo-\ncus of several recent investigations (Bikel et al, 1997;\nMiller et al, 1998; Borthwick, 1999; Mikheev et al,\n1999; Soon et al, 2001; Ng and Cardie, 2002; Florian\net al, 2004), and have been at the center of evalu-\nations such as: MUC-6, MUC-7, and the CoNLL?02\nand CoNLL?03 shared tasks. Usually, in computa-\ntional linguistics literature, a named entity is an in-\nstance of a location, a person, or an organization, and\nthe NER task consists of identifying each of these\noccurrences. Instead, we will adopt the nomencla-\nture of the Automatic Content Extraction program\n(NIST, 2004): we will call the instances of textual\nreferences to objects/abstractions mentions, which\ncan be either named (e.g. John Mayor), nominal\n(the president) or pronominal (she, it). An entity is\nthe aggregate of all the mentions (of any level) which\nrefer to one conceptual entity. For instance, in the\nsentence\nPresident John Smith said he has no com-\nments\nthere are two mentions (named and pronomial) but\nonly one entity, formed by the set {John Smith, he}.\nWe separate the EDR task into two parts: a men-\ntion detection step, which identifies and classifies all\nthe mentions in a text ? and a coreference resolution\nstep, which combinines the detected mentions into\ngroups that refer to the same object. In its entirety,\nthe EDR task is arguably harder than traditional\nnamed entity recognition, because of the additional\ncomplexity involved in extracting non-named men-\ntions (nominal and pronominal) and the requirement\nof grouping mentions into entities. This is particu-\nlarly true for Arabic where nominals and pronouns\nare also attached to the word they modify. In fact,\nmost Arabic words are morphologically derived from\na list of base forms or stems, to which prefixes and\nsuffixes can be attached to form Arabic surface forms\n(blank-delimited words). In addition to the differ-\nent forms of the Arabic word that result from the\n"},{"#tail":"\n","@confidence":"0.991163431818182","#text":"\nderivational and inflectional process, most preposi-\ntions, conjunctions, pronouns, and possessive forms\nare attached to the Arabic surface word. It is these\northographic variations and complex morphological\nstructure that make Arabic language processing chal-\nlenging (Xu et al, 2001; Xu et al, 2002).\nBoth tasks are performed with a statistical frame-\nwork: the mention detection system is similar to\nthe one presented in (Florian et al, 2004) and\nthe coreference resolution system is similar to the\none described in (Luo et al, 2004). Both systems\nare built around from the maximum-entropy tech-\nnique (Berger et al, 1996). We formulate the men-\ntion detection task as a sequence classification prob-\nlem. While this approach is language independent,\nit must be modified to accomodate the particulars of\nthe Arabic language. The Arabic words may be com-\nposed of zero or more prefixes, followed by a stem and\nzero or more suffixes. We begin with a segmentation\nof the written text before starting the classification.\nThis segmentation process consists of separating the\nnormal whitespace delimited words into (hypothe-\nsized) prefixes, stems, and suffixes, which become the\nsubject of analysis (tokens). The resulting granular-\nity of breaking words into prefixes and suffixes allows\ndifferent mention type labels beyond the stem label\n(for instance, in the case of nominal and pronominal\nmentions). Additionally, because the prefixes and\nsuffixes are quite frequent, directly processing unseg-\nmented words results in significant data sparseness.\nWe present in Section 2 the relevant particularities\nof the Arabic language for natural language process-\ning, especially for the EDR task. We then describe\nthe segmentation system we employed for this task in\nSection 3. Section 4 briefly describes our mention de-\ntection system, explaining the different feature types\nwe use. We focus in particular on the stem n-gram,\nprefix n-gram, and suffix n-gram features that are\nspecific to a morphologically rich language such as\nArabic. We describe in Section 5 our coreference\nresolution system where we also describe the advan-\ntage of using stem based features. Section 6 shows\nand discusses the different experimental results and\nSection 7 concludes the paper.\n"},{"#tail":"\n","@confidence":"0.969337851851852","#text":"\nExtraction difficult?\nThe Arabic language, which is the mother tongue of\nmore than 300 million people (Center, 2000), present\nsignificant challenges to many natural language pro-\ncessing applications. Arabic is a highly inflected and\nderived language. In Arabic morphology, most mor-\nphemes are comprised of a basic word form (the root\nor stem), to which many affixes can be attached to\nform Arabic words. The Arabic alphabet consists\nof 28 letters that can be extended to ninety by ad-\nditional shapes, marks, and vowels (Tayli and Al-\nSalamah, 1990). Unlike Latin-based alphabets, the\norientation of writing in Arabic is from right to left.\nIn written Arabic, short vowels are often omitted.\nAlso, because variety in expression is appreciated\nas part of a good writing style, the synonyms are\nwidespread. Arabic nouns encode information about\ngender, number, and grammatical cases. There are\ntwo genders (masculine and feminine), three num-\nbers (singular, dual, and plural), and three gram-\nmatical cases (nominative, genitive, and accusative).\nA noun has a nominative case when it is a subject,\naccusative case when it is the object of a verb, and\ngenitive case when it is the object of a preposition.\nThe form of an Arabic noun is consequently deter-\nmined by its gender, number, and grammatical case.\nThe definitive nouns are formed by attaching the\nArabic article ?\n\n@ to the immediate front of the\nnouns, such as in the word ??Q???\n\n@ (the company).\nAlso, prepositions such as H. (by), and ? (to) can beattached as a prefix as in ??Q???? (to the company).\nA noun may carry a possessive pronoun as a suffix,\nsuch as in ?? D?Q?? (their company). For the EDR task,\nin this previous example, the Arabic blank-delimited\nword ?? D?Q?? should be split into two tokens: ??Q?? and\n??. The first token ??Q?? is a mention that refers to\nan organization, whereas the second token ?? is also\na mention, but one that may refer to a person. Also,\nthe prepositions (i.e., H. and ?) not be considered a\npart of the mention.\nArabic has two kinds of plurals: broken plurals and\nsound plurals (Wightwick and Gaafar, 1998; Chen\nand Gey, 2002). The formation of broken plurals is\ncommon, more complex and often irregular. As an\nexample, the plural form of the noun ?g. P (man) is\n?A g. P (men), which is formed by inserting the infix\n@. The plural form of the noun H. A\nJ? (book) is I. J?\n(books), which is formed by deleting the infix @. The\nplural form and the singular form may also be com-\npletely different (e.g. ?\n"},{"#tail":"\n","@confidence":"0.994459588235294","#text":"\nwomen). The sound plurals are formed by adding\nplural suffixes to singular nouns (e.g., IkAK. meaning\nresearcher): the plural suffix is H@ for feminine nouns\nin grammatical cases (e.g., HA\nJkAK.), ?? for masculine\nnouns in the nominative case (e.g., ??JkAK.), and ?K\nfor masculine nouns in the genitive and accusative\ncases (e.g., ?\nJkAK.). The dual suffix is ?@ for the nom-\ninative case (e.g., ?A\nJkAK.), and ?K\nfor the genitive or\naccusative (e.g., ?\nJkAK.).\nBecause we consider pronouns and nominals as men-\ntions, it is essential to segment Arabic words into\nthese subword tokens. We also believe that the in-\n"},{"#tail":"\n","@confidence":"0.975754371428571","#text":"\nformation denoted by these affixes can help with the\ncoreference resolution task1.\nArabic verbs have perfect and imperfect tenses (Ab-\nbou and McCarus, 1983). Perfect tense denotes com-\npleted actions, while imperfect denotes ongoing ac-\ntions. Arabic verbs in the perfect tense consist of a\nstem followed by a subject marker, denoted as a suf-\nfix. The subject marker indicates the person, gender,\nand number of the subject. As an example, the verb\n?K. A\n? (to meet) has a perfect tense I?K. A\n? for the third\nperson feminine singular, and @?\n?K. A\n? for the third per-\nson masculine plural. We notice also that a verb with\na subject marker and a pronoun suffix can be by itself\na complete sentence, such us in the word ?? D?K. A\n?: it\nhas a third-person feminine singular subject-markerH (she) and a pronoun suffix ?? (them). It is also\na complete sentence meaning ?she met them.? The\nsubject markers are often suffixes, but we may find\na subject marker as a combination of a prefix and a\nsuffix as in ???K. A\n?K (she meets them). In this example,\nthe EDR system should be able to separate ???K. A\n?K,\nto create two mentions ( H and ??). Because the\ntwo mentions belong to different entities, the EDR\nsystem should not chain them together. An Arabic\nword can potentially have a large number of vari-\nants, and some of the variants can be quite complex.\nAs an example, consider the word A ?D\nJkAJ. ?? (and to\nher researchers) which contains two prefixes and one\n"},{"#tail":"\n","@confidence":"0.98820228","#text":"\nLee et al (2003) demonstrates a technique for seg-\nmenting Arabic text and uses it as a morphological\nprocessing step in machine translation. A trigram\nlanguage model was used to score and select among\nhypothesized segmentations determined by a set of\nprefix and suffix expansion rules.\nIn our latest implementation of this algorithm, we\nhave recast this segmentation strategy as the com-\nposition of three distinct finite state machines. The\nfirst machine, illustrated in Figure 1 encodes the pre-\nfix and suffix expansion rules, producing a lattice of\npossible segmentations. The second machine is a dic-\ntionary that accepts characters and produces identi-\nfiers corresponding to dictionary entries. The final\nmachine is a trigram language model, specifically a\nKneser-Ney (Chen and Goodman, 1998) based back-\noff language model. Differing from (Lee et al, 2003),\nwe have also introduced an explicit model for un-\n1As an example, we do not chain mentions with dif-\nferent gender, number, etc.\nknown words based upon a character unigram model,\nalthough this model is dominated by an empirically\nchosen unknown word penalty. Using 0.5M words\nfrom the combined Arabic Treebanks 1V2, 2V2 and\n3V1, the dictionary based segmenter achieves a exact\n"},{"#tail":"\n","@confidence":"0.999299857142857","#text":"\nIn addition to the model based upon a dictionary of\nstems and words, we also experimented with models\nbased upon character n-grams, similar to those used\nfor Chinese segmentation (Sproat et al, 1996). For\nthese models, both arabic characters and spaces, and\nthe inserted prefix and suffix markers appear on the\narcs of the finite state machine. Here, the language\nmodel is conditioned to insert prefix and suffix mark-\ners based upon the frequency of their appearance in\nn-gram character contexts that appear in the train-\ning data. The character based model alone achieves\na 94.5% exact match segmentation accuracy, consid-\nerably less accurate then the dictionary based model.\nHowever, an analysis of the errors indicated that the\ncharacter based model is more effective at segment-\ning words that do not appear in the training data.\nWe seeked to exploit this ability to generalize to im-\nprove the dictionary based model. As in (Lee et al,\n2003), we used unsupervised training data which is\nautomatically segmented to discover previously un-\nseen stems. In our case, the character n-gram model\nis used to segment a portion of the Arabic Giga-\nword corpus. From this, we create a vocabulary of\nstems and affixes by requiring that tokens appear\nmore than twice in the supervised training data or\nmore than ten times in the unsupervised, segmented\ncorpus.\nThe resulting vocabulary, predominately of word\nstems, is 53K words, or about six times the vo-\ncabulary observed in the supervised training data.\nThis represents about only 18% of the total num-\nber of unique tokens observed in the aggregate\ntraining data. With the addition of the automat-\nically acquired vocabulary, the segmentation accu-\nracy achieves 98.1% exact match.\n"},{"#tail":"\n","@confidence":"0.9933105","#text":"\nBecause the Arabic treebank and the gigaword cor-\npora are based upon news data, we apply some\nsmall amount of regular expression based preprocess-\ning. Arabic specific processing include removal of\nthe characters tatweel (), and vowels. Also, the fol-\nlowing characters are treated as an equivalence class\n"},{"#tail":"\n","@confidence":"0.986917166666667","#text":"\n@. We define a token and introduce whites-\npace boundaries between every span of one or more\nalphabetic or numeric characters. Each punctuation\nsymbol is considered a separate token. Character\nclasses, such as punctuation, are defined according\nto the Unicode Standard (Aliprand et al, 2004).\n"},{"#tail":"\n","@confidence":"0.8901735","#text":"\nThe mention detection task we investigate identifies,\nfor each mention, four pieces of information:\n"},{"#tail":"\n","@confidence":"0.999729871794872","#text":"\nWe formulate the mention detection problem as a\nclassification problem, which takes as input seg-\nmented Arabic text. We assign to each token in the\ntext a label indicating whether it starts a specific\nmention, is inside a specific mention, or is outside\nany mentions. We use a maximum entropy Markov\nmodel (MEMM) classifier. The principle of maxi-\nmum entropy states that when one searches among\nprobability distributions that model the observed\ndata (evidence), the preferred one is the one that\nmaximizes the entropy (a measure of the uncertainty\nof the model) (Berger et al, 1996). One big advan-\ntage of this approach is that it can combine arbitrary\nand diverse types of information in making a classi-\nfication decision.\nOur mention detection system predicts the four la-\nbels types associated with a mention through a cas-\ncade approach. It first predicts the boundary and\nthe main entity type for each mention. Then, it uses\nthe information regarding the type and boundary in\ndifferent second-stage classifiers to predict the sub-\ntype, the mention level, and the mention class. Af-\nter the first stage, when the boundary (starting, in-\nside, or outside a mention) has been determined, the\nother classifiers can use this information to analyze\na larger context, capturing the patterns around the\nentire mentions, rather than words. As an example,\nthe token sequence that refers to a mention will be-\ncome a single recognized unit and, consequently, lex-\nical and syntactic features occuring inside or outside\nof the entire mention span can be used in prediction.\nIn the first stage (entity type detection and classifica-\ntion), Arabic blank-delimited words, after segment-\ning, become a series of tokens representing prefixes,\nstems, and suffixes (cf. section 2). We allow any\ncontiguous sequence of tokens can represent a men-\ntion. Thus, prefixes and suffixes can be, and often\nare, labeled with a different mention type than the\nstem of the word that contains them as constituents.\n"},{"#tail":"\n","@confidence":"0.994945636363636","#text":"\nWe use a large set of features to improve the predic-\ntion of mentions. This set can be partitioned into\n4 categories: lexical, syntactic, gazetteer-based, and\nthose obtained by running other named-entity clas-\nsifiers (with different tag sets). We use features such\nas the shallow parsing information associated with\nthe tokens in a window of 3 tokens, POS, etc.\nThe context of a current token ti is clearly one of\nthe most important features in predicting whether ti\nis a mention or not (Florian et al, 2004). We de-\nnote these features as backward token tri-grams and\nforward token tri-grams for the previous and next\ncontext of ti respectively. For a token ti, the back-\nward token n-gram feature will contains the previous\nn ? 1 tokens in the history (ti?n+1, . . . ti?1) and the\nforward token n-gram feature will contains the next\nn ? 1 tokens (ti+1, . . . ti+n?1).\nBecause we are segmenting arabic words into\nmultiple tokens, there is some concern that tri-\ngram contexts will no longer convey as much\ncontextual information. Consider the following\nsentence extracted from the development set:\n"},{"#tail":"\n","@confidence":"0.855935","#text":"\ntagged as an organization and, as a word-for-word\ntranslation, is expressed as ?to the Office of the\npolitical to the party?. It is clear in this example\nthat the word Q?? (location for) contains crucial\ninformation in distinguishing between a location\nand an organization when tagging the token I. J?\n?\n"},{"#tail":"\n","@confidence":"0.889223","#text":"\nWhen predicting if the token I. J?\n? (office) is the\nbeginning of an organization or not, backward and\nforward token n-gram features contain only ?\n"},{"#tail":"\n","@confidence":"0.962366","#text":"\n@ (the political). This is\nmost likely not enough context, and addressing the\nproblem by increasing the size of the n-gram context\nquickly leads to a data sparseness problem.\nWe propose in this paper the stem n-gram features as\nadditional features to the lexical set. If the current\ntoken ti is a stem, the backward stem n-gram feature\ncontains the previous n ? 1 stems and the forward\nstem n-gram feature will contain the following n? 1\nstems. We proceed similarly for prefixes and suffixes:\nif ti is a prefix (or suffix, respectively) we take the\nprevious and following prefixes (or suffixes)2. In the\nsentence shown above, when the system is predict-\ning if the token I. J?\n? (office) is the beginning of an\norganization or not, the backward and forward stem\nn-gram features contain Q?? ?J? (represent location\nof) and H. Qk ?\n"},{"#tail":"\n","@confidence":"0.968226166666667","#text":"\n? (political office). The stem fea-\ntures contain enough information in this example to\nmake a decision that I. J?\n? (office) is the beginning of\nan organization. In our experiments, n is 3, therefore\nwe use stem trigram features.\n"},{"#tail":"\n","@confidence":"0.952810230769231","#text":"\nCoreference resolution (or entity recognition) is de-\nfined as grouping together mentions referring to the\nsame object or entity. For example, in the following\ntext,\n(I) ?John believes Mary to be the best student?\nthree mentions ?John?, ?Mary?, ?student? are un-\nderlined. ?Mary? and ?student? are in the same en-\ntity since both refer to the same person.\nThe coreference system system is similar to the Bell\ntree algorithm as described by (Luo et al, 2004).\nIn our implementation, the link model between a\ncandidate entity e and the current mention m is com-\nputed as\n"},{"#tail":"\n","@confidence":"0.978880888888889","#text":"\n2Thus, the difference to token n-grams is that the to-\nkens of different type are removed from the streams, be-\nfore the features are created.\nwhere mk is one mention in entity e, and the basic\nmodel building block P?L(L = 1|e, mk, m) is an ex-\nponential or maximum entropy model (Berger et al,\n1996).\nFor the start model, we use the following approxima-\ntion:\n"},{"#tail":"\n","@confidence":"0.989452","#text":"\nThe start model (cf. equation 2) says that the prob-\nability of starting a new entity, given the current\nmention m and the previous entities e1, e2, ? ? ? , et, is\nsimply 1 minus the maximum link probability be-\ntween the current mention and one of the previous\nentities.\nThe maximum-entropy model provides us with a\nflexible framework to encode features into the the\nsystem. Our Arabic entity recognition system uses\nmany language-indepedent features such as strict\nand partial string match, and distance features (Luo\net al, 2004). In this paper, however, we focus on the\naddition of Arabic stem-based features.\n"},{"#tail":"\n","@confidence":"0.993823173913043","#text":"\nFeatures using the word context (left and right to-\nkens) have been shown to be very helpful in corefer-\nence resolution (Luo et al, 2004). For Arabic, since\nwords are morphologically derived from a list of roots\n(stems), we expected that a feature based on the\nright and left stems would lead to improvement in\nsystem accuracy.\nLet m1 and m2 be two candidate mentions where\na mention is a string of tokens (prefixes, stems,\nand suffixes) extracted from the segmented text.\nIn order to make a decision in either linking the\ntwo mentions or not we use additional features\nsuch as: do the stems in m1 and m2 match, do\nstems in m1 match all stems in m2, do stems\nin m1 partially match stems in m2. We proceed\nsimilarly for prefixes and suffixes. Since prefixes and\nsuffixes can belong to different mention types, we\nbuild a parse tree on the segmented text and we can\nexplore features dealing with the gender and number\nof the token. In the following example, between\nparentheses we make a word-for-word translations in\norder to better explain our stemming feature. Let us\ntake the two mentions H. Qj?? ?\n"},{"#tail":"\n","@confidence":"0.9978925","#text":"\ndevelopment corpus, these two mentions are chained\nto the same entity. The stemming match feature\nin this case will contain information such us all\nstems of m2 match, which is a strong indicator\nthat these mentions should be chained together.\nFeatures based on the words alone would not help\nthis specific example, because the two strings m1\nand m2 do not match.\n"},{"#tail":"\n","@confidence":"0.929274904761905","#text":"\nThe system is trained on the Arabic ACE 2003 and\npart of the 2004 data. We introduce here a clearly\ndefined and replicable split of the ACE 2004 data,\nso that future investigations can accurately and cor-\nrectly compare against the results presented here.\nThere are 689 Arabic documents in LDC?s 2004 re-\nlease (version 1.4) of ACE data from three sources:\nthe Arabic Treebank, a subset of the broadcast\n(bnews) and newswire (nwire) TDT-4 documents.\nThe 178-document devtest is created by taking\nthe last (in chronological order) 25% of docu-\nments in each of three sources: 38 Arabic tree-\nbank documents dating from ?20000715? (i.e., July\n15, 2000) to ?20000815,? 76 bnews documents from\n?20001205.1100.0489? (i.e., Dec. 05 of 2000 from\n11:00pm to 04:89am) to ?20001230.1100.1216,? and\n64 nwire documents from ?20001206.1000.0050? to\n?20001230.0700.0061.? The time span of the test\nset is intentionally non-overlapping with that of the\ntraining set within each data source, as this models\nhow the system will perform in the real world.\n"},{"#tail":"\n","@confidence":"0.9889653","#text":"\nWe want to investigate the usefulness of stem n-\ngram features in the mention detection system. As\nstated before, the experiments are run in the ACE?04\nframework (NIST, 2004) where the system will iden-\ntify mentions and will label them (cf. Section 4)\nwith a type (person, organization, etc), a sub-type\n(OrgCommercial, OrgGovernmental, etc), a mention\nlevel (named, nominal, etc), and a class (specific,\ngeneric, etc). Detecting the mention boundaries (set\nof consecutive tokens) and their main type is one of\nthe important steps of our mention detection sys-\ntem. The score that the ACE community uses (ACE\nvalue) attributes a higher importance (outlined by\nits weight) to the main type compared to other sub-\ntasks, such as the mention level and the class. Hence,\nto build our mention detection system we spent a lot\nof effort in improving the first step: detecting the\nmention boundary and their main type. In this pa-\nper, we report the results in terms of precision, recall,\nand F-measure3.\n"},{"#tail":"\n","@confidence":"0.987184322580645","#text":"\ntem using lexical features only.\nTo assess the impact of stemming n-gram features\non the system under different conditions, we consider\ntwo cases: one where the system only has access to\nlexical features (the tokens and direct derivatives in-\ncluding standard n-gram features), and one where\nthe system has access to a richer set of information,\nincluding lexical features, POS tags, text chunks,\nparse tree, and gazetteer information. The former\nframework has the advantage of being fast (making\nit more appropriate for deployment in commercial\nsystems). The number of parameters to optimize in\nthe MaxEnt framework we use when only lexical fea-\ntures are explored is around 280K parameters. This\nnumber increases to 443K approximately when all in-\nformation is used except the stemming feature. The\nnumber of parameters introduced by the use of stem-\nming is around 130K parameters. Table 1 reports\nexperimental results using lexical features only; we\nobserve that the stemming n-gram features boost the\nperformance by one point (64.7 vs. 65.8). It is im-\nportant to notice the stemming n-gram features im-\nproved the performance of each category of the main\ntype.\nIn the second case, the systems have access to a large\namount of feature types, including lexical, syntac-\ntic, gazetteer, and those obtained by running other\n3The ACE value is an important factor for us, but its\nrelative complexity, due to different weights associated\nwith the subparts, makes for a hard comparison, while\nthe F-measure is relatively easy to interpret.\n"},{"#tail":"\n","@confidence":"0.993777933333333","#text":"\ntem using lexical, syntactic, gazetteer features as well\nas features obtained by running other named-entity\nclassifiers\nnamed-entity classifiers (with different semantic tag\nsets). Features are also extracted from the shal-\nlow parsing information associated with the tokens\nin window of 3, POS, etc. The All-features system\nincorporates all the features except for the stem n-\ngrams. Table 2 shows the experimental results with\nand without the stem n-grams features. Again, Ta-\nble 2 shows that using stem n-grams features gave\na small boost to the whole main-type classification\nsystem4. This is true for all types. It is interesting to\nnote that the increase in performance in both cases\n(Tables 1 and 2) is obtained from increased recall,\nwith little change in precision. When the prefix and\nsuffix n-gram features are removed from the feature\nset, we notice in both cases (Tables 1 and 2) a in-\nsignificant decrease of the overall performance, which\nis expected: what should a feature of preceeding (or\nfollowing) prepositions or finite articles captures?\nAs stated in Section 4.1, the mention detection sys-\ntem uses a cascade approach. However, we were curi-\nous to see if the gain we obtained at the first level was\nsuccessfully transfered into the overall performance\nof the mention detection system. Table 3 presents\nthe performance in terms of precision, recall, and F-\nmeasure of the whole system. Despite the fact that\nthe improvement was small in terms of F-measure\n(59.4 vs. 59.7), the stemming n-gram features gave\n"},{"#tail":"\n","@confidence":"0.999759642857143","#text":"\nIn this section, we present the coreference results on\nthe devtest defined earlier. First, to see the effect of\nstem matching features, we compare two coreference\nsystems: one with the stem features, the other with-\nout. We test the two systems on both ?true? and\nsystem mentions of the devtest set. ?True? men-\ntions mean that input to the coreference system are\nmentions marked by human, while system mentions\nare output from the mention detection system. We\nreport results with two metrics: ECM-F and ACE-\nValue. ECM-F is an entity-constrained mention F-\nmeasure (cf. (Luo et al, 2004) for how ECM-F is\ncomputed), and ACE-Value is the official ACE eval-\nuation metric. The result is shown in Table 4: the\nbaseline numbers without stem features are listed un-\nder ?Base,? and the results of the coreference system\nwith stem features are listed under ?Base+Stem.?\nOn true mention, the stem matching features im-\nprove ECM-F from 77.7% to 80.0%, and ACE-value\nfrom 86.9% to 88.2%. The similar improvement is\nalso observed on system mentions.The overall ECM-\nF improves from 62.3% to 64.2% and the ACE value\nimproves from 61.9 to 63.1%. Note that the increase\non the ACE value is smaller than ECM-F. This is\nbecause ACE-value is a weighted metric which em-\nphasizes on NAME mentions and heavily discounts\nPRONOUN mentions. Overall the stem features give\nrise to consistent gain to the coreference system.\n"},{"#tail":"\n","@confidence":"0.997936111111111","#text":"\nIn this paper, we present a fully fledged Entity Detec-\ntion and Tracking system for Arabic. At its base, the\nsystem fundamentally depends on a finite state seg-\nmenter and makes good use of the relationships that\noccur between word stems, by introducing features\nwhich take into account the type of each segment.\nIn mention detection, the features are represented as\nstem n-grams, while in coreference resolution they\nare captured through stem-tailored match features.\n"},{"#tail":"\n","@confidence":"0.979520764705882","#text":"\nerence resolution. The row marked with ?Truth?\nrepresents the results with ?true? mentions while the\nrow marked with ?System? represents that mentions\nare detected by the system. Numbers under ?ECM-\nF? are Entity-Constrained-Mention F-measure and\nnumbers under ?ACE-Val? are ACE-values.\nThese types of features result in an improvement in\nboth the mention detection and coreference resolu-\ntion performance, as shown through experiments on\nthe ACE 2004 Arabic data. The experiments are per-\nformed on a clearly specified partition of the data, so\ncomparisons against the presented work can be cor-\nrectly and accurately made in the future. In addi-\ntion, we also report results on the official test data.\nThe presented system has obtained competitive re-\nsults in the ACE 2004 evaluation, being ranked\namongst the top competitors.\n"},{"#tail":"\n","@confidence":"0.988107142857143","#text":"\nThis work was partially supported by the Defense\nAdvanced Research Projects Agency and monitored\nby SPAWAR under contract No. N66001-99-2-8916.\nThe views and findings contained in this material are\nthose of the authors and do not necessarily reflect\nthe position of policy of the U.S. government and no\nofficial endorsement should be inferred.\n"}],"#text":"\n","sectionHeader":[{"#tail":"\n","@confidence":"0.575259666666667","@genericHeader":"abstract","#text":"\nIBM T.J. Watson Research Center\n1101 Kitchawan Rd, Yorktown Heights, NY 10598, USA\nAbstract\n"},{"#tail":"\n","@confidence":"0.998289","@genericHeader":"method","#text":"\n1 Introduction\n"},{"#tail":"\n","@confidence":"0.395199","@genericHeader":"method","#text":"\n2 Why is Arabic Information\n"},{"#tail":"\n","@confidence":"0.976142","@genericHeader":"method","#text":"\n3 Arabic Segmentation\n"},{"#tail":"\n","@confidence":"0.98313","@genericHeader":"method","#text":"\n4 Mention Detection\n"},{"#tail":"\n","@confidence":"0.976309","@genericHeader":"method","#text":"\n5 Coreference Resolution\n"},{"#tail":"\n","@confidence":"0.995451","@genericHeader":"evaluation","#text":"\n6 Experiments\n"},{"#tail":"\n","@confidence":"0.998162","@genericHeader":"conclusions","#text":"\n7 Conclusion\n"},{"#tail":"\n","@confidence":"0.99849","@genericHeader":"acknowledgments","#text":"\n8 Acknowledgements\n"},{"#tail":"\n","@confidence":"0.992148","@genericHeader":"references","#text":"\nReferences\n"}],"tableCaption":[{"#tail":"\n","@confidence":"0.999544","#text":"\nTable 1: Performance of the mention detection sys-\n"},{"#tail":"\n","@confidence":"0.999093","#text":"\nTable 2: Performance of the mention detection sys-\n"},{"#tail":"\n","@confidence":"0.938372","#text":"\nTable 3: Performance of the mention detection sys-\ntem including all ACE?04 subtasks\n"},{"#tail":"\n","@confidence":"0.997548","#text":"\nTable 4: Effect of Arabic stemming features on coref-\n"}],"page":[{"#tail":"\n","@confidence":"0.998524","#text":"\n63\n"},{"#tail":"\n","@confidence":"0.997782","#text":"\n64\n"},{"#tail":"\n","@confidence":"0.991001","#text":"\n65\n"},{"#tail":"\n","@confidence":"0.484942","#text":"\n66\n"},{"#tail":"\n","@confidence":"0.998605","#text":"\n67\n"},{"#tail":"\n","@confidence":"0.994198","#text":"\n68\n"},{"#tail":"\n","@confidence":"0.991027","#text":"\n69\n"},{"#tail":"\n","@confidence":"0.994708","#text":"\n70\n"}],"figureCaption":[{"#tail":"\n","@confidence":"0.980027","#text":"\nFigure 1: Illustration of dictionary based segmenta-\ntion finite state transducer\n"},{"#tail":"\n","@confidence":"0.4585505","#text":"\ntion ?This represents the location for Political\nParty Office?). The ?Political Party Office? is\n"}],"table":[{"#tail":"\n","@confidence":"0.893907111111111","#text":"\n@ + I. J?\n? + ?\n\n@ + ?\nand ?\n+ H. Qk + ?\n\n@ + I. J?\n? respectively. In our\n"},{"#tail":"\n","@confidence":"0.991270090909091","#text":"\nLexical features\nPrecision Recall F-measure\n(%) (%) (%)\nTotal 73.3 58.0 64.7\nFAC 76.0 24.0 36.5\nGPE 79.4 65.6 71.8\nLOC 57.7 29.9 39.4\nORG 63.1 46.6 53.6\nPER 73.2 63.5 68.0\nVEH 83.5 29.7 43.8\nWEA 77.3 25.4 38.2\nLexical features + Stem\nPrecision Recall F-measure\n(%) (%) (%)\nTotal 73.6 59.4 65.8\nFAC 72.7 29.0 41.4\nGPE 79.9 67.2 73.0\nLOC 58.6 31.9 41.4\nORG 62.6 47.2 53.8\nPER 73.8 64.6 68.9\nVEH 81.7 35.9 49.9\nWEA 78.4 29.9 43.2\n"},{"#tail":"\n","@confidence":"0.998738","#text":"\nAllFeatures\nPrecision Recall F-measure\n(%) (%) (%)\nTotal 74.3 64.0 68.8\nFAC 72.3 36.8 48.8\nGPE 80.5 70.8 75.4\nLOC 61.1 35.4 44.8\nORG 61.4 50.3 55.3\nPER 75.3 70.2 72.7\nVEH 83.2 38.1 52.3\nWEA 69.0 36.6 47.8\nAll-Features + Stem\nPrecision Recall F-measure\n(%) (%) (%)\nTotal 74.4 64.6 69.2\nFAC 68.8 38.5 49.4\nGPE 80.8 71.9 76.1\nLOC 60.2 36.8 45.7\nORG 62.2 51.0 56.1\nPER 75.3 70.2 72.7\nVEH 81.4 41.8 55.2\nWEA 70.3 38.8 50.0\n"},{"#tail":"\n","@confidence":"0.898921666666667","#text":"\nnificant\ninteresting improvement in terms of ACE value to\nthe hole EDR system as showed in section 6.3.\nPrecision Recall F-measure\n(%) (%) (%)\nAll-Features 64.2 55.3 59.4\nAll-Features+Stem 64.4 55.7 59.7\nLexical 64.4 50.8 56.8\nLexical+Stem 64.6 52.0 57.6\n"},{"#tail":"\n","@confidence":"0.9704935","#text":"\nBase Base+Stem\nECM-F ACEVal ECM-F ACEVal\nTruth 77.7 86.9 80.0 88.2\nSystem 62.3 61.9 64.2 63.1\n"}],"email":{"#tail":"\n","@confidence":"0.720622","#text":"\n{izitouni, sorenj, xiaoluo, raduf}@watson.ibm.com\n"}}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.815786","#tail":"\n","@no":"0","note":{"#tail":"\n","@confidence":"0.974643","#text":"Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages, pages 63?70, Ann Arbor, June 2005. c?2005 Association for Computational Linguistics"},"address":{"#tail":"\n","@confidence":"0.999641","#text":"1101 Kitchawan Rd, Yorktown Heights, NY 10598, USA"},"#text":"\n","affiliation":{"#tail":"\n","@confidence":"0.999621","#text":"IBM T.J. Watson Research Center"},"author":[{"#tail":"\n","@confidence":"0.979832","#text":"Imed Zitouni"},{"#tail":"\n","@confidence":"0.979832","#text":"Jeff Sorensen"},{"#tail":"\n","@confidence":"0.979832","#text":"Xiaoqiang Luo"},{"#tail":"\n","@confidence":"0.979832","#text":"Radu Florian"}],"abstract":{"#tail":"\n","@confidence":"0.994623636363636","#text":"Arabic presents an interesting challenge to natural language processing, being a highly inflected and agglutinative language. In particular, this paper presents an in-depth investigation of the entity detection and recognition (EDR) task for Arabic. We start by highlighting why segmentation is a necessary prerequisite for EDR, continue by presenting a finite-state statistical segmenter, and then examine how the resulting segments can be better included into a mention detection system and an entity recognition system; both systems are statistical, build around the maximum entropy principle. Experiments on a clearly stated partition of the ACE 2004 data show that stem-based features can significantly improve the performance of the EDT system by 2 absolute F-measure points. The system presented here had a competitive performance in the ACE 2004 evaluation."},"title":{"#tail":"\n","@confidence":"0.9944925","#text":"The Impact of Morphological Stemming on Arabic Mention Detection and Coreference Resolution"},"email":[{"#tail":"\n","@confidence":"0.998123","#text":"izitouni@watson.ibm.com"},{"#tail":"\n","@confidence":"0.998123","#text":"sorenj@watson.ibm.com"},{"#tail":"\n","@confidence":"0.998123","#text":"xiaoluo@watson.ibm.com"},{"#tail":"\n","@confidence":"0.998123","#text":"raduf@watson.ibm.com"}]}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"1983"},"editor":{"#tail":"\n","#text":"N. McCarus, editors."},"rawString":{"#tail":"\n","#text":"Peter F. Abbou and Ernest N. McCarus, editors. 1983. Elementary modern standard Arabic. Cambridge University Press."},"#text":"\n","marker":{"#tail":"\n","#text":"Peter, 1983"},"publisher":{"#tail":"\n","#text":"Cambridge University Press."},"title":{"#tail":"\n","#text":"Abbou and Ernest"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"F Peter"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"note":{"#tail":"\n","#text":"http://www.ldc.upenn.edu/Projects/ACE/."},"rawString":{"#tail":"\n","#text":"ACE. 2004. Automatic content extraction. http://www.ldc.upenn.edu/Projects/ACE/."},"#text":"\n","marker":{"#tail":"\n","#text":"ACE, 2004"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"tural language processing, being a highly inflected and agglutinative language. In particular, this paper presents an in-depth investigation of the entity detection and recognition (EDR) task for Arabic. We start by highlighting why segmentation is a necessary prerequisite for EDR, continue by presenting a finite-state statistical segmenter, and then examine how the resulting segments can be better included into a mention detection system and an entity recognition system; both systems are statistical, build around the maximum entropy principle. Experiments on a clearly stated partition of the ACE 2004 data show that stem-based features can significantly improve the performance of the EDT system by 2 absolute F-measure points. The system presented here had a competitive performance in the ACE 2004 evaluation. 1 Introduction Information extraction is a crucial step toward understanding and processing language. One goal of information extraction tasks is to identify important conceptual information in a discourse. These tasks have applications in summarization, information retrieval (one can get al hits for Washington/person and not the ones for Washington/state or Washington/city), data mini","@endWordPosition":"156","@position":"1111","annotationId":"T1","@startWordPosition":"155","@citStr":"ACE 2004"},{"#tail":"\n","#text":"a separate token. Character classes, such as punctuation, are defined according to the Unicode Standard (Aliprand et al, 2004). 4 Mention Detection The mention detection task we investigate identifies, for each mention, four pieces of information: 1. the mention type: person (PER), organization (ORG), location (LOC), geopolitical entity (GPE), facility (FAC), vehicle (VEH), and weapon (WEA) 2. the mention level (named, nominal, pronominal, or premodifier) 3. the mention class (generic, specific, negatively quantified, etc.) 4. the mention sub-type, which is a sub-category of the mention type (ACE, 2004) (e.g. OrgGovernmental, FacilityPath, etc.). 4.1 System Description We formulate the mention detection problem as a classification problem, which takes as input segmented Arabic text. We assign to each token in the text a label indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions. We use a maximum entropy Markov model (MEMM) classifier. The principle of maximum entropy states that when one searches among probability distributions that model the observed data (evidence), the preferred one is the one that maximizes the entropy (a measure of th","@endWordPosition":"2511","@position":"15346","annotationId":"T2","@startWordPosition":"2510","@citStr":"ACE, 2004"},{"#tail":"\n","#text":" J? ? + ?  @ + ? and ? + H. Qk + ?  @ + I. J? ? respectively. In our 67 development corpus, these two mentions are chained to the same entity. The stemming match feature in this case will contain information such us all stems of m2 match, which is a strong indicator that these mentions should be chained together. Features based on the words alone would not help this specific example, because the two strings m1 and m2 do not match. 6 Experiments 6.1 Data The system is trained on the Arabic ACE 2003 and part of the 2004 data. We introduce here a clearly defined and replicable split of the ACE 2004 data, so that future investigations can accurately and correctly compare against the results presented here. There are 689 Arabic documents in LDC?s 2004 release (version 1.4) of ACE data from three sources: the Arabic Treebank, a subset of the broadcast (bnews) and newswire (nwire) TDT-4 documents. The 178-document devtest is created by taking the last (in chronological order) 25% of documents in each of three sources: 38 Arabic treebank documents dating from ?20000715? (i.e., July 15, 2000) to ?20000815,? 76 bnews documents from ?20001205.1100.0489? (i.e., Dec. 05 of 2000 from 11:00pm to 04","@endWordPosition":"4051","@position":"23953","annotationId":"T3","@startWordPosition":"4050","@citStr":"ACE 2004"},{"#tail":"\n","#text":" features. 69 Base Base+Stem ECM-F ACEVal ECM-F ACEVal Truth 77.7 86.9 80.0 88.2 System 62.3 61.9 64.2 63.1 Table 4: Effect of Arabic stemming features on coreference resolution. The row marked with ?Truth? represents the results with ?true? mentions while the row marked with ?System? represents that mentions are detected by the system. Numbers under ?ECMF? are Entity-Constrained-Mention F-measure and numbers under ?ACE-Val? are ACE-values. These types of features result in an improvement in both the mention detection and coreference resolution performance, as shown through experiments on the ACE 2004 Arabic data. The experiments are performed on a clearly specified partition of the data, so comparisons against the presented work can be correctly and accurately made in the future. In addition, we also report results on the official test data. The presented system has obtained competitive results in the ACE 2004 evaluation, being ranked amongst the top competitors. 8 Acknowledgements This work was partially supported by the Defense Advanced Research Projects Agency and monitored by SPAWAR under contract No. N66001-99-2-8916. The views and findings contained in this material are those of the","@endWordPosition":"5496","@position":"32718","annotationId":"T4","@startWordPosition":"5495","@citStr":"ACE 2004"}]},"title":{"#tail":"\n","#text":"Automatic content extraction."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"ACE"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"note":{"#tail":"\n","#text":"http://www.unicode.org/."},"rawString":{"#tail":"\n","#text":"Joan Aliprand, Julie Allen, Joe Becker, Mark Davis, Michael Everson, Asmus Freytag, John Jenkins, Mike Ksar, Rick McGowan, Eric Muller, Lisa Moore, Michel Suignard, and Ken Whistler. 2004. The unicode standard. http://www.unicode.org/."},"#text":"\n","marker":{"#tail":"\n","#text":"Aliprand, Allen, Becker, Davis, Everson, 2004"},"location":{"#tail":"\n","#text":"Asmus Freytag, John Jenkins, Mike Ksar, Rick McGowan, Eric Muller, Lisa"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" corpora are based upon news data, we apply some small amount of regular expression based preprocessing. Arabic specific processing include removal of the characters tatweel (), and vowels. Also, the following characters are treated as an equivalence class during all lookups and processing: (1) ? ,? , and (2)  @ , @  ,  @ ,  @. We define a token and introduce whitespace boundaries between every span of one or more alphabetic or numeric characters. Each punctuation symbol is considered a separate token. Character classes, such as punctuation, are defined according to the Unicode Standard (Aliprand et al, 2004). 4 Mention Detection The mention detection task we investigate identifies, for each mention, four pieces of information: 1. the mention type: person (PER), organization (ORG), location (LOC), geopolitical entity (GPE), facility (FAC), vehicle (VEH), and weapon (WEA) 2. the mention level (named, nominal, pronominal, or premodifier) 3. the mention class (generic, specific, negatively quantified, etc.) 4. the mention sub-type, which is a sub-category of the mention type (ACE, 2004) (e.g. OrgGovernmental, FacilityPath, etc.). 4.1 System Description We formulate the mention detection problem as a ","@endWordPosition":"2440","@position":"14862","annotationId":"T5","@startWordPosition":"2437","@citStr":"Aliprand et al, 2004"}},"title":{"#tail":"\n","#text":"The unicode standard."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Joan Aliprand"},{"#tail":"\n","#text":"Julie Allen"},{"#tail":"\n","#text":"Joe Becker"},{"#tail":"\n","#text":"Mark Davis"},{"#tail":"\n","#text":"Michael Everson"}]}},{"volume":{"#tail":"\n","#text":"22"},"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"A. Berger, S. Della Pietra, and V. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39?71."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"1"},"marker":{"#tail":"\n","#text":"Berger, Pietra, Pietra, 1996"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"3 derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word. It is these orthographic variations and complex morphological structure that make Arabic language processing challenging (Xu et al, 2001; Xu et al, 2002). Both tasks are performed with a statistical framework: the mention detection system is similar to the one presented in (Florian et al, 2004) and the coreference resolution system is similar to the one described in (Luo et al, 2004). Both systems are built around from the maximum-entropy technique (Berger et al, 1996). We formulate the mention detection task as a sequence classification problem. While this approach is language independent, it must be modified to accomodate the particulars of the Arabic language. The Arabic words may be composed of zero or more prefixes, followed by a stem and zero or more suffixes. We begin with a segmentation of the written text before starting the classification. This segmentation process consists of separating the normal whitespace delimited words into (hypothesized) prefixes, stems, and suffixes, which become the subject of analysis (tokens). The resulting granularity ","@endWordPosition":"710","@position":"4537","annotationId":"T6","@startWordPosition":"707","@citStr":"Berger et al, 1996"},{"#tail":"\n","#text":"ityPath, etc.). 4.1 System Description We formulate the mention detection problem as a classification problem, which takes as input segmented Arabic text. We assign to each token in the text a label indicating whether it starts a specific mention, is inside a specific mention, or is outside any mentions. We use a maximum entropy Markov model (MEMM) classifier. The principle of maximum entropy states that when one searches among probability distributions that model the observed data (evidence), the preferred one is the one that maximizes the entropy (a measure of the uncertainty of the model) (Berger et al, 1996). One big advantage of this approach is that it can combine arbitrary and diverse types of information in making a classification decision. Our mention detection system predicts the four labels types associated with a mention through a cascade approach. It first predicts the boundary and the main entity type for each mention. Then, it uses the information regarding the type and boundary in different second-stage classifiers to predict the subtype, the mention level, and the mention class. After the first stage, when the boundary (starting, inside, or outside a mention) has been determined, the","@endWordPosition":"2615","@position":"15994","annotationId":"T7","@startWordPosition":"2612","@citStr":"Berger et al, 1996"},{"#tail":"\n","#text":"nt? are in the same entity since both refer to the same person. The coreference system system is similar to the Bell tree algorithm as described by (Luo et al, 2004). In our implementation, the link model between a candidate entity e and the current mention m is computed as PL(L = 1|e, m) ? maxmk?e P?L(L = 1|e, mk, m), (1) 2Thus, the difference to token n-grams is that the tokens of different type are removed from the streams, before the features are created. where mk is one mention in entity e, and the basic model building block P?L(L = 1|e, mk, m) is an exponential or maximum entropy model (Berger et al, 1996). For the start model, we use the following approximation: PS(S = 1|e1, e2, ? ? ? , et, m) ? 1 ? max 1?i?t PL(L = 1|ei, m) (2) The start model (cf. equation 2) says that the probability of starting a new entity, given the current mention m and the previous entities e1, e2, ? ? ? , et, is simply 1 minus the maximum link probability between the current mention and one of the previous entities. The maximum-entropy model provides us with a flexible framework to encode features into the the system. Our Arabic entity recognition system uses many language-indepedent features such as strict and partia","@endWordPosition":"3559","@position":"21312","annotationId":"T8","@startWordPosition":"3556","@citStr":"Berger et al, 1996"}]},"title":{"#tail":"\n","#text":"A maximum entropy approach to natural language processing."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A Berger"},{"#tail":"\n","#text":"S Della Pietra"},{"#tail":"\n","#text":"V Della Pietra"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"D. M. Bikel, S. Miller, R. Schwartz, and R. Weischedel. 1997. Nymble: a high-performance learning name-finder. In Proceedings of ANLP-97, pages 194?201."},"#text":"\n","pages":{"#tail":"\n","#text":"194--201"},"marker":{"#tail":"\n","#text":"Bikel, Miller, Schwartz, Weischedel, 1997"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"raction tasks is to identify important conceptual information in a discourse. These tasks have applications in summarization, information retrieval (one can get al hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of several recent investigations (Bikel et al, 1997; Miller et al, 1998; Borthwick, 1999; Mikheev et al, 1999; Soon et al, 2001; Ng and Cardie, 2002; Florian et al, 2004), and have been at the center of evaluations such as: MUC-6, MUC-7, and the CoNLL?02 and CoNLL?03 shared tasks. Usually, in computational linguistics literature, a named entity is an instance of a location, a person, or an organization, and the NER task consists of identifying each of these occurrences. Instead, we will adopt the nomenclature of the Automatic Content Extraction program (NIST, 2004): we will call the instances of textual references to objects/abstractions menti","@endWordPosition":"304","@position":"2069","annotationId":"T9","@startWordPosition":"301","@citStr":"Bikel et al, 1997"}},"title":{"#tail":"\n","#text":"Nymble: a high-performance learning name-finder."},"booktitle":{"#tail":"\n","#text":"In Proceedings of ANLP-97,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"D M Bikel"},{"#tail":"\n","#text":"S Miller"},{"#tail":"\n","#text":"R Schwartz"},{"#tail":"\n","#text":"R Weischedel"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Ph.D. thesis,"},"date":{"#tail":"\n","#text":"1999"},"institution":{"#tail":"\n","#text":"New York University."},"rawString":{"#tail":"\n","#text":"A. Borthwick. 1999. A Maximum Entropy Approach to Named Entity Recognition. Ph.D. thesis, New York University."},"#text":"\n","marker":{"#tail":"\n","#text":"Borthwick, 1999"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"conceptual information in a discourse. These tasks have applications in summarization, information retrieval (one can get al hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of several recent investigations (Bikel et al, 1997; Miller et al, 1998; Borthwick, 1999; Mikheev et al, 1999; Soon et al, 2001; Ng and Cardie, 2002; Florian et al, 2004), and have been at the center of evaluations such as: MUC-6, MUC-7, and the CoNLL?02 and CoNLL?03 shared tasks. Usually, in computational linguistics literature, a named entity is an instance of a location, a person, or an organization, and the NER task consists of identifying each of these occurrences. Instead, we will adopt the nomenclature of the Automatic Content Extraction program (NIST, 2004): we will call the instances of textual references to objects/abstractions mentions, which can be either named (e.g. ","@endWordPosition":"310","@position":"2106","annotationId":"T10","@startWordPosition":"309","@citStr":"Borthwick, 1999"}},"title":{"#tail":"\n","#text":"A Maximum Entropy Approach to Named Entity Recognition."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"A Borthwick"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"note":{"#tail":"\n","#text":"http://www.frcu.eun.eg/www/homepage/cdc/cdc.htm."},"rawString":{"#tail":"\n","#text":"Egyptian Demographic Center. 2000. http://www.frcu.eun.eg/www/homepage/cdc/cdc.htm."},"#text":"\n","marker":{"#tail":"\n","#text":"Center, 2000"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"y describes our mention detection system, explaining the different feature types we use. We focus in particular on the stem n-gram, prefix n-gram, and suffix n-gram features that are specific to a morphologically rich language such as Arabic. We describe in Section 5 our coreference resolution system where we also describe the advantage of using stem based features. Section 6 shows and discusses the different experimental results and Section 7 concludes the paper. 2 Why is Arabic Information Extraction difficult? The Arabic language, which is the mother tongue of more than 300 million people (Center, 2000), present significant challenges to many natural language processing applications. Arabic is a highly inflected and derived language. In Arabic morphology, most morphemes are comprised of a basic word form (the root or stem), to which many affixes can be attached to form Arabic words. The Arabic alphabet consists of 28 letters that can be extended to ninety by additional shapes, marks, and vowels (Tayli and AlSalamah, 1990). Unlike Latin-based alphabets, the orientation of writing in Arabic is from right to left. In written Arabic, short vowels are often omitted. Also, because variety in expre","@endWordPosition":"985","@position":"6299","annotationId":"T11","@startWordPosition":"984","@citStr":"Center, 2000"}},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Egyptian Demographic Center"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Aitao Chen and Fredic Gey. 2002. Building an arabic stemmer for information retrieval. In Proceedings of the Eleventh Text REtrieval Conference (TREC 2002), National Institute of Standards and Technology, November."},"#text":"\n","marker":{"#tail":"\n","#text":"Chen, Gey, 2002"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"s a prefix as in ??Q???? (to the company). A noun may carry a possessive pronoun as a suffix, such as in ?? D?Q?? (their company). For the EDR task, in this previous example, the Arabic blank-delimited word ?? D?Q?? should be split into two tokens: ??Q?? and ??. The first token ??Q?? is a mention that refers to an organization, whereas the second token ?? is also a mention, but one that may refer to a person. Also, the prepositions (i.e., H. and ?) not be considered a part of the mention. Arabic has two kinds of plurals: broken plurals and sound plurals (Wightwick and Gaafar, 1998; Chen and Gey, 2002). The formation of broken plurals is common, more complex and often irregular. As an example, the plural form of the noun ?g. P (man) is ?A g. P (men), which is formed by inserting the infix @. The plural form of the noun H. A J? (book) is I. J? (books), which is formed by deleting the infix @. The plural form and the singular form may also be completely different (e.g. ?  @Q?@  for woman, but ZA ?\t for women). The sound plurals are formed by adding plural suffixes to singular nouns (e.g., IkAK. meaning researcher): the plural suffix is H@ for feminine nouns in grammatical cases (e","@endWordPosition":"1331","@position":"8314","annotationId":"T12","@startWordPosition":"1328","@citStr":"Chen and Gey, 2002"}},"title":{"#tail":"\n","#text":"Building an arabic stemmer for information retrieval."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Eleventh Text REtrieval Conference (TREC 2002), National Institute of Standards and Technology,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Aitao Chen"},{"#tail":"\n","#text":"Fredic Gey"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Technical Report TR-10-98,"},"date":{"#tail":"\n","#text":"1998"},"institution":{"#tail":"\n","#text":"Center for Research in Computing Technology, Harvard University,"},"rawString":{"#tail":"\n","#text":"S. F. Chen and J. Goodman. 1998. An empirical study of smoothing techinques for language modeling. Technical Report TR-10-98, Center for Research in Computing Technology, Harvard University, Cambridge, Massachusettes, August."},"#text":"\n","marker":{"#tail":"\n","#text":"Chen, Goodman, 1998"},"location":{"#tail":"\n","#text":"Cambridge, Massachusettes,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"s used to score and select among hypothesized segmentations determined by a set of prefix and suffix expansion rules. In our latest implementation of this algorithm, we have recast this segmentation strategy as the composition of three distinct finite state machines. The first machine, illustrated in Figure 1 encodes the prefix and suffix expansion rules, producing a lattice of possible segmentations. The second machine is a dictionary that accepts characters and produces identifiers corresponding to dictionary entries. The final machine is a trigram language model, specifically a Kneser-Ney (Chen and Goodman, 1998) based backoff language model. Differing from (Lee et al, 2003), we have also introduced an explicit model for un1As an example, we do not chain mentions with different gender, number, etc. known words based upon a character unigram model, although this model is dominated by an empirically chosen unknown word penalty. Using 0.5M words from the combined Arabic Treebanks 1V2, 2V2 and 3V1, the dictionary based segmenter achieves a exact word match 97.8% correct segmentation. SEP/epsilon a/A# epsilon/# a/epsilon a/epsilon b/epsilon b/B UNK/epsilon c/C b/epsilon c/BC e/+E epsilon/+ d/epsilon d/epsi","@endWordPosition":"1923","@position":"11682","annotationId":"T13","@startWordPosition":"1920","@citStr":"Chen and Goodman, 1998"}},"title":{"#tail":"\n","#text":"An empirical study of smoothing techinques for language modeling."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"S F Chen"},{"#tail":"\n","#text":"J Goodman"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"R. Florian, H. Hassan, A. Ittycheriah, H. Jing, N. Kambhatla, X. Luo, N Nicolov, and S Roukos. 2004. A statistical model for multilingual entity detection and tracking."},"#text":"\n","marker":{"#tail":"\n","#text":"Florian, Hassan, Ittycheriah, Jing, Kambhatla, Luo, Nicolov, Roukos, 2004"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"rization, information retrieval (one can get al hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of several recent investigations (Bikel et al, 1997; Miller et al, 1998; Borthwick, 1999; Mikheev et al, 1999; Soon et al, 2001; Ng and Cardie, 2002; Florian et al, 2004), and have been at the center of evaluations such as: MUC-6, MUC-7, and the CoNLL?02 and CoNLL?03 shared tasks. Usually, in computational linguistics literature, a named entity is an instance of a location, a person, or an organization, and the NER task consists of identifying each of these occurrences. Instead, we will adopt the nomenclature of the Automatic Content Extraction program (NIST, 2004): we will call the instances of textual references to objects/abstractions mentions, which can be either named (e.g. John Mayor), nominal (the president) or pronominal (she, it). An entity is the agg","@endWordPosition":"326","@position":"2188","annotationId":"T14","@startWordPosition":"323","@citStr":"Florian et al, 2004"},{"#tail":"\n","#text":", to which prefixes and suffixes can be attached to form Arabic surface forms (blank-delimited words). In addition to the different forms of the Arabic word that result from the 63 derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word. It is these orthographic variations and complex morphological structure that make Arabic language processing challenging (Xu et al, 2001; Xu et al, 2002). Both tasks are performed with a statistical framework: the mention detection system is similar to the one presented in (Florian et al, 2004) and the coreference resolution system is similar to the one described in (Luo et al, 2004). Both systems are built around from the maximum-entropy technique (Berger et al, 1996). We formulate the mention detection task as a sequence classification problem. While this approach is language independent, it must be modified to accomodate the particulars of the Arabic language. The Arabic words may be composed of zero or more prefixes, followed by a stem and zero or more suffixes. We begin with a segmentation of the written text before starting the classification. This segmentation process consist","@endWordPosition":"680","@position":"4359","annotationId":"T15","@startWordPosition":"677","@citStr":"Florian et al, 2004"},{"#tail":"\n","#text":"h a different mention type than the stem of the word that contains them as constituents. 4.2 Stem n-gram Features We use a large set of features to improve the prediction of mentions. This set can be partitioned into 4 categories: lexical, syntactic, gazetteer-based, and those obtained by running other named-entity classifiers (with different tag sets). We use features such as the shallow parsing information associated with the tokens in a window of 3 tokens, POS, etc. The context of a current token ti is clearly one of the most important features in predicting whether ti is a mention or not (Florian et al, 2004). We denote these features as backward token tri-grams and forward token tri-grams for the previous and next context of ti respectively. For a token ti, the backward token n-gram feature will contains the previous n ? 1 tokens in the history (ti?n+1, . . . ti?1) and the forward token n-gram feature will contains the next n ? 1 tokens (ti+1, . . . ti+n?1). Because we are segmenting arabic words into multiple tokens, there is some concern that trigram contexts will no longer convey as much contextual information. Consider the following sentence extracted from the development set: H. Qj?? ? ??A ","@endWordPosition":"2934","@position":"17911","annotationId":"T16","@startWordPosition":"2931","@citStr":"Florian et al, 2004"}]},"title":{"#tail":"\n","#text":"A statistical model for multilingual entity detection and tracking."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"R Florian"},{"#tail":"\n","#text":"H Hassan"},{"#tail":"\n","#text":"A Ittycheriah"},{"#tail":"\n","#text":"H Jing"},{"#tail":"\n","#text":"N Kambhatla"},{"#tail":"\n","#text":"X Luo"},{"#tail":"\n","#text":"N Nicolov"},{"#tail":"\n","#text":"S Roukos"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"In Proceedings of HLT-NAACL 2004, pages 1?8."},"#text":"\n","pages":{"#tail":"\n","#text":"1--8"},"marker":{"#tail":"\n","#text":"2004"},"booktitle":{"#tail":"\n","#text":"In Proceedings of HLT-NAACL"},"@valid":"true"},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Y.-S. Lee, K. Papineni, S. Roukos, O. Emam, and H. Hassan. 2003. Language model based Arabic word segmentation. In Proceedings of the ACL?03, pages 399?406."},"#text":"\n","pages":{"#tail":"\n","#text":"399--406"},"marker":{"#tail":"\n","#text":"Lee, Papineni, Roukos, Emam, Hassan, 2003"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" may find a subject marker as a combination of a prefix and a suffix as in ???K. A ?K (she meets them). In this example, the EDR system should be able to separate ???K. A ?K, to create two mentions ( H and ??). Because the two mentions belong to different entities, the EDR system should not chain them together. An Arabic word can potentially have a large number of variants, and some of the variants can be quite complex. As an example, consider the word A ?D JkAJ. ?? (and to her researchers) which contains two prefixes and one suffix ( A ? + ? ?kAK. + ? + ?). 3 Arabic Segmentation Lee et al (2003) demonstrates a technique for segmenting Arabic text and uses it as a morphological processing step in machine translation. A trigram language model was used to score and select among hypothesized segmentations determined by a set of prefix and suffix expansion rules. In our latest implementation of this algorithm, we have recast this segmentation strategy as the composition of three distinct finite state machines. The first machine, illustrated in Figure 1 encodes the prefix and suffix expansion rules, producing a lattice of possible segmentations. The second machine is a dictionary that acce","@endWordPosition":"1804","@position":"10908","annotationId":"T17","@startWordPosition":"1801","@citStr":"Lee et al (2003)"},{"#tail":"\n","#text":" finite state machine. Here, the language model is conditioned to insert prefix and suffix markers based upon the frequency of their appearance in n-gram character contexts that appear in the training data. The character based model alone achieves a 94.5% exact match segmentation accuracy, considerably less accurate then the dictionary based model. However, an analysis of the errors indicated that the character based model is more effective at segmenting words that do not appear in the training data. We seeked to exploit this ability to generalize to improve the dictionary based model. As in (Lee et al, 2003), we used unsupervised training data which is automatically segmented to discover previously unseen stems. In our case, the character n-gram model is used to segment a portion of the Arabic Gigaword corpus. From this, we create a vocabulary of stems and affixes by requiring that tokens appear more than twice in the supervised training data or more than ten times in the unsupervised, segmented corpus. The resulting vocabulary, predominately of word stems, is 53K words, or about six times the vocabulary observed in the supervised training data. This represents about only 18% of the total number ","@endWordPosition":"2193","@position":"13380","annotationId":"T18","@startWordPosition":"2190","@citStr":"Lee et al, 2003"}]},"title":{"#tail":"\n","#text":"Language model based Arabic word segmentation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the ACL?03,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Y-S Lee"},{"#tail":"\n","#text":"K Papineni"},{"#tail":"\n","#text":"S Roukos"},{"#tail":"\n","#text":"O Emam"},{"#tail":"\n","#text":"H Hassan"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Xiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, Nanda Kambhatla, and Salim Roukos. 2004. A mentionsynchronous coreference resolution algorithm based on the bell tree. In Proc. of ACL?04."},"#text":"\n","marker":{"#tail":"\n","#text":"Luo, Ittycheriah, Jing, Kambhatla, Roukos, 2004"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"words). In addition to the different forms of the Arabic word that result from the 63 derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word. It is these orthographic variations and complex morphological structure that make Arabic language processing challenging (Xu et al, 2001; Xu et al, 2002). Both tasks are performed with a statistical framework: the mention detection system is similar to the one presented in (Florian et al, 2004) and the coreference resolution system is similar to the one described in (Luo et al, 2004). Both systems are built around from the maximum-entropy technique (Berger et al, 1996). We formulate the mention detection task as a sequence classification problem. While this approach is language independent, it must be modified to accomodate the particulars of the Arabic language. The Arabic words may be composed of zero or more prefixes, followed by a stem and zero or more suffixes. We begin with a segmentation of the written text before starting the classification. This segmentation process consists of separating the normal whitespace delimited words into (hypothesized) prefixes, stems, ","@endWordPosition":"696","@position":"4450","annotationId":"T19","@startWordPosition":"693","@citStr":"Luo et al, 2004"},{"#tail":"\n","#text":"a decision that I. J? ? (office) is the beginning of an organization. In our experiments, n is 3, therefore we use stem trigram features. 5 Coreference Resolution Coreference resolution (or entity recognition) is defined as grouping together mentions referring to the same object or entity. For example, in the following text, (I) ?John believes Mary to be the best student? three mentions ?John?, ?Mary?, ?student? are underlined. ?Mary? and ?student? are in the same entity since both refer to the same person. The coreference system system is similar to the Bell tree algorithm as described by (Luo et al, 2004). In our implementation, the link model between a candidate entity e and the current mention m is computed as PL(L = 1|e, m) ? maxmk?e P?L(L = 1|e, mk, m), (1) 2Thus, the difference to token n-grams is that the tokens of different type are removed from the streams, before the features are created. where mk is one mention in entity e, and the basic model building block P?L(L = 1|e, mk, m) is an exponential or maximum entropy model (Berger et al, 1996). For the start model, we use the following approximation: PS(S = 1|e1, e2, ? ? ? , et, m) ? 1 ? max 1?i?t PL(L = 1|ei, m) (2) The start model (cf","@endWordPosition":"3471","@position":"20858","annotationId":"T20","@startWordPosition":"3468","@citStr":"Luo et al, 2004"},{"#tail":"\n","#text":" is simply 1 minus the maximum link probability between the current mention and one of the previous entities. The maximum-entropy model provides us with a flexible framework to encode features into the the system. Our Arabic entity recognition system uses many language-indepedent features such as strict and partial string match, and distance features (Luo et al, 2004). In this paper, however, we focus on the addition of Arabic stem-based features. 5.1 Arabic Stem Match Feature Features using the word context (left and right tokens) have been shown to be very helpful in coreference resolution (Luo et al, 2004). For Arabic, since words are morphologically derived from a list of roots (stems), we expected that a feature based on the right and left stems would lead to improvement in system accuracy. Let m1 and m2 be two candidate mentions where a mention is a string of tokens (prefixes, stems, and suffixes) extracted from the segmented text. In order to make a decision in either linking the two mentions or not we use additional features such as: do the stems in m1 and m2 match, do stems in m1 match all stems in m2, do stems in m1 partially match stems in m2. We proceed similarly for prefixes and suffi","@endWordPosition":"3722","@position":"22213","annotationId":"T21","@startWordPosition":"3719","@citStr":"Luo et al, 2004"},{"#tail":"\n","#text":"subtasks 6.3 Coreference Resolution In this section, we present the coreference results on the devtest defined earlier. First, to see the effect of stem matching features, we compare two coreference systems: one with the stem features, the other without. We test the two systems on both ?true? and system mentions of the devtest set. ?True? mentions mean that input to the coreference system are mentions marked by human, while system mentions are output from the mention detection system. We report results with two metrics: ECM-F and ACEValue. ECM-F is an entity-constrained mention Fmeasure (cf. (Luo et al, 2004) for how ECM-F is computed), and ACE-Value is the official ACE evaluation metric. The result is shown in Table 4: the baseline numbers without stem features are listed under ?Base,? and the results of the coreference system with stem features are listed under ?Base+Stem.? On true mention, the stem matching features improve ECM-F from 77.7% to 80.0%, and ACE-value from 86.9% to 88.2%. The similar improvement is also observed on system mentions.The overall ECMF improves from 62.3% to 64.2% and the ACE value improves from 61.9 to 63.1%. Note that the increase on the ACE value is smaller than ECM-","@endWordPosition":"5192","@position":"30836","annotationId":"T22","@startWordPosition":"5189","@citStr":"Luo et al, 2004"}]},"title":{"#tail":"\n","#text":"A mentionsynchronous coreference resolution algorithm based on the bell tree."},"booktitle":{"#tail":"\n","#text":"In Proc. of ACL?04."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Xiaoqiang Luo"},{"#tail":"\n","#text":"Abe Ittycheriah"},{"#tail":"\n","#text":"Hongyan Jing"},{"#tail":"\n","#text":"Nanda Kambhatla"},{"#tail":"\n","#text":"Salim Roukos"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"A. Mikheev, M. Moens, and C. Grover. 1999. Named entity recognition without gazetteers. In Proceedings of EACL?99."},"#text":"\n","marker":{"#tail":"\n","#text":"Mikheev, Moens, Grover, 1999"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ation in a discourse. These tasks have applications in summarization, information retrieval (one can get al hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of several recent investigations (Bikel et al, 1997; Miller et al, 1998; Borthwick, 1999; Mikheev et al, 1999; Soon et al, 2001; Ng and Cardie, 2002; Florian et al, 2004), and have been at the center of evaluations such as: MUC-6, MUC-7, and the CoNLL?02 and CoNLL?03 shared tasks. Usually, in computational linguistics literature, a named entity is an instance of a location, a person, or an organization, and the NER task consists of identifying each of these occurrences. Instead, we will adopt the nomenclature of the Automatic Content Extraction program (NIST, 2004): we will call the instances of textual references to objects/abstractions mentions, which can be either named (e.g. John Mayor), nominal ","@endWordPosition":"314","@position":"2127","annotationId":"T23","@startWordPosition":"311","@citStr":"Mikheev et al, 1999"}},"title":{"#tail":"\n","#text":"Named entity recognition without gazetteers."},"booktitle":{"#tail":"\n","#text":"In Proceedings of EACL?99."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A Mikheev"},{"#tail":"\n","#text":"M Moens"},{"#tail":"\n","#text":"C Grover"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"S. Miller, M. Crystal, H. Fox, L. Ramshaw, R. Schwarz, R. Stone, and R. Weischedel. 1998. Bbn: Description of the SIFT system as used for MUC-7. In MUC-7."},"#text":"\n","marker":{"#tail":"\n","#text":"Miller, Crystal, Fox, Ramshaw, Schwarz, Stone, Weischedel, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" identify important conceptual information in a discourse. These tasks have applications in summarization, information retrieval (one can get al hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of several recent investigations (Bikel et al, 1997; Miller et al, 1998; Borthwick, 1999; Mikheev et al, 1999; Soon et al, 2001; Ng and Cardie, 2002; Florian et al, 2004), and have been at the center of evaluations such as: MUC-6, MUC-7, and the CoNLL?02 and CoNLL?03 shared tasks. Usually, in computational linguistics literature, a named entity is an instance of a location, a person, or an organization, and the NER task consists of identifying each of these occurrences. Instead, we will adopt the nomenclature of the Automatic Content Extraction program (NIST, 2004): we will call the instances of textual references to objects/abstractions mentions, which can be ei","@endWordPosition":"308","@position":"2089","annotationId":"T24","@startWordPosition":"305","@citStr":"Miller et al, 1998"}},"title":{"#tail":"\n","#text":"Bbn: Description of the SIFT system as used for MUC-7."},"booktitle":{"#tail":"\n","#text":"In MUC-7."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"S Miller"},{"#tail":"\n","#text":"M Crystal"},{"#tail":"\n","#text":"H Fox"},{"#tail":"\n","#text":"L Ramshaw"},{"#tail":"\n","#text":"R Schwarz"},{"#tail":"\n","#text":"R Stone"},{"#tail":"\n","#text":"R Weischedel"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"V. Ng and C. Cardie. 2002. Improving machine learning approaches to coreference resolution. In Proceedings of the ACL?02, pages 104?111."},"#text":"\n","pages":{"#tail":"\n","#text":"104--111"},"marker":{"#tail":"\n","#text":"Ng, Cardie, 2002"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"applications in summarization, information retrieval (one can get al hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of several recent investigations (Bikel et al, 1997; Miller et al, 1998; Borthwick, 1999; Mikheev et al, 1999; Soon et al, 2001; Ng and Cardie, 2002; Florian et al, 2004), and have been at the center of evaluations such as: MUC-6, MUC-7, and the CoNLL?02 and CoNLL?03 shared tasks. Usually, in computational linguistics literature, a named entity is an instance of a location, a person, or an organization, and the NER task consists of identifying each of these occurrences. Instead, we will adopt the nomenclature of the Automatic Content Extraction program (NIST, 2004): we will call the instances of textual references to objects/abstractions mentions, which can be either named (e.g. John Mayor), nominal (the president) or pronominal (she, it)","@endWordPosition":"322","@position":"2166","annotationId":"T25","@startWordPosition":"319","@citStr":"Ng and Cardie, 2002"}},"title":{"#tail":"\n","#text":"Improving machine learning approaches to coreference resolution."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the ACL?02,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"V Ng"},{"#tail":"\n","#text":"C Cardie"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"NIST. 2004. Proceedings of ace evaluation and pi meeting 2004 workshop. Alexandria, VA, September. NIST."},"#text":"\n","marker":{"#tail":"\n","#text":"NIST, 2004"},"publisher":{"#tail":"\n","#text":"NIST."},"location":{"#tail":"\n","#text":"Alexandria, VA,"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"lution tasks, which have been the focus of several recent investigations (Bikel et al, 1997; Miller et al, 1998; Borthwick, 1999; Mikheev et al, 1999; Soon et al, 2001; Ng and Cardie, 2002; Florian et al, 2004), and have been at the center of evaluations such as: MUC-6, MUC-7, and the CoNLL?02 and CoNLL?03 shared tasks. Usually, in computational linguistics literature, a named entity is an instance of a location, a person, or an organization, and the NER task consists of identifying each of these occurrences. Instead, we will adopt the nomenclature of the Automatic Content Extraction program (NIST, 2004): we will call the instances of textual references to objects/abstractions mentions, which can be either named (e.g. John Mayor), nominal (the president) or pronominal (she, it). An entity is the aggregate of all the mentions (of any level) which refer to one conceptual entity. For instance, in the sentence President John Smith said he has no comments there are two mentions (named and pronomial) but only one entity, formed by the set {John Smith, he}. We separate the EDR task into two parts: a mention detection step, which identifies and classifies all the mentions in a text ? and a coreferenc","@endWordPosition":"393","@position":"2589","annotationId":"T26","@startWordPosition":"392","@citStr":"NIST, 2004"},{"#tail":"\n","#text":"000715? (i.e., July 15, 2000) to ?20000815,? 76 bnews documents from ?20001205.1100.0489? (i.e., Dec. 05 of 2000 from 11:00pm to 04:89am) to ?20001230.1100.1216,? and 64 nwire documents from ?20001206.1000.0050? to ?20001230.0700.0061.? The time span of the test set is intentionally non-overlapping with that of the training set within each data source, as this models how the system will perform in the real world. 6.2 Mention Detection We want to investigate the usefulness of stem ngram features in the mention detection system. As stated before, the experiments are run in the ACE?04 framework (NIST, 2004) where the system will identify mentions and will label them (cf. Section 4) with a type (person, organization, etc), a sub-type (OrgCommercial, OrgGovernmental, etc), a mention level (named, nominal, etc), and a class (specific, generic, etc). Detecting the mention boundaries (set of consecutive tokens) and their main type is one of the important steps of our mention detection system. The score that the ACE community uses (ACE value) attributes a higher importance (outlined by its weight) to the main type compared to other subtasks, such as the mention level and the class. Hence, to build our","@endWordPosition":"4222","@position":"25033","annotationId":"T27","@startWordPosition":"4221","@citStr":"NIST, 2004"}]},"title":{"#tail":"\n","#text":"Proceedings of ace evaluation and pi meeting"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"NIST"}}},{"volume":{"#tail":"\n","#text":"27"},"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"W. M. Soon, H. T. Ng, and C. Y. Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521?544."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"4"},"marker":{"#tail":"\n","#text":"Soon, Ng, Lim, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" These tasks have applications in summarization, information retrieval (one can get al hits for Washington/person and not the ones for Washington/state or Washington/city), data mining, question answering, language understanding, etc. In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004). The EDR has close ties to the named entity recognition (NER) and coreference resolution tasks, which have been the focus of several recent investigations (Bikel et al, 1997; Miller et al, 1998; Borthwick, 1999; Mikheev et al, 1999; Soon et al, 2001; Ng and Cardie, 2002; Florian et al, 2004), and have been at the center of evaluations such as: MUC-6, MUC-7, and the CoNLL?02 and CoNLL?03 shared tasks. Usually, in computational linguistics literature, a named entity is an instance of a location, a person, or an organization, and the NER task consists of identifying each of these occurrences. Instead, we will adopt the nomenclature of the Automatic Content Extraction program (NIST, 2004): we will call the instances of textual references to objects/abstractions mentions, which can be either named (e.g. John Mayor), nominal (the president) or","@endWordPosition":"318","@position":"2145","annotationId":"T28","@startWordPosition":"315","@citStr":"Soon et al, 2001"}},"title":{"#tail":"\n","#text":"A machine learning approach to coreference resolution of noun phrases."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"W M Soon"},{"#tail":"\n","#text":"H T Ng"},{"#tail":"\n","#text":"C Y Lim"}]}},{"volume":{"#tail":"\n","#text":"22"},"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"R. Sproat, C. Shih, W. Gale, and N. Chang. 1996. A stochastic finite-state word-segmentation algorithm for Chinese. Computational Linguistics, 22(3)."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"3"},"marker":{"#tail":"\n","#text":"Sproat, Shih, Gale, Chang, 1996"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"m the combined Arabic Treebanks 1V2, 2V2 and 3V1, the dictionary based segmenter achieves a exact word match 97.8% correct segmentation. SEP/epsilon a/A# epsilon/# a/epsilon a/epsilon b/epsilon b/B UNK/epsilon c/C b/epsilon c/BC e/+E epsilon/+ d/epsilon d/epsilon epsilon/epsilon b/AB# b/A#B# e/+DE c/epsilon d/BCD e/+D+E Figure 1: Illustration of dictionary based segmentation finite state transducer 3.1 Bootstrapping In addition to the model based upon a dictionary of stems and words, we also experimented with models based upon character n-grams, similar to those used for Chinese segmentation (Sproat et al, 1996). For these models, both arabic characters and spaces, and the inserted prefix and suffix markers appear on the arcs of the finite state machine. Here, the language model is conditioned to insert prefix and suffix markers based upon the frequency of their appearance in n-gram character contexts that appear in the training data. The character based model alone achieves a 94.5% exact match segmentation accuracy, considerably less accurate then the dictionary based model. However, an analysis of the errors indicated that the character based model is more effective at segmenting words that do not ","@endWordPosition":"2069","@position":"12641","annotationId":"T29","@startWordPosition":"2066","@citStr":"Sproat et al, 1996"}},"title":{"#tail":"\n","#text":"A stochastic finite-state word-segmentation algorithm for Chinese."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"R Sproat"},{"#tail":"\n","#text":"C Shih"},{"#tail":"\n","#text":"W Gale"},{"#tail":"\n","#text":"N Chang"}]}},{"volume":{"#tail":"\n","#text":"33"},"#tail":"\n","date":{"#tail":"\n","#text":"1990"},"rawString":{"#tail":"\n","#text":"M. Tayli and A. Al-Salamah. 1990. Building bilingual microcomputer systems. Communications of the ACM, 33(5):495?505."},"journal":{"#tail":"\n","#text":"Communications of the ACM,"},"#text":"\n","issue":{"#tail":"\n","#text":"5"},"marker":{"#tail":"\n","#text":"Tayli, Al-Salamah, 1990"},"title":{"#tail":"\n","#text":"Building bilingual microcomputer systems."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"M Tayli"},{"#tail":"\n","#text":"A Al-Salamah"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"J. Wightwick and M. Gaafar. 1998. Arabic Verbs and Essentials of Grammar. Passport Books."},"#text":"\n","marker":{"#tail":"\n","#text":"Wightwick, Gaafar, 1998"},"publisher":{"#tail":"\n","#text":"Passport Books."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"and ? (to) can beattached as a prefix as in ??Q???? (to the company). A noun may carry a possessive pronoun as a suffix, such as in ?? D?Q?? (their company). For the EDR task, in this previous example, the Arabic blank-delimited word ?? D?Q?? should be split into two tokens: ??Q?? and ??. The first token ??Q?? is a mention that refers to an organization, whereas the second token ?? is also a mention, but one that may refer to a person. Also, the prepositions (i.e., H. and ?) not be considered a part of the mention. Arabic has two kinds of plurals: broken plurals and sound plurals (Wightwick and Gaafar, 1998; Chen and Gey, 2002). The formation of broken plurals is common, more complex and often irregular. As an example, the plural form of the noun ?g. P (man) is ?A g. P (men), which is formed by inserting the infix @. The plural form of the noun H. A J? (book) is I. J? (books), which is formed by deleting the infix @. The plural form and the singular form may also be completely different (e.g. ?  @Q?@  for woman, but ZA ?\t for women). The sound plurals are formed by adding plural suffixes to singular nouns (e.g., IkAK. meaning researcher): the plural suffix is H@ for feminine nouns in","@endWordPosition":"1327","@position":"8293","annotationId":"T30","@startWordPosition":"1324","@citStr":"Wightwick and Gaafar, 1998"}},"title":{"#tail":"\n","#text":"Arabic Verbs and Essentials of Grammar."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"J Wightwick"},{"#tail":"\n","#text":"M Gaafar"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"J. Xu, A. Fraser, and R. Weischedel. 2001. Trec2001 cross-lingual retrieval at bbn. In TREC 2001, Gaithersburg: NIST."},"#text":"\n","marker":{"#tail":"\n","#text":"Xu, Fraser, Weischedel, 2001"},"location":{"#tail":"\n","#text":"Gaithersburg: NIST."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ominals and pronouns are also attached to the word they modify. In fact, most Arabic words are morphologically derived from a list of base forms or stems, to which prefixes and suffixes can be attached to form Arabic surface forms (blank-delimited words). In addition to the different forms of the Arabic word that result from the 63 derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word. It is these orthographic variations and complex morphological structure that make Arabic language processing challenging (Xu et al, 2001; Xu et al, 2002). Both tasks are performed with a statistical framework: the mention detection system is similar to the one presented in (Florian et al, 2004) and the coreference resolution system is similar to the one described in (Luo et al, 2004). Both systems are built around from the maximum-entropy technique (Berger et al, 1996). We formulate the mention detection task as a sequence classification problem. While this approach is language independent, it must be modified to accomodate the particulars of the Arabic language. The Arabic words may be composed of zero or more prefixes, follo","@endWordPosition":"652","@position":"4200","annotationId":"T31","@startWordPosition":"649","@citStr":"Xu et al, 2001"}},"title":{"#tail":"\n","#text":"Trec2001 cross-lingual retrieval at bbn."},"booktitle":{"#tail":"\n","#text":"In TREC 2001,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"J Xu"},{"#tail":"\n","#text":"A Fraser"},{"#tail":"\n","#text":"R Weischedel"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"J. Xu, A. Fraser, and R. Weischedel. 2002. Empirical studies in strategies for arabic information retrieval. In SIGIR 2002, Tampere, Finland."},"#text":"\n","marker":{"#tail":"\n","#text":"Xu, Fraser, Weischedel, 2002"},"location":{"#tail":"\n","#text":"Tampere, Finland."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ouns are also attached to the word they modify. In fact, most Arabic words are morphologically derived from a list of base forms or stems, to which prefixes and suffixes can be attached to form Arabic surface forms (blank-delimited words). In addition to the different forms of the Arabic word that result from the 63 derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word. It is these orthographic variations and complex morphological structure that make Arabic language processing challenging (Xu et al, 2001; Xu et al, 2002). Both tasks are performed with a statistical framework: the mention detection system is similar to the one presented in (Florian et al, 2004) and the coreference resolution system is similar to the one described in (Luo et al, 2004). Both systems are built around from the maximum-entropy technique (Berger et al, 1996). We formulate the mention detection task as a sequence classification problem. While this approach is language independent, it must be modified to accomodate the particulars of the Arabic language. The Arabic words may be composed of zero or more prefixes, followed by a stem and","@endWordPosition":"656","@position":"4217","annotationId":"T32","@startWordPosition":"653","@citStr":"Xu et al, 2002"}},"title":{"#tail":"\n","#text":"Empirical studies in strategies for arabic information retrieval."},"booktitle":{"#tail":"\n","#text":"In SIGIR 2002,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"J Xu"},{"#tail":"\n","#text":"A Fraser"},{"#tail":"\n","#text":"R Weischedel"}]}}]}}]}}
