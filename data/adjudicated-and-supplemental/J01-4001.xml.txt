and formalisms uch as Discourse Representation Theory and Cen- tering Theory inspired new research on the computational treatment of anaphora. The drive toward corpus-based robust NLP solutions further stimulated interest in alterna- tive and/or data-enriched approaches. Last, but not least, application-driven research in areas uch as automatic abstracting and information extraction i dependently high- lighted the importance of anaphora nd coreference r solution, boosting research in this area. Much of the earlier work in anaphora resolution heavily exploited omain and lin- guistic knowledge (Sidner 1979; Carter 1987; Rich and LuperFoy 1988; Carbonell and Brown 1988), which was difficult both to represent and to process, and which required considerable human input. However, the pressing need for the development of robust and inexpensive solutions to meet the demands of practical NLP systems encouraged many researchers tomove away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution strategies. A number of proposals in the 1990s deliberately imited the extent o which they relied on domain and/or linguistic knowledge and reported promising
s uch as Discourse Representation Theory and Cen- tering Theory inspired new research on the computational treatment of anaphora. The drive toward corpus-based robust NLP solutions further stimulated interest in alterna- tive and/or data-enriched approaches. Last, but not least, application-driven research in areas uch as automatic abstracting and information extraction i dependently high- lighted the importance of anaphora nd coreference r solution, boosting research in this area. Much of the earlier work in anaphora resolution heavily exploited omain and lin- guistic knowledge (Sidner 1979; Carter 1987; Rich and LuperFoy 1988; Carbonell and Brown 1988), which was difficult both to represent and to process, and which required considerable human input. However, the pressing need for the development of robust and inexpensive solutions to meet the demands of practical NLP systems encouraged many researchers tomove away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution strategies. A number of proposals in the 1990s deliberately imited the extent o which they relied on domain and/or linguistic knowledge and reported promising results in k
ourse Representation Theory and Cen- tering Theory inspired new research on the computational treatment of anaphora. The drive toward corpus-based robust NLP solutions further stimulated interest in alterna- tive and/or data-enriched approaches. Last, but not least, application-driven research in areas uch as automatic abstracting and information extraction i dependently high- lighted the importance of anaphora nd coreference r solution, boosting research in this area. Much of the earlier work in anaphora resolution heavily exploited omain and lin- guistic knowledge (Sidner 1979; Carter 1987; Rich and LuperFoy 1988; Carbonell and Brown 1988), which was difficult both to represent and to process, and which required considerable human input. However, the pressing need for the development of robust and inexpensive solutions to meet the demands of practical NLP systems encouraged many researchers tomove away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution strategies. A number of proposals in the 1990s deliberately imited the extent o which they relied on domain and/or linguistic knowledge and reported promising results in knowledge-poor per- ation
ory and Cen- tering Theory inspired new research on the computational treatment of anaphora. The drive toward corpus-based robust NLP solutions further stimulated interest in alterna- tive and/or data-enriched approaches. Last, but not least, application-driven research in areas uch as automatic abstracting and information extraction i dependently high- lighted the importance of anaphora nd coreference r solution, boosting research in this area. Much of the earlier work in anaphora resolution heavily exploited omain and lin- guistic knowledge (Sidner 1979; Carter 1987; Rich and LuperFoy 1988; Carbonell and Brown 1988), which was difficult both to represent and to process, and which required considerable human input. However, the pressing need for the development of robust and inexpensive solutions to meet the demands of practical NLP systems encouraged many researchers tomove away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution strategies. A number of proposals in the 1990s deliberately imited the extent o which they relied on domain and/or linguistic knowledge and reported promising results in knowledge-poor per- ational environments (Dagan and 
rown 1988), which was difficult both to represent and to process, and which required considerable human input. However, the pressing need for the development of robust and inexpensive solutions to meet the demands of practical NLP systems encouraged many researchers tomove away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution strategies. A number of proposals in the 1990s deliberately imited the extent o which they relied on domain and/or linguistic knowledge and reported promising results in knowledge-poor per- ational environments (Dagan and Itai 1990, 1991; Lappin and Leass 1994; Nasukawa 1994; Kennedy and Boguraev 1996; Williams, Harvey, and Preston 1996; Baldwin 1997; Mitkov 1996, 1998b). The drive toward knowledge-poor and robust approaches was further motivated by the emergence of cheaper and more reliable corpus-based NLP tools such as part- of-speech taggers and shallow parsers, alongside the increasing availability of corpora and other NLP resources (e.g., ontologies). In fact, the availability of corpora, both raw and annotated with coreferential links, provided a strong impetus to anaphora resolu- * School of Humanities, Language
cult both to represent and to process, and which required considerable human input. However, the pressing need for the development of robust and inexpensive solutions to meet the demands of practical NLP systems encouraged many researchers tomove away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution strategies. A number of proposals in the 1990s deliberately imited the extent o which they relied on domain and/or linguistic knowledge and reported promising results in knowledge-poor per- ational environments (Dagan and Itai 1990, 1991; Lappin and Leass 1994; Nasukawa 1994; Kennedy and Boguraev 1996; Williams, Harvey, and Preston 1996; Baldwin 1997; Mitkov 1996, 1998b). The drive toward knowledge-poor and robust approaches was further motivated by the emergence of cheaper and more reliable corpus-based NLP tools such as part- of-speech taggers and shallow parsers, alongside the increasing availability of corpora and other NLP resources (e.g., ontologies). In fact, the availability of corpora, both raw and annotated with coreferential links, provided a strong impetus to anaphora resolu- * School of Humanities, Language and Social Sciences, Staffor
and to process, and which required considerable human input. However, the pressing need for the development of robust and inexpensive solutions to meet the demands of practical NLP systems encouraged many researchers tomove away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution strategies. A number of proposals in the 1990s deliberately imited the extent o which they relied on domain and/or linguistic knowledge and reported promising results in knowledge-poor per- ational environments (Dagan and Itai 1990, 1991; Lappin and Leass 1994; Nasukawa 1994; Kennedy and Boguraev 1996; Williams, Harvey, and Preston 1996; Baldwin 1997; Mitkov 1996, 1998b). The drive toward knowledge-poor and robust approaches was further motivated by the emergence of cheaper and more reliable corpus-based NLP tools such as part- of-speech taggers and shallow parsers, alongside the increasing availability of corpora and other NLP resources (e.g., ontologies). In fact, the availability of corpora, both raw and annotated with coreferential links, provided a strong impetus to anaphora resolu- * School of Humanities, Language and Social Sciences, Stafford Street, Wolve
 and which required considerable human input. However, the pressing need for the development of robust and inexpensive solutions to meet the demands of practical NLP systems encouraged many researchers tomove away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution strategies. A number of proposals in the 1990s deliberately imited the extent o which they relied on domain and/or linguistic knowledge and reported promising results in knowledge-poor per- ational environments (Dagan and Itai 1990, 1991; Lappin and Leass 1994; Nasukawa 1994; Kennedy and Boguraev 1996; Williams, Harvey, and Preston 1996; Baldwin 1997; Mitkov 1996, 1998b). The drive toward knowledge-poor and robust approaches was further motivated by the emergence of cheaper and more reliable corpus-based NLP tools such as part- of-speech taggers and shallow parsers, alongside the increasing availability of corpora and other NLP resources (e.g., ontologies). In fact, the availability of corpora, both raw and annotated with coreferential links, provided a strong impetus to anaphora resolu- * School of Humanities, Language and Social Sciences, Stafford Street, Wolverhampton WV1 1SB, UK. E-mai
sing need for the development of robust and inexpensive solutions to meet the demands of practical NLP systems encouraged many researchers tomove away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution strategies. A number of proposals in the 1990s deliberately imited the extent o which they relied on domain and/or linguistic knowledge and reported promising results in knowledge-poor per- ational environments (Dagan and Itai 1990, 1991; Lappin and Leass 1994; Nasukawa 1994; Kennedy and Boguraev 1996; Williams, Harvey, and Preston 1996; Baldwin 1997; Mitkov 1996, 1998b). The drive toward knowledge-poor and robust approaches was further motivated by the emergence of cheaper and more reliable corpus-based NLP tools such as part- of-speech taggers and shallow parsers, alongside the increasing availability of corpora and other NLP resources (e.g., ontologies). In fact, the availability of corpora, both raw and annotated with coreferential links, provided a strong impetus to anaphora resolu- * School of Humanities, Language and Social Sciences, Stafford Street, Wolverhampton WV1 1SB, UK. E-maih r.mitkov@wlv.ac.uk t 30 Saw Mill River Road, Haw
the development of robust and inexpensive solutions to meet the demands of practical NLP systems encouraged many researchers tomove away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution strategies. A number of proposals in the 1990s deliberately imited the extent o which they relied on domain and/or linguistic knowledge and reported promising results in knowledge-poor per- ational environments (Dagan and Itai 1990, 1991; Lappin and Leass 1994; Nasukawa 1994; Kennedy and Boguraev 1996; Williams, Harvey, and Preston 1996; Baldwin 1997; Mitkov 1996, 1998b). The drive toward knowledge-poor and robust approaches was further motivated by the emergence of cheaper and more reliable corpus-based NLP tools such as part- of-speech taggers and shallow parsers, alongside the increasing availability of corpora and other NLP resources (e.g., ontologies). In fact, the availability of corpora, both raw and annotated with coreferential links, provided a strong impetus to anaphora resolu- * School of Humanities, Language and Social Sciences, Stafford Street, Wolverhampton WV1 1SB, UK. E-maih r.mitkov@wlv.ac.uk t 30 Saw Mill River Road, Hawthorne, NY 10
: bkb@watson.ibm.com ~: Department of Computer Science, King's College, The Strand, London WC2R 2LS, UK. E-mail: lappin@dcs.kcl.ac.uk @ 2001 Association for Computational Linguistics Computational Linguistics Volume 27, Number 4 tion with regard to both training and evaluation. Corpora (especially when annotated) are an invaluable source not only for empirical research but also for automated learning (e.g., machine learning) methods aiming to develop new rules and approaches; they also provide an important resource for evaluation of the implemented approaches. From simple co-occurrence rules (Dagan and Itai 1990) through training decision trees to identify anaphor-antecedent pairs (Aone and Bennett 1995) to genetic algorithms to optimize the resolution factors (Or~san, Evans, and Mitkov 2000), the successful per- formance of more and more modern approaches was made possible by the availability of suitable corpora. While the shift toward knowledge-poor strategies and the use of corpora repre- sented the main trends of anaphora resolution in the 1990s, there are other signifi- cant highlights in recent anaphora resolution research. The inclusion of the corefer- ence task in the Sixth and Seventh Message
WC2R 2LS, UK. E-mail: lappin@dcs.kcl.ac.uk @ 2001 Association for Computational Linguistics Computational Linguistics Volume 27, Number 4 tion with regard to both training and evaluation. Corpora (especially when annotated) are an invaluable source not only for empirical research but also for automated learning (e.g., machine learning) methods aiming to develop new rules and approaches; they also provide an important resource for evaluation of the implemented approaches. From simple co-occurrence rules (Dagan and Itai 1990) through training decision trees to identify anaphor-antecedent pairs (Aone and Bennett 1995) to genetic algorithms to optimize the resolution factors (Or~san, Evans, and Mitkov 2000), the successful per- formance of more and more modern approaches was made possible by the availability of suitable corpora. While the shift toward knowledge-poor strategies and the use of corpora repre- sented the main trends of anaphora resolution in the 1990s, there are other signifi- cant highlights in recent anaphora resolution research. The inclusion of the corefer- ence task in the Sixth and Seventh Message Understanding Conferences (MUC-6 and MUC-7) gave a considerable impetus to the development o
d Mitkov 2000), the successful per- formance of more and more modern approaches was made possible by the availability of suitable corpora. While the shift toward knowledge-poor strategies and the use of corpora repre- sented the main trends of anaphora resolution in the 1990s, there are other signifi- cant highlights in recent anaphora resolution research. The inclusion of the corefer- ence task in the Sixth and Seventh Message Understanding Conferences (MUC-6 and MUC-7) gave a considerable impetus to the development of coreference resolution algorithms and systems, such as those described in Baldwin et al (1995), Gaizauskas and Humphreys (1996), and Kameyama (1997). The last decade of the 20th century saw a number of anaphora resolution projects for languages other than English such as French, German, Japanese, Spanish, Portuguese, and Turkish. Against the background of a growing interest in multilingual NLP, multilingual anaphora/coreference reso- lution has gained considerable momentum in recent years (Aone and McKee 1993; Azzam, Humphreys, and Gaizauskas 1998; Harabagiu and Maiorano 2000; Mitkov and Barbu 2000; Mitkov 1999; Mitkov and Stys 1997; Mitkov, Belguith, and Stys 1998). Other milestones o
ccessful per- formance of more and more modern approaches was made possible by the availability of suitable corpora. While the shift toward knowledge-poor strategies and the use of corpora repre- sented the main trends of anaphora resolution in the 1990s, there are other signifi- cant highlights in recent anaphora resolution research. The inclusion of the corefer- ence task in the Sixth and Seventh Message Understanding Conferences (MUC-6 and MUC-7) gave a considerable impetus to the development of coreference resolution algorithms and systems, such as those described in Baldwin et al (1995), Gaizauskas and Humphreys (1996), and Kameyama (1997). The last decade of the 20th century saw a number of anaphora resolution projects for languages other than English such as French, German, Japanese, Spanish, Portuguese, and Turkish. Against the background of a growing interest in multilingual NLP, multilingual anaphora/coreference reso- lution has gained considerable momentum in recent years (Aone and McKee 1993; Azzam, Humphreys, and Gaizauskas 1998; Harabagiu and Maiorano 2000; Mitkov and Barbu 2000; Mitkov 1999; Mitkov and Stys 1997; Mitkov, Belguith, and Stys 1998). Other milestones of recent research include the dep
re modern approaches was made possible by the availability of suitable corpora. While the shift toward knowledge-poor strategies and the use of corpora repre- sented the main trends of anaphora resolution in the 1990s, there are other signifi- cant highlights in recent anaphora resolution research. The inclusion of the corefer- ence task in the Sixth and Seventh Message Understanding Conferences (MUC-6 and MUC-7) gave a considerable impetus to the development of coreference resolution algorithms and systems, such as those described in Baldwin et al (1995), Gaizauskas and Humphreys (1996), and Kameyama (1997). The last decade of the 20th century saw a number of anaphora resolution projects for languages other than English such as French, German, Japanese, Spanish, Portuguese, and Turkish. Against the background of a growing interest in multilingual NLP, multilingual anaphora/coreference reso- lution has gained considerable momentum in recent years (Aone and McKee 1993; Azzam, Humphreys, and Gaizauskas 1998; Harabagiu and Maiorano 2000; Mitkov and Barbu 2000; Mitkov 1999; Mitkov and Stys 1997; Mitkov, Belguith, and Stys 1998). Other milestones of recent research include the deployment of probabilis
th Message Understanding Conferences (MUC-6 and MUC-7) gave a considerable impetus to the development of coreference resolution algorithms and systems, such as those described in Baldwin et al (1995), Gaizauskas and Humphreys (1996), and Kameyama (1997). The last decade of the 20th century saw a number of anaphora resolution projects for languages other than English such as French, German, Japanese, Spanish, Portuguese, and Turkish. Against the background of a growing interest in multilingual NLP, multilingual anaphora/coreference reso- lution has gained considerable momentum in recent years (Aone and McKee 1993; Azzam, Humphreys, and Gaizauskas 1998; Harabagiu and Maiorano 2000; Mitkov and Barbu 2000; Mitkov 1999; Mitkov and Stys 1997; Mitkov, Belguith, and Stys 1998). Other milestones of recent research include the deployment of probabilistic and ma- chine learning techniques (Aone and Bennett 1995; Kehler 1997; Ge, Hale, and Char- niak 1998; Cardie and Wagstaff 1999; the continuing interest in centering, used either in original or in revised form (Abra~os and Lopes 1994; Strube and Hahn 1996; Hahn and Strube 1997; Tetreault 1999); and proposals related to the evaluation methodology in anaphora res
a considerable impetus to the development of coreference resolution algorithms and systems, such as those described in Baldwin et al (1995), Gaizauskas and Humphreys (1996), and Kameyama (1997). The last decade of the 20th century saw a number of anaphora resolution projects for languages other than English such as French, German, Japanese, Spanish, Portuguese, and Turkish. Against the background of a growing interest in multilingual NLP, multilingual anaphora/coreference reso- lution has gained considerable momentum in recent years (Aone and McKee 1993; Azzam, Humphreys, and Gaizauskas 1998; Harabagiu and Maiorano 2000; Mitkov and Barbu 2000; Mitkov 1999; Mitkov and Stys 1997; Mitkov, Belguith, and Stys 1998). Other milestones of recent research include the deployment of probabilistic and ma- chine learning techniques (Aone and Bennett 1995; Kehler 1997; Ge, Hale, and Char- niak 1998; Cardie and Wagstaff 1999; the continuing interest in centering, used either in original or in revised form (Abra~os and Lopes 1994; Strube and Hahn 1996; Hahn and Strube 1997; Tetreault 1999); and proposals related to the evaluation methodology in anaphora resolution (Mitkov 1998a, 2001b). For a more detailed survey of the sta
 development of coreference resolution algorithms and systems, such as those described in Baldwin et al (1995), Gaizauskas and Humphreys (1996), and Kameyama (1997). The last decade of the 20th century saw a number of anaphora resolution projects for languages other than English such as French, German, Japanese, Spanish, Portuguese, and Turkish. Against the background of a growing interest in multilingual NLP, multilingual anaphora/coreference reso- lution has gained considerable momentum in recent years (Aone and McKee 1993; Azzam, Humphreys, and Gaizauskas 1998; Harabagiu and Maiorano 2000; Mitkov and Barbu 2000; Mitkov 1999; Mitkov and Stys 1997; Mitkov, Belguith, and Stys 1998). Other milestones of recent research include the deployment of probabilistic and ma- chine learning techniques (Aone and Bennett 1995; Kehler 1997; Ge, Hale, and Char- niak 1998; Cardie and Wagstaff 1999; the continuing interest in centering, used either in original or in revised form (Abra~os and Lopes 1994; Strube and Hahn 1996; Hahn and Strube 1997; Tetreault 1999); and proposals related to the evaluation methodology in anaphora resolution (Mitkov 1998a, 2001b). For a more detailed survey of the state of the art in anapho
ence resolution algorithms and systems, such as those described in Baldwin et al (1995), Gaizauskas and Humphreys (1996), and Kameyama (1997). The last decade of the 20th century saw a number of anaphora resolution projects for languages other than English such as French, German, Japanese, Spanish, Portuguese, and Turkish. Against the background of a growing interest in multilingual NLP, multilingual anaphora/coreference reso- lution has gained considerable momentum in recent years (Aone and McKee 1993; Azzam, Humphreys, and Gaizauskas 1998; Harabagiu and Maiorano 2000; Mitkov and Barbu 2000; Mitkov 1999; Mitkov and Stys 1997; Mitkov, Belguith, and Stys 1998). Other milestones of recent research include the deployment of probabilistic and ma- chine learning techniques (Aone and Bennett 1995; Kehler 1997; Ge, Hale, and Char- niak 1998; Cardie and Wagstaff 1999; the continuing interest in centering, used either in original or in revised form (Abra~os and Lopes 1994; Strube and Hahn 1996; Hahn and Strube 1997; Tetreault 1999); and proposals related to the evaluation methodology in anaphora resolution (Mitkov 1998a, 2001b). For a more detailed survey of the state of the art in anaphora resolution
on algorithms and systems, such as those described in Baldwin et al (1995), Gaizauskas and Humphreys (1996), and Kameyama (1997). The last decade of the 20th century saw a number of anaphora resolution projects for languages other than English such as French, German, Japanese, Spanish, Portuguese, and Turkish. Against the background of a growing interest in multilingual NLP, multilingual anaphora/coreference reso- lution has gained considerable momentum in recent years (Aone and McKee 1993; Azzam, Humphreys, and Gaizauskas 1998; Harabagiu and Maiorano 2000; Mitkov and Barbu 2000; Mitkov 1999; Mitkov and Stys 1997; Mitkov, Belguith, and Stys 1998). Other milestones of recent research include the deployment of probabilistic and ma- chine learning techniques (Aone and Bennett 1995; Kehler 1997; Ge, Hale, and Char- niak 1998; Cardie and Wagstaff 1999; the continuing interest in centering, used either in original or in revised form (Abra~os and Lopes 1994; Strube and Hahn 1996; Hahn and Strube 1997; Tetreault 1999); and proposals related to the evaluation methodology in anaphora resolution (Mitkov 1998a, 2001b). For a more detailed survey of the state of the art in anaphora resolution, see Mitkov (forthcom
aw a number of anaphora resolution projects for languages other than English such as French, German, Japanese, Spanish, Portuguese, and Turkish. Against the background of a growing interest in multilingual NLP, multilingual anaphora/coreference reso- lution has gained considerable momentum in recent years (Aone and McKee 1993; Azzam, Humphreys, and Gaizauskas 1998; Harabagiu and Maiorano 2000; Mitkov and Barbu 2000; Mitkov 1999; Mitkov and Stys 1997; Mitkov, Belguith, and Stys 1998). Other milestones of recent research include the deployment of probabilistic and ma- chine learning techniques (Aone and Bennett 1995; Kehler 1997; Ge, Hale, and Char- niak 1998; Cardie and Wagstaff 1999; the continuing interest in centering, used either in original or in revised form (Abra~os and Lopes 1994; Strube and Hahn 1996; Hahn and Strube 1997; Tetreault 1999); and proposals related to the evaluation methodology in anaphora resolution (Mitkov 1998a, 2001b). For a more detailed survey of the state of the art in anaphora resolution, see Mitkov (forthcoming). The papers published in this issue reflect he major trends in anaphora resolution in recent years. Some of them describe approaches that do not exploit full synta
 resolution projects for languages other than English such as French, German, Japanese, Spanish, Portuguese, and Turkish. Against the background of a growing interest in multilingual NLP, multilingual anaphora/coreference reso- lution has gained considerable momentum in recent years (Aone and McKee 1993; Azzam, Humphreys, and Gaizauskas 1998; Harabagiu and Maiorano 2000; Mitkov and Barbu 2000; Mitkov 1999; Mitkov and Stys 1997; Mitkov, Belguith, and Stys 1998). Other milestones of recent research include the deployment of probabilistic and ma- chine learning techniques (Aone and Bennett 1995; Kehler 1997; Ge, Hale, and Char- niak 1998; Cardie and Wagstaff 1999; the continuing interest in centering, used either in original or in revised form (Abra~os and Lopes 1994; Strube and Hahn 1996; Hahn and Strube 1997; Tetreault 1999); and proposals related to the evaluation methodology in anaphora resolution (Mitkov 1998a, 2001b). For a more detailed survey of the state of the art in anaphora resolution, see Mitkov (forthcoming). The papers published in this issue reflect he major trends in anaphora resolution in recent years. Some of them describe approaches that do not exploit full syntactic knowledg
n English such as French, German, Japanese, Spanish, Portuguese, and Turkish. Against the background of a growing interest in multilingual NLP, multilingual anaphora/coreference reso- lution has gained considerable momentum in recent years (Aone and McKee 1993; Azzam, Humphreys, and Gaizauskas 1998; Harabagiu and Maiorano 2000; Mitkov and Barbu 2000; Mitkov 1999; Mitkov and Stys 1997; Mitkov, Belguith, and Stys 1998). Other milestones of recent research include the deployment of probabilistic and ma- chine learning techniques (Aone and Bennett 1995; Kehler 1997; Ge, Hale, and Char- niak 1998; Cardie and Wagstaff 1999; the continuing interest in centering, used either in original or in revised form (Abra~os and Lopes 1994; Strube and Hahn 1996; Hahn and Strube 1997; Tetreault 1999); and proposals related to the evaluation methodology in anaphora resolution (Mitkov 1998a, 2001b). For a more detailed survey of the state of the art in anaphora resolution, see Mitkov (forthcoming). The papers published in this issue reflect he major trends in anaphora resolution in recent years. Some of them describe approaches that do not exploit full syntactic knowledge (as in the case of Palomar et al's and Stuckardt's work
ingual NLP, multilingual anaphora/coreference reso- lution has gained considerable momentum in recent years (Aone and McKee 1993; Azzam, Humphreys, and Gaizauskas 1998; Harabagiu and Maiorano 2000; Mitkov and Barbu 2000; Mitkov 1999; Mitkov and Stys 1997; Mitkov, Belguith, and Stys 1998). Other milestones of recent research include the deployment of probabilistic and ma- chine learning techniques (Aone and Bennett 1995; Kehler 1997; Ge, Hale, and Char- niak 1998; Cardie and Wagstaff 1999; the continuing interest in centering, used either in original or in revised form (Abra~os and Lopes 1994; Strube and Hahn 1996; Hahn and Strube 1997; Tetreault 1999); and proposals related to the evaluation methodology in anaphora resolution (Mitkov 1998a, 2001b). For a more detailed survey of the state of the art in anaphora resolution, see Mitkov (forthcoming). The papers published in this issue reflect he major trends in anaphora resolution in recent years. Some of them describe approaches that do not exploit full syntactic knowledge (as in the case of Palomar et al's and Stuckardt's work) or that employ machine learning techniques (Soon, Ng, and Lira); others present centering-based pro- noun resolution (Tetreaul
al anaphora/coreference reso- lution has gained considerable momentum in recent years (Aone and McKee 1993; Azzam, Humphreys, and Gaizauskas 1998; Harabagiu and Maiorano 2000; Mitkov and Barbu 2000; Mitkov 1999; Mitkov and Stys 1997; Mitkov, Belguith, and Stys 1998). Other milestones of recent research include the deployment of probabilistic and ma- chine learning techniques (Aone and Bennett 1995; Kehler 1997; Ge, Hale, and Char- niak 1998; Cardie and Wagstaff 1999; the continuing interest in centering, used either in original or in revised form (Abra~os and Lopes 1994; Strube and Hahn 1996; Hahn and Strube 1997; Tetreault 1999); and proposals related to the evaluation methodology in anaphora resolution (Mitkov 1998a, 2001b). For a more detailed survey of the state of the art in anaphora resolution, see Mitkov (forthcoming). The papers published in this issue reflect he major trends in anaphora resolution in recent years. Some of them describe approaches that do not exploit full syntactic knowledge (as in the case of Palomar et al's and Stuckardt's work) or that employ machine learning techniques (Soon, Ng, and Lira); others present centering-based pro- noun resolution (Tetreault) or discuss theoreti
e reso- lution has gained considerable momentum in recent years (Aone and McKee 1993; Azzam, Humphreys, and Gaizauskas 1998; Harabagiu and Maiorano 2000; Mitkov and Barbu 2000; Mitkov 1999; Mitkov and Stys 1997; Mitkov, Belguith, and Stys 1998). Other milestones of recent research include the deployment of probabilistic and ma- chine learning techniques (Aone and Bennett 1995; Kehler 1997; Ge, Hale, and Char- niak 1998; Cardie and Wagstaff 1999; the continuing interest in centering, used either in original or in revised form (Abra~os and Lopes 1994; Strube and Hahn 1996; Hahn and Strube 1997; Tetreault 1999); and proposals related to the evaluation methodology in anaphora resolution (Mitkov 1998a, 2001b). For a more detailed survey of the state of the art in anaphora resolution, see Mitkov (forthcoming). The papers published in this issue reflect he major trends in anaphora resolution in recent years. Some of them describe approaches that do not exploit full syntactic knowledge (as in the case of Palomar et al's and Stuckardt's work) or that employ machine learning techniques (Soon, Ng, and Lira); others present centering-based pro- noun resolution (Tetreault) or discuss theoretical centering iss
Humphreys, and Gaizauskas 1998; Harabagiu and Maiorano 2000; Mitkov and Barbu 2000; Mitkov 1999; Mitkov and Stys 1997; Mitkov, Belguith, and Stys 1998). Other milestones of recent research include the deployment of probabilistic and ma- chine learning techniques (Aone and Bennett 1995; Kehler 1997; Ge, Hale, and Char- niak 1998; Cardie and Wagstaff 1999; the continuing interest in centering, used either in original or in revised form (Abra~os and Lopes 1994; Strube and Hahn 1996; Hahn and Strube 1997; Tetreault 1999); and proposals related to the evaluation methodology in anaphora resolution (Mitkov 1998a, 2001b). For a more detailed survey of the state of the art in anaphora resolution, see Mitkov (forthcoming). The papers published in this issue reflect he major trends in anaphora resolution in recent years. Some of them describe approaches that do not exploit full syntactic knowledge (as in the case of Palomar et al's and Stuckardt's work) or that employ machine learning techniques (Soon, Ng, and Lira); others present centering-based pro- noun resolution (Tetreault) or discuss theoretical centering issues (Kibble). Almost all of the papers feature extensive valuation (including comparative
ors beyond simple accuracy of resolution. In particular, both developer-oriented (e.g., related to the selection of optimal resolution factors) and application-oriented (e.g., related to the requirement of the application, as in the case of information extraction, where a proper name antecedent is needed) evaluation metrics should be considered. Tetreault's contribution features comparative valuation involving the author's own centering-based pronoun resolution algorithm called the Left-Right Centering algorithm (LRC) as well as three other pronoun resolution methods: Hobbs's naive algorithm (Hobbs 1978), BFP (Brennan, Friedman, and Pollard 1987), and Strube's S- list approach (Strube 1998). The LRC is an alternative to the original BFP algorithm in that it processes utterances incrementally. It works by first searching for an antecedent in the current sentence; if none can be found, it continues the search on the Cf-list of the previous and the other preceding utterances in a left-to-right fashion. In her squib, Byron maintains that additional kinds of information should be included in an evaluation in order to make the performance of algorithms on pronoun resolution more transparent. In par
 related to the selection of optimal resolution factors) and application-oriented (e.g., related to the requirement of the application, as in the case of information extraction, where a proper name antecedent is needed) evaluation metrics should be considered. Tetreault's contribution features comparative valuation involving the author's own centering-based pronoun resolution algorithm called the Left-Right Centering algorithm (LRC) as well as three other pronoun resolution methods: Hobbs's naive algorithm (Hobbs 1978), BFP (Brennan, Friedman, and Pollard 1987), and Strube's S- list approach (Strube 1998). The LRC is an alternative to the original BFP algorithm in that it processes utterances incrementally. It works by first searching for an antecedent in the current sentence; if none can be found, it continues the search on the Cf-list of the previous and the other preceding utterances in a left-to-right fashion. In her squib, Byron maintains that additional kinds of information should be included in an evaluation in order to make the performance of algorithms on pronoun resolution more transparent. In particular, she suggests that the pronoun coverage be explicitly reported and proposes that
which specify the center movement across sentences. Instead of defining a total preference ordering, Kibble argues that a partial ordering emerges from the interaction among cohesion (maintaining the same center), salience (realizing the center as subject), and cheapness (realizing the anticipated center of a following utterance as subject). The last years have seen considerable advances in the field of anaphora resolution, but a number of outstanding issues either remain unsolved or need more attention and, as a consequence, represent major challenges to the further development of the field (Mitkov 2001a). A fundamental question that needs further investigation is how far the performance of anaphora resolution algorithms can go and what the limitations of knowledge-poor methods are. In particular, more research should be carried out on the factors influencing the performance of these algorithms. One of the impediments to the evaluation or fuller utilization of machine learning techniques is the lack of widely available corpora annotated for anaphoric or coreferential links. More work toward the proposal of consistent and comprehensive evaluation is necessary; so too is work in multilingual c
