{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","listItem":{"#tail":"\n","@confidence":"0.682454866666667","#text":"\n1) The sentence matches a sentence meaning in the\nexpected ialogue exactly, but there is no match of\ntheir environments.\n2) The sentence matches a sentence meaning in the\nexpected ialogue similarly, but there is no match of\ntheir environments.\n3) The sentence matches a sentence meaning in the\nexpected sentence set exactly, which implies that\ntheir environments also match.\n22 Computational Linguistics, Volume 12, Number 1, January-March 1986\nPamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input\n4) The sentence matches a sentence meaning in the\nexpected sentence set similarly, which implies that\ntheir environments also match.\n5) There is no match between the sentence and any\n"},"figure":[{"#tail":"\n","@confidence":"0.950512285714286","#text":"\n'(\nr 2\nSTART\nM(Sl)\nM(S2),M(S#)\nM(SS),M(S5)\nM(S6\\]\n"},{"#tail":"\n","@confidence":"0.9369278","#text":"\n0\nSTART\nM(SI)\nM(S2)\nM(SS)\n"},{"#tail":"\n","@confidence":"0.961346777777778","#text":"\n16 Computational Linguistics, Volume 12, Number 1, January-March 1986\nPamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input\n'6,\\]\n, I I\nt l\nSTART\nM(SI)\nM(S2).H(S4)\nM(SS)\n"},{"#tail":"\n","@confidence":"0.940859647058823","#text":"\n1) WORD<=>WORD\n'entry' <=> 'number'\n2) ADJ NOUN <=> NOUN QUALIFIER\n'positive ntries' < = > 'entries which are positive'\n3) NOUN NUMBER <=> DET ORDINAL NOUN\n'row 2' <=> 'the second row'\n4) CLASSIFIER NOUN < = > NOUN of/in CLASSIFIER\n'the row 1 entries' <=> 'the entries in row 1'\n5) EQUIVALENT SETS\n'row 1' <=> 'entries in row 1'\n6) QUANTIFIERS\n'all (of) (the)entries' <=> 'the entries'\n7) CONJUNCTION OF NOUNS\n'double rows one and two' <=> 'double row one\nand row two'\n18 Computational Linguistics, Volume 12, Number 1, January-March 1986\nPamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input\n8) DEFAULT CONTEXT\n'the rows' <=> 'the rows in matrix 1'\n9) NAMES\n'column 1' <=> 'testA'\n10) PRONOUNS\n'it' < = > 'row 1'\n11) ORDINAL NOUN <=> NOUN X in COLUMN or ROW\nY\nNOUN NUMBER < = > NOUN X in COLUMN or ROW\nY\n'sixth entry' <=> 'entry 2 in column 3'\n'entry 6' < = > 'entry 3 in row 2'\n12) NUMBER <=> ENTRY X\n'9.75' <=> 'entry 3'\n13) WORD <=> {WORDS}\n'double' < = > 'multiply by two'\n14) CONJUNCTION OF VERBS\n"},{"#tail":"\n","@confidence":"0.922580944444444","#text":"\n4267\n4272\n4279\n4556\n4286\n4551\n5214\n4885\n4750\n4756\n4762\n4769\n5036\n5043\nSTART\nADV\nCHEK PART ADJ\nFILLSLOT ADJECTIVE QUOTE\nEXPCOMP ADJ\nRET\nEXPADV\nEXPCHEK ADJECTIVE\nCOPYSLOT ADJECTIVE\nCOPYWORD ADJECTIVE\ngoto 45 56\ngoto 4556\nSKIPWORD LOG7\nI FILLSLOT ADJECTIVE NIL\nCOPYWORD QUOTE NIL\ngoto 4556\nEXTRAWS LOG7\ngoto 4267\ngoto 4551\nLOSTWS LOG7\ngoto 5214\ngoto 4762\n"},{"#tail":"\n","@confidence":"0.814521583333333","#text":"\nComputational Linguistics, Volume 12, Number 1, January-March 1986 25\nPamela K.Fink and Alan W. Biermann The Correction f Ill-Formed Input\n(mul t ip ly ( r1 ) (e l (1 ' ; ) r u l t ip ly ( r2 ) ( -_\n~ ubt ract (rl) ( z~\n~ iv ide (\n(d iv ide( r2 ) (e l ( r2 ) )~ ~ubtzaet ( r l ) ( r2 )\nubt rac t ( r l ) (r\n~ero\n(r2) (eARfi)) ~dd (z l ) ( r2 )\n(r2) (rl))\n4~div ide (rl) (el))\n(.,)\n"},{"#tail":"\n","@confidence":"0.6257575","#text":"\n~STAR~\n(...d ,.1;)\n1,1\n~ d iv ide ( r l ) ( la rgest\ndd (x2) (x l\n~ 'u l t ip ly (negat ive ? ( r2 ) ) (e l )~\n"},{"#tail":"\n","@confidence":"0.716651375","#text":"\nComputational Linguistics, Volume 12, Number 1, January-March 1986 27\nPamela K.Fink and Alan W. Biermann The Correction fIll-Formed Input\nSTART)\n'~ Cr ead( rARG i )\n,L 6\nCread (x'ARG~\nCdouble (e2 (rARG)i~\nsubt rac t (e2 (~ARG)) (negat ive e )~\n"},{"#tail":"\n","@confidence":"0.980491642857143","#text":"\nSENTeNCE-ERROR-RATE\n100% -\nLEGEND:\n9o~ \\] ~ ~ ~\nlii,'&quot;&quot;! 70% t :\nL . . . . '?&quot; i !111iil\\]! ' - ' 4O% 30% -\no, _ ~ . . . . . . . . . . . . . . . ~..-.'.~~ ~\n% Er rors Cor rec ted by\n~: loosen ing\n~: expectat ion\n\\ [ -7 : both\ncor rec ted\n1 2 3 4 5 6 7 8 9 10\nLOOP NUMBER IN DIALOGUE\nWORD-ERROR-RATE\n100% /\n90% /\n80% /\n70% /\n60% /\n50% /\n40% /\n30% /\n20% /\n10% -\n0%\n1 2 3 4 5 a 7 8 9 10\nLOOP NUMBER IN DIALOGUE\n"},{"#tail":"\n","@confidence":"0.998584833333333","#text":"\nSENTENCE-ERROR-RATE\n100% -\n90% -\n80% -\nLEGEND: % Er rors\nr - - l :\nCorrected by\nloosen ing\nexpectat ion\nboth\nnot cor rec ted\n70% -\n60% -\n50% -\n40% -\n30% -\n20% -\n10% -\n0%\n1 2 3 4\nLOOP NU\n. n ?\n5\nMBER IN\n6 7\nDIALOGUE\n8 9 10\nWORD-ERROR- RATE\n100% -\n90% -\n80% -\n70% -\n60% -\n50% -\n40% -\n30% -\n20% -\n10% -\n0%\n1 2 3 4 5 6 7\nLOOP NUMBER IN D IALOGUE\n8 9 10\n"},{"#tail":"\n","@confidence":"0.996328119047619","#text":"\nSEN TEN CE- ERROR- RATE\n100% -\n90% -\n80% -\nLEGEND : % E: rors\n70% -\n60% -\n50% -\n40% -\n30% -\n20% -\n10% -\n0%\nN\n1 2 3 4\nLOOP NUMBER I\n5\n!t\\i;! Ii.I\n6\nN D IALOGUE\nCor rected by\nl o o s e n i n g\nexpectat ion\nboth\nnot cor rec ted\n~&quot; i &quot; &quot; - &quot;\n7 8 9 10\nWORD-ERROR-RATE\n100% -\n90% -\n80% -\n7 0% -\n60% -\n50% -\n40% -\n30% -\n20%\n10%\n0%\n1 2 3 4 5 6 7 8\nLOOP NUMBER IN DIALOGUE\n9 10\n"},{"#tail":"\n","@confidence":"0.9952787","#text":"\nSEN TEN CE- ERROR- RATE\n100% -\n90% -\n80% -\n70% -\n60% -\n50% -\n40% -\n30% -\n20% -\n10% -\n0%\nJ\n1 2\nLEGEND: % Er rors Cor rected by\n~ : l o o s e n i n g\n~ : expectat ion\nEZ\\ ] : both\n~ : not cor rec ted\n3\nLOOP\nUiliiI !llll\nL:Z.\n4 5 6 7\nNUMBER IN D IALOGUE\n8 9 10\nWORD- ERROR- RATE\n100% -\n90% -\n80% -\n70% -\n60% -\n50% -\n40% -\n30% -\n20% -\nO~ _ _ _\n1 2 3 4 5 6 7\nLOOP NUMBER IN D IALOGUE\n8 9 10\n"},{"#tail":"\n","@confidence":"0.991193035714286","#text":"\n# OF WORDS/SECOND\n4 -\nI\n3 -\nI\n2 -\nI\n1 -\nI\n0\nTEST I - T o t a l l y - O r d e r e d S c h ~ / /\n1 2 3\n# OF WORDS/SECOND\n4 -\nI\n3 -\nI\n2 -\nI\n1 -\n0\n4 5 6 7 8 9\nLOOP NUMBER IN DIALOGUE\nTEST I I - Par t ia l l y -Ordered Schema\n10\n1 2 3 4 $ 6 7 8 9\nLOOP NUMBER IN DIALOGUE\n# OF WORDS/SECOND\n4 -\nI\n3 -\nI\n2 -\nI\n1 -\nI\n0\nTEST I I I - Tota l ly -Unoxdered Schema\n10\n1 2 3 4 5 6 7 8 9\nLOOP NUMBER IN DIALOGUE\n10\n# OF WORDS/SECOND\n4 -\nI\n3 -\nI\n2 -\nI\n1 -\nI\n0\nTEST IV - Tota l ly -Ordered Schema v i th Arguments\n1 2 3 4 5 6 7 8 9\nLOOP NUMBER IN DIALOGUE\n10\n"}],"address":[{"#tail":"\n","@confidence":"0.910969","#text":"\n6220 Culebra Road\nSan Antonio, TX 78284\n"},{"#tail":"\n","@confidence":"0.687622","#text":"\nDurham, NC 27706\n"}],"author":[{"#tail":"\n","@confidence":"0.887177","#text":"\nPamela K. Fink\n"},{"#tail":"\n","@confidence":"0.974102","#text":"\nAlan W. Biermann\n"}],"equation":[{"#tail":"\n","@confidence":"0.929075444444444","#text":"\nm m\nI EXPECTAT ION I\nI MODULE I\n#r I\ni\nWORD\nSEQUENCE=> I EXPECTAT ION I\nNETWORK I PARSER I\nL .___ J\n"},{"#tail":"\n","@confidence":"0.688391","#text":"\nE(i) = {k I J > 0 ( i , j , k ) is in B}, the set of successor\n"},{"#tail":"\n","@confidence":"0.931674","#text":"\nM(S1) = P(S1, {}).\n"},{"#tail":"\n","@confidence":"0.9412898","#text":"\nC(current) := C(current) + 1; (state O's count is incremented)\ncurrent := bsize; (the new state is now the current state)\nM(current) := M(S); (the new state's meaning is recorded)\nC(current) := 0; (this state has not yet been visited and exited)\nbsize : = bsize + 1; (the size of graph B is incremented)\n"},{"#tail":"\n","@confidence":"0.9995345","#text":"\nC(current) := C(current) + 1;\nMk := Merge(Mk, M(S));\nPut(current, 1, k) into B;\ncurrent := k;\n"},{"#tail":"\n","@confidence":"0.812330818181818","#text":"\nC(current) := C(current) + 1;\nMk := Merge(Mk, M(S));\nIncrement r in (current, r, k);\ncurrent := k;\nFigure 5 shows the result.\nI\nSTART\nI\nM(SI )\nM(S2).H(S4)\nM(S3),H(S5)\n"},{"#tail":"\n","@confidence":"0.97245259375","#text":"\nbegin\nbsize : = 1;\nM0 := start;\nCO := 0;\nend;\nelse\nload B;\ncurrent := 0;\nrepeat\nbegin\nread input sentence S;\nM(S) := P(S, &quot;Mk I k in E(current)&quot;);\nif Predicts(Mk, M(S)) where k in E(current) then\nbegin\nC(current) := C(current) + 1;\nMk := Merge(Mk, M(S));\nIncrement r in (current, r, k);\ncurrent := k;\nend;\nelse\nif Mergeable(&quot;Mk I k = 1 and/or 2 and/or ...\nbsize-l&quot;, M(S)) then\nbegin\nC(current) := C(current) + 1;\nMk := Merge(&quot;Mk I k = 1 and/or 2\nand/or ... bsize-l&quot;, M(S));\nPut(current, 1, k) into B;\ncurrent := k;\nend;\nelse\ncreate aNEW NODE;\nend;\n"},{"#tail":"\n","@confidence":"0.821340538461538","#text":"\n0 and lO00*log\\[1.O\\] -- 0\nadd lO00*log\\[0.8\\] = -22\n1 row 1000*log\\[1.0\\] = 0\nrows 1000.1og\\[0.8\\] = -22\n2 * 1000*log\\[ 1.0\\] -- 0\n3 to 1000*log\\[ 1.0\\] = 0\ntwo 1000*log\\[1.0\\] = 0\ninto 1000.1og\\[0.8\\] -- -22\n20 Computational Linguistics, Volume 12, Number 1, January-March 1986\nPamela K. F ink and A lan W. Biermann The Correction of Ill-Formed Input\n4 row 1000*log\\[1.0\\] = 0\nrows 1000*log\\[0.8\\] = -22\n5 1000*log!l.0! = 0\n"},{"#tail":"\n","@confidence":"0.9876795","#text":"\nMerge (M1, M2)\nbegin\nfor each slot x in M1 and M2 do\nif x(M1) != x(M2) then\nx(M) := ARG;\nelse\nx(M) := x(M1);\nend;\n"}],"subsectionHeader":[{"#tail":"\n","@confidence":"0.615274","#text":"\nSentence Label\n"},{"#tail":"\n","@confidence":"0.602469","#text":"\n5.2 ROUTINES OF THE EXPECTATION MODULE\n"},{"#tail":"\n","@confidence":"0.768146","#text":"\nII) Partially-Ordered Schema\n"}],"footnote":[{"#tail":"\n","@confidence":"0.904787","#text":"\nNational Science Foundation under Grant number MCS\n7904120 and Grant number MCS 8113491 and by the\nAir Force Office of Scientific Research, Air Force\nSystems Command, USAF, under Grant 81-0221.\n"},{"#tail":"\n","@confidence":"0.687525125","#text":"\n1. Minimum word slot transition value ( -52)\nMinimum sentence transition value ( -12)\n2. Mimmum word slot word value ( -150)\nMinimum sentence word value ( -60)\n3. Minimum word slot expectation value ( -23)\nMimmum sentence xpectation value ( -7 )\n4. Minimum word slot parse value ( -190)\nMinimum sentence parse value ( -65)\n"}],"@confidence":"0.000000","#tail":"\n","reference":{"#tail":"\n","@confidence":"0.987352755813954","#text":"\nBallard, B. 1979 Semantic Processing for a Natural Language\nProgramming System. Ph.D. Dissertation Report CS-1979-8, Duke\nUniversity, Durham, North Carolina.\nBarnett, J.; Berstein, M.; Gillman, R.; and Kameny, I. 1980 The SDC\nSpeech Understanding System. In Lea 1980: 272-293.\nBiermann, A. and Ballard, B. 1980 Toward Natural Language Compu-\ntation. AJCL 6(2): 71-86.\nBiermann, A.; Guiho, G.; and Kodratoff, Y., Eds. 1984 Automatic\nProgram Construction Techniques. Macmillan Publishing Co., New\nYork, New York.\nBiermann, A. and Krishnaswamy, R. 1976 Construction of Programs\nfrom Example Computations. IEEE Transactions on Software Engi-\nneering SE-2(3): 141-153.\nBiermann, A.; Rodman, R.; Rubin, D.; and Heidlage, J. 1985. Natural\nLanguage with Discrete Speech as a Mode for Human-to-Machine\nCommunication. Comm. of ACM 28(6).\nCarbonell, J. and Hayes, P. 1983 Recovery Strategies for Parsing\nExtragrammatical L nguage. AJCL 9(3-4): 123-146.\nDixon, N. and Martin, T., Eds. 1979 Automatic Speech and Speaker\nRecognition. IEEE Press, New York, New York.\nErman, L.; Hayes-Roth, F; Lesser, V.; and Reddy, D. 1980 The Hear-\nsay-II Speech Understanding System: Integrating Knowledge to\nResolve Uncertainty. Computing Surveys, 12(2).\nFink, P. 1983 The Acquisition and Use of Dialogue Expectation in\nSpeech Recognition, Dissertation, Department of Computer\nScience, Duke University.\nFink, P.; Sigmon, A.; and Biermann, A. 1985 Computer Control Via\nLimited Natural Language. IEEE Trans SMC SMC-14(1): 54-68.\nGranger, R. 1983 The NOMAD System: Expectation-Based\nDetection and Correction of Errors during Understanding of\nSyntactically Ill-Formed Text. AJCL 9(3-4): 188-196.\nHaton, J. and Pierrel, J. 1976 Organization and Operation of a\nConnected Speech Understanding System at Lexical, Syntactic and\nSemantic Levels. 1976 IEEE International Conference on Acous-\ntics, Speech and Signal Processing, Philadelphia, Pennsylvania:\n430-433.\nHo, T.-P. 1984 The Dialogue Designing Dialogue System, Disserta-\ntion, Computer Science Department, California Institute of Tech-\nnology.\nJensen, K.; Heidorn, G.; Miller, L.; and Ravin, Y. 1983 Parse Fitting\nand Prose Fixing: Getting a Hold on Ill-Formedness. AJCL 9(3-4):\n147-160.\nKwasny, S. and Sondheimer, N. 1981 Relaxation Techniques for Pars-\ning Grammatically Ill-Formed Input in Natural Language Under-\nstanding Systems. AJCL 7(2): 99-108.\nLea, W., Ed. 1980 Trends in Speech Recognition. Prentice-Hall, New\nJersey.\nLowerre, B. and Reddy, R. 1980 The Harpy Speech Understanding\nSystem. In Lea 1980: 340-360.\nMedress, M. 1980 The Sperry Univac System for Continuous Speech\nRecognition. In Lea 1980.\nMichalski, R. 1980 Pattern Recognition as Rule-Guided Inductive\nInference. IEEE Trans. Pattern Analysis and Machine Intelligence.\nMichalski, R.; Carbonell, J.; and Mitchell, T. 1984 Machine Learning.\nSpringer Verlag, New York.\nMinsky, M. and Papert, S. 1969 Perceptrons. MIT Press, Cambridge,\nMassachusetts.\nReddy, D. 1976 Speech Recognition by Machine: A Review.\nProceedings of the IEEE 64(4): 501-531.\nRiesbeck, C. and Schank, R. 1976 Comprehension by Computer:\nExpectation-Based Analysis of Sentences in Context. Tech. Rep.\n78, Computer Science Department, Yale University, New Haven,\nConnecticut.\nSchank, R. and Abelson, R. 1977 Scripts, Plans, Goals, and Under-\nstanding. Lawrence Erlbaum Associates, Hillsdale, New Jersey.\nShapiro, E. 1982 Algorithmic Program Debugging. MIT Press,\nCambridge, Massachusetts.\nThompson, B. 1980 Linguistic Analysis of Natural Language Commu-\nnication with Computers. Proceedings of the Eighth International\nConference on Computational Linguistics, Tokyo, Japan: 190-201.\nWalker, D., Ed. 1978 Understahding Spoken Language. Elsevier North-\nHolland, New York, New York.\nWeischedel, R. and Black, J. 1980 Responding Intelligently to Unpars-\nable Inputs. AJCL 6(2): 97-109.\nWeisehedel, R. and Sondheimer, N. 1983 Meta-Rules as a Basis for\nProcessing Ill-Formed Input. AJCL 9(3-4): 161-177.\nWinston, P. 1975 Learning Structural Descriptions from Examples. In\nWinston, P., Ed., Psychology of Computer Vision. McGraw-Hill, New\nYork, New York.\nWolf, J. and Woods, W. 1980 The HWIM Speech Understanding\nSystem. In Lea 1980: 316-339.\nWoods, W. 1970 Transition Network Grammars for Natural\nLanguage Analysis. Comm. of the ACM 13(10): 591-606.\nNOTE\n1. UNIX is a trademark of AT&T Bell Laboratories.\n36 Computational Linguistics, Volume 12, Number 1, January-March 1986\n"},"bodyText":[{"#tail":"\n","@confidence":"0.951098142857143","#text":"\nA method for error correction of ill-formed input is described that acquires dialogue patterns in\ntypical usage and uses these patterns to predict new inputs. Error correction is done by strongly biasing\nparsing toward expected meanings unless clear evidence from the input shows the current sentence is\nnot expected. A dialogue acquisition and tracking algorithm is presented along with a description of its\nimplementation i a voice interactive system. A series of tests are described that show the power of\nthe error correction methodology when stereotypic dialogue occurs.\nThis material is based upon work supported by The\n"},{"#tail":"\n","@confidence":"0.985837076923077","#text":"\nIn an environment where stereotypic discourse commonly\noccurs, the repetitiveness and predictability of the inter-\nactions may enable a machine to effectively anticipate\nsome inputs. For a speech understanding system, such\nanticipation can greatly enhance the processor's capabili-\nties for error correction so that proper action will take\nplace despite inaccuracies at the voice recognition phase.\nThis paper is concerned with the automatic onstruction\nof a model of user behaviors in typical interactions and\nthe use of such a model in the correction of misrecogni-\ntion errors.\nIt is assumed that a user approaches the machine in a\ntypical application with a problem to be solved. He or\nshe inputs a series of sentences requesting action or\ninformation that will lead to a solution and then leaves\nwhen the task is complete. In the early examples of such\nan interaction, the machine will have little or no expecta-\ntion and will be dependent on its basic capabilities for\nunderstanding and carrying out commands. However, if\nrepetitive behaviors occur, the processor will effectively\nuse them to anticipate inputs and correct errors. This will\nenable the user to speak less precisely and more quickly\nwhile still achieving reliable performance.\nSuch repetitive behaviors may occur within a single\ndialogue where a user may utter sentences with similar\nmeanings again and again (as in &quot;Is there a plane on\nThursday? What time does it leave? Is there one on\nFriday? When does it leave?&quot;). They may also occur\nwhen a given dialogue resembles earlier ones. The\nexpectation system will thus continuously monitor inputs,\nlooking for repetition. If no repetitious behavior occurs,\nthe natural language processor is allowed to proceed\nwithout intervention in handling a dialogue. However, if\nrepetitiveness i detected, the expectation system will\nsupply the processor with anticipated behaviors which\ncan be used to help remove uncertainties in sentence\nrecognition when they occur.\nIn the following sections, an overview of the history-\nbased expectation system is given. Then a representation\nfor user behaviors is described, followed by an algorithm\nfor creating and tracking such models along with a meth-\nCopyright1986 bythe Association for Computational Linguistics. Permission tocopy without fee all or part of this material isgranted provided that\nthe copies are not made for direct commercial dvantage and the CL reference and this copyright notice are included on the first page. To copy\notherwise, or to republish, requires a fee and/or specific permission.\n0362-613X/86/010013-36503.00\nComputational Linguistics, Volume 12, Number 1, January-March 1986 13\nPamela K. Fink and Alan W. Biermann The Correction of IH-Formed Input\nod for using them in error correction. Finally, an imple-\nmentation of this methodology is described in the domain\nof speech recognition and results from a series of tests\ninvestigating the system's performance in various situ-\nations are presented.\n"},{"#tail":"\n","@confidence":"0.960522976744186","#text":"\nThe general goal of the history-based expectation system\nis to merge a series of dialogues, each of which consists\nof a sequence of sentences, into a more general dialogue\nthat reflects the patterns that exist between and within\nthe separate dialogues. Thus, the expectation system\nmust:\n- save incoming dialogues,\n- f ind patterns between and within these dialogues so\nthat they can be merged into a more general dialogue\nwhich becomes a formula for a more general situation,\nand\n- use this information to help predict what will be said by\na user in a given situation.\nThis ability to predict what might be said by a user can\nhelp error correct what is input to the natural anguage\nsystem through errorful means, such as a voice recogniz-\ner. We will call this ability expectation. Figure 1 shows\nan overview of the structure of the history-based expec-\ntation system. Expectation is acquired at two levels, the\nsentence level and the dialogue level. A special parser,\ncalled the expectation parser, is used to analyze at the\nsentence level. The expected ialogue is a data structure\nused to store the history-based expectation that is\nacquired using an expectation acquisition algorithm. This\nconstitutes the dialogue level.\nAs each sentence is entered into the system, such as\nthrough a speech recognition device, it is parsed and a\nmeaning representation is produced and saved by an\nexpectation acquisition algorithm in the expectation\nmodule (see 1 in Figure 1). The parse is also output for\nuse in the next step in the system's processing of the\nsentence. This process builds a sequence of sentence\nmeanings, which are then incorporated into an expected\ndialogue (see 2 in Figure 1). After an expected ialogue\nis partially or completely built, the expectation module\nattempts to determine where the user is in a given\ndialogue using information from the expected ialogue\nand the current parsed sentence (see 1 and 3 in Figure\n1). If it succeeds, it creates and transmits (see 4 in\nFigure 1) an expected sentence set to the expectation\nparser. The expectation parser will then use this infor-\nmation to improve its ability to recognize the next incom-\ning sentence.\n"},{"#tail":"\n","@confidence":"0.933056","#text":"\nSuppose a user inputs the following sequence:\n"},{"#tail":"\n","@confidence":"0.995638382352941","#text":"\nDisplay my mail summary for today. S 1\nShow me this letter. (with touch input) $2\n(the letter appears on the screen)\nRemove this letter. $3\nDisplay the letter from JA. $4\n(letter appears on the screen)\nDelete it. $5\nLog off. $6\nWe denote the meaning of each sentence Si with the\nnotation M(Si). The exact form of M(Si) need not be\ndiscussed at this point; it could be a conceptual depend-\nence graph (Schank and Abelson 1977), a deep parse of\nSi, or some other representation. A user behavior is\nrepresented by a network, or directed graph, of such\nmeanings. At the beginning of a task, the state of the\ninteraction is represented by the start state of the graph.\nThe immediate successors of this state are the typical\nopening meaning structures for this user, and succeeding\nstates represent, historically, paths that have been\nfollowed by this user.\nIt is important hat if two sentences, Si and Sj, have\napproximately the same meaning this should be clear in\nthe representations M(Si) and M(Sj). Our algorithm,\ndescribed below, merges two meanings M(Si) and M(Sj)\ninto a single node in the behavior epresentation if they\n- are sufficiently similar, and\n- appear in similar contexts.\nThus, in the above example it would appear that M(S3)\nand M(S5) play similar roles and could be represented by\none structure: after a letter is read, one might expect o\nsee it deleted.\nOften, two commands will be similar except for the\ninstantiation of certain constituents. This is the case in\nsentences $2 and $4, which request the display of,\nrespectively, the message indicated by a touch and the\nletter from JA. Again, it is desired to represent such\nsimilar meanings in a behavior graph with a single node if\nthey appear in similar environments. Thus, a routine will\nbe needed to find a generalization of two such sentences\nthat can represent their common meaning. In the exam-\nple, the generalization of $2 and $4 might be &quot;display\n(LETTER)&quot; where &quot;(LETTER)&quot; is a noun group referring\nto a letter.\nIn tracking a dialogue, we may arrive at a node in the\nbehavior graph with meaning M1. This means a\ncommand is expected with meaning M2 that is either\nidentical to, or a special case of, M1. If such an M2 is\ninput at this time, we will say that M1 predicts M2 and\ndefine the predicate:\nPredicts(M1, M2) = true if and only if meaning M1\nis identical or similar to M2.\nIt is quite possible, as with M(S2) and M(S4) above, that\na common generalization can be found for two sentences\nthat appear in similar contexts. Then one will be able to\nmerge them into a single node in the behavior graph.\nThus, it is necessary to have a predicate to check whether\nthese conditions hold and a function to find the desired\ngeneralization. The following two routines do this:\nMergeable(M1, M2) = true if and only if an M can\nbe found such that Predicts(M, M1) and\nPredicts(M, M2).\nMerge(M1, M2) yields a meaning M that is identi-\ncal to, or a generalization of, M1 and M2.\nA user behavior is represented as a network of\nsentence meanings with transitions from one meaning to\nanother that indicate traversals observed in actual\ndialogues and their frequencies. For example, the above\nsix-sentence sequence could be represented as shown in\n"},{"#tail":"\n","@confidence":"0.994415533333333","#text":"\nMore formally, a behavior graph B will consist of a set\nof nodes named 0, 1, 2, 3 . . . . . bsize-1. Each node i will\nhave its associated Mi and Ci and the first node will have\na special meaning M0 = 'start'. The transitions will be\nrepresented as triples (i, j, k) where the traversal is from\nnode i to node k and has been observed j times. The\nexample six-command sequence would be represented by\nComputational Linguistics, Volume 12, Number 1, January-March 1986 15\nPamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input\nthe nodes 0 through 4 with Mi's and Ci's as shown and\nwith the triples\n{(0,1,1) (1,1,2) (2,2,3) (3,1,2) (3,1,4)}.\nNotice that the observed probability of crossing transi-\ntion (i, j, k) is j /Ci, a fact that is used by the expectation\nparser.\n"},{"#tail":"\n","@confidence":"0.995845375","#text":"\nIt is desired to have an algorithm to monitor the\ndiscourse, collect the history of inputs, and invoke expec-\ntation when any kind of repetition occurs. Such an algo-\nrithm is described below. To do so, however, some\nadditional notation is needed:\ncurrent = an integer giving the state number in B corre-\nsponding to the most recently recognized sentence.\nbsize = the total number of states in B.\n"},{"#tail":"\n","@confidence":"0.938540647058823","#text":"\nstates to state i, also called the expected sentence set\nof i.\nP(S, E(current)) = The result of the expectation parser\nwith input S and E(current), where S is the current\ninput sentence which may have errors, and E(current)\nis a set of expected meanings in B, the successors of\nnode current. The result or output of the parse of\nsentence S is its meaning M(S).\nThe behavior graph B begins with one state numbered\n&quot;0&quot; and with M0 = start, C(0) = 0. Thus, the size of\nthe graph is bsize = 1 and the most recently recognized\nsentence is assumed to be this start state, current = 0.\nSuppose that the first sentence in the above sample\ndialogue is read:\nS1 = &quot;Display my mail summary for today.&quot;\nThen the processor will begin with no expectation since\nE(0) is currently the empty set, and find\n"},{"#tail":"\n","@confidence":"0.9534388","#text":"\nThis will result in the creation of a second state in B with\nthe following statements:\nCreate a NEW NODE:\nPut(current, 1, bsize) into B;\n(a transition to the new state is created)\n"},{"#tail":"\n","@confidence":"0.9990314","#text":"\nThus, the first two states shown in Figure 2 will exist\nwith the single transition (0, 1, 1). Sentence $2 and $3\nresult in similar processing, the addition of states 2 and 3,\nand the creation of transitions (1, 1, 2) and (2, 1, 3) as\nshown in Figure 3.\n"},{"#tail":"\n","@confidence":"0.9930702","#text":"\nThe input sentence will yield a different action,\nhowever, if its meaning M(S) is determined to be merge-\nable with the meaning of an existing node Mk on the\ngraph. While the details of mergeability have not yet\nbeen discussed, let us assume for the current example\nthat M(S4) is mergeable with M(S2). Then a new mean-\ning will appear in the graph that is a generalization of\nthese two, Merge(M(S2), M(S4)), and a graph transition\nwill be built to this new meaning. Transfer to the exist-\ning meaning Mk would proceed as follows:\n"},{"#tail":"\n","@confidence":"0.9887935","#text":"\nFigure 4 shows the updated graph. At this point, current\n= 2, and the expectation set, E(2), is non-empty for the\nfirst time. So, now we compute P(S5, {M3}), meaning\nthat $5 is read with the expectation that its meaning will\nbe &quot;remove this one&quot;. Given this expectation, the parser\nwill prefer any transitions down paths that lead to some\nparaphrase of this sentence and, unless the system clearly\nrecognizes that something else has been said, a sentence\nmeaning &quot;remove this one&quot; should be recognized. If it is,\nthen current will be advanced to this expected node. In\ngeneral, there may be several expected sentence mean-\nings, and the processor will select the one most similar to\nthe incoming utterance unless that sentence is clearly not\nany member of the expected set.\n"},{"#tail":"\n","@confidence":"0.97089","#text":"\nThus, if a successor k to the current state predicts the\nincoming sentence, we track that successor. Tracking\nthe expected meaning Mk would proceed as follows:\n"},{"#tail":"\n","@confidence":"0.715114","#text":"\nThe final sentence $6 in the dialogue will cause the\ncreation of a termination state and complete the graph of\n"},{"#tail":"\n","@confidence":"0.912848","#text":"\nrithm is thus the collection of the above code segments:\nif no behavior graph B exists then\n"},{"#tail":"\n","@confidence":"0.956480384615385","#text":"\nuntil M(S) is a dialogue termination.\nThis code creates a finite state model of the dialogue\nbased on equivalence or similarity classes defined by the\nfunctions Predicts, Mergeable, and Merge. As will be\ndiscussed in the next section, similarity classes are based\nnot only on the similarity of the sentences themselves,\nbut also on the environment in which they occur. Thus,\nthere is only one state for each such similarity class in the\nfinite state model created.\nWhen the user enters the system again, this algorithm\ncan be reinvoked using the existing B graph. If the next\ndialogue is very similar to a previous one, then the expec-\ntation dialogue will powerfully support error correction.\nIf the next dialogue has little resemblance to previous\nones, then no expectation will be available, and the user\nwill be dependent on basic processor recognition capabil-\nities.\nThis section has given an overview of the approach to\nhistory-based expectation processing. The details of the\nmethod are dependent on how the functions P, Predicts,\nMergeable, and Merge are implemented. The following\nsections describe our implementation, which was used to\ninvestigate the viability of this approach and the perform-\nance it can achieve.\nComputational Linguistics, Volume 12, Number 1, January-March 1986 17\nPamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input\n"},{"#tail":"\n","@confidence":"0.999566521276596","#text":"\nThe usefulness of the methodology described above was\ntested in the implementation of a connected speech\nunderstanding system. An off-the-shelf speech recogni-\ntion device, a Nippon Electric Corporation DP-200, was\nadded to an existing natural anguage processing system,\nthe Natural Language Computer (NLC) (Ballard 1979,\nBiermann and Ballard 1980). The expectation system\nprovided the intermediate processing between the error-\nful output of the speech recognizer and the deep seman-\ntics of NLC. The resulting speech understanding system\nis called the Voice Natural Language Computer with\nExpectation (VNLCE, Fink 1983). \\[The current system\nshould be distinguished from an earlier voice system\n(VNLC, Biermann et al 1985), which had no expectation\nand which handled discrete speech where a 300 millisec-\nond pause must follow each word.\\]\nIt should be emphasized, of course, that the central\nissue here is the study of expectation mechanisms and the\ndetails of the design decisions could have been made in\nrather different ways. Thus one could have implemented\nexpectation error correction with a typed input system or\nwith a speech input system that integrates voice signal\nprocessing with higher level functions in a way not possi-\nble with a commercial recognizer. This implementation\nshows only one way in which the functions P, Predicts,\nMergeable, and Merge can be constructed to achieve\nexpectation capabilities. The conclusion of this paper is\nthat in this particular situation substantial error\ncorrection is achieved, and thus one may suspect that\nsimilar results can be achieved in other applications.\nThe implementation, as in the overview of the general\nsystem presented in section 2, consists of two major\nparts, an expectation parser and an expectation module,\nand their respective data structures. The expectation\nparser embodies the function P, while the major func-\ntions of the expectation module are Predicts, Mergeable,\nand Merge. An expected sentence set, E(current), along\nwith the most recent input sentence S, are inputs to the\nexpectation parser P. The expectation parser P uses\nthese two inputs to determine the meaning M(S) of the\ninput sentence S. Thus, M(S) is a deep parse of S. The\nfunction Predicts determines if one of the sentences in\nE(current) predicts M(S). If so, then 1~(S) is merged\nwith this sentence meaning and dialogue tracking is\nbegun from that point. Otherwise the function Mergea-\nble determines how &quot;similar&quot; M(S) is to any other\nsentences in the expected ialogue. In this implementa-\ntion, the function Mergeable is actually much more\ncautious about determining whether or not a set of\nsentences should be merged. For the implementation, if\nMergeable determines that certain nodes in the expected\ndialogue are mergeable with M(S), then it adds the\nsuccessors of these nodes to E, creating an expanded\nexpected sentence set. Then, if the next sentence input is\npredicted by one or more of these sentences, they are\nmerged through the action of Predicts and Merge.\nThe purpose of the expectation parser in this implemen-\ntation of a speech understanding system is to take input\nfrom the scanner and the expectation module, and use\nthis information to determine what was said by the user.\nThus, during the parsing process, the expectation parser\nmust reconcile the sequence of words input from the\nscanner with the expected sentence set from the expecta-\ntion module, or determine that the scanner input is not\nlike anything that was expected and, thus, ignore\nexpectation. In this way, the expectation parser parses\nfrom two inputs. It is constantly trying to maintain an\nequilibrium between the input from the scanner and the\ninput from the expectation module. This balancing is\nkept in line by a set of rating factors that are used during\nthe parsing procedure to help guide the search for a\nreasonable sentence structure. These rating factors, at\ntimes, will be referred to as probabilities in the following\ndiscussion. However, in reality, the ratings are one thou-\nsand times the values of the logarithms of numbers\nbetween 0 and 1. Thus, the ratings span the values -999\nto 0, where 0 is equivalent to a probability of one. These\nratings are computed this way because they remain inte-\ngral and still fairly accurately represent the correct\nvalues. Also, they can simply be added and subtracted\nrather than multiplied and divided in the hundreds of\ncalculations required for a single sentence parse.\nThe expectation parser uses an ATN-like represen-\ntation for its grammar (Woods 1970). Its strategy is\ntop-down. The types of sentences accepted are essential-\nly those accepted by the original NLC grammar, imper-\native sentences with nested noun groups and\nconjunctions (Ballard 1979). An attempt has been made\nto build as deep a parse as possible so that sentences with\nthe same meaning result in identical parses. Sentences\nhave the same &quot;meaning&quot; if they &quot;result in identical tasks\nbeing performed. The various sentence structures that\nWe have have the same meaning we call paraphrases.\nstudied the following types of paraphrasing:\n"},{"#tail":"\n","@confidence":"0.968012178947369","#text":"\n'double row two and zero matrix one.'\n<= > 'double row two. zero matrix one.'\nIt is obvious from this list that there are varying levels of\nparaphrasing. Some arise at the vocabulary level\n(number 1), some at the syntactic level (numbers 2, 3, 4,\n5, 6, and 7), some at the semantic level (numbers 8, 9,\nand 10), some at the current world level (numbers 11\nand 12), and some at a combination of levels (numbers\n13 and 14). Some are domain dependent, especially at\nthe vocabulary level such as entry < = > number. Others\nare not, such as ADJ NOUN <=> NOUN QUALIFIER.\nThose that only require knowledge of the vocabulary or\nof the grammar are implemented in the current history-\nbased expectation system. This means that paraphrases\none through seven are handled currently as part of the\nparsing process itself. The last seven may be dealt with\nat some future date. However, they are somewhat more\ncomplicated because they require temporal-type know-\nledge such as the current referent of a pronoun or the\ncurrent size of a matrix. The lexical and grammatical\nparaphrases, on the other hand, will always have the\nsame meaning, regardless of the current state of the\nworld. By handling the seven lexical and syntactic para-\nphrases, a stored parse can aid in recognizing many\nsentences with the same &quot;meaning&quot; but different surface\nstructures.\nTo simplify representation of the parser output we\nhave developed a special notation to indicate the deep\nparse of a sentence. For example, the parse of the\nsentences:\nDouble the positive row 1 entries.\nDouble the positive entries in row 1.\nDouble the row 1 entries which are positive.\nDouble the entries in row 1 which are positive.\nis notated as:\nDouble (entries (positive) (rl))\nThe mechanism for using the expectation i formation\nduring parsing is built into the ATN-like network. The\nparser eceives from the scanner a sequence of word slots.\nThese word slots are defined by the speech recognition\nsystem based on the sequence of words it recognized.\nThus, there could be missing or extra word slots due to\nerrors made during speech recognition. To each word\nslot the scanner adds other possible words based on what\nwords the system tends to confuse. The scanner also\nrates the possibilities for each word slot by the same\nscale discussed previously. During parsing, the parser\ncreates a template that represents the parse of the\nsentence input. This template contains slots that repre-\nsent the parts of a sentence such as verb, adjective, and\nheadnoun. At each point in the parse of a sentence,\nwhen the expectation parser is trying to determine what\nthe role of the current word slot is in the sentence, five\ndifferent attempts are made to use the current word slot\nas needed to fill the template slot at the current point in\nthe grammar network. These are:\n? ADV (advance): Find a word in the current word slot\nfrom the scanner output that will fit the needs at this\nnode in the grammar. If such_ a word cannot be found,\ntry choice 2.\n? EXPADV (expectation advance): Look at the parse of\nthe current expected sentence to see if the template\nslot that the parser is currently trying to fill is filled in\nthe expected sentence. If so, copy the value in the\ntemplate slot from the expected sentence to the current\nparse, ignoring the word slot from the scanner. Other-\nwise, try choice 3.\n? SKIPWORD: Skip the current word slot from the scan-\nner output, filling the corresponding parser template\nslot, when appropriate, with a NIL value to indicate\nthat a word has been skipped and that it was assumed\nto have the function associated with the template slot.\nIf the parse fails later on, and the parser backs up to\nthis point, try choice 4.\n? EXTRAWS (extra word slot): Assume that the word\nslot from the scanner is an extra one due to an error in\nrecognition. Skip this word slot and again try choice 1.\nIf failure occurs, try choice 2. Finally, if failure again\noccurs, try choice 5.\n? LOSTWS (lost word slot): Assume that the needed\nword slot from the scanner is lost due to an error in\nrecognition. Without advancing to the next scanner\nword slot, try step 2 again. If this fails, then fill the\nparser template slot, when appropriate, with a NIL\nvalue to indicate that a word has been lost and that it\nwas assumed to have the function associated with that\ntemplate slot. Remain at the current scanner word slot\nso that it can again be evaluated for a different func-\ntion.\nAn example piece of the parser network is shown in\nFigure 6. The five kinds of error correction were hand\ncoded into each network so that the special character-\nComputational Linguistics, Volume 12, Number 1, January-March 1986 19\nPamela K. Fink and Alan W. Biermann The Correction of HI-Formed Input\nformatted routine FILLADJ:\n"},{"#tail":"\n","@confidence":"0.986862866666667","#text":"\nistics of each grammatical structure could be accounted\nfor individually. Thus in some cases, certain error\ncorrection alternatives were checked immediately while\nin others it was wiser to determine whether normal proc-\nessing would fail at deeper levels before attempting those\nsame corrections. The network represents a tree struc-\nture which is searched by the expectation parser.\nSuccession in the network is represented by the parent-\nchild relationship, which is indicated in Figure 6 by\nindentation. Thus, the node containing the command\nADV is the parent of the node containing the command\nCHEK PART ADJ, and so is succeeded by it. Should a\ncommand fail, the parser backs up to the parent node of\nthe node that has just failed. Thus, if a check for an\nadjective in CHEK PART ADJ fails, control will back up\nto the node containing ADV. Choice is represented by\nthe sibling relationship which is indicated in Figure 6 by\nthe vertical lines connecting nodes. Thus, ADV,\nEXPADV, SKIPWORD, EXTRAWS, and LOSTWS are all\nsiblings in the tree network and are choices that the\nparser can make when parsing a sentence. Note that, in\nthis case, these five choices represent he five possible\nattempts that are made in trying to parse a word slot that\nwere discussed above. A choice is made by picking the\nsiblings in the order in which they appear in the network.\nThus, when the CHEK PART ADJ fails and control backs\nup to ADV, the expectation parser will back up to the\nSTART node and then take the second choice, EXPADV,\nand attempt to proceed own that chain of commands.\nThe scoring mechanism within the parser serves to aid\nin the evaluation of the alternative paths during the parse\nprocess and the pruning of improbable choices. A typical\nspoken input to the system is\n&quot;add row one to row two&quot;\nand the speech recognition machine will often return\nsuch errorful output as\n&quot;and row * to row&quot;.\nThe asterisk indicates that the device guesses the exist-\nence of a word but has failed to identify it.\nThe parser must be able to extract the user's original\nintent and its operation is guided by rating factors which\nevaluate the quality of the path through the parser, the\nword selection, the level of agreement with expectation,\nand the self consistency (or compatibility) of the\nsentence. These individual ratings work as follows:\n"},{"#tail":"\n","@confidence":"0.999010083333333","#text":"\nEvery time the parser moves over a SKIPWORD,\nEXTRAWS, or LOSTWS command a charge is made\nto the value of the transition. Normally, a transition\ndoes not cost anything, but each SKIPWORD,\nEXTRAWS, and LOSTWS executed results in a lower-\ning of the transition's value. This charge is made for\nthe rest of the parse unless the SKIPWORD,\nEXTRAWS, or LOSTWS is backed over. This charge\ncan be seen in the sample grammar net appearing in\nFigure 6 after the words SKIPWORD, EXTRAWS, and\nLOSTWS. The charge in this example for each of the\nthree commands i 1000*log\\[0.7\\] = -35 .\n"},{"#tail":"\n","@confidence":"0.9600405","#text":"\nWe define the synophones of a given vocabulary\nword to be the words a user might speak that could\npossibly be recognized as that word. Because of the\nnature of the dynamic programming algorithm in the\nNEC machine, it yields only one guess at each word\nslot. So it is necessary for our software to provide\nthe set of synophones for each guessed word. This,\nin effect, simulates the situation where the speech\nrecognition device provides a larger number of possi-\nble matches. Thus, in the case of the above recog-\nnizer outpu t, the following synophones would be\nproduced to represent the sequence of possible\nwords spoken:\nword slot word rating\n"},{"#tail":"\n","@confidence":"0.9985762","#text":"\nEach alternative word is given a rating. The words\nselected by the recognizer are given maximum\nratings and alternatives are given lower values. If\ntwo words have the same pronunciation as with to\nand two, they are given the same values.\n"},{"#tail":"\n","@confidence":"0.995631","#text":"\nThis value is based on whether or not there is an\nexpected sentence, how well the current parse is\nmatching the current expected sentence from the\nexpected sentence set, and how much the current\nparse is using this expected sentence. Whenever a\nslot is filled by the parser, it is compared with the\ncorresponding slot in the expected sentence. If they\ndo not match, the expectation value decreases, other-\nwise the expectation value remains the same.\n"},{"#tail":"\n","@confidence":"0.992776111111111","#text":"\nThis value differs from the other three in that it is\nsimply true or false. Verb-operand, noungroup-\nnoungroup, and expectation are checks made during\nthe parse. If compatibility fails, then the expectation\nparser backs up, otherwise it continues forward.\nEach of these components has a value assessed at each\nword slot in the incoming sentence as well as one for the\nentire sentence. The word slot values are assumed to\nhave a top rating until the parser reaches that word slot.\nThus, the parser is always examining a best case situation\nbased on what it has already done. For example, all\nword slot transition values are assumed, initially, to have\nthe value 1000*log\\[i\\] = 0. The transition value at a\nword slot is only lowered if it is necessary for the parser\nto execute a SKIPWORD, EXTRAWS, or LOSTWS\ncommand in parsing that word slot. The charge made is\naccOrding to the value indicated at the particular\ncommand in the grammar network. The average of the\ncurrent values of all word slot transition values creates\nthe sentence transition rating for the parse so far. The\nword slot and sentence values for the expectation and\nword values are computed similarly. The compatibility\nvalue differs, however, since it does not have degrees of\nratings but rather indicates acceptability or lack thereof.\nThus, it is not included in the formula for determining a\nrating for the parse. Rather, if it fails, then parsing auto-\nmatically backs up. If it succeeds, then parsing continues\nforward.\nThe values of the transition, word, and expectation\ncomponents are used to determine two sentence parse\nratings. At each word slot, the values of the three factors\nare averaged together to produce a general word slot\nparse rating. Also, the sentence values for the three\ncomponents are averaged together to obtain a general\nsentence parse rating. Thus, we have the following\nequations that define the various rating values, where n is\n"},{"#tail":"\n","@confidence":"0.900593941176471","#text":"\nThe transition confidence, word confidence and\nexpectation confidence provide an average overall\nvalue for the ws transition, ws word, and\nws expectation ratings, respectively. These average\nvalues provide a best case rating at any point during the\nparse because they assume perfect ratings for all word\nslots not yet parsed. The overall parse values,\nwords lo t fac tor and sentence factor, are calculated\nsimply from the average of the other three rating values.\nThis is done so that each factor has equivalent power in\ncontrolling the parse. If it is desirable to allow one factor\nto have more control over the parse than the other two,\nthen this can be accomplished by manipulating the partic-\nular minimum rating values discussed below. In order to\ncontrol the expectation parsing, search is cut-off if rating\nvalues fall below certain levels. Currently, these levels\nare:\n"},{"#tail":"\n","@confidence":"0.9909085","#text":"\nIf any one of the rating factors drops below its corre-\nsponding minimum value, the current search path is cut-\noff and a different route through the grammar nets is\nattempted. In this way, there is a control over the extent\nof the search. By setting all the minimum ratings to\nComputational Linguistics, Volume 12, Number 1, January-March 1986 21\nPamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input\n-999, for example, all possibilities in the grammar are\nchecked. On the other hand, setting all the minimum\nratings to 0 results in the expectation parser behaving like\na normal parser since this essentially turns off the use of\nthe SKIPWORD, EXTRAWS, and LOSTWS commands, the\nuse of synophones, and expectation.\nIn theory, the parsing algorithm is admissible. That is,\nit is capable of finding the best possible parse. The vari-\nous rating factors can initially be set high and gradually\nlowered until a parse is found. This parse would have the\nhighest rating possible. However, this is impractical in\npractice due to the amount of time required to repeatedly\nsearch a growing space. Thus, minimum rating values are\nset and the search is conducted once. In this way, the\nfirst parse found is the &quot;best&quot; parse in the sense that it is\nthe first one found whose rating was higher than the\nminimum pre-set value.\n"},{"#tail":"\n","@confidence":"0.989290892857143","#text":"\nThe task of the expectation module is to acquire a gener-\nal dialogue from a series of dialogues poken by a user.\nThe dialogues essentially contain examples of how to go\nabout solving a particular kind of problem. In acquiring\nthese dialogues and merging them into one generalized\ndialogue, the expectation system learns how to solve this\nparticular kind of problem through examples. In a sense,\nby building this generalized dialogue the expectation\nsystem is creating a procedure that can solve a particular\nsubset of problems. This is a future goal of the project.\nHowever, the current application is for the generalized\ndialogue to be used as an aid in the voice recognition\nprocess by offering predictions about what might be said\nnext.\nThe types of problems that can be learned by the\nexisting history-based expectation system include linear\nalgebra applications uch as matrix multiplication, simul-\ntaneous linear equations, and Gaussian elimination.\nNon-linear algebra problems that require matrix-type\nrepresentations can also be learned, such as gradebook\nmaintenance and invoice manipulation. Though the\nimplemented system is limited to matrix-oriented prob-\nlems, the theoretical system is capable of learning a wide\nrange of problem types. The only requirement on the\nproblem or situation is that it can be entered into the\nexpectation system in the form of examples. Thus, for\nexample, it can acquire a &quot;script&quot; such as the one for\ngoing to a restaurant as defined in Schank and Abelson\n(1977).\nThe expectation module takes two inputs and produc-\nes two outputs. The inputs are\n? the user behavior graph discussed earlier, called the\nexpected ialogue D, and\n? the meaning of the most recently input sentence, M(S).\nIts outputs are a new expected dialogue D modified\naccording to the latest input sentence M(S) and an\nexpected sentence set E. These outputs are produced\nbased upon the inputs and the functions Predicts, Merge-\nable, and Merge.\nThe role of the predicate Predicts can be best under-\nstood by recalling the function of the parser P. P uses\nthe set of expected sentences E(current) to try to error\ncorrect the incoming sentence S. P may do this by\ndiscovering that some Mk in E(current) is quite similar to\nM(S). If P does select such an Mk and uses it to help\nparse S, then Predicts (Mk, M(S)) is true. Otherwise,\nPredicts (Mk, M(S)) is false. Thus the function of\nPredicts is to select he Mk which the parser used in pars-\ning S. If the parser did not use expectation, then Predicts\nalways is false.\nIf the incoming sentence was not predicted by existing\ntransitions in D, perhaps it can be found to be similar to\nsome node Mk in D and a new transition could be added\nto that node. The routine Mergeable has the job of find-\ning one or more such Mk's into which the current\nsentence meaning M(S) can be merged. The question of\nsimilarity of two sentences i determined by the meanings\nof the sentences themselves and the &quot;environment&quot; in\nwhich they occur in the dialogue. Sentence &quot;meanings&quot;\nare based on the sentence deep parses produced by the\nexpectation parser, while a sentence &quot;environment&quot; is\nbased on the meanings of the sentences preceding and\nfollowing it in the expected ialogue.\nSimilarity is based on the notion of &quot;distance&quot;.\nCurrently two sentences are considered similar in mean-\ning if their parses differ in only one slot in the noun\ngroup template. This means that their noun group\ndistance cannot be greater than one to be considered\nsimilar. For example, the following two sentences are\nsimilar:\nM(&quot;double the first row&quot;) = double (r l )\nM(&quot;double row 2&quot;) = double (r2)\nThe environment of one sentence matches that of another if\nthe sentence meanings preceding the two sentences being\ncompared are identical and/or the sentence meanings\nfollowing them are identical. Clearly, these definitions\nare quite arbitrary and many other strategies could be\ntried. However, for the purposes of this study, they were\nquite satisfactory.\nBased on the question of how well the environment\nand the sentence itself matches previously seen environ-\nments and sentences, five different matches are possible\nbetween the current incoming sentence and the elements\nof the expected ialogue:\n"},{"#tail":"\n","@confidence":"0.966637044776119","#text":"\nsentence meaning in the expected ialogue.\nIn cases 1, 2, and 5, the sentence is determined to be new\nand unique to the expected ialogue. Therefore, Mk and\nM(S) are not mergeable. In such cases, M(S) is added as\na new entry in the expected ialogue D. In the other two\ncases, numbers 3 and 4, the incoming sentence is deter-\nmined to be the same as or similar to one already seen\npreviously in an exact or similar situation. Thus, Mk is\nmergeable with M(S). In case 3 the sentence is automat-\nically merged with the one that it matches exactly in the\nexpected sentence set. In case 4, the sentence is merged\nwith the one that it matches similarly in the expected\nsentence set only after it has passed an argument creation\nalgorithm test to be discussed below. Otherwise it is also\nconsidered new and unique and added to the expected\ndialogue as in cases 1, 2, and 5. The actual argument\ncreation occurs in the function Merge.\nThe notion of creating an argument is associated with\nthe problem of when to merge a set of similar sentences\nin an expected ialogue into one sentence with a special\nflag in the slot where the sentences differ. This is deter-\nmined by the function Mergeable. As an example, at a\ncertain point in a dialogue, one may have an expected\nsentence set E(i) such as the following:\ndouble (rl) .33\ndouble (r2) .33\ndouble (r3) .33\nThe numbers indicate the probability levels, derived from\nj/Ci, as discussed at the end of section 3.\nIn such a situation, the user's intentions may be\nreflected more correctly by the following expected\nsentence set:\ndouble (rARG) 1.0\nwhich signifies that any row may be referred to. Howev-\ner, though this simplified expected sentence set may be a\ngood generalization of the pattern observed, it has\nramifications for error correction. Specifically, it will be\nunable to fill in a row number should that value be miss-\ning in the incoming sentence. The first option also has its\ndrawbacks. In this case, should the row number be miss-\ning in the sentence, the expectation parser will error\ncorrect the sentence to the most probable value, or the\nfirst one in the set if the probabilities are equal, here the\nvalue one for row 1. Thus, both options are imperfect in\nterms of the error correction capabilities that they can\nprovide. The comparison that must be made to deter-\nmine which option is better in a given situation is how\noften the first will error correct incorrectly as opposed to\nhow much error correcting power we will lose by using\nthe second. How it is done is beyond the scope of this\npaper but is explained in detail in Fink (1983).\nThe Merge function takes two inputs, M1 and M2,\nwhich have been determined by the Mergeable function\nto be similar in some way by considering their respective\nenvironments and meanings. Based upon how similar the\ntwo meanings are, Merge creates a meaning M that is a\ngeneralization of M1 and M2, sometimes employing an\nargument. Thus, there are only two possible kinds of\nmatches at this point between an input sentence and a\nmember of the expected sentence set, an exact match or\na similar match. In the case of an exact match M = M1\n= M2 and M replaces Mi in the expected ialogue. In\nthe case of a similar match, the meanings only differ by\none slot in the noun group of their deep parse represen-\ntation, so a generalization of that slot to &quot;ARG&quot; is made,\nmeaning an argument is created. The function appears as\nfollows:\n"},{"#tail":"\n","@confidence":"0.972926333333333","#text":"\nThus, if the sentences &quot;Double ( r l ) &quot; and &quot;Double (r2)&quot;\nare inputs to Merge, the output would be &quot;Double\n(rARG)&quot;.\n"},{"#tail":"\n","@confidence":"0.985189411764706","#text":"\nAn experiment was run using VNLCE to test the error\ncorrection capabilities in different situations. These situ-\nations were simulated by making the test subjects\nperform certain tasks on the system that resulted in\ndifferent dialogue structures, or schemas. The four tests\nmade on VNLCE in this experiment are considered to be\nrepresentative of the possible schemas that can be\nproduced by different dialogues in different situations.\nAll possible dialogue schemas actually produce a contin-\nuum of patterns from totally-ordered to totally-unord-\nered. The tests described below are simply points on this\ncontinuum.\nI) Totally-Ordered Schema\nThis type of schema occurs whenever the system has\nat most two sentences at a time in its expected\nsentence set and one of these always has a probabili-\nty rating over 80%.\n"},{"#tail":"\n","@confidence":"0.987029365384615","#text":"\nIn this case, there is a general order to the sentences\nbeing spoken, but there is not usually just one highly\nprobable sentence in the expected sentence set at a\ntime, but several with varying degrees of probability.\nIII) Totally-Unordered Schema\nThis occurs when there is no over-all order to the\nsentences being spoken. Essentially any sentence in\nComputational Linguistics, Volume 12, Number 1, January-March 1986 23\nPamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input\nthe expectation dialogue has a probability of being\nspoken next.\nIV) Totally-Ordered Schema with Arguments\nThis test is an example of a totally-ordered schema,\nbut the system does not know exactly what will be\nsaid all the time because one or more of the expected\nsentences contain an argument.\nEach of the four tests was run on three different test\nsubjects to acquire data concerning how fast a user\nspeaks, what types of errors are produced by the voice\nrecognizer, and how well the expectation system acquires\nand uses the expected ialogue to help error correct the\ninput.\nTo begin the experiment session, the subject trained\nthe voice recognizer, a NEC DP-200, on a specific vocab-\nulary of 49 different words in connected speech mode.\nThe DP-200 can handle only 150 word slots in connected\nspeech mode, so 49 allowed for some repetitive training.\nThe subject was then given a brief tutorial that lead\nhim/her through a few features of the VNLCE system\nand gave him/her some practice in talking to the NEC\ndevice. This training session usually took a total of about\n45 minutes. The subject was then given one or more of\nthe test sheets representing the problems to be solved.\nThe number was based on the amount of time that the\nsubject was willing to donate to the effort.\nEach test dialogue had a similar over-all structure in\nthat it required a certain amount of repetition, thus creat-\ning a loop structure in the expected ialogue. In all tests,\nexcept test II, the subject was provided with the specific\nsequence of sentences to be spoken. This guaranteed\nthat the desired level of repetition was actually achieved.\nHow much repetition there was in each dialogue\ndepended on the expected dialogue schema being\nimitated. In test I, which was done to demonstrate a\ntotally-ordered schema, the test subject had to repeat an\nidentical sequence of six sentences nine times in a row\nexcept for the seventh time when four new sentences\nwere inserted into the loop. A sample schema can be\nseen in Figure 7. In test II, the user had much more free-\ndom, since its purpose was to demonstrate a partially-\nordered schema. Here the subject had to solve six sets of\nsimultaneous linear equations with two equations and\n"},{"#tail":"\n","@confidence":"0.992019538461538","#text":"\ncorrection works when the dialogue seems random, creat-\ning a totally-unordered schema. To create such an envi-\nronment, the user was asked to repeat four sentences in\nrandom order eight times. An example xpected ialogue\nschema that resulted from this test is shown in Figure 9.\nIn the last test, test IV, the subject was asked to repeat a\nsequence of four sentences ix times, each time through\nchanging the value of the row number spoken. This\ndemonstrates the argument creation facility in a totally-\nordered dialogue schema. The expected ialogue gener-\nated from this test appears in Figure 10.\nEach test has associated with it three charts indicating\nthe results. The first graph represents the average\nsentence rror and correction rates, the second shows the\naverage word error and correction rates, while the third\nillustrates the average rate-of-speech in words-per-sec-\nond spoken by the subject while doing the experiment.\nThe charts indicating the average rror and correction\nrates of the four tests reflect the loop structure of the\ndialogues. Each chart is a series of bar graphs, each bar\ngraph representing the average rror and correction rates\nover the sentences poken by the subjects in a particular\nloop of the dialogue. The highest point on each of these\nbars represents the raw error rate of the voice recognizer.\nThe different markings within the bars themselves repre-\nsent the percentage of the errors that were corrected by a\nparticular facility of the expectation system. The hori-\nzontal design associated with &quot;loosening&quot; indicates the\npercentage of the errors that were corrected by the use of\nthe flexible parsing techniques, such features as the syno-\nphones and the parser commands SKIPWORD,\nEXTRAWS, and LOSTWS. The vertical design associated\nwith expectation indicates the percentage of the errors\nthat were corrected by use of the expected sentence set\nalone. The blank area indicates the percentage of the\nerrors that were corrected by using both of the above\nfacilities. Finally, the dot design shows the percentage of\nthe errors that were not corrected. Thus, for example, in\nthe top chart in Figure 11, the eighth loop of the dialogue\nhad an 85% sentence rror rate from the voice recogniz-\ner. Of those errors, 6% were corrected using the facili-\nties associated with loosening the search, while 25%\nwere corrected by using only expectation. Another 63%\nwere corrected using features from both categories. Only\n6% could not be corrected.\nTest I, using a totany-ordered dialogue schema, was\ndone to show how well the expectation system can error\ncorrect errorful input when it can predict exactly what\nwill be said next. As can be seen from the graphs in\nFigure 11, as the ability to predict what will be said next\nincreases, so does the ability to error correct. In loop\nseven of the dialogue, we deliberately had each user add\nfour extra sentences between the fourth and fifth\nsentences of the loop. This was done to show that the\nexpectation system had not become a complete automa-\nton, but that it was still capable of dealing with unex-\npected input. However, as can be seen from these graphs\n(Figure 11), the expectation system's error correcting\npower decreases in that particular loop of the dialogue\nsince there is no expectation at certain points to help it.\nTest II, creating a partially-ordered dialogue schema,\nwas done to show how the expectation acquisition algo-\nrithm dealt with dialogues containing some pattern and to\nsee how well error correction could work when expecta-\ntion was not perfect. The results are shown in Figure 12.\n"},{"#tail":"\n","@confidence":"0.99827934375","#text":"\nTest III demonstrates the error correction capabilities\nof the system when expectation only knows that one of a\ngroup of sentences will be said next. It produces a total-\nly-unordered dialogue schema. The results of the\nsystems error correction capabilities in such a situation\nappear in Figure 13.\nTest IV uses a totally-ordered dialogue schema, but\nwith a variation from test I. Each sentence sooner or\nlater contains an argument so that the system does not\nknow everything about the sentence that will be said\nnext. The data given in Figure 14 shows the error\ncorrection rates for this dialogue. It clearly shows how\nerror correction failures increase until after the third loop\nwhen argument creation begins so that the system no\nlonger error corrects incorrectly.\nFigure 15 shows the graphs of the average speech rate\nof the speakers for each of the four tests. Like the other\neight graphs, these graphs reflect the loop structure of\nthe dialogues. As can be seen, the speakers tended to\nincrease their speech rate as they talked to the system.\nThis behavior was hoped for because as the speech rate\nincreased, so did the error rate of the speech recognizer,\nthus placing more of a burden on the error correcting\nabilities of the expectation system. Note that, in all eight\ngraphs in Figures 11 through 14, the word and sentence\nerror rates from the voice recognizer generally increased\nwith the progress through the dialogue. This is due to the\nincreased rate of speech. However, the actual failure rate\nof VNLCE did not increase by the same amount. These\nextra errors were corrected by the expectation system.\nFigure 16 gives a summary of the average error and\ncorrection rates for each test and over all.\n"},{"#tail":"\n","@confidence":"0.803772304347826","#text":"\nA number of speech understanding systems have been\ndeveloped uring the past fifteen years (Barnett et al\n1980, Dixon and Martin 1979, Erman et al 1980, Haton\nand Pierrel 1976, Lea 1980, Lowerre and Reddy 1980,\nMedress 1980, Reddy 1976, Walker 1978, and Wolf and\nWoods 1980). Most of these efforts concentrated on the\ninteraction between low level information sources from a\nspeech recognizer and a natural language processor to\ndiscover the meaning of an input sentence. While some\nof these systems did exhibit expectation capabilities at\nthe sentence level, none acquired dialogues of the kind\ndescribed here for the sake of dialogue level expectation\nand error correction. A detailed escription of the kinds\nof expectation mechanisms appearing in these systems\nappears in Fink (1983).\nThe problem of handling ill-formed input has been\nstudied by Carbonell and Hayes (1983), Granger (1983),\nJensen et al (1983), Kwasny and Sondheimer (1981),\nRiesbeek and Schank (1976), Thompson (1980), Weis-\nchedel and Black (1980), and Weischedel and Sondheim-\ner (1983). A wide variety of techniques have been\ndeveloped for addressing problems at the word, phrase,\nsentence, and in some cases, dialogue level. However,\nthese methodologies have not used historical information\nat the dialogue level as described here. In most cases, the\ngoal of these systems is to characterize the ill-formed\ninput into classes of errors and to correct on that basis.\nThe work described here makes no attempt to classify the\nerrors, but treats them as random events that occur at\nany point in a sentence. Thus, an error in this work has\nno pattern but occurs probabilistically. A verb is just as\nlikely to be mis-recognized or not recognized as is a\nnoun, adjective, determiner, etc.\nTest I Tes t I I Tes t I I I Tes t IV Over -a l l\nword-er ror - ra te 18 .78 11.75 11 .25 12 .17 13 .49\ncor rected\nword-er ror - ra te\nsentence-er ror - ra te\n.59 1 .50 1 .50 4 .17 1 .94\n61 .22 40 .83 52 .25 56.33 52.66\ncor rected\nsentence-er ror - ra te\n3.22 6 .00 5 .38 16 ,00 7 .65\naverage speak ing ra te 2 .27 2 .95 1 .85 1 .97 2 .26\nFigure 16. Average word and sentence rror rate in percent,\naverage speaking rate in words-spoken-per-minute.\n"},{"#tail":"\n","@confidence":"0.973660032258064","#text":"\nPamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input\nThe acquisition of dialogue as implemented in VNLCE\nis reminiscent of the program synthesis methodology\ndeveloped by Biermann and Krishnaswamy (1976)\nwhere program flowcharts were constructed from traces\nof their behaviors. However, the &quot;flowcharts&quot; in the\ncurrent project are probabilistic in nature and the prob-\nlems associated with matching incoming sentences to\nexisting nodes has not been previously addressed.\nAnother dialogue acquisition system has been developed\nby Ho (1984). However, that system has different goals:\nto enable the user to consciously design a dialogue to\nembody a particular human-machine interaction. The\nacquisition system described here is aimed at dealing with\nill-formed input and is completely automatic and invisible\nto the user. It self activates to bias recognition toward\nhistorically observed patterns but is not otherwise\nobservable.\nThe VNLCE processor may be considered to be a\nlearning system of the tradition described, for example, in\nMichalski et al (1984). The current system learns finite\nstate flowcharts whereas typical learning systems usually\nacquire coefficient values as in Minsky and Papert\n(1969), assertional statements as in Michalski (1980), or\nsemantic nets as in Winston (1975). That is, the current\nsystem learns procedures rather than data structures.\nThere is some literature on procedure acquisition such as\nthe LISP synthesis work described in Biermann et al\n(1984) and the PROLOG synthesis method of Shapiro\n(1982). However, the latter methodologies have not\nbeen applied to dialogue acquisition.\n"},{"#tail":"\n","@confidence":"0.998630265306123","#text":"\nWe have shown that the ability to use expectation i the\nform of knowledge about the dialogue being spoken, as\nwith humans, is a tremendous aid to speech recognition\nby computer. Since expectation, in this research, has\nbeen based on repetition of patterns, the expectation\nsystem's ability to correct varies, of course, with the\nrepetitiveness of the dialogue itself. We have attempted,\nin sections 5 and 6, to justify this decision by demon-\nstrating how the expectation system can acquire common\nprogramming constructs uch as loops and arguments. It\nis our belief that repetitious patterns occur in everyday\nlife, and that the expectation system is capable of dealing\nwith such patterns, resulting in a generalized situation\nsimilar to a Schankian script. Finally, we have tested the\nexpectation system's correction power in some represen-\ntative situations, as discussed in section 6. It has been\ndemonstrated that the expectation system has the capa-\nbilities of reducing a large sentence rror rate to nearly\nzero in many situations. At the word level, error rates to\nthe expectation system climbed as high as 47 % in certain\nuser dialogues when the user was speaking fast. At the\nsame time, the error rate leaving the expectation system\nremained fairly low at between zero and fifteen percent.\nOn the average, the system was able to lower a sentence\nerror rate of 53% to 8%, and a word error rate of\n13.5% to 2%. The use of expectation, along with an\nability to ignore or add words to the input stream of the\nparser, is all that is needed to achieve this error\ncorrection rate on randomly erroneous input.\nThe parser design, with the five choices at each word\nslot, has the potential to run into problems with the expo-\nnential growth of the search and to result in unacceptably\nlong parse times. However, when the rating scheme is\nused intelligently, it not only aids in finding the best\nparse of a word sequence, but it also helps to lower the\nsearch time necessary by pruning unreasonable search\nchoices. The average parse time for a sentence, from the\ntests discussed above, was 5.1 seconds while the average\ntotal processing time for a sentence was 10.5 seconds.\nThis was on a highly loaded PDP 11/70 under the UNIX 1\noperating system. In the event that a particular word\nsequence leads the parser down a garden path, a time-\nout facility has been implemented that causes the parser\nto fail after one minute of real-time. However, out of a\ntotal of 629 sentences spoken in the above four tests, this\nfeature was needed only 19 times.\nThe research reported on here was divided into two\nparts, the theory and the implementation. Most of the\ntheory developed was implemented in the VNLCE\nsystem. This theory has been aimed at error correction\nof random errors using expectation based on historical\ninformation. However, there are many possible exten-\nsions that could be examined in the future and added to\nthe implementation if the investigation indicates that it\nwould create a yet more usable system. These include\nthe following:\n? use of low level knowledge from the speech recognition\nphase,\n? use of high level knowledge about the domain in partic-\nular and the dialogue task in general,\n? a &quot;continue&quot; facility and an &quot;auto-loop&quot; facility as\ndescribed by Biermann and Krishnaswamy (1976),\n? a &quot;conditioning&quot; facility as described by Fink et al\n(1985),\n? implementation f new types of paraphrasing,\n? checking a larger environment in the expectation\nacquisition algorithm when deciding if an incoming\nsentence is the same or similar to one already seen, and\n? examining inter-speaker dialogue patterns.\nAll but two of these areas for expansion are aimed at\nmoving the expectation system from one that finds\npatterns in a user's dialogues and acquires historical\nknowledge about them to one that can acquire true\nprocedures. The first two areas for expansion have noth-\ning to do with creating a true procedure acquisition\nmodule but would be highly desirable from the point of\nview of the speech recognition application. Features\nthree and four would simply make the system easier to\nuse and would require little theoretical investigation. The\nfinal three would require research efforts.\nIn conclusion, we have designed a system that is capa-\nble of correcting ill-formed input and implemented the\nComputational Linguistics, Volume 12, Number 1, January-March 1986 35\nPamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input\ndesign in the area of speech recognition. The system\nperforms error-correction through a mechanism also used\nby humans in the same situation, that of expectation. We\nhave shown that the expectation algorithm is general\nenough to handle almost any dialogue structure. It is\npossible to predict approximately what kind of error\ncorrection to expect from the system based on the\ndialogue structure and the word error rate. We have also\nshown that the theory on which the implemented expec-\ntation system is based is capable of acquiring and gener-\nalizing real-world, script-like situations. This research\ncan serve as a starting point for further esearch into the\nfield of computer expectation, procedure acquisition, and\nlearning.\n"}],"#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.924004","#text":"\nSouthwest Research Institute\n"},{"#tail":"\n","@confidence":"0.9625675","#text":"\nDepartment of Computer Science\nDuke University\n"}],"sectionHeader":[{"#tail":"\n","@confidence":"0.9797685","@genericHeader":"abstract","#text":"\nTHE CORRECTION OF ILL -FORMED INPUT US ING H ISTORY-BASED\nEXPECTAT ION WITH APPL ICAT IONS TO SPEECH UNDERSTANDING\n"},{"#tail":"\n","@confidence":"0.97688","@genericHeader":"introduction","#text":"\n1 INTRODUCTION\n"},{"#tail":"\n","@confidence":"0.9997485","@genericHeader":"method","#text":"\n2 AN OVERVIEW OF THE HISTORY-BASED\nEXPECTATION SYSTEM\n"},{"#tail":"\n","@confidence":"0.978337","@genericHeader":"method","#text":"\n3 A REPRESENTATION FOR USER BEHAVIORS\n"},{"#tail":"\n","@confidence":"0.9984685","@genericHeader":"method","#text":"\n4 THE EXPECTATION MODEL BUILDING AND\nTRACKING ALGORITHM\n"},{"#tail":"\n","@confidence":"0.952674","@genericHeader":"method","#text":"\n5 AN IMPLEMENTATION 5.1 THE EXPECTATION PARSER\n"},{"#tail":"\n","@confidence":"0.678725","@genericHeader":"method","#text":"\n1) The Transition Value\n"},{"#tail":"\n","@confidence":"0.67863","@genericHeader":"method","#text":"\n2) The Word Value\n"},{"#tail":"\n","@confidence":"0.876823","@genericHeader":"method","#text":"\n3) The Expectation Value\n"},{"#tail":"\n","@confidence":"0.756037","@genericHeader":"method","#text":"\n4) The Compatibility Value\n"},{"#tail":"\n","@confidence":"0.999199","@genericHeader":"evaluation","#text":"\n6 EXPERIMENTAL RESULTS\n"},{"#tail":"\n","@confidence":"0.99948","@genericHeader":"related work","#text":"\n7 RELATED LITERATURE\n"},{"#tail":"\n","@confidence":"0.181577","@genericHeader":"method","#text":"\n34 Computational Linguistics, Volume 12, Number 1, January-March 1986\n"},{"#tail":"\n","@confidence":"0.999894","@genericHeader":"conclusions","#text":"\n8 CONCLUSIONS AND AREAS FOR FUTURE RESEARCH\n"},{"#tail":"\n","@confidence":"0.997581","@genericHeader":"references","#text":"\nREFERENCES\n"}],"page":[{"#tail":"\n","@confidence":"0.700713","#text":"\n4257\n"},{"#tail":"\n","@confidence":"0.524316","#text":"\n26\n"},{"#tail":"\n","@confidence":"0.847789","#text":"\n28\n"},{"#tail":"\n","@confidence":"0.81111","#text":"\n30\n"},{"#tail":"\n","@confidence":"0.800352","#text":"\n32\n"}],"category":{"#tail":"\n","@confidence":"0.394071","#text":"\n14 Computational Linguistics, Volume 12, Number 1, January-March 1986\nPamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input\n"},"figureCaption":[{"#tail":"\n","@confidence":"0.930765","#text":"\nFigure 1. Overview of the history-based\nexpectation system.\n"},{"#tail":"\n","@confidence":"0.4856752","#text":"\nFigure 2. Each node i has a meaning Mi and a count Ci,\nwhich gives the number of times in observed dialogues\nthis node has been visited. The integer on each transition\ngives the number of times it has been traversed in\nobserved ialogues.\n"},{"#tail":"\n","@confidence":"0.999203","#text":"\nFigure 2. Modelling the user's behavior.\n"},{"#tail":"\n","@confidence":"0.999289","#text":"\nFigure 3. Constructing the behavior graph.\n"},{"#tail":"\n","@confidence":"0.998625","#text":"\nFigure 4. Merging M(S2) and M(S4).\n"},{"#tail":"\n","@confidence":"0.931014","#text":"\nFigure 5. Merging M(S3) and M(S5).\n"},{"#tail":"\n","@confidence":"0.837922","#text":"\nFigure 2. The behavior graph creation and trackihg algo-\n"},{"#tail":"\n","@confidence":"0.991136","#text":"\nFigure 6. An example parse net.\n"},{"#tail":"\n","@confidence":"0.83276825","#text":"\ntwo unknowns and he/she spoke whatever sentences that\nseemed appropriate. A sample schema is shown in\nFigure 8. Notice that in one case an argument was\ncreated. The third test was done to show how well error\n"},{"#tail":"\n","@confidence":"0.979432","#text":"\nFigure 7. Expected ialogue schema for Test I.\n"},{"#tail":"\n","@confidence":"0.877148666666667","#text":"\nFigure 8. Expected ialogue schema for Test II.\nComputational Linguistics, Volume 12, Number 1, January-March 1986\nPamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input\n"},{"#tail":"\n","@confidence":"0.981734","#text":"\nFigure 9. Expected ialogue schema for Test III.\n"},{"#tail":"\n","@confidence":"0.900462","#text":"\nFigure 10. Expected ialogue schema for Test IV.\nComputational Linguistics, Volume 12, Number 1, January-March 1986\nPamela K. Fink and Alan W. Biermann The Correction of lll-Formed Input\n"},{"#tail":"\n","@confidence":"0.897874333333333","#text":"\nFigure 11. Error and correction rates for Test I.\nComputational Linguistics, Volume 12, Number 1, January-March 1986 29\nPamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input\n"},{"#tail":"\n","@confidence":"0.514726666666667","#text":"\nFigure 12. Error and correction rates for Test II.\nComputational Linguistics, Volume 12, Number 1, January-March 1986\nPamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input\n"},{"#tail":"\n","@confidence":"0.621585","#text":"\nFigure 13. Error and correction rates for Test III.\nComputational Linguistics, Volume 12, Number 1, January-March 1986 31\nPamela K. Fink and Alan W. Biermann The Correction of lll-Formed Input\n"},{"#tail":"\n","@confidence":"0.595764333333333","#text":"\nFigure 14. Error and correction rates for Test IV.\nComputational Linguistics, Volume 12, Number 1, January-March 1986\nPamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input\n"},{"#tail":"\n","@confidence":"0.678931666666667","#text":"\nFigure 15. Speech rate in the four dialogue schema tests.\nComputational Linguistics, Volume 12, Number 1, January-March 1986 33\nPamela K. Fink and Alan W. Biermann The Correction of m-Formed Input\n"}],"table":[{"#tail":"\n","@confidence":"0.956043","#text":"\nthe number of word slots in the sentence:\n1) The Transition Value\nword slot transition value:\nws transition\\[x\\] = value of SKIPWORD, EXTRA.WS, or\nLOSTWS at word slot x\nsentence transition value:\ntransition confidence = E ws transition\\[i\\]/n\n- - i=0 - -\n2) The Word Value\nword slot word value:\nws word\\[x\\] = value of the word chosen from the\nscanner input for word slot x\nsentence word value:\nword confidence= E ws word\\[i\\]/n\n- - i=0 - -\n3) The Expectation Value\nword slot expectation value:\nws expectation\\[x\\] = match of word slot x in current\nparse with slot x in the expected sentence\nsentence xpectation value:\nexpectation confidence = E ws expectation\\[i\\]/n\ni=0\n4) The Parse Values\nword slot parse value:\nword slot factor\\[x\\] = (ws transition\\[x\\] +\nws word\\[x\\]+ ws expectation\\[x\\])/3\nsentence parse value:\nsentence factor = (transition confidence +\nword confidence + expectation confidence)/3\n"},{"#tail":"\n","@confidence":"0.946156166666667","#text":"\n24 Computational Linguistics, Volume 12, Number 1, January-March 1986\nPamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input\n(c reate (2) (3 i )\n- ~ (~ead (rl))\n(d'ivide ,pos ,),c3;)\n(do.io (~o,.~,.? ? (.~,;)\n(.~d ,,~, (,,.()\n(mul t ip ly (c3) (e6)\n- I 1 '\n)\n@obt~.ot ,.i, ,~2;)\n(r2) ( la rgest o) ' )\n"}]}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.886142","#tail":"\n","@no":"0","note":{"#tail":"\n","@confidence":"0.994654","#text":"This material is based upon work supported by The National Science Foundation under Grant number MCS 7904120 and Grant number MCS 8113491 and by the Air Force Office of Scientific Research, Air Force Systems Command, USAF, under Grant 81-0221."},"address":[{"#tail":"\n","@confidence":"0.999607","#text":"6220 Culebra Road San Antonio, TX 78284"},{"#tail":"\n","@confidence":"0.974351","#text":"Durham, NC 27706"}],"#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.999617","#text":"Southwest Research Institute"},{"#tail":"\n","@confidence":"0.9998815","#text":"Department of Computer Science Duke University"}],"author":[{"#tail":"\n","@confidence":"0.999995","#text":"Pamela K Fink"},{"#tail":"\n","@confidence":"0.999972","#text":"Alan W Biermann"}],"abstract":{"#tail":"\n","@confidence":"0.992524333333333","#text":"A method for error correction of ill-formed input is described that acquires dialogue patterns in typical usage and uses these patterns to predict new inputs. Error correction is done by strongly biasing parsing toward expected meanings unless clear evidence from the input shows the current sentence is not expected. A dialogue acquisition and tracking algorithm is presented along with a description of its implementation i a voice interactive system. A series of tests are described that show the power of the error correction methodology when stereotypic dialogue occurs."},"title":{"#tail":"\n","@confidence":"0.9854365","#text":"THE CORRECTION OF ILL -FORMED INPUT US ING H ISTORY-BASED EXPECTAT ION WITH APPL ICAT IONS TO SPEECH UNDERSTANDING"}}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","tech":{"#tail":"\n","#text":"Ph.D. Dissertation Report CS-1979-8,"},"date":{"#tail":"\n","#text":"1979"},"institution":{"#tail":"\n","#text":"Duke University,"},"rawString":{"#tail":"\n","#text":"Ballard, B. 1979 Semantic Processing for a Natural Language Programming System. Ph.D. Dissertation Report CS-1979-8, Duke University, Durham, North Carolina."},"#text":"\n","marker":{"#tail":"\n","#text":"Ballard, 1979"},"location":{"#tail":"\n","#text":"Durham, North Carolina."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ion, which was used to investigate the viability of this approach and the perform- ance it can achieve. Computational Linguistics, Volume 12, Number 1, January-March 1986 17 Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input 5 AN IMPLEMENTATION 5.1 THE EXPECTATION PARSER The usefulness of the methodology described above was tested in the implementation of a connected speech understanding system. An off-the-shelf speech recogni- tion device, a Nippon Electric Corporation DP-200, was added to an existing natural anguage processing system, the Natural Language Computer (NLC) (Ballard 1979, Biermann and Ballard 1980). The expectation system provided the intermediate processing between the error- ful output of the speech recognizer and the deep seman- tics of NLC. The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (VNLCE, Fink 1983). \\[The current system should be distinguished from an earlier voice system (VNLC, Biermann et al 1985), which had no expectation and which handled discrete speech where a 300 millisec- ond pause must follow each word.\\] It should be emphasized, of course, that the central issue here is the study o","@endWordPosition":"3005","@position":"17701","annotationId":"T1","@startWordPosition":"3004","@citStr":"Ballard 1979"},{"#tail":"\n","#text":"o 0, where 0 is equivalent to a probability of one. These ratings are computed this way because they remain inte- gral and still fairly accurately represent the correct values. Also, they can simply be added and subtracted rather than multiplied and divided in the hundreds of calculations required for a single sentence parse. The expectation parser uses an ATN-like represen- tation for its grammar (Woods 1970). Its strategy is top-down. The types of sentences accepted are essential- ly those accepted by the original NLC grammar, imper- ative sentences with nested noun groups and conjunctions (Ballard 1979). An attempt has been made to build as deep a parse as possible so that sentences with the same meaning result in identical parses. Sentences have the same &quot;meaning&quot; if they &quot;result in identical tasks being performed. The various sentence structures that We have have the same meaning we call paraphrases. studied the following types of paraphrasing: 1) WORD<=>WORD 'entry' <=> 'number' 2) ADJ NOUN <=> NOUN QUALIFIER 'positive ntries' < = > 'entries which are positive' 3) NOUN NUMBER <=> DET ORDINAL NOUN 'row 2' <=> 'the second row' 4) CLASSIFIER NOUN < = > NOUN of/in CLASSIFIER 'the row 1 entrie","@endWordPosition":"3718","@position":"22124","annotationId":"T2","@startWordPosition":"3717","@citStr":"Ballard 1979"}]},"title":{"#tail":"\n","#text":"Semantic Processing for a Natural Language Programming System."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"B Ballard"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1980"},"rawString":{"#tail":"\n","#text":"Barnett, J.; Berstein, M.; Gillman, R.; and Kameny, I. 1980 The SDC Speech Understanding System. In Lea 1980: 272-293."},"#text":"\n","pages":{"#tail":"\n","#text":"272--293"},"marker":{"#tail":"\n","#text":"Barnett, Berstein, Gillman, Kameny, 1980"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"es of the expectation system. Note that, in all eight graphs in Figures 11 through 14, the word and sentence error rates from the voice recognizer generally increased with the progress through the dialogue. This is due to the increased rate of speech. However, the actual failure rate of VNLCE did not increase by the same amount. These extra errors were corrected by the expectation system. Figure 16 gives a summary of the average error and correction rates for each test and over all. 7 RELATED LITERATURE A number of speech understanding systems have been developed uring the past fifteen years (Barnett et al 1980, Dixon and Martin 1979, Erman et al 1980, Haton and Pierrel 1976, Lea 1980, Lowerre and Reddy 1980, Medress 1980, Reddy 1976, Walker 1978, and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds","@endWordPosition":"10694","@position":"61115","annotationId":"T3","@startWordPosition":"10691","@citStr":"Barnett et al 1980"}},"title":{"#tail":"\n","#text":"The SDC Speech Understanding System. In Lea"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"J Barnett"},{"#tail":"\n","#text":"M Berstein"},{"#tail":"\n","#text":"R Gillman"},{"#tail":"\n","#text":"I Kameny"}]}},{"date":{"#tail":"\n","#text":"1980"},"issue":{"#tail":"\n","#text":"2"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" used to investigate the viability of this approach and the perform- ance it can achieve. Computational Linguistics, Volume 12, Number 1, January-March 1986 17 Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input 5 AN IMPLEMENTATION 5.1 THE EXPECTATION PARSER The usefulness of the methodology described above was tested in the implementation of a connected speech understanding system. An off-the-shelf speech recogni- tion device, a Nippon Electric Corporation DP-200, was added to an existing natural anguage processing system, the Natural Language Computer (NLC) (Ballard 1979, Biermann and Ballard 1980). The expectation system provided the intermediate processing between the error- ful output of the speech recognizer and the deep seman- tics of NLC. The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (VNLCE, Fink 1983). \\[The current system should be distinguished from an earlier voice system (VNLC, Biermann et al 1985), which had no expectation and which handled discrete speech where a 300 millisec- ond pause must follow each word.\\] It should be emphasized, of course, that the central issue here is the study of expectation mechanisms and","@endWordPosition":"3009","@position":"17729","annotationId":"T4","@startWordPosition":"3006","@citStr":"Biermann and Ballard 1980"}},"title":{"#tail":"\n","#text":"Toward Natural Language Computation."},"volume":{"#tail":"\n","#text":"6"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Biermann, A. and Ballard, B. 1980 Toward Natural Language Computation. AJCL 6(2): 71-86."},"journal":{"#tail":"\n","#text":"AJCL"},"#text":"\n","pages":{"#tail":"\n","#text":"71--86"},"marker":{"#tail":"\n","#text":"Biermann, Ballard, 1980"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A Biermann"},{"#tail":"\n","#text":"B Ballard"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1984"},"rawString":{"#tail":"\n","#text":"Biermann, A.; Guiho, G.; and Kodratoff, Y., Eds. 1984 Automatic Program Construction Techniques. Macmillan Publishing Co., New York, New York."},"#text":"\n","marker":{"#tail":"\n","#text":"Biermann, Guiho, Kodratoff, Eds, 1984"},"publisher":{"#tail":"\n","#text":"Macmillan Publishing Co.,"},"location":{"#tail":"\n","#text":"New York, New York."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"historically observed patterns but is not otherwise observable. The VNLCE processor may be considered to be a learning system of the tradition described, for example, in Michalski et al (1984). The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in Minsky and Papert (1969), assertional statements as in Michalski (1980), or semantic nets as in Winston (1975). That is, the current system learns procedures rather than data structures. There is some literature on procedure acquisition such as the LISP synthesis work described in Biermann et al (1984) and the PROLOG synthesis method of Shapiro (1982). However, the latter methodologies have not been applied to dialogue acquisition. 8 CONCLUSIONS AND AREAS FOR FUTURE RESEARCH We have shown that the ability to use expectation i the form of knowledge about the dialogue being spoken, as with humans, is a tremendous aid to speech recognition by computer. Since expectation, in this research, has been based on repetition of patterns, the expectation system's ability to correct varies, of course, with the repetitiveness of the dialogue itself. We have attempted, in sections 5 and 6, to justify this","@endWordPosition":"11299","@position":"64781","annotationId":"T5","@startWordPosition":"11296","@citStr":"Biermann et al (1984)"}},"title":{"#tail":"\n","#text":"Automatic Program Construction Techniques."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A Biermann"},{"#tail":"\n","#text":"G Guiho"},{"#tail":"\n","#text":"Y Kodratoff"},{"#tail":"\n","#text":"Eds"}]}},{"date":{"#tail":"\n","#text":"1976"},"issue":{"#tail":"\n","#text":"3"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"r rected word-er ror - ra te sentence-er ror - ra te .59 1 .50 1 .50 4 .17 1 .94 61 .22 40 .83 52 .25 56.33 52.66 cor rected sentence-er ror - ra te 3.22 6 .00 5 .38 16 ,00 7 .65 average speak ing ra te 2 .27 2 .95 1 .85 1 .97 2 .26 Figure 16. Average word and sentence rror rate in percent, average speaking rate in words-spoken-per-minute. 34 Computational Linguistics, Volume 12, Number 1, January-March 1986 Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input The acquisition of dialogue as implemented in VNLCE is reminiscent of the program synthesis methodology developed by Biermann and Krishnaswamy (1976) where program flowcharts were constructed from traces of their behaviors. However, the &quot;flowcharts&quot; in the current project are probabilistic in nature and the prob- lems associated with matching incoming sentences to existing nodes has not been previously addressed. Another dialogue acquisition system has been developed by Ho (1984). However, that system has different goals: to enable the user to consciously design a dialogue to embody a particular human-machine interaction. The acquisition system described here is aimed at dealing with ill-formed input and is completely automatic and invisib","@endWordPosition":"11108","@position":"63499","annotationId":"T6","@startWordPosition":"11105","@citStr":"Biermann and Krishnaswamy (1976)"},{"#tail":"\n","#text":" implemented in the VNLCE system. This theory has been aimed at error correction of random errors using expectation based on historical information. However, there are many possible exten- sions that could be examined in the future and added to the implementation if the investigation indicates that it would create a yet more usable system. These include the following: ? use of low level knowledge from the speech recognition phase, ? use of high level knowledge about the domain in partic- ular and the dialogue task in general, ? a &quot;continue&quot; facility and an &quot;auto-loop&quot; facility as described by Biermann and Krishnaswamy (1976), ? a &quot;conditioning&quot; facility as described by Fink et al (1985), ? implementation f new types of paraphrasing, ? checking a larger environment in the expectation acquisition algorithm when deciding if an incoming sentence is the same or similar to one already seen, and ? examining inter-speaker dialogue patterns. All but two of these areas for expansion are aimed at moving the expectation system from one that finds patterns in a user's dialogues and acquires historical knowledge about them to one that can acquire true procedures. The first two areas for expansion have noth- ing to do with crea","@endWordPosition":"11885","@position":"68259","annotationId":"T7","@startWordPosition":"11882","@citStr":"Biermann and Krishnaswamy (1976)"}]},"title":{"#tail":"\n","#text":"Construction of Programs from Example Computations."},"volume":{"#tail":"\n","#text":"2"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Biermann, A. and Krishnaswamy, R. 1976 Construction of Programs from Example Computations. IEEE Transactions on Software Engineering SE-2(3): 141-153."},"journal":{"#tail":"\n","#text":"IEEE Transactions on Software Engineering"},"#text":"\n","pages":{"#tail":"\n","#text":"141--153"},"marker":{"#tail":"\n","#text":"Biermann, Krishnaswamy, 1976"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A Biermann"},{"#tail":"\n","#text":"R Krishnaswamy"}]}},{"volume":{"#tail":"\n","#text":"28"},"#tail":"\n","date":{"#tail":"\n","#text":"1985"},"rawString":{"#tail":"\n","#text":"Biermann, A.; Rodman, R.; Rubin, D.; and Heidlage, J. 1985. Natural Language with Discrete Speech as a Mode for Human-to-Machine Communication. Comm. of ACM 28(6)."},"journal":{"#tail":"\n","#text":"Comm. of ACM"},"#text":"\n","issue":{"#tail":"\n","#text":"6"},"marker":{"#tail":"\n","#text":"Biermann, Rodman, Rubin, Heidlage, 1985"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" understanding system. An off-the-shelf speech recogni- tion device, a Nippon Electric Corporation DP-200, was added to an existing natural anguage processing system, the Natural Language Computer (NLC) (Ballard 1979, Biermann and Ballard 1980). The expectation system provided the intermediate processing between the error- ful output of the speech recognizer and the deep seman- tics of NLC. The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (VNLCE, Fink 1983). \\[The current system should be distinguished from an earlier voice system (VNLC, Biermann et al 1985), which had no expectation and which handled discrete speech where a 300 millisec- ond pause must follow each word.\\] It should be emphasized, of course, that the central issue here is the study of expectation mechanisms and the details of the design decisions could have been made in rather different ways. Thus one could have implemented expectation error correction with a typed input system or with a speech input system that integrates voice signal processing with higher level functions in a way not possi- ble with a commercial recognizer. This implementation shows only one way in which the f","@endWordPosition":"3065","@position":"18105","annotationId":"T8","@startWordPosition":"3062","@citStr":"Biermann et al 1985"}},"title":{"#tail":"\n","#text":"Natural Language with Discrete Speech as a Mode for Human-to-Machine Communication."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A Biermann"},{"#tail":"\n","#text":"R Rodman"},{"#tail":"\n","#text":"D Rubin"},{"#tail":"\n","#text":"J Heidlage"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1983"},"rawString":{"#tail":"\n","#text":"Carbonell, J. and Hayes, P. 1983 Recovery Strategies for Parsing Extragrammatical L nguage. AJCL 9(3-4): 123-146."},"journal":{"#tail":"\n","#text":"AJCL"},"#text":"\n","pages":{"#tail":"\n","#text":"9--3"},"marker":{"#tail":"\n","#text":"Carbonell, Hayes, 1983"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed input has been studied by Carbonell and Hayes (1983), Granger (1983), Jensen et al (1983), Kwasny and Sondheimer (1981), Riesbeek and Schank (1976), Thompson (1980), Weis- chedel and Black (1980), and Weischedel and Sondheim- er (1983). A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level. However, these methodologies have not used historical information at the dialogue level as described here. In most cases, the goal of these systems is to characterize the ill-formed input into classes of errors and to correct on that basis. The work described here makes no at","@endWordPosition":"10815","@position":"61880","annotationId":"T9","@startWordPosition":"10812","@citStr":"Carbonell and Hayes (1983)"}},"title":{"#tail":"\n","#text":"Recovery Strategies for Parsing Extragrammatical L nguage."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"J Carbonell"},{"#tail":"\n","#text":"P Hayes"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1979"},"rawString":{"#tail":"\n","#text":"Dixon, N. and Martin, T., Eds. 1979 Automatic Speech and Speaker Recognition. IEEE Press, New York, New York."},"#text":"\n","marker":{"#tail":"\n","#text":"Dixon, Martin, Eds, 1979"},"publisher":{"#tail":"\n","#text":"IEEE Press,"},"location":{"#tail":"\n","#text":"New York, New York."},"title":{"#tail":"\n","#text":"Automatic Speech and Speaker Recognition."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"N Dixon"},{"#tail":"\n","#text":"T Martin"},{"#tail":"\n","#text":"Eds"}]}},{"volume":{"#tail":"\n","#text":"12"},"#tail":"\n","date":{"#tail":"\n","#text":"1980"},"rawString":{"#tail":"\n","#text":"Erman, L.; Hayes-Roth, F; Lesser, V.; and Reddy, D. 1980 The Hearsay-II Speech Understanding System: Integrating Knowledge to Resolve Uncertainty. Computing Surveys, 12(2)."},"journal":{"#tail":"\n","#text":"Computing Surveys,"},"#text":"\n","issue":{"#tail":"\n","#text":"2"},"marker":{"#tail":"\n","#text":"Erman, Hayes-Roth, Lesser, Reddy, 1980"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" all eight graphs in Figures 11 through 14, the word and sentence error rates from the voice recognizer generally increased with the progress through the dialogue. This is due to the increased rate of speech. However, the actual failure rate of VNLCE did not increase by the same amount. These extra errors were corrected by the expectation system. Figure 16 gives a summary of the average error and correction rates for each test and over all. 7 RELATED LITERATURE A number of speech understanding systems have been developed uring the past fifteen years (Barnett et al 1980, Dixon and Martin 1979, Erman et al 1980, Haton and Pierrel 1976, Lea 1980, Lowerre and Reddy 1980, Medress 1980, Reddy 1976, Walker 1978, and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in t","@endWordPosition":"10702","@position":"61156","annotationId":"T10","@startWordPosition":"10699","@citStr":"Erman et al 1980"}},"title":{"#tail":"\n","#text":"The Hearsay-II Speech Understanding System: Integrating Knowledge to Resolve Uncertainty."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"L Erman"},{"#tail":"\n","#text":"F Hayes-Roth"},{"#tail":"\n","#text":"V Lesser"},{"#tail":"\n","#text":"D Reddy"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1983"},"institution":{"#tail":"\n","#text":"Dissertation, Department of Computer Science, Duke University."},"rawString":{"#tail":"\n","#text":"Fink, P. 1983 The Acquisition and Use of Dialogue Expectation in Speech Recognition, Dissertation, Department of Computer Science, Duke University."},"#text":"\n","marker":{"#tail":"\n","#text":"Fink, 1983"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ess of the methodology described above was tested in the implementation of a connected speech understanding system. An off-the-shelf speech recogni- tion device, a Nippon Electric Corporation DP-200, was added to an existing natural anguage processing system, the Natural Language Computer (NLC) (Ballard 1979, Biermann and Ballard 1980). The expectation system provided the intermediate processing between the error- ful output of the speech recognizer and the deep seman- tics of NLC. The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (VNLCE, Fink 1983). \\[The current system should be distinguished from an earlier voice system (VNLC, Biermann et al 1985), which had no expectation and which handled discrete speech where a 300 millisec- ond pause must follow each word.\\] It should be emphasized, of course, that the central issue here is the study of expectation mechanisms and the details of the design decisions could have been made in rather different ways. Thus one could have implemented expectation error correction with a typed input system or with a speech input system that integrates voice signal processing with higher level functions in a","@endWordPosition":"3049","@position":"18002","annotationId":"T11","@startWordPosition":"3048","@citStr":"Fink 1983"},{"#tail":"\n","#text":"ng in the sentence, the expectation parser will error correct the sentence to the most probable value, or the first one in the set if the probabilities are equal, here the value one for row 1. Thus, both options are imperfect in terms of the error correction capabilities that they can provide. The comparison that must be made to deter- mine which option is better in a given situation is how often the first will error correct incorrectly as opposed to how much error correcting power we will lose by using the second. How it is done is beyond the scope of this paper but is explained in detail in Fink (1983). The Merge function takes two inputs, M1 and M2, which have been determined by the Mergeable function to be similar in some way by considering their respective environments and meanings. Based upon how similar the two meanings are, Merge creates a meaning M that is a generalization of M1 and M2, sometimes employing an argument. Thus, there are only two possible kinds of matches at this point between an input sentence and a member of the expected sentence set, an exact match or a similar match. In the case of an exact match M = M1 = M2 and M replaces Mi in the expected ialogue. In the case of ","@endWordPosition":"7874","@position":"46302","annotationId":"T12","@startWordPosition":"7873","@citStr":"Fink (1983)"},{"#tail":"\n","#text":", Lea 1980, Lowerre and Reddy 1980, Medress 1980, Reddy 1976, Walker 1978, and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed input has been studied by Carbonell and Hayes (1983), Granger (1983), Jensen et al (1983), Kwasny and Sondheimer (1981), Riesbeek and Schank (1976), Thompson (1980), Weis- chedel and Black (1980), and Weischedel and Sondheim- er (1983). A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level. However, these methodologies have not used historical information at the dialogue level as described here. In most cases, the goal of these systems is to characterize the ill-formed input","@endWordPosition":"10801","@position":"61791","annotationId":"T13","@startWordPosition":"10800","@citStr":"Fink (1983)"}]},"title":{"#tail":"\n","#text":"The Acquisition and Use of Dialogue Expectation in Speech Recognition,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"P Fink"}}},{"date":{"#tail":"\n","#text":"1985"},"issue":{"#tail":"\n","#text":"1"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"on of random errors using expectation based on historical information. However, there are many possible exten- sions that could be examined in the future and added to the implementation if the investigation indicates that it would create a yet more usable system. These include the following: ? use of low level knowledge from the speech recognition phase, ? use of high level knowledge about the domain in partic- ular and the dialogue task in general, ? a &quot;continue&quot; facility and an &quot;auto-loop&quot; facility as described by Biermann and Krishnaswamy (1976), ? a &quot;conditioning&quot; facility as described by Fink et al (1985), ? implementation f new types of paraphrasing, ? checking a larger environment in the expectation acquisition algorithm when deciding if an incoming sentence is the same or similar to one already seen, and ? examining inter-speaker dialogue patterns. All but two of these areas for expansion are aimed at moving the expectation system from one that finds patterns in a user's dialogues and acquires historical knowledge about them to one that can acquire true procedures. The first two areas for expansion have noth- ing to do with creating a true procedure acquisition module but would be highly de","@endWordPosition":"11896","@position":"68322","annotationId":"T14","@startWordPosition":"11893","@citStr":"Fink et al (1985)"}},"title":{"#tail":"\n","#text":"Computer Control Via Limited Natural Language."},"volume":{"#tail":"\n","#text":"14"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Fink, P.; Sigmon, A.; and Biermann, A. 1985 Computer Control Via Limited Natural Language. IEEE Trans SMC SMC-14(1): 54-68."},"journal":{"#tail":"\n","#text":"IEEE Trans SMC"},"#text":"\n","pages":{"#tail":"\n","#text":"54--68"},"marker":{"#tail":"\n","#text":"Fink, Sigmon, Biermann, 1985"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"P Fink"},{"#tail":"\n","#text":"A Sigmon"},{"#tail":"\n","#text":"A Biermann"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1983"},"rawString":{"#tail":"\n","#text":"Granger, R. 1983 The NOMAD System: Expectation-Based Detection and Correction of Errors during Understanding of Syntactically Ill-Formed Text. AJCL 9(3-4): 188-196."},"journal":{"#tail":"\n","#text":"AJCL"},"#text":"\n","pages":{"#tail":"\n","#text":"9--3"},"marker":{"#tail":"\n","#text":"Granger, 1983"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ost of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed input has been studied by Carbonell and Hayes (1983), Granger (1983), Jensen et al (1983), Kwasny and Sondheimer (1981), Riesbeek and Schank (1976), Thompson (1980), Weis- chedel and Black (1980), and Weischedel and Sondheim- er (1983). A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level. However, these methodologies have not used historical information at the dialogue level as described here. In most cases, the goal of these systems is to characterize the ill-formed input into classes of errors and to correct on that basis. The work described here makes no attempt to classif","@endWordPosition":"10817","@position":"61896","annotationId":"T15","@startWordPosition":"10816","@citStr":"Granger (1983)"}},"title":{"#tail":"\n","#text":"The NOMAD System: Expectation-Based Detection and Correction of Errors during Understanding of Syntactically Ill-Formed Text."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"R Granger"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1976"},"rawString":{"#tail":"\n","#text":"Haton, J. and Pierrel, J. 1976 Organization and Operation of a Connected Speech Understanding System at Lexical, Syntactic and Semantic Levels. 1976 IEEE International Conference on Acoustics, Speech and Signal Processing, Philadelphia, Pennsylvania: 430-433."},"#text":"\n","pages":{"#tail":"\n","#text":"430--433"},"marker":{"#tail":"\n","#text":"Haton, Pierrel, 1976"},"location":{"#tail":"\n","#text":"Philadelphia, Pennsylvania:"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"in Figures 11 through 14, the word and sentence error rates from the voice recognizer generally increased with the progress through the dialogue. This is due to the increased rate of speech. However, the actual failure rate of VNLCE did not increase by the same amount. These extra errors were corrected by the expectation system. Figure 16 gives a summary of the average error and correction rates for each test and over all. 7 RELATED LITERATURE A number of speech understanding systems have been developed uring the past fifteen years (Barnett et al 1980, Dixon and Martin 1979, Erman et al 1980, Haton and Pierrel 1976, Lea 1980, Lowerre and Reddy 1980, Medress 1980, Reddy 1976, Walker 1978, and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in ","@endWordPosition":"10706","@position":"61180","annotationId":"T16","@startWordPosition":"10703","@citStr":"Haton and Pierrel 1976"}},"title":{"#tail":"\n","#text":"Organization and Operation of a Connected Speech Understanding System at Lexical, Syntactic and Semantic Levels."},"booktitle":{"#tail":"\n","#text":"IEEE International Conference on Acoustics, Speech and Signal Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"J Haton"},{"#tail":"\n","#text":"J Pierrel"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1984"},"institution":{"#tail":"\n","#text":"Computer Science Department, California Institute of Technology."},"rawString":{"#tail":"\n","#text":"Ho, T.-P. 1984 The Dialogue Designing Dialogue System, Dissertation, Computer Science Department, California Institute of Technology."},"#text":"\n","marker":{"#tail":"\n","#text":"Ho, 1984"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" Linguistics, Volume 12, Number 1, January-March 1986 Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input The acquisition of dialogue as implemented in VNLCE is reminiscent of the program synthesis methodology developed by Biermann and Krishnaswamy (1976) where program flowcharts were constructed from traces of their behaviors. However, the &quot;flowcharts&quot; in the current project are probabilistic in nature and the prob- lems associated with matching incoming sentences to existing nodes has not been previously addressed. Another dialogue acquisition system has been developed by Ho (1984). However, that system has different goals: to enable the user to consciously design a dialogue to embody a particular human-machine interaction. The acquisition system described here is aimed at dealing with ill-formed input and is completely automatic and invisible to the user. It self activates to bias recognition toward historically observed patterns but is not otherwise observable. The VNLCE processor may be considered to be a learning system of the tradition described, for example, in Michalski et al (1984). The current system learns finite state flowcharts whereas typical learning syste","@endWordPosition":"11156","@position":"63834","annotationId":"T17","@startWordPosition":"11155","@citStr":"Ho (1984)"}},"title":{"#tail":"\n","#text":"The Dialogue Designing Dialogue System, Dissertation,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"T-P Ho"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1983"},"rawString":{"#tail":"\n","#text":"Jensen, K.; Heidorn, G.; Miller, L.; and Ravin, Y. 1983 Parse Fitting and Prose Fixing: Getting a Hold on Ill-Formedness. AJCL 9(3-4): 147-160."},"journal":{"#tail":"\n","#text":"AJCL"},"#text":"\n","pages":{"#tail":"\n","#text":"9--3"},"marker":{"#tail":"\n","#text":"Jensen, Heidorn, Miller, Ravin, 1983"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"orts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed input has been studied by Carbonell and Hayes (1983), Granger (1983), Jensen et al (1983), Kwasny and Sondheimer (1981), Riesbeek and Schank (1976), Thompson (1980), Weis- chedel and Black (1980), and Weischedel and Sondheim- er (1983). A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level. However, these methodologies have not used historical information at the dialogue level as described here. In most cases, the goal of these systems is to characterize the ill-formed input into classes of errors and to correct on that basis. The work described here makes no attempt to classify the errors, but tre","@endWordPosition":"10821","@position":"61917","annotationId":"T18","@startWordPosition":"10818","@citStr":"Jensen et al (1983)"}},"title":{"#tail":"\n","#text":"Parse Fitting and Prose Fixing: Getting a Hold on Ill-Formedness."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"K Jensen"},{"#tail":"\n","#text":"G Heidorn"},{"#tail":"\n","#text":"L Miller"},{"#tail":"\n","#text":"Y Ravin"}]}},{"date":{"#tail":"\n","#text":"1981"},"issue":{"#tail":"\n","#text":"2"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed input has been studied by Carbonell and Hayes (1983), Granger (1983), Jensen et al (1983), Kwasny and Sondheimer (1981), Riesbeek and Schank (1976), Thompson (1980), Weis- chedel and Black (1980), and Weischedel and Sondheim- er (1983). A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level. However, these methodologies have not used historical information at the dialogue level as described here. In most cases, the goal of these systems is to characterize the ill-formed input into classes of errors and to correct on that basis. The work described here makes no attempt to classify the errors, but treats them as random events that","@endWordPosition":"10825","@position":"61947","annotationId":"T19","@startWordPosition":"10822","@citStr":"Kwasny and Sondheimer (1981)"}},"title":{"#tail":"\n","#text":"Relaxation Techniques for Parsing Grammatically Ill-Formed Input in Natural Language Understanding Systems."},"volume":{"#tail":"\n","#text":"7"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Kwasny, S. and Sondheimer, N. 1981 Relaxation Techniques for Parsing Grammatically Ill-Formed Input in Natural Language Understanding Systems. AJCL 7(2): 99-108."},"journal":{"#tail":"\n","#text":"AJCL"},"#text":"\n","pages":{"#tail":"\n","#text":"99--108"},"marker":{"#tail":"\n","#text":"Kwasny, Sondheimer, 1981"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"S Kwasny"},{"#tail":"\n","#text":"N Sondheimer"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1980"},"rawString":{"#tail":"\n","#text":"Lea, W., Ed. 1980 Trends in Speech Recognition. Prentice-Hall, New Jersey."},"#text":"\n","marker":{"#tail":"\n","#text":"Lea, Ed, 1980"},"publisher":{"#tail":"\n","#text":"Prentice-Hall,"},"location":{"#tail":"\n","#text":"New Jersey."},"title":{"#tail":"\n","#text":"Trends in Speech Recognition."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"W Lea"},{"#tail":"\n","#text":"Ed"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1980"},"rawString":{"#tail":"\n","#text":"Lowerre, B. and Reddy, R. 1980 The Harpy Speech Understanding System. In Lea 1980: 340-360."},"#text":"\n","pages":{"#tail":"\n","#text":"340--360"},"marker":{"#tail":"\n","#text":"Lowerre, Reddy, 1980"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" and sentence error rates from the voice recognizer generally increased with the progress through the dialogue. This is due to the increased rate of speech. However, the actual failure rate of VNLCE did not increase by the same amount. These extra errors were corrected by the expectation system. Figure 16 gives a summary of the average error and correction rates for each test and over all. 7 RELATED LITERATURE A number of speech understanding systems have been developed uring the past fifteen years (Barnett et al 1980, Dixon and Martin 1979, Erman et al 1980, Haton and Pierrel 1976, Lea 1980, Lowerre and Reddy 1980, Medress 1980, Reddy 1976, Walker 1978, and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handli","@endWordPosition":"10712","@position":"61214","annotationId":"T20","@startWordPosition":"10709","@citStr":"Lowerre and Reddy 1980"}},"title":{"#tail":"\n","#text":"The Harpy Speech Understanding System. In Lea"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"B Lowerre"},{"#tail":"\n","#text":"R Reddy"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1980"},"rawString":{"#tail":"\n","#text":"Medress, M. 1980 The Sperry Univac System for Continuous Speech Recognition. In Lea 1980."},"#text":"\n","marker":{"#tail":"\n","#text":"Medress, 1980"},"location":{"#tail":"\n","#text":"Lea"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"s from the voice recognizer generally increased with the progress through the dialogue. This is due to the increased rate of speech. However, the actual failure rate of VNLCE did not increase by the same amount. These extra errors were corrected by the expectation system. Figure 16 gives a summary of the average error and correction rates for each test and over all. 7 RELATED LITERATURE A number of speech understanding systems have been developed uring the past fifteen years (Barnett et al 1980, Dixon and Martin 1979, Erman et al 1980, Haton and Pierrel 1976, Lea 1980, Lowerre and Reddy 1980, Medress 1980, Reddy 1976, Walker 1978, and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed ","@endWordPosition":"10714","@position":"61228","annotationId":"T21","@startWordPosition":"10713","@citStr":"Medress 1980"}},"title":{"#tail":"\n","#text":"The Sperry Univac System for Continuous Speech Recognition. In"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"M Medress"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1980"},"rawString":{"#tail":"\n","#text":"Michalski, R. 1980 Pattern Recognition as Rule-Guided Inductive Inference. IEEE Trans. Pattern Analysis and Machine Intelligence."},"journal":{"#tail":"\n","#text":"IEEE Trans. Pattern Analysis and Machine Intelligence."},"#text":"\n","marker":{"#tail":"\n","#text":"Michalski, 1980"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"embody a particular human-machine interaction. The acquisition system described here is aimed at dealing with ill-formed input and is completely automatic and invisible to the user. It self activates to bias recognition toward historically observed patterns but is not otherwise observable. The VNLCE processor may be considered to be a learning system of the tradition described, for example, in Michalski et al (1984). The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in Minsky and Papert (1969), assertional statements as in Michalski (1980), or semantic nets as in Winston (1975). That is, the current system learns procedures rather than data structures. There is some literature on procedure acquisition such as the LISP synthesis work described in Biermann et al (1984) and the PROLOG synthesis method of Shapiro (1982). However, the latter methodologies have not been applied to dialogue acquisition. 8 CONCLUSIONS AND AREAS FOR FUTURE RESEARCH We have shown that the ability to use expectation i the form of knowledge about the dialogue being spoken, as with humans, is a tremendous aid to speech recognition by computer. Since expecta","@endWordPosition":"11262","@position":"64549","annotationId":"T22","@startWordPosition":"11261","@citStr":"Michalski (1980)"}},"title":{"#tail":"\n","#text":"Pattern Recognition as Rule-Guided Inductive Inference."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"R Michalski"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1984"},"rawString":{"#tail":"\n","#text":"Michalski, R.; Carbonell, J.; and Mitchell, T. 1984 Machine Learning. Springer Verlag, New York."},"#text":"\n","marker":{"#tail":"\n","#text":"Michalski, Carbonell, Mitchell, 1984"},"publisher":{"#tail":"\n","#text":"Springer Verlag,"},"location":{"#tail":"\n","#text":"New York."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"s has not been previously addressed. Another dialogue acquisition system has been developed by Ho (1984). However, that system has different goals: to enable the user to consciously design a dialogue to embody a particular human-machine interaction. The acquisition system described here is aimed at dealing with ill-formed input and is completely automatic and invisible to the user. It self activates to bias recognition toward historically observed patterns but is not otherwise observable. The VNLCE processor may be considered to be a learning system of the tradition described, for example, in Michalski et al (1984). The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in Minsky and Papert (1969), assertional statements as in Michalski (1980), or semantic nets as in Winston (1975). That is, the current system learns procedures rather than data structures. There is some literature on procedure acquisition such as the LISP synthesis work described in Biermann et al (1984) and the PROLOG synthesis method of Shapiro (1982). However, the latter methodologies have not been applied to dialogue acquisition. 8 CONCLUSIONS AND AREAS FOR FUTURE RES","@endWordPosition":"11235","@position":"64352","annotationId":"T23","@startWordPosition":"11232","@citStr":"Michalski et al (1984)"}},"booktitle":{"#tail":"\n","#text":"Machine Learning."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"R Michalski"},{"#tail":"\n","#text":"J Carbonell"},{"#tail":"\n","#text":"T Mitchell"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1969"},"rawString":{"#tail":"\n","#text":"Minsky, M. and Papert, S. 1969 Perceptrons. MIT Press, Cambridge, Massachusetts."},"#text":"\n","marker":{"#tail":"\n","#text":"Minsky, Papert, 1969"},"publisher":{"#tail":"\n","#text":"MIT Press,"},"location":{"#tail":"\n","#text":"Cambridge, Massachusetts."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"to enable the user to consciously design a dialogue to embody a particular human-machine interaction. The acquisition system described here is aimed at dealing with ill-formed input and is completely automatic and invisible to the user. It self activates to bias recognition toward historically observed patterns but is not otherwise observable. The VNLCE processor may be considered to be a learning system of the tradition described, for example, in Michalski et al (1984). The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in Minsky and Papert (1969), assertional statements as in Michalski (1980), or semantic nets as in Winston (1975). That is, the current system learns procedures rather than data structures. There is some literature on procedure acquisition such as the LISP synthesis work described in Biermann et al (1984) and the PROLOG synthesis method of Shapiro (1982). However, the latter methodologies have not been applied to dialogue acquisition. 8 CONCLUSIONS AND AREAS FOR FUTURE RESEARCH We have shown that the ability to use expectation i the form of knowledge about the dialogue being spoken, as with humans, is a tremendous aid t","@endWordPosition":"11256","@position":"64502","annotationId":"T24","@startWordPosition":"11253","@citStr":"Minsky and Papert (1969)"}},"title":{"#tail":"\n","#text":"Perceptrons."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"M Minsky"},{"#tail":"\n","#text":"S Papert"}]}},{"date":{"#tail":"\n","#text":"1976"},"issue":{"#tail":"\n","#text":"4"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ce recognizer generally increased with the progress through the dialogue. This is due to the increased rate of speech. However, the actual failure rate of VNLCE did not increase by the same amount. These extra errors were corrected by the expectation system. Figure 16 gives a summary of the average error and correction rates for each test and over all. 7 RELATED LITERATURE A number of speech understanding systems have been developed uring the past fifteen years (Barnett et al 1980, Dixon and Martin 1979, Erman et al 1980, Haton and Pierrel 1976, Lea 1980, Lowerre and Reddy 1980, Medress 1980, Reddy 1976, Walker 1978, and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed input has be","@endWordPosition":"10716","@position":"61240","annotationId":"T25","@startWordPosition":"10715","@citStr":"Reddy 1976"}},"title":{"#tail":"\n","#text":"Speech Recognition by Machine: A Review."},"volume":{"#tail":"\n","#text":"64"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Reddy, D. 1976 Speech Recognition by Machine: A Review. Proceedings of the IEEE 64(4): 501-531."},"journal":{"#tail":"\n","#text":"Proceedings of the IEEE"},"#text":"\n","pages":{"#tail":"\n","#text":"501--531"},"marker":{"#tail":"\n","#text":"Reddy, 1976"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"D Reddy"}}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Tech. Rep. 78,"},"date":{"#tail":"\n","#text":"1976"},"institution":{"#tail":"\n","#text":"Computer Science Department, Yale University,"},"rawString":{"#tail":"\n","#text":"Riesbeck, C. and Schank, R. 1976 Comprehension by Computer: Expectation-Based Analysis of Sentences in Context. Tech. Rep. 78, Computer Science Department, Yale University, New Haven, Connecticut."},"#text":"\n","marker":{"#tail":"\n","#text":"Riesbeck, Schank, 1976"},"location":{"#tail":"\n","#text":"New Haven, Connecticut."},"title":{"#tail":"\n","#text":"Comprehension by Computer: Expectation-Based Analysis of Sentences in Context."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"C Riesbeck"},{"#tail":"\n","#text":"R Schank"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1977"},"rawString":{"#tail":"\n","#text":"Schank, R. and Abelson, R. 1977 Scripts, Plans, Goals, and Understanding. Lawrence Erlbaum Associates, Hillsdale, New Jersey."},"#text":"\n","marker":{"#tail":"\n","#text":"Schank, Abelson, 1977"},"location":{"#tail":"\n","#text":"Hillsdale, New Jersey."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"Number 1, January-March 1986 Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input 3 A REPRESENTATION FOR USER BEHAVIORS Suppose a user inputs the following sequence: Sentence Label Display my mail summary for today. S 1 Show me this letter. (with touch input) $2 (the letter appears on the screen) Remove this letter. $3 Display the letter from JA. $4 (letter appears on the screen) Delete it. $5 Log off. $6 We denote the meaning of each sentence Si with the notation M(Si). The exact form of M(Si) need not be discussed at this point; it could be a conceptual depend- ence graph (Schank and Abelson 1977), a deep parse of Si, or some other representation. A user behavior is represented by a network, or directed graph, of such meanings. At the beginning of a task, the state of the interaction is represented by the start state of the graph. The immediate successors of this state are the typical opening meaning structures for this user, and succeeding states represent, historically, paths that have been followed by this user. It is important hat if two sentences, Si and Sj, have approximately the same meaning this should be clear in the representations M(Si) and M(Sj). Our algorithm, described be","@endWordPosition":"1153","@position":"7147","annotationId":"T26","@startWordPosition":"1150","@citStr":"Schank and Abelson 1977"},{"#tail":"\n","#text":" multiplication, simul- taneous linear equations, and Gaussian elimination. Non-linear algebra problems that require matrix-type representations can also be learned, such as gradebook maintenance and invoice manipulation. Though the implemented system is limited to matrix-oriented prob- lems, the theoretical system is capable of learning a wide range of problem types. The only requirement on the problem or situation is that it can be entered into the expectation system in the form of examples. Thus, for example, it can acquire a &quot;script&quot; such as the one for going to a restaurant as defined in Schank and Abelson (1977). The expectation module takes two inputs and produc- es two outputs. The inputs are ? the user behavior graph discussed earlier, called the expected ialogue D, and ? the meaning of the most recently input sentence, M(S). Its outputs are a new expected dialogue D modified according to the latest input sentence M(S) and an expected sentence set E. These outputs are produced based upon the inputs and the functions Predicts, Merge- able, and Merge. The role of the predicate Predicts can be best under- stood by recalling the function of the parser P. P uses the set of expected sentences E(current)","@endWordPosition":"6835","@position":"40297","annotationId":"T27","@startWordPosition":"6832","@citStr":"Schank and Abelson (1977)"}]},"title":{"#tail":"\n","#text":"Scripts, Plans, Goals, and Understanding. Lawrence Erlbaum Associates,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"R Schank"},{"#tail":"\n","#text":"R Abelson"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1982"},"rawString":{"#tail":"\n","#text":"Shapiro, E. 1982 Algorithmic Program Debugging. MIT Press, Cambridge, Massachusetts."},"#text":"\n","marker":{"#tail":"\n","#text":"Shapiro, 1982"},"publisher":{"#tail":"\n","#text":"MIT Press,"},"location":{"#tail":"\n","#text":"Cambridge, Massachusetts."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"vable. The VNLCE processor may be considered to be a learning system of the tradition described, for example, in Michalski et al (1984). The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in Minsky and Papert (1969), assertional statements as in Michalski (1980), or semantic nets as in Winston (1975). That is, the current system learns procedures rather than data structures. There is some literature on procedure acquisition such as the LISP synthesis work described in Biermann et al (1984) and the PROLOG synthesis method of Shapiro (1982). However, the latter methodologies have not been applied to dialogue acquisition. 8 CONCLUSIONS AND AREAS FOR FUTURE RESEARCH We have shown that the ability to use expectation i the form of knowledge about the dialogue being spoken, as with humans, is a tremendous aid to speech recognition by computer. Since expectation, in this research, has been based on repetition of patterns, the expectation system's ability to correct varies, of course, with the repetitiveness of the dialogue itself. We have attempted, in sections 5 and 6, to justify this decision by demon- strating how the expectation s","@endWordPosition":"11307","@position":"64831","annotationId":"T28","@startWordPosition":"11306","@citStr":"Shapiro (1982)"}},"title":{"#tail":"\n","#text":"Algorithmic Program Debugging."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"E Shapiro"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1980"},"rawString":{"#tail":"\n","#text":"Thompson, B. 1980 Linguistic Analysis of Natural Language Communication with Computers. Proceedings of the Eighth International Conference on Computational Linguistics, Tokyo, Japan: 190-201."},"#text":"\n","marker":{"#tail":"\n","#text":"Thompson, 1980"},"location":{"#tail":"\n","#text":"Tokyo, Japan:"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed input has been studied by Carbonell and Hayes (1983), Granger (1983), Jensen et al (1983), Kwasny and Sondheimer (1981), Riesbeek and Schank (1976), Thompson (1980), Weis- chedel and Black (1980), and Weischedel and Sondheim- er (1983). A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level. However, these methodologies have not used historical information at the dialogue level as described here. In most cases, the goal of these systems is to characterize the ill-formed input into classes of errors and to correct on that basis. The work described here makes no attempt to classify the errors, but treats them as random events that occur at any point in a sentence. Thus, an e","@endWordPosition":"10831","@position":"61992","annotationId":"T29","@startWordPosition":"10830","@citStr":"Thompson (1980)"}},"title":{"#tail":"\n","#text":"Linguistic Analysis of Natural Language Communication with Computers."},"booktitle":{"#tail":"\n","#text":"Proceedings of the Eighth International Conference on Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"B Thompson"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1978"},"rawString":{"#tail":"\n","#text":"Walker, D., Ed. 1978 Understahding Spoken Language. Elsevier NorthHolland, New York, New York."},"#text":"\n","marker":{"#tail":"\n","#text":"Walker, Ed, 1978"},"publisher":{"#tail":"\n","#text":"Elsevier NorthHolland,"},"location":{"#tail":"\n","#text":"New York, New York."},"title":{"#tail":"\n","#text":"Understahding Spoken Language."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"D Walker"},{"#tail":"\n","#text":"Ed"}]}},{"volume":{"#tail":"\n","#text":"6"},"#tail":"\n","date":{"#tail":"\n","#text":"1980"},"rawString":{"#tail":"\n","#text":"Weischedel, R. and Black, J. 1980 Responding Intelligently to Unparsable Inputs. AJCL 6(2): 97-109."},"journal":{"#tail":"\n","#text":"AJCL"},"#text":"\n","pages":{"#tail":"\n","#text":"97--109"},"issue":{"#tail":"\n","#text":"2"},"marker":{"#tail":"\n","#text":"Weischedel, Black, 1980"},"title":{"#tail":"\n","#text":"Responding Intelligently to Unparsable Inputs."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"R Weischedel"},{"#tail":"\n","#text":"J Black"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1983"},"rawString":{"#tail":"\n","#text":"Weisehedel, R. and Sondheimer, N. 1983 Meta-Rules as a Basis for Processing Ill-Formed Input. AJCL 9(3-4): 161-177."},"journal":{"#tail":"\n","#text":"AJCL"},"#text":"\n","pages":{"#tail":"\n","#text":"9--3"},"marker":{"#tail":"\n","#text":"Weisehedel, Sondheimer, 1983"},"title":{"#tail":"\n","#text":"Meta-Rules as a Basis for Processing Ill-Formed Input."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"R Weisehedel"},{"#tail":"\n","#text":"N Sondheimer"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1975"},"institution":{"#tail":"\n","#text":"Psychology of Computer Vision."},"rawString":{"#tail":"\n","#text":"Winston, P. 1975 Learning Structural Descriptions from Examples. In Winston, P., Ed., Psychology of Computer Vision. McGraw-Hill, New York, New York."},"#text":"\n","marker":{"#tail":"\n","#text":"Winston, 1975"},"publisher":{"#tail":"\n","#text":"McGraw-Hill,"},"location":{"#tail":"\n","#text":"New York, New York."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"tion. The acquisition system described here is aimed at dealing with ill-formed input and is completely automatic and invisible to the user. It self activates to bias recognition toward historically observed patterns but is not otherwise observable. The VNLCE processor may be considered to be a learning system of the tradition described, for example, in Michalski et al (1984). The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in Minsky and Papert (1969), assertional statements as in Michalski (1980), or semantic nets as in Winston (1975). That is, the current system learns procedures rather than data structures. There is some literature on procedure acquisition such as the LISP synthesis work described in Biermann et al (1984) and the PROLOG synthesis method of Shapiro (1982). However, the latter methodologies have not been applied to dialogue acquisition. 8 CONCLUSIONS AND AREAS FOR FUTURE RESEARCH We have shown that the ability to use expectation i the form of knowledge about the dialogue being spoken, as with humans, is a tremendous aid to speech recognition by computer. Since expectation, in this research, has been based ","@endWordPosition":"11269","@position":"64588","annotationId":"T30","@startWordPosition":"11268","@citStr":"Winston (1975)"}},"title":{"#tail":"\n","#text":"Learning Structural Descriptions from Examples. In"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"P Winston"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1980"},"rawString":{"#tail":"\n","#text":"Wolf, J. and Woods, W. 1980 The HWIM Speech Understanding System. In Lea 1980: 316-339."},"#text":"\n","pages":{"#tail":"\n","#text":"316--339"},"marker":{"#tail":"\n","#text":"Wolf, Woods, 1980"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ased with the progress through the dialogue. This is due to the increased rate of speech. However, the actual failure rate of VNLCE did not increase by the same amount. These extra errors were corrected by the expectation system. Figure 16 gives a summary of the average error and correction rates for each test and over all. 7 RELATED LITERATURE A number of speech understanding systems have been developed uring the past fifteen years (Barnett et al 1980, Dixon and Martin 1979, Erman et al 1980, Haton and Pierrel 1976, Lea 1980, Lowerre and Reddy 1980, Medress 1980, Reddy 1976, Walker 1978, and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed input has been studied by Carbonell and Hayes (1983","@endWordPosition":"10723","@position":"61279","annotationId":"T31","@startWordPosition":"10720","@citStr":"Wolf and Woods 1980"}},"title":{"#tail":"\n","#text":"The HWIM Speech Understanding System. In Lea"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"J Wolf"},{"#tail":"\n","#text":"W Woods"}]}},{"date":{"#tail":"\n","#text":"1970"},"issue":{"#tail":"\n","#text":"10"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"probabilities in the following discussion. However, in reality, the ratings are one thou- sand times the values of the logarithms of numbers between 0 and 1. Thus, the ratings span the values -999 to 0, where 0 is equivalent to a probability of one. These ratings are computed this way because they remain inte- gral and still fairly accurately represent the correct values. Also, they can simply be added and subtracted rather than multiplied and divided in the hundreds of calculations required for a single sentence parse. The expectation parser uses an ATN-like represen- tation for its grammar (Woods 1970). Its strategy is top-down. The types of sentences accepted are essential- ly those accepted by the original NLC grammar, imper- ative sentences with nested noun groups and conjunctions (Ballard 1979). An attempt has been made to build as deep a parse as possible so that sentences with the same meaning result in identical parses. Sentences have the same &quot;meaning&quot; if they &quot;result in identical tasks being performed. The various sentence structures that We have have the same meaning we call paraphrases. studied the following types of paraphrasing: 1) WORD<=>WORD 'entry' <=> 'number' 2) ADJ NOUN <","@endWordPosition":"3688","@position":"21924","annotationId":"T32","@startWordPosition":"3687","@citStr":"Woods 1970"}},"title":{"#tail":"\n","#text":"Transition Network Grammars for Natural Language Analysis."},"volume":{"#tail":"\n","#text":"13"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Woods, W. 1970 Transition Network Grammars for Natural Language Analysis. Comm. of the ACM 13(10): 591-606. NOTE 1. UNIX is a trademark of AT&T Bell Laboratories."},"journal":{"#tail":"\n","#text":"Comm. of the ACM"},"#text":"\n","pages":{"#tail":"\n","#text":"591--606"},"marker":{"#tail":"\n","#text":"Woods, 1970"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"W Woods"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1986"},"rawString":{"#tail":"\n","#text":"36 Computational Linguistics, Volume 12, Number 1, January-March 1986"},"#text":"\n","marker":{"#tail":"\n","#text":"1986"},"booktitle":{"#tail":"\n","#text":"36 Computational Linguistics, Volume 12, Number 1, January-March"},"@valid":"true"}]}}]}}
