{"algorithms":{"#text":"\n","@version":"110505","algorithm":{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Barzilay, Regina and Lillian Lee. 2004. Catching the drift: Probabilistic content models with applications to generation and summarization. In Proceedings of HLT-NAACL 2004, pages 113\u2013120, Boston, MA."},"#text":"\n","pages":{"#tail":"\n","#text":"113--120"},"marker":{"#tail":"\n","#text":"Barzilay, Lee, 2004"},"location":{"#tail":"\n","#text":"Boston, MA."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"vestigate the usefulness of such metrics for information ordering in automatic text generation. We estimate empirically which is the most promising metric and how useful this metric is using a general methodology applied on several corpora. Our main result is that the simplest metric (which relies exclusively on NOCB transitions) sets a robust baseline that cannot be outperformed by other metrics which make use of additional centering-based features. This baseline can be used for the development of both text-to-text and concept-to-text generation systems. 1. Introduction Information ordering (Barzilay and Lee 2004), that is, deciding in which sequence to present a set of preselected information-bearing items, has received much attention in recent work in automatic text generation. This is because text generation systems need to organize the content in a way that makes the output text coherent, that is, easy to read and understand. The easiest way to exemplify coherence is by arbitrarily reordering the sentences of a comprehensible text. This process very often gives rise to documents that do not make sense although the information content is the same before and after the reordering (Hovy 1988; Marcu 199","@endWordPosition":"131","@position":"935","annotationId":"T1","@startWordPosition":"128","@citStr":"Barzilay and Lee 2004"},{"#tail":"\n","#text":"er 2000, 2004; O\u2019Donnell et al. 2001; Cheng 2002; Lapata * Computer Laboratory, William Gates Building, Cambridge CB3 0FD, UK. Nikiforos.Karamanis@cl.cam.ac.uk. ** Department of Computing Science, King\u2019s College, Aberdeen AB24 3UE, UK. t Department of Computer Science, Wivenhoe Park, Colchester CO4 3SQ, UK. t School of Informatics, 2 Buccleuch Place, Edinburgh EH8 9LW, UK. Submission received: 15 May 2006; revised submission received: 15 December 2007; accepted for publication: 7 January 2008. © 2008 Association for Computational Linguistics Computational Linguistics Volume 35, Number 1 2003; Barzilay and Lee 2004; Barzilay and Lapata 2005, among others). Although these approaches often make use of heuristics related to centering, the features of entity coherence they employ are usually defined informally. Additionally, centering-related features are combined with other coherence-inducing factors in ways that are based mainly on intuition, leaving many equally plausible options unexplored. Thus, the answers to the following questions remain unclear: (i) How appropriate is centering for information ordering in text generation? (ii) Which aspects of centering are most useful for this purpose? These are t","@endWordPosition":"425","@position":"2887","annotationId":"T2","@startWordPosition":"422","@citStr":"Barzilay and Lee 2004"},{"#tail":"\n","#text":"uctures from existing corpora. Section 5 discusses how centering can be used to define various metrics of coherence suitable for information ordering. Then, Section 6 outlines a corpus-based methodology for choosing among these metrics. Section 7 reports on the results of our experiments and Section 8 discusses their implications. We conclude the paper with directions for future work and a summary of our main contributions.1 2. Information Ordering Information ordering has been investigated by substantial recent work in text-totext generation (Barzilay, Elhadad, and McKeown 2002; Lapata 2003; Barzilay and Lee 2004; Barzilay and Lapata 2005; Bollegala, Okazaki, and Ishizuka 2006; Ji and Pulman 2006; Siddharthan 2006; Soricut and Marcu 2006; Madnani et al. 2007, among others) as well as concept-to-text generation (particularly Kan and McKeown [2002] and Dimitromanolaki and Androutsopoulos 2003).2 We added to this work by presenting approaches to information ordering based on a genetic algorithm (Karamanis and Manurung 2002) and linear programming (Althaus, Karamanis, and Koller 2004) which can be applied to both concept-to-text and text-to-text generation. These approaches use a metric of coherence defin","@endWordPosition":"809","@position":"5519","annotationId":"T3","@startWordPosition":"806","@citStr":"Barzilay and Lee 2004"},{"#tail":"\n","#text":"mal definition of the metrics discussed previously. 6. Evaluation Methodology Because using naturally occurring discourse in psycholinguistic studies to investigate coherence effects is almost infeasible, computational corpus-based experiments are 11 In order to estimate the effect of CHEAPNESS only, NOCBs are not counted as violations of CHEAPNESS. 12 Following Brennan, Friedman [Walker], and Pollard (1987), NOCBs are not taken into account for the definition of transitions in M.BFP. 38 Karamanis et al. Centering for Information Ordering often the most viable alternative (Poesio et al. 2004; Barzilay and Lee 2004). Corpusbased evaluation can be usefully employed during system development and may be later supplemented by less extended evaluation based on human judgments as suggested by Lapata (2006). The corpus-based methodology of Karamanis (2003) served as our experimental framework. This methodology is based on the premise that the original sentence order (OSO, Barzilay and Lee 2004) observed in a corpus text is more coherent than any other ordering. If a metric takes an alternative ordering to be more coherent than the OSO, it has to be penalized. Karamanis (2003) introduced a performance measure ca","@endWordPosition":"4849","@position":"30922","annotationId":"T4","@startWordPosition":"4846","@citStr":"Barzilay and Lee 2004"},{"#tail":"\n","#text":"s of additional centering features that the other metrics make use of. In this section, we compare our work with other recent evaluation studies, including the corpus-based investigation of centering by Poesio et al. (2004); discuss the implications of our findings for text generation; and summarize our contributions. 8.1 Recent Evaluation Studies in Information Ordering There has been significant recent work on the corpus-based evaluation for information ordering. In this section, we discuss the methodological differences between our work and the studies which are most closely related to it. Barzilay and Lee (2004) introduce a stochastic model for information ordering which computes the probability of generating the OSO and every alternative ordering. Then, all orderings are ranked according to this probability and the rank given to the OSO is retrieved. Several evaluation measures are discussed, the most important of which is the average OSO rank, that is, the average rank of the OSOs in their corpora. This measure does not take into account that the OSOs differ in length. However, this information is necessary to estimate reliably the performance of an information ordering approach, as we discuss in K","@endWordPosition":"5920","@position":"37489","annotationId":"T5","@startWordPosition":"5917","@citStr":"Barzilay and Lee (2004)"},{"#tail":"\n","#text":"d in Karamanis (2003, Chapter 5). Equally important is the emphasis we placed on the use of statistical tests, which were not deployed by either Barzilay and Lee or Barzilay and Lapata. Lapata (2003) presented a methodology for automatically evaluating generated orderings on the basis of their distance from observed sentence orderings in a corpus. A measure of rank correlation (called Kendall\u2019s τ), which was subsequently shown to correlate reliably with human ratings and reading times (Lapata 2006), was used to estimate the distance between orderings. 16 Neither Barzilay and Lapata (2005) nor Barzilay and Lee (2004) appear to consider the possibility that two orderings may be equally ranked. 41 Computational Linguistics Volume 35, Number 1 Whereas -r estimates how close the predictions of a metric are to several original orderings, we measure how likely a metric is to lead to an ordering different than the OSO. Taking into account more than one OSO for information ordering is the main strength of Lapata\u2019s method, but to do this one needs to ask several humans to order the same set of sentences (Madnani et al. 2007). Karamanis and Mellish (2005b) conducted an experiment in the MPIRO domain using Lapata\u2019s ","@endWordPosition":"6228","@position":"39491","annotationId":"T6","@startWordPosition":"6225","@citStr":"Barzilay and Lee (2004)"}]},"title":{"#tail":"\n","#text":"Catching the drift: Probabilistic content models with applications to generation and summarization."},"booktitle":{"#tail":"\n","#text":"In Proceedings of HLT-NAACL 2004,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Regina Barzilay"},{"#tail":"\n","#text":"Lillian Lee"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1987"},"rawString":{"#tail":"\n","#text":"Friedman [Walker], and Carl J. Pollard. 1987. A centering approach to pronouns."},"#text":"\n","marker":{"#tail":"\n","#text":"Pollard, 1987"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ntences of a comprehensible text. This process very often gives rise to documents that do not make sense although the information content is the same before and after the reordering (Hovy 1988; Marcu 1997; Reiter and Dale 2000). Entity coherence, which is based on the way the referents of noun phrases (NPs) relate subsequent clauses in the text, is an important aspect of textual organization. Since the early 1980s, when it was first introduced, centering theory has been an influential framework for modelling entity coherence. Seminal papers on centering such as Brennan, Friedman [Walker], and Pollard (1987, page 160) and Grosz, Joshi, and Weinstein (1995, page 215) suggest that centering may provide solutions for information ordering. Indeed, following the pioneering work of McKeown (1985), recent work on text generation exploits constraints on entity coherence to organize information (Mellish et al. 1998; Kibble and Power 2000, 2004; O\u2019Donnell et al. 2001; Cheng 2002; Lapata * Computer Laboratory, William Gates Building, Cambridge CB3 0FD, UK. Nikiforos.Karamanis@cl.cam.ac.uk. ** Department of Computing Science, King\u2019s College, Aberdeen AB24 3UE, UK. t Department of Computer Science, Wivenhoe ","@endWordPosition":"291","@position":"1945","annotationId":"T7","@startWordPosition":"290","@citStr":"Pollard (1987"},{"#tail":"\n","#text":"re applicable to both concept-to-text and text-to-text generation. 3. Centering Overview This section provides an overview of centering, focusing on the aspects which are most closely related to our work. Poesio et al. (2004) and Walker, Joshi, and Prince (1998) discuss centering and its relation to other theories of coherence in more detail. According to Grosz, Joshi, and Weinstein (1995), each utterance U\u201e is assigned a ranked list of forward looking centers (i.e., discourse entities) denoted as CF(U\u201e). The members of CF(U\u201e) must be realized by the NPs in U\u201e (Brennan, Friedman [Walker], and Pollard 1987). The first member of CF(U\u201e) is called the preferred center CP(U\u201e). The backward looking center CB(U\u201e) links U\u201e to the previous utterance U\u201e_1. CB(U\u201e) is defined as the most highly ranked member of CF(U\u201e_1) which also belongs to CF(U\u201e). CF lists prior to CF(U\u201e_1) are not taken into account for the computation 31 Computational Linguistics Volume 35, Number 1 Table 1 Centering transitions are defined according to whether the backward looking center, CB, is the same in two subsequent utterances, Un−1 and Un, and whether the CB of the current utterance, CB(Un), is the same as its preferred center,","@endWordPosition":"1428","@position":"9699","annotationId":"T8","@startWordPosition":"1427","@citStr":"Pollard 1987"},{"#tail":"\n","#text":"ith an asterisk. COHERENCE: COHERENCE*: CB(Un)=CB(Un−1) CB(Un)#CB(Un−1) or CB(Un−1) undef. SALIENCE: CB(Un)=CP(Un) CONTINUE SMOOTH-SHIFT SALIENCE*: CB(Un)#CP(Un) RETAIN ROUGH-SHIFT of CB(Un). The original formulations of centering by Brennan, Friedman [Walker], and Pollard (1987) and Grosz, Joshi, and Weinstein (1995) lay emphasis on the uniqueness and the locality of the CB and will serve as the foundations of our work. The CB and the CP are combined to define transitions across pairs of adjacent utterances (Table 1). This definition of transitions is based on Brennan, Friedman [Walker], and Pollard (1987) and has been popular with subsequent work. There exist several variations, however, the most important of which comes from Grosz, Joshi, and Weinstein (1995), who define only one SHIFT transition.3 Centering makes two major claims about textual coherence, the first of which is known as Rule 2. Rule 2 states that CONTINUE is preferred to RETAIN, which is preferred to SMOOTH-SHIFT, which is preferred to ROUGH-SHIFT. Although the Rule was introduced within an algorithm for anaphora resolution, Brennan, Friedman [Walker], and Pollard (1987, page 160) consider it to be relevant to text generation ","@endWordPosition":"1635","@position":"11041","annotationId":"T9","@startWordPosition":"1634","@citStr":"Pollard (1987)"},{"#tail":"\n","#text":" in Table 5. The table reports the sentences marked with each centering feature: That is, sentences (3e) and (3f) are classified as NOCBs, and so on. CONTINUITY∗ COHERENCE∗ SALIENCE∗ CHEAPNESS∗ NOCB: CB,, # CB,,−1: CB,, # CP,,: CB,, # CP,,−1: (3e), (3f) − (3b) (3b), (3c) CONTINUE: RETAIN: SMOOTH-SHIFT: ROUGH-SHIFT: (3c), (3d) (3b) − − according to M.CHEAP is 2.11 If another candidate ordering with fewer violations of CHEAPNESS exists, it will be chosen as a preferred output according to M.CHEAP. M.BFP employs the transition preferences of Rule 2 as specified by Brennan, Friedman [Walker], and Pollard (1987). The first score to be computed by M.BFP is the sum of CONTINUE transitions, which is 2 for the candidate ordering according to Table 6. If this ordering is found to score higher than every other candidate ordering for the number of CONTINUEs, it is selected as the output. If another ordering is found to have the same number of CONTINUEs, the sum of RETAINs is examined, and so forth for the other two types of centering transitions.12 M.KP, the metric deployed by Kibble and Power (2000) in their text generation system, sums up the NOCBs as well as the violations of CHEAPNESS, COHERENCE, and SA","@endWordPosition":"4461","@position":"28468","annotationId":"T10","@startWordPosition":"4460","@citStr":"Pollard (1987)"},{"#tail":"\n","#text":"efinitions of centering\u2019s transitions and the various ways in which transitions and principles can be combined. These are explored in more detail in Karamanis (2003, Chapter 3), which also provides a formal definition of the metrics discussed previously. 6. Evaluation Methodology Because using naturally occurring discourse in psycholinguistic studies to investigate coherence effects is almost infeasible, computational corpus-based experiments are 11 In order to estimate the effect of CHEAPNESS only, NOCBs are not counted as violations of CHEAPNESS. 12 Following Brennan, Friedman [Walker], and Pollard (1987), NOCBs are not taken into account for the definition of transitions in M.BFP. 38 Karamanis et al. Centering for Information Ordering often the most viable alternative (Poesio et al. 2004; Barzilay and Lee 2004). Corpusbased evaluation can be usefully employed during system development and may be later supplemented by less extended evaluation based on human judgments as suggested by Lapata (2006). The corpus-based methodology of Karamanis (2003) served as our experimental framework. This methodology is based on the premise that the original sentence order (OSO, Barzilay and Lee 2004) observed ","@endWordPosition":"4815","@position":"30711","annotationId":"T11","@startWordPosition":"4814","@citStr":"Pollard (1987)"}]},"title":{"#tail":"\n","#text":"A centering approach to pronouns."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Carl J Pollard"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1987"},"rawString":{"#tail":"\n","#text":"Friedman [Walker], and Carl J. Pollard. 1987. A centering approach to pronouns."},"#text":"\n","marker":{"#tail":"\n","#text":"Pollard, 1987"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ntences of a comprehensible text. This process very often gives rise to documents that do not make sense although the information content is the same before and after the reordering (Hovy 1988; Marcu 1997; Reiter and Dale 2000). Entity coherence, which is based on the way the referents of noun phrases (NPs) relate subsequent clauses in the text, is an important aspect of textual organization. Since the early 1980s, when it was first introduced, centering theory has been an influential framework for modelling entity coherence. Seminal papers on centering such as Brennan, Friedman [Walker], and Pollard (1987, page 160) and Grosz, Joshi, and Weinstein (1995, page 215) suggest that centering may provide solutions for information ordering. Indeed, following the pioneering work of McKeown (1985), recent work on text generation exploits constraints on entity coherence to organize information (Mellish et al. 1998; Kibble and Power 2000, 2004; O\u2019Donnell et al. 2001; Cheng 2002; Lapata * Computer Laboratory, William Gates Building, Cambridge CB3 0FD, UK. Nikiforos.Karamanis@cl.cam.ac.uk. ** Department of Computing Science, King\u2019s College, Aberdeen AB24 3UE, UK. t Department of Computer Science, Wivenhoe ","@endWordPosition":"291","@position":"1945","annotationId":"T12","@startWordPosition":"290","@citStr":"Pollard (1987"},{"#tail":"\n","#text":"re applicable to both concept-to-text and text-to-text generation. 3. Centering Overview This section provides an overview of centering, focusing on the aspects which are most closely related to our work. Poesio et al. (2004) and Walker, Joshi, and Prince (1998) discuss centering and its relation to other theories of coherence in more detail. According to Grosz, Joshi, and Weinstein (1995), each utterance U\u201e is assigned a ranked list of forward looking centers (i.e., discourse entities) denoted as CF(U\u201e). The members of CF(U\u201e) must be realized by the NPs in U\u201e (Brennan, Friedman [Walker], and Pollard 1987). The first member of CF(U\u201e) is called the preferred center CP(U\u201e). The backward looking center CB(U\u201e) links U\u201e to the previous utterance U\u201e_1. CB(U\u201e) is defined as the most highly ranked member of CF(U\u201e_1) which also belongs to CF(U\u201e). CF lists prior to CF(U\u201e_1) are not taken into account for the computation 31 Computational Linguistics Volume 35, Number 1 Table 1 Centering transitions are defined according to whether the backward looking center, CB, is the same in two subsequent utterances, Un−1 and Un, and whether the CB of the current utterance, CB(Un), is the same as its preferred center,","@endWordPosition":"1428","@position":"9699","annotationId":"T13","@startWordPosition":"1427","@citStr":"Pollard 1987"},{"#tail":"\n","#text":"ith an asterisk. COHERENCE: COHERENCE*: CB(Un)=CB(Un−1) CB(Un)#CB(Un−1) or CB(Un−1) undef. SALIENCE: CB(Un)=CP(Un) CONTINUE SMOOTH-SHIFT SALIENCE*: CB(Un)#CP(Un) RETAIN ROUGH-SHIFT of CB(Un). The original formulations of centering by Brennan, Friedman [Walker], and Pollard (1987) and Grosz, Joshi, and Weinstein (1995) lay emphasis on the uniqueness and the locality of the CB and will serve as the foundations of our work. The CB and the CP are combined to define transitions across pairs of adjacent utterances (Table 1). This definition of transitions is based on Brennan, Friedman [Walker], and Pollard (1987) and has been popular with subsequent work. There exist several variations, however, the most important of which comes from Grosz, Joshi, and Weinstein (1995), who define only one SHIFT transition.3 Centering makes two major claims about textual coherence, the first of which is known as Rule 2. Rule 2 states that CONTINUE is preferred to RETAIN, which is preferred to SMOOTH-SHIFT, which is preferred to ROUGH-SHIFT. Although the Rule was introduced within an algorithm for anaphora resolution, Brennan, Friedman [Walker], and Pollard (1987, page 160) consider it to be relevant to text generation ","@endWordPosition":"1635","@position":"11041","annotationId":"T14","@startWordPosition":"1634","@citStr":"Pollard (1987)"},{"#tail":"\n","#text":" in Table 5. The table reports the sentences marked with each centering feature: That is, sentences (3e) and (3f) are classified as NOCBs, and so on. CONTINUITY∗ COHERENCE∗ SALIENCE∗ CHEAPNESS∗ NOCB: CB,, # CB,,−1: CB,, # CP,,: CB,, # CP,,−1: (3e), (3f) − (3b) (3b), (3c) CONTINUE: RETAIN: SMOOTH-SHIFT: ROUGH-SHIFT: (3c), (3d) (3b) − − according to M.CHEAP is 2.11 If another candidate ordering with fewer violations of CHEAPNESS exists, it will be chosen as a preferred output according to M.CHEAP. M.BFP employs the transition preferences of Rule 2 as specified by Brennan, Friedman [Walker], and Pollard (1987). The first score to be computed by M.BFP is the sum of CONTINUE transitions, which is 2 for the candidate ordering according to Table 6. If this ordering is found to score higher than every other candidate ordering for the number of CONTINUEs, it is selected as the output. If another ordering is found to have the same number of CONTINUEs, the sum of RETAINs is examined, and so forth for the other two types of centering transitions.12 M.KP, the metric deployed by Kibble and Power (2000) in their text generation system, sums up the NOCBs as well as the violations of CHEAPNESS, COHERENCE, and SA","@endWordPosition":"4461","@position":"28468","annotationId":"T15","@startWordPosition":"4460","@citStr":"Pollard (1987)"},{"#tail":"\n","#text":"efinitions of centering\u2019s transitions and the various ways in which transitions and principles can be combined. These are explored in more detail in Karamanis (2003, Chapter 3), which also provides a formal definition of the metrics discussed previously. 6. Evaluation Methodology Because using naturally occurring discourse in psycholinguistic studies to investigate coherence effects is almost infeasible, computational corpus-based experiments are 11 In order to estimate the effect of CHEAPNESS only, NOCBs are not counted as violations of CHEAPNESS. 12 Following Brennan, Friedman [Walker], and Pollard (1987), NOCBs are not taken into account for the definition of transitions in M.BFP. 38 Karamanis et al. Centering for Information Ordering often the most viable alternative (Poesio et al. 2004; Barzilay and Lee 2004). Corpusbased evaluation can be usefully employed during system development and may be later supplemented by less extended evaluation based on human judgments as suggested by Lapata (2006). The corpus-based methodology of Karamanis (2003) served as our experimental framework. This methodology is based on the premise that the original sentence order (OSO, Barzilay and Lee 2004) observed ","@endWordPosition":"4815","@position":"30711","annotationId":"T16","@startWordPosition":"4814","@citStr":"Pollard (1987)"}]},"title":{"#tail":"\n","#text":"A centering approach to pronouns."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Carl J Pollard"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1988"},"rawString":{"#tail":"\n","#text":"Hovy, Eduard. 1988. Planning coherent multisentential text. In Proceedings of ACL 1988, pages 163\u2013169, Buffalo, NY."},"#text":"\n","pages":{"#tail":"\n","#text":"163--169"},"marker":{"#tail":"\n","#text":"Hovy, 1988"},"location":{"#tail":"\n","#text":"Buffalo, NY."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"rzilay and Lee 2004), that is, deciding in which sequence to present a set of preselected information-bearing items, has received much attention in recent work in automatic text generation. This is because text generation systems need to organize the content in a way that makes the output text coherent, that is, easy to read and understand. The easiest way to exemplify coherence is by arbitrarily reordering the sentences of a comprehensible text. This process very often gives rise to documents that do not make sense although the information content is the same before and after the reordering (Hovy 1988; Marcu 1997; Reiter and Dale 2000). Entity coherence, which is based on the way the referents of noun phrases (NPs) relate subsequent clauses in the text, is an important aspect of textual organization. Since the early 1980s, when it was first introduced, centering theory has been an influential framework for modelling entity coherence. Seminal papers on centering such as Brennan, Friedman [Walker], and Pollard (1987, page 160) and Grosz, Joshi, and Weinstein (1995, page 215) suggest that centering may provide solutions for information ordering. Indeed, following the pioneering work of McKeow","@endWordPosition":"226","@position":"1524","annotationId":"T17","@startWordPosition":"225","@citStr":"Hovy 1988"},{"#tail":"\n","#text":" question, we define metrics which are purely centering-based, placing any attempt to specify a more elaborate model of coherence beyond the scope of this article. This strategy is similar to most work on centering for text interpretation in which additional constraints on coherence are not taken into account (the papers in Walker, Joshi, and Prince [1998] are characteristic examples). This simplification makes it possible to assess for the first time how useful the employed centering features are for information ordering. Work on text generation which is solely based on rhetorical relations (Hovy 1988; Marcu 1997, among others) typically masks entity coherence under the ELABORATION relation. However, ELABORATION has been characterized as \u201cthe weakest of all rhetorical relations\u201d (Scott and de Souza 1990, page 60). Knott et al. (2001) identified several theoretical problems all related to ELABORATION and suggested that this relation be replaced by a theory of entity coherence for text generation. Our work builds on this suggestion by investigating how appropriate centering is as a theory of entity coherence for information ordering. McKeown (1985, pages 60\u201375) also deployed features of enti","@endWordPosition":"1178","@position":"8027","annotationId":"T18","@startWordPosition":"1177","@citStr":"Hovy 1988"}]},"title":{"#tail":"\n","#text":"Planning coherent multisentential text."},"booktitle":{"#tail":"\n","#text":"In Proceedings of ACL 1988,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Eduard Hovy"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Karamanis, Nikiforos and Hisar Maruli Manurung. 2002. Stochastic text structuring using the principle of continuity. In Proceedings of INLG 2002, pages 81\u201388, Harriman, NY."},"#text":"\n","pages":{"#tail":"\n","#text":"81--88"},"marker":{"#tail":"\n","#text":"Karamanis, Manurung, 2002"},"location":{"#tail":"\n","#text":"Harriman, NY."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ain contributions.1 2. Information Ordering Information ordering has been investigated by substantial recent work in text-totext generation (Barzilay, Elhadad, and McKeown 2002; Lapata 2003; Barzilay and Lee 2004; Barzilay and Lapata 2005; Bollegala, Okazaki, and Ishizuka 2006; Ji and Pulman 2006; Siddharthan 2006; Soricut and Marcu 2006; Madnani et al. 2007, among others) as well as concept-to-text generation (particularly Kan and McKeown [2002] and Dimitromanolaki and Androutsopoulos 2003).2 We added to this work by presenting approaches to information ordering based on a genetic algorithm (Karamanis and Manurung 2002) and linear programming (Althaus, Karamanis, and Koller 2004) which can be applied to both concept-to-text and text-to-text generation. These approaches use a metric of coherence defined using features derived from 1 Earlier versions of this work were presented in Karamanis et al. (2004) and Karamanis (2006). 2 Concept-to-text generation is concerned with the automatic generation of text from some underlying non-linguistic representation. By contrast, the input to text-to-text generation applications is text. 30 Karamanis et al. Centering for Information Ordering centering and will serve as th","@endWordPosition":"869","@position":"5935","annotationId":"T19","@startWordPosition":"866","@citStr":"Karamanis and Manurung 2002"},{"#tail":"\n","#text":" SMOOTH-SHIFT, which is preferred to ROUGH-SHIFT. Although the Rule was introduced within an algorithm for anaphora resolution, Brennan, Friedman [Walker], and Pollard (1987, page 160) consider it to be relevant to text generation too. Grosz, Joshi, and Weinstein (1995, page 215) also take Rule 2 to suggest that text generation systems should attempt to avoid unfavorable transitions such as SHIFTs. The second claim, which is implied by the definition of the CB (Poesio et al. 2004), is that CF(Un) should contain at least one member of CF(Un−1). This became known as the principle of CONTINUITY (Karamanis and Manurung 2002). Although Grosz, Joshi, and Weinstein and Brennan, Friedman [Walker], and Pollard do not discuss the effect of violating CONTINUITY, Kibble and Power (2000, Figure 1) define the additional transition NOCB to account for this case. Different types of NOCB transitions are introduced by Passoneau (1998) and Poesio et al. (2004), among others. Other researchers, however, consider the NOCB transition to be a type of ROUGH-SHIFT (Miltsakaki and Kukich 2004). Kibble (2001) and Beaver (2004) introduced the principles of COHERENCE and SALIENCE, which correspond to the identity checks used to define th","@endWordPosition":"1794","@position":"12038","annotationId":"T20","@startWordPosition":"1791","@citStr":"Karamanis and Manurung 2002"},{"#tail":"\n","#text":"tions of CHEAPNESS (denoted with an asterisk) for Example (3) from the NEWS corpus. Sentence CF list: next referent} CB Transition CHEAPNESS {CP, CBn=CPn−1 (3a) {department, microsoft, ...} n.a. n.a. n.a. (3b) {products, microsoft, ...} microsoft RETAIN ∗ (3c) {microsoft, case, ...} microsoft CONTINUE ∗ (3d) {microsoft, tactics} microsoft CONTINUE (3e) {government, conspiracy, ...} (3f) {microsoft, earnings, ... } − NOCB n.a. deployed directly on unseen texts, so we treated all texts in NEWS and ACCS as test data.8 5. Computing Centering-Based Metrics of Coherence Following our previous work (Karamanis and Manurung 2002; Althaus, Karamanis, and Koller 2004), the input to information ordering is an unordered set of informationbearing items represented as CF lists. A set of candidate orderings is produced by creating different permutations of these lists. A metric of coherence uses features from centering to compute a score for each candidate ordering and select the highest scoring ordering as the output.9 A wide range of metrics of coherence can be defined in centering\u2019s terms, simply on the basis of the work we reviewed in Section 3. To exemplify this, let us first assume that the ordering in Example (3), wh","@endWordPosition":"3988","@position":"25495","annotationId":"T21","@startWordPosition":"3985","@citStr":"Karamanis and Manurung 2002"}]},"title":{"#tail":"\n","#text":"Stochastic text structuring using the principle of continuity."},"booktitle":{"#tail":"\n","#text":"In Proceedings of INLG 2002,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Nikiforos Karamanis"},{"#tail":"\n","#text":"Hisar Maruli Manurung"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"Karamanis, Nikiforos and Chris Mellish. 2005b. Using a corpus of sentence orderings defined by many experts to evaluate metrics of coherence for text structuring. In Proceedings of ENLG 2005, pages 174\u2013179, Aberdeen."},"#text":"\n","pages":{"#tail":"\n","#text":"174--179"},"marker":{"#tail":"\n","#text":"Karamanis, Mellish, 2005"},"location":{"#tail":"\n","#text":"Aberdeen."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"), and the two corpora that Barzilay and Lapata (2005) experimented with. In this section, we discuss how the centering representations we utilize were derived from each corpus. 4.1 The MPIRO-CF Corpus Dimitromanolaki and Androutsopoulos (2003, henceforth D&A) derived facts from the database of the MPIRO concept-to-text generation system (Isard et al. 2003), realized them as sentences, and organized them in sets. Each set consisted of six facts which were ordered by a domain expert. The orderings produced by this expert were shown to be very close to those produced by two other archeologists (Karamanis and Mellish 2005b). Our first corpus, MPIRO-CF, consists of 122 orderings that were made available to us by D&A. We computed a CF list for each fact in each ordering by applying the instantiation of centering introduced by Kibble and Power (2000, 2004) for concept-totext generation. That is, we took each database fact to correspond to an \u201cutterance\u201d and specified the \u201crealization\u201d parameter using the arguments of each fact as the members of the corresponding CF list. Table 2 shows the CF lists, the CBs, the centering transitions, and the violations of CHEAPNESS for the following example from MPIRO-CF: (1) (a)","@endWordPosition":"2176","@position":"14513","annotationId":"T22","@startWordPosition":"2173","@citStr":"Karamanis and Mellish 2005"},{"#tail":"\n","#text":") introduce a stochastic model for information ordering which computes the probability of generating the OSO and every alternative ordering. Then, all orderings are ranked according to this probability and the rank given to the OSO is retrieved. Several evaluation measures are discussed, the most important of which is the average OSO rank, that is, the average rank of the OSOs in their corpora. This measure does not take into account that the OSOs differ in length. However, this information is necessary to estimate reliably the performance of an information ordering approach, as we discuss in Karamanis and Mellish (2005a) in more detail. Barzilay and Lapata (2005) overcome this difficulty by introducing a performance measure called ranking accuracy which expresses the percentage of alternative orderings that are ranked lower than the OSO. In Karamanis\u2019s (2003) terms, ranking accuracy equals 100% − Better(M, OSO), assuming that no equally ranking orderings exist.16 Barzilay and Lapata (2005) compare the OSO with just 20 alternative orderings, often sampled out of several millions. On the other hand, Barzilay and Lee (2004) enumerate exhaustively each possible ordering, which might become impractical as the se","@endWordPosition":"6019","@position":"38115","annotationId":"T23","@startWordPosition":"6016","@citStr":"Karamanis and Mellish (2005"},{"#tail":"\n","#text":"ance between orderings. 16 Neither Barzilay and Lapata (2005) nor Barzilay and Lee (2004) appear to consider the possibility that two orderings may be equally ranked. 41 Computational Linguistics Volume 35, Number 1 Whereas -r estimates how close the predictions of a metric are to several original orderings, we measure how likely a metric is to lead to an ordering different than the OSO. Taking into account more than one OSO for information ordering is the main strength of Lapata\u2019s method, but to do this one needs to ask several humans to order the same set of sentences (Madnani et al. 2007). Karamanis and Mellish (2005b) conducted an experiment in the MPIRO domain using Lapata\u2019s methodology which supplements the work reported in this article. However, such an approach is less practical for much larger collections of texts such as NEWS and ACCS. This is presumably the reason why Barzilay and Lapata (2005) use ranking accuracy instead of -r in their evaluation. 8.2 Previous Corpus-Based Evaluations of Centering Our work investigates how the coherence score of the OSO compares to the scores of alternative orderings of the sentences that the OSO consists of. As Kibble (2001, page 582) noticed, this question is ","@endWordPosition":"6320","@position":"40029","annotationId":"T24","@startWordPosition":"6317","@citStr":"Karamanis and Mellish (2005"}]},"title":{"#tail":"\n","#text":"Using a corpus of sentence orderings defined by many experts to evaluate metrics of coherence for text structuring."},"booktitle":{"#tail":"\n","#text":"In Proceedings of ENLG"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Nikiforos Karamanis"},{"#tail":"\n","#text":"Chris Mellish"}]}},{"volume":{"#tail":"\n","#text":"27"},"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Kibble, Rodger. 2001. A reformulation of rule 2 of centering theory. Computational Linguistics, 27(4):579\u2013587."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"4"},"marker":{"#tail":"\n","#text":"Kibble, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" is that CF(Un) should contain at least one member of CF(Un−1). This became known as the principle of CONTINUITY (Karamanis and Manurung 2002). Although Grosz, Joshi, and Weinstein and Brennan, Friedman [Walker], and Pollard do not discuss the effect of violating CONTINUITY, Kibble and Power (2000, Figure 1) define the additional transition NOCB to account for this case. Different types of NOCB transitions are introduced by Passoneau (1998) and Poesio et al. (2004), among others. Other researchers, however, consider the NOCB transition to be a type of ROUGH-SHIFT (Miltsakaki and Kukich 2004). Kibble (2001) and Beaver (2004) introduced the principles of COHERENCE and SALIENCE, which correspond to the identity checks used to define the transitions (see Table 1). To improve the way centering resolves pronominal anaphora, Strube and Hahn (1999) introduced a fourth principle called CHEAPNESS and defined it as CB(Un)=CP(Un−1). They also redefined Rule 2 to favor transition pairs which satisfy 3 \u201cCB(Un−1) undef.\u201d in Table 1 stands for the cases where Un−1 does not have a CB. Instead of classifying the transition of Un as a CONTINUE or a RETAIN in such cases, the additional transition ESTABLISHMENT is ","@endWordPosition":"1865","@position":"12509","annotationId":"T25","@startWordPosition":"1864","@citStr":"Kibble (2001)"},{"#tail":"\n","#text":"tric deployed by Kibble and Power (2000) in their text generation system, sums up the NOCBs as well as the violations of CHEAPNESS, COHERENCE, and SALIENCE, preferring the ordering with the lowest total cost. In addition to the violations of CONTINUITY and CHEAPNESS, the candidate ordering also violates SALIENCE once, so its score according to M.KP is 5. An alternative ordering with a lower score (if any) will be preferred by this metric. Although Kibble and Power (2004) introduced a weighted version of M.KP, the exact weighting of centering\u2019s principles remains an open question, as argued by Kibble (2001). This is why we decided to experiment with M.KP instead of its weighted variant. In the remainder of the paper, we take forward the four metrics motivated in this section as the most appropriate starting point for experimentation. We would like to emphasize, however, that these are not the only possible options. Indeed, similarly to the various ways in which centering\u2019s parameters can be specified, there exist many other ways of using centering to define metrics of entity coherence for information ordering. These possibilities arise from the numerous other definitions of centering\u2019s transitio","@endWordPosition":"4640","@position":"29532","annotationId":"T26","@startWordPosition":"4639","@citStr":"Kibble (2001)"},{"#tail":"\n","#text":"(Madnani et al. 2007). Karamanis and Mellish (2005b) conducted an experiment in the MPIRO domain using Lapata\u2019s methodology which supplements the work reported in this article. However, such an approach is less practical for much larger collections of texts such as NEWS and ACCS. This is presumably the reason why Barzilay and Lapata (2005) use ranking accuracy instead of -r in their evaluation. 8.2 Previous Corpus-Based Evaluations of Centering Our work investigates how the coherence score of the OSO compares to the scores of alternative orderings of the sentences that the OSO consists of. As Kibble (2001, page 582) noticed, this question is crucial from an information ordering viewpoint, but was not taken into account by any previous corpus-based study of centering. Grosz, Joshi, and Weinstein (1995, page 215) also suggested that Rule 2 should be tested by examining \u201calternative multi-utterance sequences that differentially realize the same content.\u201d We are the first to have pursued this research objective in the evaluation of centering for information ordering. Poesio et al. (2004) observed that there remained a large number of NOCBs under every instantiation of centering they tested and con","@endWordPosition":"6409","@position":"40591","annotationId":"T27","@startWordPosition":"6408","@citStr":"Kibble (2001"}]},"title":{"#tail":"\n","#text":"A reformulation of rule 2 of centering theory."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Rodger Kibble"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Kibble, Rodger and Richard Power. 2000. An integrated framework for text planning and pronominalisation. In Proceedings of INLG 2000, pages 77\u201384, Mitzpe Ramon."},"#text":"\n","pages":{"#tail":"\n","#text":"77--84"},"marker":{"#tail":"\n","#text":"Kibble, Power, 2000"},"location":{"#tail":"\n","#text":"Mitzpe Ramon."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"equent clauses in the text, is an important aspect of textual organization. Since the early 1980s, when it was first introduced, centering theory has been an influential framework for modelling entity coherence. Seminal papers on centering such as Brennan, Friedman [Walker], and Pollard (1987, page 160) and Grosz, Joshi, and Weinstein (1995, page 215) suggest that centering may provide solutions for information ordering. Indeed, following the pioneering work of McKeown (1985), recent work on text generation exploits constraints on entity coherence to organize information (Mellish et al. 1998; Kibble and Power 2000, 2004; O\u2019Donnell et al. 2001; Cheng 2002; Lapata * Computer Laboratory, William Gates Building, Cambridge CB3 0FD, UK. Nikiforos.Karamanis@cl.cam.ac.uk. ** Department of Computing Science, King\u2019s College, Aberdeen AB24 3UE, UK. t Department of Computer Science, Wivenhoe Park, Colchester CO4 3SQ, UK. t School of Informatics, 2 Buccleuch Place, Edinburgh EH8 9LW, UK. Submission received: 15 May 2006; revised submission received: 15 December 2007; accepted for publication: 7 January 2008. © 2008 Association for Computational Linguistics Computational Linguistics Volume 35, Number 1 2003; Barzila","@endWordPosition":"339","@position":"2273","annotationId":"T28","@startWordPosition":"336","@citStr":"Kibble and Power 2000"},{"#tail":"\n","#text":" use a metric of coherence defined using features derived from 1 Earlier versions of this work were presented in Karamanis et al. (2004) and Karamanis (2006). 2 Concept-to-text generation is concerned with the automatic generation of text from some underlying non-linguistic representation. By contrast, the input to text-to-text generation applications is text. 30 Karamanis et al. Centering for Information Ordering centering and will serve as the premises of our investigation of centering in this article. Metrics of coherence are used in other work on text generation, too (Mellish et al. 1998; Kibble and Power 2000, 2004; Cheng 2002). With the exception of Kibble and Power\u2019s work, the features of entity coherence used in these metrics are informally defined using heuristics related to centering. Additionally, the metrics are further specified by combining these features with other coherence-inducing factors such as rhetorical relations (Mann and Thompson 1987). However, as acknowledged in most of this work, these are preliminary computational investigations of the complex interactions between different types of coherence which leave many other equally plausible combinations unexplored. Clearly, one woul","@endWordPosition":"984","@position":"6708","annotationId":"T29","@startWordPosition":"981","@citStr":"Kibble and Power 2000"},{"#tail":"\n","#text":"llard (1987, page 160) consider it to be relevant to text generation too. Grosz, Joshi, and Weinstein (1995, page 215) also take Rule 2 to suggest that text generation systems should attempt to avoid unfavorable transitions such as SHIFTs. The second claim, which is implied by the definition of the CB (Poesio et al. 2004), is that CF(Un) should contain at least one member of CF(Un−1). This became known as the principle of CONTINUITY (Karamanis and Manurung 2002). Although Grosz, Joshi, and Weinstein and Brennan, Friedman [Walker], and Pollard do not discuss the effect of violating CONTINUITY, Kibble and Power (2000, Figure 1) define the additional transition NOCB to account for this case. Different types of NOCB transitions are introduced by Passoneau (1998) and Poesio et al. (2004), among others. Other researchers, however, consider the NOCB transition to be a type of ROUGH-SHIFT (Miltsakaki and Kukich 2004). Kibble (2001) and Beaver (2004) introduced the principles of COHERENCE and SALIENCE, which correspond to the identity checks used to define the transitions (see Table 1). To improve the way centering resolves pronominal anaphora, Strube and Hahn (1999) introduced a fourth principle called CHEAPNES","@endWordPosition":"1817","@position":"12194","annotationId":"T30","@startWordPosition":"1814","@citStr":"Kibble and Power (2000"},{"#tail":"\n","#text":"ulos (2003, henceforth D&A) derived facts from the database of the MPIRO concept-to-text generation system (Isard et al. 2003), realized them as sentences, and organized them in sets. Each set consisted of six facts which were ordered by a domain expert. The orderings produced by this expert were shown to be very close to those produced by two other archeologists (Karamanis and Mellish 2005b). Our first corpus, MPIRO-CF, consists of 122 orderings that were made available to us by D&A. We computed a CF list for each fact in each ordering by applying the instantiation of centering introduced by Kibble and Power (2000, 2004) for concept-totext generation. That is, we took each database fact to correspond to an \u201cutterance\u201d and specified the \u201crealization\u201d parameter using the arguments of each fact as the members of the corresponding CF list. Table 2 shows the CF lists, the CBs, the centering transitions, and the violations of CHEAPNESS for the following example from MPIRO-CF: (1) (a) This exhibit is an amphora. (b) This exhibit was decorated by the Painter of Kleofrades. (c) The Painter of Kleofrades used to decorate big vases. (d) This exhibit depicts a warrior performing splachnoscopy before leaving for th","@endWordPosition":"2215","@position":"14742","annotationId":"T31","@startWordPosition":"2212","@citStr":"Kibble and Power (2000"},{"#tail":"\n","#text":"ording to M.CHEAP. M.BFP employs the transition preferences of Rule 2 as specified by Brennan, Friedman [Walker], and Pollard (1987). The first score to be computed by M.BFP is the sum of CONTINUE transitions, which is 2 for the candidate ordering according to Table 6. If this ordering is found to score higher than every other candidate ordering for the number of CONTINUEs, it is selected as the output. If another ordering is found to have the same number of CONTINUEs, the sum of RETAINs is examined, and so forth for the other two types of centering transitions.12 M.KP, the metric deployed by Kibble and Power (2000) in their text generation system, sums up the NOCBs as well as the violations of CHEAPNESS, COHERENCE, and SALIENCE, preferring the ordering with the lowest total cost. In addition to the violations of CONTINUITY and CHEAPNESS, the candidate ordering also violates SALIENCE once, so its score according to M.KP is 5. An alternative ordering with a lower score (if any) will be preferred by this metric. Although Kibble and Power (2004) introduced a weighted version of M.KP, the exact weighting of centering\u2019s principles remains an open question, as argued by Kibble (2001). This is why we decided to","@endWordPosition":"4548","@position":"28959","annotationId":"T32","@startWordPosition":"4545","@citStr":"Kibble and Power (2000)"}]},"title":{"#tail":"\n","#text":"An integrated framework for text planning and pronominalisation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of INLG"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Rodger Kibble"},{"#tail":"\n","#text":"Richard Power"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Ng, Vincent and Claire Cardie. 2002. Improving machine learning approaches to coreference resolution. In Proceedings of ACL 2002, pages 104\u2013111, Philadelphia, PA."},"#text":"\n","pages":{"#tail":"\n","#text":"104--111"},"marker":{"#tail":"\n","#text":"Ng, Cardie, 2002"},"location":{"#tail":"\n","#text":"Philadelphia, PA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"gs]O despite [the trial]X. Barzilay and Lapata automatically annotated their corpora for the grammatical function of the NPs in each sentence (denoted in the example by the subscripts S, O, and X for subject, object, and other, respectively) as well as their coreferential relations (which do not include bridging references). More specifically, they used a parser (Collins 1997) to determine the constituent structure of the sentences from which the grammatical function for each NP was derived.6 Coreferential NPs such as Microsoft Corp. and the company in (3a) were identified using the system of Ng and Cardie (2002). The entity grid is a two-dimensional array that captures the distribution of NP referents across sentences in the text using the aforementioned symbols for their grammatical role and the symbol \u201c−\u201d for a referent that does not occur in a sentence. Table 4 illustrates a fragment of the grid for the sentences in Example (3).7 Barzilay and Lapata use the grid to compute models of coherence that are considerably more elaborate than centering. To derive an appropriate instantiation of centering for our investigation, we compute a CF list for each grid row using the referents with the symbols S, O","@endWordPosition":"3589","@position":"23061","annotationId":"T33","@startWordPosition":"3586","@citStr":"Ng and Cardie (2002)"}},"title":{"#tail":"\n","#text":"Improving machine learning approaches to coreference resolution."},"booktitle":{"#tail":"\n","#text":"In Proceedings of ACL 2002,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Vincent Ng"},{"#tail":"\n","#text":"Claire Cardie"}]}}]}}}}
