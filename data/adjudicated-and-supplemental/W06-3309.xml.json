{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","address":{"#tail":"\n","@confidence":"0.853736","#text":"\nCollege Park, MD 20742, USA Baltimore, MD 21218, USA\n"},"subsectionHeader":[{"#tail":"\n","@confidence":"0.990321","#text":"\n2.1 Corpus and Data Preparation\n"},{"#tail":"\n","@confidence":"0.949928","#text":"\n2.2 Generative Models of Content\n"}],"footnote":[{"#tail":"\n","@confidence":"0.6870325","#text":"\nProceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 65?72,\nNew York City, June 2006. c?2006 Association for Computational Linguistics\nGenerative Content Models for Structural Analysis of Medical Abstracts\nJimmy Lin1,2, Damianos Karakos3, Dina Demner-Fushman2, and Sanjeev Khudanpur3\n1College of Information Studies 3Center for Language and\n2Institute for Advanced Computer Studies Speech Processing\n"},{"#tail":"\n","@confidence":"0.7334915","#text":"\n1After contacting the authors, we were unable to obtain the\nsame exact dataset that they used for their experiments.\n"}],"@confidence":"0.001870","reference":[{"#tail":"\n","@confidence":"0.974875368421053","#text":"\nation for Computational Linguistics Annual Meeting\n(HLT/NAACL 2004).\nDavid G. Covell, Gwen C. Uman, and Phil R. Manning.\n1985. Information needs in office practice: Are they\nbeing met? Annals of Internal Medicine, 103(4):596?\n599, October.\nDina Demner-Fushman and Jimmy Lin. 2005. Knowl-\nedge extraction for clinical question answering: Pre-\nliminary results. In Proceedings of the AAAI-05 Work-\nshop on Question Answering in Restricted Domains.\nDina Demner-Fushman, Susan E. Hauser, and George R.\nThoma. 2005. The role of title, metadata and ab-\nstract in identifying clinically relevant journal arti-\ncles. In Proceeding of the 2005 Annual Symposium of\nthe American Medical Informatics Association (AMIA\n2005), pages 191?195.\nJohn W. Ely, Jerome A. Osheroff, M. Lee Chambliss,\nMark H. Ebell, and Marcy E. Rosenbaum. 2005. An-\nswering physicians? clinical questions: Obstacles and\n"},{"#tail":"\n","@confidence":"0.998339311827957","#text":"\npotential solutions. Journal of the American Medical\nInformatics Association, 12(2):217?224, March-April.\nGunnar Evermann, H. Y. Chan, Mark J. F. Gales, Thomas\nHain, Xunying Liu, David Mrva, Lan Wang, and Phil\nWoodland. 2004. Development of the 2003 CU-HTK\nConversational Telephone Speech Transcription Sys-\ntem. In Proceedings of the 2004 International Con-\nference on Acoustics, Speech and Signal Processing\n(ICASSP04).\nClifford W. Gay, Mehmet Kayaalp, and Alan R. Aronson.\n2005. Semi-automatic indexing of full text biomedi-\ncal articles. In Proceeding of the 2005 Annual Sympo-\nsium of the American Medical Informatics Association\n(AMIA 2005), pages 271?275.\nPaul N. Gorman, Joan S. Ash, and Leslie W. Wykoff.\n1994. Can primary care physicians? questions be an-\nswered using the medical journal literature? Bulletin\nof the Medical Library Association, 82(2):140?146,\nApril.\nThorsten Joachims. 1998. Text categorization with Sup-\nport Vector Machines: Learning with many relevant\nfeatures. In Proceedings of the European Conference\non Machine Learning (ECML 1998).\nDonald A. Lindberg, Betsy L. Humphreys, and Alexa T.\nMcCray. 1993. The Unified Medical Language Sys-\ntem. Methods of Information in Medicine, 32(4):281?\n291, August.\nDaniel Marcu and Abdessamad Echihabi. 2002. An\nunsupervised approach to recognizing discourse rela-\ntions. In Proceedings of the 40th Annual Meeting of\nthe Association for Computational Linguistics (ACL\n2002).\nKathleen McKeown, Noemie Elhadad, and Vasileios\nHatzivassiloglou. 2003. Leveraging a common rep-\nresentation for personalized search and summarization\nin a medical digital library. In Proceedings of the\n3rd ACM/IEEE Joint Conference on Digital Libraries\n(JCDL 2003).\nKathleen R. McKeown. 1985. Text Generation: Using\nDiscourse Strategies and Focus Constraints to Gen-\nerate Natural Language Text. Cambridge University\nPress, Cambridge, England.\nLarry McKnight and Padmini Srinivasan. 2003. Catego-\nrization of sentence types in medical abstracts. In Pro-\nceeding of the 2003 Annual Symposium of the Ameri-\ncan Medical Informatics Association (AMIA 2003).\nYoko Mizuta, Anna Korhonen, Tony Mullen, and Nigel\nCollier. 2005. Zone analysis in biology articles as a\nbasis for information extraction. International Journal\nof Medical Informatics, in press.\nAndrew Y. Ng and Michael Jordan. 2001. On discrim-\ninative vs. generative classifiers: A comparison of lo-\ngistic regression and naive Bayes. In Advances in Neu-\nral Information Processing Systems 14.\nConstantin Ora?san. 2001. Patterns in scientific abstracts.\nIn Proceedings of the 2001 Corpus Linguistics Confer-\nence.\nThomas C. Rindflesch and Marcelo Fiszman. 2003. The\ninteraction of domain knowledge and linguistic struc-\nture in natural language processing: Interpreting hy-\npernymic propositions in biomedical text. Journal of\nBiomedical Informatics, 36(6):462?477, December.\nPatrick Ruch, Christine Chichester, Gilles Cohen, Gio-\nvanni Coray, Fre?de?ric Ehrler, Hatem Ghorbel, Hen-\nning Mu?ller, and Vincenzo Pallotta. 2003. Report\non the TREC 2003 experiment: Genomic track. In\nProceedings of the Twelfth Text REtrieval Conference\n(TREC 2003).\nFranc?oise Salanger-Meyer. 1990. Discoursal movements\nin medical English abstracts and their linguistic expo-\nnents: A genre analysis study. INTERFACE: Journal\nof Applied Linguistics, 4(2):107?124.\nJohn M. Swales. 1990. Genre Analysis: English in Aca-\ndemic and Research Settings. Cambridge University\nPress, Cambridge, England.\nImad Tbahriti, Christine Chichester, Fre?de?rique Lisacek,\nand Patrick Ruch. 2005. Using argumentation to re-\ntrieve articles with similar citations: An inquiry into\nimproving related articles search in the MEDLINE\ndigital library. International Journal of Medical In-\nformatics, in press.\nSimone Teufel and Marc Moens. 2000. What?s yours\nand what?s mine: Determining intellectual attribu-\ntion in scientific text. In Proceedings of the Joint\nSIGDAT Conference on Empirical Methods in Nat-\nural Language Processing and Very Large Corpora\n(EMNLP/VLC-2000).\nWilliam N. Venables and Brian D. Ripley. 1994. Modern\nApplied Statistics with S-Plus. Springer-Verlag.\nSteve Young, Gunnar Evermann, Thomas Hain, Dan Ker-\nshaw, Gareth Moore, Julian Odell, Dave Ollason, Dan\nPovey, Valtcho Valtchev, and Phil Woodland. 2002.\nThe HTK Book. Cambridge University Press.\n"}],"#tail":"\n","bodyText":[{"#tail":"\n","@confidence":"0.9996374","#text":"\nThe ability to accurately model the con-\ntent structure of text is important for\nmany natural language processing appli-\ncations. This paper describes experi-\nments with generative models for analyz-\ning the discourse structure of medical ab-\nstracts, which generally follow the pattern\nof ?introduction?, ?methods?, ?results?,\nand ?conclusions?. We demonstrate that\nHidden Markov Models are capable of ac-\ncurately capturing the structure of such\ntexts, and can achieve classification ac-\ncuracy comparable to that of discrimina-\ntive techniques. In addition, generative\napproaches provide advantages that may\nmake them preferable to discriminative\ntechniques such as Support Vector Ma-\nchines under certain conditions. Our work\nmakes two contributions: at the applica-\ntion level, we report good performance\non an interesting task in an important do-\nmain; more generally, our results con-\ntribute to an ongoing discussion regarding\nthe tradeoffs between generative and dis-\ncriminative techniques.\n"},{"#tail":"\n","@confidence":"0.998298710526316","#text":"\nCertain types of text follow a predictable structure,\nthe knowledge of which would be useful in many\nnatural language processing applications. As an\nexample, scientific abstracts across many different\nfields generally follow the pattern of ?introduction?,\n?methods?, ?results?, and ?conclusions? (Salanger-\nMeyer, 1990; Swales, 1990; Ora?san, 2001). The\nability to explicitly identify these sections in un-\nstructured text could play an important role in ap-\nplications such as document summarization (Teufel\nand Moens, 2000), information retrieval (Tbahriti\net al, 2005), information extraction (Mizuta et al,\n2005), and question answering. Although there is\na trend towards analysis of full article texts, we\nbelieve that abstracts still provide a tremendous\namount of information, and much value can still be\nextracted from them. For example, Gay et al (2005)\nexperimented with abstracts and full article texts in\nthe task of automatically generating index term rec-\nommendations and discovered that using full article\ntexts yields at most a 7.4% improvement in F-score.\nDemner-Fushman et al (2005) found a correlation\nbetween the quality and strength of clinical conclu-\nsions in the full article texts and abstracts.\nThis paper presents experiments with generative\ncontent models for analyzing the discourse struc-\nture of medical abstracts, which has been con-\nfirmed to follow the four-section pattern discussed\nabove (Salanger-Meyer, 1990). For a variety of rea-\nsons, medicine is an interesting domain of research.\nThe need for information systems to support physi-\ncians at the point of care has been well studied (Cov-\nell et al, 1985; Gorman et al, 1994; Ely et al,\n2005). Retrieval techniques can have a large im-\npact on how physicians access and leverage clini-\ncal evidence. Information that satisfies physicians?\nneeds can be found in theMEDLINE database main-\ntained by the U.S. National Library of Medicine\n"},{"#tail":"\n","@confidence":"0.9989098125","#text":"\n(NLM), which also serves as a readily available\ncorpus of abstracts for our experiments. Further-\nmore, the availability of rich ontological resources,\nin the form of the Unified Medical Language Sys-\ntem (UMLS) (Lindberg et al, 1993), and the avail-\nability of software that leverages this knowledge?\nMetaMap (Aronson, 2001) for concept identification\nand SemRep (Rindflesch and Fiszman, 2003) for re-\nlation extraction?provide a foundation for studying\nthe role of semantics in various tasks.\nMcKnight and Srinivasan (2003) have previously\nexamined the task of categorizing sentences in med-\nical abstracts using supervised discriminative ma-\nchine learning techniques. Building on the work of\nRuch et al (2003) in the same domain, we present a\ngenerative approach that attempts to directly model\nthe discourse structure of MEDLINE abstracts us-\ning Hidden Markov Models (HMMs); cf. (Barzilay\nand Lee, 2004). Although our results were not ob-\ntained from the same exact collection as those used\nby authors of these two previous studies, comparable\nexperiments suggest that our techniques are compet-\nitive in terms of performance, and may offer addi-\ntional advantages as well.\nDiscriminative approaches (especially SVMs)\nhave been shown to be very effective for many\nsupervised classification tasks; see, for exam-\nple, (Joachims, 1998; Ng and Jordan, 2001). How-\never, their high computational complexity (quadratic\nin the number of training samples) renders them pro-\nhibitive for massive data processing. Under certain\nconditions, generative approaches with linear com-\nplexity are preferable, even if their performance is\nlower than that which can be achieved through dis-\ncriminative training. Since HMMs are very well-\nsuited to modeling sequences, our discourse model-\ning task lends itself naturally to this particular gener-\native approach. In fact, we demonstrate that HMMs\nare competitive with SVMs, with the added advan-\ntage of lower computational complexity. In addition,\ngenerative models can be directly applied to tackle\ncertain classes of problems, such as sentence order-\ning, in ways that discriminative approaches cannot\nreadily. In the context of machine learning, we see\nour work as contributing to the ongoing debate be-\ntween generative and discriminative approaches?\nwe provide a case study in an interesting domain that\nbegins to explore some of these tradeoffs.\n"},{"#tail":"\n","@confidence":"0.995870155555555","#text":"\nOur experiments involved MEDLINE, the biblio-\ngraphical database of biomedical articles maintained\nby the U.S. National Library of Medicine (NLM).\nWe used the subset of MEDLINE that was extracted\nfor the TREC 2004 Genomics Track, consisting of\ncitations from 1994 to 2003. In total, 4,591,008\nrecords (abstract text and associated metadata) were\nextracted using the Date Completed (DCOM) field\nfor all references in the range of 19940101 to\n20031231.\nViewing structural modeling of medical abstracts\nas a sentence classification task, we leveraged the\nexistence of so-called structured abstracts (see Fig-\nure 1 for an example) in order to obtain the appro-\npriate section label for each sentence. The use of\nsection headings is a device recommended by the\nAd Hoc Working Group for Critical Appraisal of the\nMedical Literature (1987) to help humans assess the\nreliability and content of a publication and to facil-\nitate the indexing and retrieval processes. Although\nstructured abstracts loosely adhere to the introduc-\ntion, methods, results, and conclusions format, the\nexact choice of section headings varies from ab-\nstract to abstract and from journal to journal. In our\ntest collection, we observed a total of 2688 unique\nsection headings in structured abstracts?these were\nmanually mapped to the four broad classes of ?intro-\nduction?, ?methods?, ?results?, and ?conclusions?.\nAll sentences falling under a section heading were\nassigned the label of its appropriately-mapped head-\ning (naturally, the actual section headings were re-\nmoved in our test collection). As a concrete exam-\nple, in the abstract shown in Figure 1, the ?OBJEC-\nTIVE? section would be mapped to ?introduction?,\nthe ?RESEARCH DESIGN AND METHODS? sec-\ntion to ?methods?. The ?RESULTS? and ?CON-\nCLUSIONS? sections map directly to our own la-\nbels. In total, 308,055 structured abstracts were ex-\ntracted and prepared in this manner, serving as the\ncomplete dataset. In addition, we created a reduced\ncollection of 27,075 abstracts consisting of only\nRandomized Controlled Trials (RCTs), which rep-\nresent definitive sources of evidence highly-valued\nin the clinical decision-making process.\nSeparately, we manually annotated 49 unstruc-\n"},{"#tail":"\n","@confidence":"0.99181165","#text":"\nIntegrating medical management with diabetes self-management training: a randomized control trial of the Diabetes\nOutpatient Intensive Treatment program.\nOBJECTIVE? This study evaluated the Diabetes Outpatient Intensive Treatment (DOIT) program, a multiday group educa-\ntion and skills training experience combined with daily medical management, followed by case management over 6 months.\nUsing a randomized control design, the study explored how DOIT affected glycemic control and self-care behaviors over a\nshort term. The impact of two additional factors on clinical outcomes were also examined (frequency of case management\ncontacts and whether or not insulin was started during the program). RESEARCH DESIGN AND METHODS? Patients\nwith type 1 and type 2 diabetes in poor glycemic control (A1c ?8.5%) were randomly assigned to DOIT or a second con-\ndition, entitled EDUPOST, which was standard diabetes care with the addition of quarterly educational mailings. A total\nof 167 patients (78 EDUPOST, 89 DOIT) completed all baseline measures, including A1c and a questionnaire assessing\ndiabetes-related self-care behaviors. At 6 months, 117 patients (52 EDUPOST, 65 DOIT) returned to complete a follow-up\nA1c and the identical self-care questionnaire. RESULTS? At follow-up, DOIT evidenced a significantly greater drop in A1c\nthan EDUPOST. DOIT patients also reported significantly more frequent blood glucose monitoring and greater attention to\ncarbohydrate and fat contents (ACFC) of food compared with EDUPOST patients. An increase in ACFC over the 6-month\nperiod was associated with improved glycemic control among DOIT patients. Also, the frequency of nurse case manager\nfollow-up contacts was positively linked to better A1c outcomes. The addition of insulin did not appear to be a significant\ncontributor to glycemic change. CONCLUSIONS? DOIT appears to be effective in promoting better diabetes care and posi-\ntively influencing glycemia and diabetes-related self-care behaviors. However, it demands significant time, commitment, and\ncareful coordination with many health care professionals. The role of the nurse case manager in providing ongoing follow-up\ncontact seems important.\n"},{"#tail":"\n","@confidence":"0.997388","#text":"\ntured abstracts of randomized controlled trials re-\ntrieved to answer a question about the manage-\nment of elevated low-density lipoprotein cholesterol\n(LDL-C). We submitted a PubMed query (?elevated\nLDL-C?) and restricted results to English abstracts\nof RCTs, gathering 49 unstructured abstracts from\n26 journals. Each sentence was annotated with its\nsection label by the third author, who is a medical\ndoctor?this collection served as our blind held-out\ntestset. Note that the annotation process preceded\nour experiments, which helped to guard against\nannotator-introduced bias. Of 49 abstracts, 35 con-\ntained all four sections (which we refer to as ?com-\nplete?), while 14 abstracts were missing one or more\nsections (which we refer to as ?partial?).\nTwo different types of experiments were con-\nducted: the first consisted of cross-validation on the\nstructured abstracts; the second consisted of train-\ning on the structured abstracts and testing on the\nunstructured abstracts. We hypothesized that struc-\ntured and unstructured abstracts share the same un-\nderlying discourse patterns, and that content models\ntrained with one can be applied to the other.\n"},{"#tail":"\n","@confidence":"0.995662939393939","#text":"\nFollowing Ruch et al (2003) and Barzilay and\nLee (2004), we employed Hidden Markov Models\nto model the discourse structure of MEDLINE ab-\nstracts. The four states in our HMMs correspond\nto the information that characterizes each section\n(?introduction?, ?methods?, ?results?, and ?conclu-\nsions?) and state transitions capture the discourse\nflow from section to section.\nUsing the SRI language modeling toolkit, we\nfirst computed bigram language models for each\nof the four sections using Kneser-Ney discounting\nand Katz backoff. All words in the training set\nwere downcased, all numbers were converted into\na generic symbol, and all singleton unigrams and bi-\ngrams were removed. Using these results, each sen-\ntence was converted into a four dimensional vector,\nwhere each component represents the log probabil-\nity, divided by the number of words, of the sentence\nunder each of the four language models.\nWe then built a four-state Hidden Markov Model\nthat outputs these four-dimensional vectors. The\ntransition probability matrix of the HMM was ini-\ntialized with uniform probabilities over a fully\nconnected graph. The output probabilities were\nmodeled as four-dimensional Gaussians mixtures\nwith diagonal covariance matrices. Using the sec-\ntion labels, the HMM was trained using the HTK\ntoolkit (Young et al, 2002), which efficiently per-\nforms the forward-backward algorithm and Baum-\nWelch estimation. For testing, we performed a\nViterbi (maximum likelihood) estimation of the la-\nbel of each test sentence/vector (also using the HTK\ntoolkit).\n"},{"#tail":"\n","@confidence":"0.998629068965517","#text":"\nIn an attempt to further boost performance, we\nemployed Linear Discriminant Analysis (LDA) to\nfind a linear projection of the four-dimensional vec-\ntors that maximizes the separation of the Gaussians\n(corresponding to the HMM states). Venables and\nRipley (1994) describe an efficient algorithm (of lin-\near complexity in the number of training sentences)\nfor computing the LDA transform matrix, which en-\ntails computing the within- and between-covariance\nmatrices of the classes, and using Singular Value De-\ncomposition (SVD) to compute the eigenvectors of\nthe new space. Each sentence/vector is then mul-\ntiplied by this matrix, and new HMM models are\nre-computed from the projected data.\nAn important aspect of our work is modeling con-\ntent structure using generative techniques. To as-\nsess the impact of taking discourse transitions into\naccount, we compare our fully trained model to\none that does not take advantage of the Markov\nassumption?i.e., it assumes that the labels are in-\ndependently and identically distributed.\nTo facilitate comparison with previous work, we\nalso experimented with binary classifiers specifi-\ncally tuned to each section. This was done by creat-\ning a two-state HMM: one state corresponds to the\nlabel we want to detect, and the other state corre-\nsponds to all the other labels. We built four such\nclassifiers, one for each section, and trained them in\nthe same manner as above.\n"},{"#tail":"\n","@confidence":"0.993537375","#text":"\nWe report results on three distinct sets of experi-\nments: (1) ten-fold cross-validation (90/10 split) on\nall structured abstracts from the TREC 2004 MED-\nLINE corpus, (2) ten-fold cross-validation (90/10\nsplit) on the RCT subset of structured abstracts from\nthe TREC 2004 MEDLINE corpus, (3) training on\nthe RCT subset of the TREC 2004 MEDLINE cor-\npus and testing on the 49 hand-annotated held-out\ntestset.\nThe results of our first set of experiments are\nshown in Tables 1(a) and 1(b). Table 1(a) reports\nthe classification error in assigning a unique label to\nevery sentence, drawn from the set {?introduction?,\n?methods?, ?results?, ?conclusions?}. For this task,\nwe compare the performance of three separate mod-\nels: one that does not make the Markov assumption,\n"},{"#tail":"\n","@confidence":"0.994635166666667","#text":"\nstructured abstracts from the TREC 2004 MED-\nLINE corpus: multi-way classification on complete\nabstract structure (a) and by-section binary classifi-\ncation (b).\nthe basic four-state HMM, and the improved four-\nstate HMM with LDA. As expected, explicitly mod-\neling the discourse transitions significantly reduces\nthe error rate. Applying LDA further enhances clas-\nsification performance. Table 1(b) reports accuracy,\nprecision, recall, and F-measure for four separate bi-\nnary classifiers specifically trained for each of the\nsections (one per row in the table). We only dis-\nplay results with our best model, namely HMM with\nLDA.\nThe results of our second set of experiments (with\nRCTs only) are shown in Tables 2(a) and 2(b).\nTable 2(a) reports the multi-way classification er-\nror rate; once again, applying the Markov assump-\ntion to model discourse transitions improves perfor-\nmance, and using LDA further reduces error rate.\nTable 2(b) reports accuracy, precision, recall, and F-\nmeasure for four separate binary classifiers (HMM\nwith LDA) specifically trained for each of the sec-\ntions (one per row in the table). The table also\npresents the closest comparable experimental re-\nsults reported by McKnight and Srinivasan (2003).1\nMcKnight and Srinivasan (henceforth, M&S) cre-\nated a test collection consisting of 37,151 RCTs\nfrom approximately 12 million MEDLINE abstracts\ndated between 1976 and 2001. This collection has\n"},{"#tail":"\n","@confidence":"0.9809735","#text":"\nhand-annotated abstracts: multi-way classification (a) and binary classification (b). Unstructured abstracts\nwith all four sections (complete), and with missing sections (partial) are shown. Table (b) again repro-\nduces the results from McKnight and Srinivasan (2003) for a comparable task on a different subset of 206\nunstructured abstracts.\n"},{"#tail":"\n","@confidence":"0.996125060606061","#text":"\nsignificantly more training examples than our corpus\nof 27,075 abstracts, which could be a source of per-\nformance differences. Furthermore, details regard-\ning their procedure for mapping structured abstract\nheadings to one of the four general labels was not\ndiscussed in their paper. Nevertheless, our HMM-\nbased approach is at least competitive with SVMs,\nperhaps better in some cases.\nThe results of our third set of experiments (train-\ning on RCTs and testing on a held-out testset of\nhand-annotated abstracts) is shown in Tables 3(a)\nand 3(b). Mirroring the presentation format above,\nTable 3(a) shows the classification error for the four-\nway label assignment problem. We noticed that\nsome unstructured abstracts are qualitatively differ-\nent from structured abstracts in that some sections\nare missing. For example, some unstructured ab-\nstracts lack an introduction, and instead dive straight\ninto methods; other unstructured abstracts lack a\nconclusion. As a result, classification error is higher\nin this experiment than in the cross-validation ex-\nperiments. We report performance figures for 35 ab-\nstracts that contained all four sections (?complete?)\nand for 14 abstracts that had one or more miss-\ning sections (?partial?). Table 3(b) reports accu-\nracy, precision, recall, and F-measure for four sep-\narate binary classifiers (HMM with LDA) specifi-\ncally trained for each section (one per row in the\ntable). The table also presents the closest compa-\nrable experimental results reported by M&S?over\n206 hand-annotated unstructured abstracts. Interest-\ningly, M&S did not specifically note missing sec-\ntions in their testset.\n"},{"#tail":"\n","@confidence":"0.998166733333333","#text":"\nAn interesting aspect of our generative approach\nis that we model HMM outputs as Gaussian vec-\ntors (log probabilities of observing entire sentences\nbased on our language models), as opposed to se-\nquences of terms, as done in (Barzilay and Lee,\n2004). This technique provides two important ad-\nvantages. First, Gaussian modeling adds an ex-\ntra degree of freedom during training, by capturing\nsecond-order statistics. This is not possible when\nmodeling word sequences, where only the probabil-\nity of a sentence is actually used in the HMM train-\ning. Second, using continuous distributions allows\nus to leverage a variety of tools (e.g., LDA) that have\nbeen shown to be successful in other fields, such as\nspeech recognition (Evermann et al, 2004).\nTable 2(b) represents the closest head-to-head\ncomparison between our generative approach\n(HMM with LDA) and state-of-the-art results\nreported by M&S using SVMs. In some ways, the\nresults reported by M&S have an advantage because\nthey use significantly more training examples. Yet,\nwe can see that generative techniques for the model-\ning of content structure are at least competitive?we\neven outperform SVMs on detecting ?methods?\nand ?results?. Moreover, the fact that the training\nand testing of HMMs have linear complexity (as\nopposed to the quadratic complexity of SVMs)\nmakes our approach a very attractive alternative,\ngiven the amount of training data that is available\nfor such experiments.\nAlthough exploration of the tradeoffs between\ngenerative and discriminative machine learning\ntechniques is one of the aims of this work, our ul-\ntimate goal, however, is to build clinical systems\nthat provide timely access to information essential\nto the patient treatment process. In truth, our cross-\nvalidation experiments do not correspond to any\nmeaningful naturally-occurring task?structured ab-\nstracts are, after all, already appropriately labeled.\nThe true utility of content models is to struc-\nture abstracts that have no structure to begin with.\nThus, our exploratory experiments in applying con-\ntent models trained with structured RCTs on un-\nstructured RCTs is a closer approximation of an\nextrinsically-valid measure of performance. Such a\ncomponent would serve as the first stage of a clin-\nical question answering system (Demner-Fushman\nand Lin, 2005) or summarization system (McKe-\nown et al, 2003). We chose to focus on randomized\ncontrolled trials because they represent the standard\nbenchmark by which all other clinical studies are\nmeasured.\nTable 3(b) shows the effectiveness of our trained\ncontent models on abstracts that had no explicit\nstructure to begin with. We can see that although\nclassification accuracy is lower than that from our\ncross-validation experiments, performance is quite\nrespectable. Thus, our hypothesis that unstructured\nabstracts are not qualitatively different from struc-\ntured abstracts appears to be mostly valid.\n"},{"#tail":"\n","@confidence":"0.998871884615385","#text":"\nAlthough not the first to employ a generative ap-\nproach to directly model content, the seminal work\nof Barzilay and Lee (2004) is a noteworthy point\nof reference and comparison. However, our study\ndiffers in several important respects. Barzilay and\nLee employed an unsupervised approach to building\ntopic sequence models for the newswire text genre\nusing clustering techniques. In contrast, because\nthe discourse structure of medical abstracts is well-\ndefined and training data is relatively easy to ob-\ntain, we were able to apply a supervised approach.\nWhereas Barzilay and Lee evaluated their work in\nthe context of document summarization, the four-\npart structure of medical abstracts allows us to con-\nduct meaningful intrinsic evaluations and focus on\nthe sentence classification task. Nevertheless, their\nwork bolsters our claims regarding the usefulness of\ngenerative models in extrinsic tasks, which we do\nnot describe here.\nAlthough this study falls under the general topic\nof discourse modeling, our work differs from previ-\nous attempts to characterize text in terms of domain-\nindependent rhetorical elements (McKeown, 1985;\nMarcu and Echihabi, 2002). Our task is closer to the\nwork of Teufel and Moens (2000), who looked at the\nproblem of intellectual attribution in scientific texts.\n"},{"#tail":"\n","@confidence":"0.999802071428571","#text":"\nWe believe that there are two contributions as a re-\nsult of our work. From the perspective of machine\nlearning, the assignment of sequentially-occurring\nlabels represents an underexplored problem with re-\nspect to the generative vs. discriminative debate?\nprevious work has mostly focused on stateless clas-\nsification tasks. This paper demonstrates that Hid-\nden Markov Models are capable of capturing dis-\ncourse transitions from section to section, and are\nat least competitive with Support Vector Machines\nfrom a purely performance point of view.\nThe other contribution of our work is that it con-\ntributes to building advanced clinical information\nsystems. From an application point of view, the abil-\nity to assign structure to otherwise unstructured text\nrepresents a key capability that may assist in ques-\ntion answering, document summarization, and other\nnatural language processing applications.\nMuch research in computational linguistics has\nfocused on corpora comprised of newswire articles.\nWe would like to point out that clinical texts provide\nanother attractive genre in which to conduct experi-\nments. Such texts are easy to acquire, and the avail-\nability of domain ontologies provides new opportu-\nnities for knowledge-rich approaches to shine. Al-\nthough we have only experimented with lexical fea-\ntures in this study, the door is wide open for follow-\non studies based on semantic features.\n"},{"#tail":"\n","@confidence":"0.99805","#text":"\nThe first author would like to thank Esther and Kiri\nfor their loving support.\n"},{"#tail":"\n","@confidence":"0.897470071428571","#text":"\nAd Hoc Working Group for Critical Appraisal of the\nMedical Literature. 1987. A proposal for more infor-\nmative abstracts of clinical articles. Annals of Internal\nMedicine, 106:595?604.\nAlan R. Aronson. 2001. Effective mapping of biomed-\nical text to the UMLS Metathesaurus: The MetaMap\nprogram. In Proceeding of the 2001 Annual Sympo-\nsium of the American Medical Informatics Association\n(AMIA 2001), pages 17?21.\nRegina Barzilay and Lillian Lee. 2004. Catching the\ndrift: Probabilistic content models, with applications\nto generation and summarization. In Proceedings\nof the 2004 Human Language Technology Confer-\nence and the North American Chapter of the Associ-\n"}],"#text":"\n","affiliation":{"#tail":"\n","@confidence":"0.840067","#text":"\nUniversity of Maryland Johns Hopkins University\n"},"sectionHeader":[{"#tail":"\n","@confidence":"0.989956","@genericHeader":"abstract","#text":"\nAbstract\n"},{"#tail":"\n","@confidence":"0.998216","@genericHeader":"keywords","#text":"\n1 Introduction\n"},{"#tail":"\n","@confidence":"0.99018","@genericHeader":"introduction","#text":"\n2 Methods\n"},{"#tail":"\n","@confidence":"0.99996","@genericHeader":"method","#text":"\n3 Results\n"},{"#tail":"\n","@confidence":"0.996447","@genericHeader":"method","#text":"\n4 Discussion\n"},{"#tail":"\n","@confidence":"0.999622","@genericHeader":"evaluation","#text":"\n5 Related Work\n"},{"#tail":"\n","@confidence":"0.997821","@genericHeader":"conclusions","#text":"\n6 Conclusion\n"},{"#tail":"\n","@confidence":"0.998762","@genericHeader":"acknowledgments","#text":"\n7 Acknowledgments\n"},{"#tail":"\n","@confidence":"0.913379","@genericHeader":"references","#text":"\nReferences\n"}],"tableCaption":[{"#tail":"\n","@confidence":"0.99721","#text":"\nTable 1: Ten-fold cross-validation results on all\n"},{"#tail":"\n","@confidence":"0.9043505","#text":"\nTable 2: Ten-fold cross-validation results on the structured RCT subset of the TREC 2004 MEDLINE\ncorpus: multi-way classification (a) and binary classification (b). Table (b) also reproduces the results from\n"},{"#tail":"\n","@confidence":"0.998856","#text":"\nTable 3: Training on the structured RCT subset of the TREC 2004 MEDLINE corpus, testing on corpus of\n"}],"page":[{"#tail":"\n","@confidence":"0.997779","#text":"\n65\n"},{"#tail":"\n","@confidence":"0.97724","#text":"\n66\n"},{"#tail":"\n","@confidence":"0.994863","#text":"\n67\n"},{"#tail":"\n","@confidence":"0.965588","#text":"\n68\n"},{"#tail":"\n","@confidence":"0.995473","#text":"\n69\n"},{"#tail":"\n","@confidence":"0.994408","#text":"\n70\n"},{"#tail":"\n","@confidence":"0.984783","#text":"\n71\n"},{"#tail":"\n","@confidence":"0.997851","#text":"\n72\n"}],"figureCaption":{"#tail":"\n","@confidence":"0.933406","#text":"\nFigure 1: Sample structured abstract from MEDLINE.\n"},"table":[{"#tail":"\n","@confidence":"0.918115818181818","#text":"\nModel Error\nnon-HMM .220\nHMM .148\nHMM + LDA .118\n(a)\nSection Acc Prec Rec F\nIntroduction .957 .930 .840 .885\nMethods .921 .810 .875 .843\nResults .921 .898 .898 .898\nConclusions .963 .898 .896 .897\n(b)\n"},{"#tail":"\n","@confidence":"0.823950666666667","#text":"\nModel Error\nnon-HMM .238\nHMM .212\nHMM + LDA .209\n(a)\nPresent study McKnight and Srinivasan\nSection Acc Prec Rec F Acc Prec Rec F\nIntroduction .931 .898 .715 .807 .967 .920 .970 .945\nMethods .904 .812 .847 .830 .895 .810 .830 .820\nResults .902 .902 .831 .867 .860 .810 .830 .820\nConclusions .929 .772 .790 .781 .970 .880 .910 .820\n(b)\n"},{"#tail":"\n","@confidence":"0.957407384615385","#text":"\nMcKnight and Srinivasan (2003) for a comparable task on a different RCT-subset of structured abstracts.\nModel Complete Partial\nnon-HMM .247 .371\nHMM .226 .314\nHMM + LDA .217 .279\n(a)\nComplete Partial McKnight and Srinivasan\nSection Acc Prec Rec F Acc Prec Rec F Acc Prec Rec F\nIntroduction .923 .739 .723 .731 .867 .368 .636 .502 .896 .630 .450 .524\nMethods .905 .841 .793 .817 .859 .958 .589 .774 .897 .880 .730 .799\nResults .899 .913 .857 .885 .892 .942 .830 .886 .872 .840 .880 .861\nConclusions .911 .639 .847 .743 .884 .361 .995 .678 .941 .830 .750 .785\n(b)\n"}],"email":{"#tail":"\n","@confidence":"0.952854","#text":"\njimmylin@umd.edu, demner@cs.umd.edu (damianos, khudanpur)@jhu.edu\n"}}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.730485","#tail":"\n","@no":"0","note":{"#tail":"\n","@confidence":"0.985784","#text":"Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 65?72, New York City, June 2006. c?2006 Association for Computational Linguistics"},"address":{"#tail":"\n","@confidence":"0.999996","#text":"College Park, MD 20742, USA Baltimore, MD 21218, USA"},"#text":"\n","affiliation":{"#tail":"\n","@confidence":"0.984095","#text":"1College of Information Studies 3Center for Language and 2Institute for Advanced Computer Studies Speech Processing University of Maryland Johns Hopkins University"},"author":[{"#tail":"\n","@confidence":"0.958378","#text":"Damianos Karakos"},{"#tail":"\n","@confidence":"0.958378","#text":"Dina Demner-Fushman"},{"#tail":"\n","@confidence":"0.958378","#text":"Sanjeev Khudanpur"}],"intro":{"#tail":"\n","@confidence":"0.841286","#text":"stracts, which generally follow the pattern"},"abstract":{"#tail":"\n","@confidence":"0.999041285714286","#text":"The ability to accurately model the content structure of text is important for many natural language processing applications. This paper describes experiments with generative models for analyzing the discourse structure of medical ab-"},"title":{"#tail":"\n","@confidence":"0.923978","#text":"Generative Content Models for Structural Analysis of Medical Abstracts"},"email":{"#tail":"\n","@confidence":"0.999956","#text":"jimmylin@umd.edu,demner@cs.umd.edu(damianos,khudanpur)@jhu.edu"}}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"1987"},"rawString":{"#tail":"\n","#text":"Ad Hoc Working Group for Critical Appraisal of the Medical Literature. 1987. A proposal for more informative abstracts of clinical articles. Annals of Internal Medicine, 106:595?604."},"journal":{"#tail":"\n","#text":"Annals of Internal Medicine,"},"#text":"\n","pages":{"#tail":"\n","#text":"106--595"},"marker":{"#tail":"\n","#text":"Hoc, 1987"},"title":{"#tail":"\n","#text":"Working Group for Critical Appraisal of the Medical Literature."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Ad Hoc"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Alan R. Aronson. 2001. Effective mapping of biomedical text to the UMLS Metathesaurus: The MetaMap program. In Proceeding of the 2001 Annual Symposium of the American Medical Informatics Association (AMIA 2001), pages 17?21."},"#text":"\n","pages":{"#tail":"\n","#text":"17--21"},"marker":{"#tail":"\n","#text":"Aronson, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ovell et al, 1985; Gorman et al, 1994; Ely et al, 2005). Retrieval techniques can have a large impact on how physicians access and leverage clinical evidence. Information that satisfies physicians? needs can be found in theMEDLINE database maintained by the U.S. National Library of Medicine 65 (NLM), which also serves as a readily available corpus of abstracts for our experiments. Furthermore, the availability of rich ontological resources, in the form of the Unified Medical Language System (UMLS) (Lindberg et al, 1993), and the availability of software that leverages this knowledge? MetaMap (Aronson, 2001) for concept identification and SemRep (Rindflesch and Fiszman, 2003) for relation extraction?provide a foundation for studying the role of semantics in various tasks. McKnight and Srinivasan (2003) have previously examined the task of categorizing sentences in medical abstracts using supervised discriminative machine learning techniques. Building on the work of Ruch et al (2003) in the same domain, we present a generative approach that attempts to directly model the discourse structure of MEDLINE abstracts using Hidden Markov Models (HMMs); cf. (Barzilay and Lee, 2004). Although our results w","@endWordPosition":"569","@position":"3844","annotationId":"T1","@startWordPosition":"568","@citStr":"Aronson, 2001"}},"title":{"#tail":"\n","#text":"Effective mapping of biomedical text to the UMLS Metathesaurus: The MetaMap program."},"booktitle":{"#tail":"\n","#text":"In Proceeding of the 2001 Annual Symposium of the American Medical Informatics Association (AMIA"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Alan R Aronson"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Regina Barzilay and Lillian Lee. 2004. Catching the drift: Probabilistic content models, with applications to generation and summarization. In Proceedings of the 2004 Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics Annual Meeting (HLT/NAACL 2004)."},"#text":"\n","marker":{"#tail":"\n","#text":"Barzilay, Lee, 2004"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"verages this knowledge? MetaMap (Aronson, 2001) for concept identification and SemRep (Rindflesch and Fiszman, 2003) for relation extraction?provide a foundation for studying the role of semantics in various tasks. McKnight and Srinivasan (2003) have previously examined the task of categorizing sentences in medical abstracts using supervised discriminative machine learning techniques. Building on the work of Ruch et al (2003) in the same domain, we present a generative approach that attempts to directly model the discourse structure of MEDLINE abstracts using Hidden Markov Models (HMMs); cf. (Barzilay and Lee, 2004). Although our results were not obtained from the same exact collection as those used by authors of these two previous studies, comparable experiments suggest that our techniques are competitive in terms of performance, and may offer additional advantages as well. Discriminative approaches (especially SVMs) have been shown to be very effective for many supervised classification tasks; see, for example, (Joachims, 1998; Ng and Jordan, 2001). However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing. Under cert","@endWordPosition":"656","@position":"4420","annotationId":"T2","@startWordPosition":"653","@citStr":"Barzilay and Lee, 2004"},{"#tail":"\n","#text":"four sections (which we refer to as ?complete?), while 14 abstracts were missing one or more sections (which we refer to as ?partial?). Two different types of experiments were conducted: the first consisted of cross-validation on the structured abstracts; the second consisted of training on the structured abstracts and testing on the unstructured abstracts. We hypothesized that structured and unstructured abstracts share the same underlying discourse patterns, and that content models trained with one can be applied to the other. 2.2 Generative Models of Content Following Ruch et al (2003) and Barzilay and Lee (2004), we employed Hidden Markov Models to model the discourse structure of MEDLINE abstracts. The four states in our HMMs correspond to the information that characterizes each section (?introduction?, ?methods?, ?results?, and ?conclusions?) and state transitions capture the discourse flow from section to section. Using the SRI language modeling toolkit, we first computed bigram language models for each of the four sections using Kneser-Ney discounting and Katz backoff. All words in the training set were downcased, all numbers were converted into a generic symbol, and all singleton unigrams and bi","@endWordPosition":"1737","@position":"11576","annotationId":"T3","@startWordPosition":"1734","@citStr":"Barzilay and Lee (2004)"},{"#tail":"\n","#text":"precision, recall, and F-measure for four separate binary classifiers (HMM with LDA) specifically trained for each section (one per row in the table). The table also presents the closest comparable experimental results reported by M&S?over 206 hand-annotated unstructured abstracts. Interestingly, M&S did not specifically note missing sections in their testset. 4 Discussion An interesting aspect of our generative approach is that we model HMM outputs as Gaussian vectors (log probabilities of observing entire sentences based on our language models), as opposed to sequences of terms, as done in (Barzilay and Lee, 2004). This technique provides two important advantages. First, Gaussian modeling adds an extra degree of freedom during training, by capturing second-order statistics. This is not possible when modeling word sequences, where only the probability of a sentence is actually used in the HMM training. Second, using continuous distributions allows us to leverage a variety of tools (e.g., LDA) that have been shown to be successful in other fields, such as speech recognition (Evermann et al, 2004). Table 2(b) represents the closest head-to-head comparison between our generative approach (HMM with LDA) and","@endWordPosition":"3143","@position":"20421","annotationId":"T4","@startWordPosition":"3140","@citStr":"Barzilay and Lee, 2004"},{"#tail":"\n","#text":"resent the standard benchmark by which all other clinical studies are measured. Table 3(b) shows the effectiveness of our trained content models on abstracts that had no explicit structure to begin with. We can see that although classification accuracy is lower than that from our cross-validation experiments, performance is quite respectable. Thus, our hypothesis that unstructured abstracts are not qualitatively different from structured abstracts appears to be mostly valid. 70 5 Related Work Although not the first to employ a generative approach to directly model content, the seminal work of Barzilay and Lee (2004) is a noteworthy point of reference and comparison. However, our study differs in several important respects. Barzilay and Lee employed an unsupervised approach to building topic sequence models for the newswire text genre using clustering techniques. In contrast, because the discourse structure of medical abstracts is welldefined and training data is relatively easy to obtain, we were able to apply a supervised approach. Whereas Barzilay and Lee evaluated their work in the context of document summarization, the fourpart structure of medical abstracts allows us to conduct meaningful intrinsic ","@endWordPosition":"3571","@position":"23203","annotationId":"T5","@startWordPosition":"3568","@citStr":"Barzilay and Lee (2004)"}]},"title":{"#tail":"\n","#text":"Catching the drift: Probabilistic content models, with applications to generation and summarization."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 2004 Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics Annual Meeting (HLT/NAACL"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Regina Barzilay"},{"#tail":"\n","#text":"Lillian Lee"}]}},{"date":{"#tail":"\n","#text":"1985"},"issue":{"#tail":"\n","#text":"4"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"rticle texts yields at most a 7.4% improvement in F-score. Demner-Fushman et al (2005) found a correlation between the quality and strength of clinical conclusions in the full article texts and abstracts. This paper presents experiments with generative content models for analyzing the discourse structure of medical abstracts, which has been confirmed to follow the four-section pattern discussed above (Salanger-Meyer, 1990). For a variety of reasons, medicine is an interesting domain of research. The need for information systems to support physicians at the point of care has been well studied (Covell et al, 1985; Gorman et al, 1994; Ely et al, 2005). Retrieval techniques can have a large impact on how physicians access and leverage clinical evidence. Information that satisfies physicians? needs can be found in theMEDLINE database maintained by the U.S. National Library of Medicine 65 (NLM), which also serves as a readily available corpus of abstracts for our experiments. Furthermore, the availability of rich ontological resources, in the form of the Unified Medical Language System (UMLS) (Lindberg et al, 1993), and the availability of software that leverages this knowledge? MetaMap (Aronson, 2001) fo","@endWordPosition":"473","@position":"3247","annotationId":"T6","@startWordPosition":"469","@citStr":"Covell et al, 1985"}},"title":{"#tail":"\n","#text":"Information needs in office practice: Are they being met?"},"volume":{"#tail":"\n","#text":"103"},"#tail":"\n","rawString":{"#tail":"\n","#text":"David G. Covell, Gwen C. Uman, and Phil R. Manning. 1985. Information needs in office practice: Are they being met? Annals of Internal Medicine, 103(4):596? 599, October."},"journal":{"#tail":"\n","#text":"Annals of Internal Medicine,"},"#text":"\n","pages":{"#tail":"\n","#text":"599"},"marker":{"#tail":"\n","#text":"Covell, Uman, Manning, 1985"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"David G Covell"},{"#tail":"\n","#text":"Gwen C Uman"},{"#tail":"\n","#text":"Phil R Manning"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"Dina Demner-Fushman and Jimmy Lin. 2005. Knowledge extraction for clinical question answering: Preliminary results. In Proceedings of the AAAI-05 Workshop on Question Answering in Restricted Domains. Dina Demner-Fushman, Susan E. Hauser, and George R."},"#text":"\n","marker":{"#tail":"\n","#text":"Demner-Fushman, Lin, 2005"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"formation essential to the patient treatment process. In truth, our crossvalidation experiments do not correspond to any meaningful naturally-occurring task?structured abstracts are, after all, already appropriately labeled. The true utility of content models is to structure abstracts that have no structure to begin with. Thus, our exploratory experiments in applying content models trained with structured RCTs on unstructured RCTs is a closer approximation of an extrinsically-valid measure of performance. Such a component would serve as the first stage of a clinical question answering system (Demner-Fushman and Lin, 2005) or summarization system (McKeown et al, 2003). We chose to focus on randomized controlled trials because they represent the standard benchmark by which all other clinical studies are measured. Table 3(b) shows the effectiveness of our trained content models on abstracts that had no explicit structure to begin with. We can see that although classification accuracy is lower than that from our cross-validation experiments, performance is quite respectable. Thus, our hypothesis that unstructured abstracts are not qualitatively different from structured abstracts appears to be mostly valid. 70 5 R","@endWordPosition":"3457","@position":"22466","annotationId":"T7","@startWordPosition":"3454","@citStr":"Demner-Fushman and Lin, 2005"}},"title":{"#tail":"\n","#text":"Knowledge extraction for clinical question answering: Preliminary results."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the AAAI-05 Workshop on Question Answering in Restricted Domains. Dina Demner-Fushman, Susan"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Dina Demner-Fushman"},{"#tail":"\n","#text":"Jimmy Lin"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"Thoma. 2005. The role of title, metadata and abstract in identifying clinically relevant journal articles. In Proceeding of the 2005 Annual Symposium of the American Medical Informatics Association (AMIA 2005), pages 191?195."},"#text":"\n","pages":{"#tail":"\n","#text":"191--195"},"marker":{"#tail":"\n","#text":"Thoma, 2005"},"title":{"#tail":"\n","#text":"The role of title, metadata and abstract in identifying clinically relevant journal articles."},"booktitle":{"#tail":"\n","#text":"In Proceeding of the 2005 Annual Symposium of the American Medical Informatics Association (AMIA"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Thoma"}}},{"volume":{"#tail":"\n","#text":"12"},"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"John W. Ely, Jerome A. Osheroff, M. Lee Chambliss, Mark H. Ebell, and Marcy E. Rosenbaum. 2005. Answering physicians? clinical questions: Obstacles and potential solutions. Journal of the American Medical Informatics Association, 12(2):217?224, March-April."},"journal":{"#tail":"\n","#text":"Journal of the American Medical Informatics Association,"},"#text":"\n","issue":{"#tail":"\n","#text":"2"},"marker":{"#tail":"\n","#text":"Ely, Osheroff, Chambliss, Ebell, Rosenbaum, 2005"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"vement in F-score. Demner-Fushman et al (2005) found a correlation between the quality and strength of clinical conclusions in the full article texts and abstracts. This paper presents experiments with generative content models for analyzing the discourse structure of medical abstracts, which has been confirmed to follow the four-section pattern discussed above (Salanger-Meyer, 1990). For a variety of reasons, medicine is an interesting domain of research. The need for information systems to support physicians at the point of care has been well studied (Covell et al, 1985; Gorman et al, 1994; Ely et al, 2005). Retrieval techniques can have a large impact on how physicians access and leverage clinical evidence. Information that satisfies physicians? needs can be found in theMEDLINE database maintained by the U.S. National Library of Medicine 65 (NLM), which also serves as a readily available corpus of abstracts for our experiments. Furthermore, the availability of rich ontological resources, in the form of the Unified Medical Language System (UMLS) (Lindberg et al, 1993), and the availability of software that leverages this knowledge? MetaMap (Aronson, 2001) for concept identification and SemRep (R","@endWordPosition":"481","@position":"3285","annotationId":"T8","@startWordPosition":"478","@citStr":"Ely et al, 2005"}},"title":{"#tail":"\n","#text":"Answering physicians? clinical questions: Obstacles and potential solutions."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"John W Ely"},{"#tail":"\n","#text":"Jerome A Osheroff"},{"#tail":"\n","#text":"M Lee Chambliss"},{"#tail":"\n","#text":"Mark H Ebell"},{"#tail":"\n","#text":"Marcy E Rosenbaum"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Gunnar Evermann, H. Y. Chan, Mark J. F. Gales, Thomas Hain, Xunying Liu, David Mrva, Lan Wang, and Phil Woodland. 2004. Development of the 2003 CU-HTK Conversational Telephone Speech Transcription System. In Proceedings of the 2004 International Conference on Acoustics, Speech and Signal Processing (ICASSP04)."},"journal":{"#tail":"\n","#text":"Development of the"},"#text":"\n","marker":{"#tail":"\n","#text":"Evermann, Chan, Gales, Hain, Liu, Mrva, Wang, Woodland, 2004"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" of observing entire sentences based on our language models), as opposed to sequences of terms, as done in (Barzilay and Lee, 2004). This technique provides two important advantages. First, Gaussian modeling adds an extra degree of freedom during training, by capturing second-order statistics. This is not possible when modeling word sequences, where only the probability of a sentence is actually used in the HMM training. Second, using continuous distributions allows us to leverage a variety of tools (e.g., LDA) that have been shown to be successful in other fields, such as speech recognition (Evermann et al, 2004). Table 2(b) represents the closest head-to-head comparison between our generative approach (HMM with LDA) and state-of-the-art results reported by M&S using SVMs. In some ways, the results reported by M&S have an advantage because they use significantly more training examples. Yet, we can see that generative techniques for the modeling of content structure are at least competitive?we even outperform SVMs on detecting ?methods? and ?results?. Moreover, the fact that the training and testing of HMMs have linear complexity (as opposed to the quadratic complexity of SVMs) makes our approach a ver","@endWordPosition":"3222","@position":"20911","annotationId":"T9","@startWordPosition":"3219","@citStr":"Evermann et al, 2004"}},"title":{"#tail":"\n","#text":"CU-HTK Conversational Telephone Speech Transcription System."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 2004 International Conference on Acoustics, Speech and Signal Processing (ICASSP04)."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Gunnar Evermann"},{"#tail":"\n","#text":"H Y Chan"},{"#tail":"\n","#text":"Mark J F Gales"},{"#tail":"\n","#text":"Thomas Hain"},{"#tail":"\n","#text":"Xunying Liu"},{"#tail":"\n","#text":"David Mrva"},{"#tail":"\n","#text":"Lan Wang"},{"#tail":"\n","#text":"Phil Woodland"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"Clifford W. Gay, Mehmet Kayaalp, and Alan R. Aronson. 2005. Semi-automatic indexing of full text biomedical articles. In Proceeding of the 2005 Annual Symposium of the American Medical Informatics Association (AMIA 2005), pages 271?275."},"#text":"\n","pages":{"#tail":"\n","#text":"271--275"},"marker":{"#tail":"\n","#text":"Gay, Kayaalp, Aronson, 2005"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"?introduction?, ?methods?, ?results?, and ?conclusions? (SalangerMeyer, 1990; Swales, 1990; Ora?san, 2001). The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization (Teufel and Moens, 2000), information retrieval (Tbahriti et al, 2005), information extraction (Mizuta et al, 2005), and question answering. Although there is a trend towards analysis of full article texts, we believe that abstracts still provide a tremendous amount of information, and much value can still be extracted from them. For example, Gay et al (2005) experimented with abstracts and full article texts in the task of automatically generating index term recommendations and discovered that using full article texts yields at most a 7.4% improvement in F-score. Demner-Fushman et al (2005) found a correlation between the quality and strength of clinical conclusions in the full article texts and abstracts. This paper presents experiments with generative content models for analyzing the discourse structure of medical abstracts, which has been confirmed to follow the four-section pattern discussed above (Salanger-Meyer, 1990). For a variety of reas","@endWordPosition":"351","@position":"2478","annotationId":"T10","@startWordPosition":"348","@citStr":"Gay et al (2005)"}},"title":{"#tail":"\n","#text":"Semi-automatic indexing of full text biomedical articles."},"booktitle":{"#tail":"\n","#text":"In Proceeding of the 2005 Annual Symposium of the American Medical Informatics Association (AMIA"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Clifford W Gay"},{"#tail":"\n","#text":"Mehmet Kayaalp"},{"#tail":"\n","#text":"Alan R Aronson"}]}},{"volume":{"#tail":"\n","#text":"82"},"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Paul N. Gorman, Joan S. Ash, and Leslie W. Wykoff. 1994. Can primary care physicians? questions be answered using the medical journal literature? Bulletin of the Medical Library Association, 82(2):140?146, April."},"journal":{"#tail":"\n","#text":"Bulletin of the Medical Library Association,"},"#text":"\n","issue":{"#tail":"\n","#text":"2"},"marker":{"#tail":"\n","#text":"Gorman, Ash, Wykoff, 1994"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"at most a 7.4% improvement in F-score. Demner-Fushman et al (2005) found a correlation between the quality and strength of clinical conclusions in the full article texts and abstracts. This paper presents experiments with generative content models for analyzing the discourse structure of medical abstracts, which has been confirmed to follow the four-section pattern discussed above (Salanger-Meyer, 1990). For a variety of reasons, medicine is an interesting domain of research. The need for information systems to support physicians at the point of care has been well studied (Covell et al, 1985; Gorman et al, 1994; Ely et al, 2005). Retrieval techniques can have a large impact on how physicians access and leverage clinical evidence. Information that satisfies physicians? needs can be found in theMEDLINE database maintained by the U.S. National Library of Medicine 65 (NLM), which also serves as a readily available corpus of abstracts for our experiments. Furthermore, the availability of rich ontological resources, in the form of the Unified Medical Language System (UMLS) (Lindberg et al, 1993), and the availability of software that leverages this knowledge? MetaMap (Aronson, 2001) for concept identifica","@endWordPosition":"477","@position":"3267","annotationId":"T11","@startWordPosition":"474","@citStr":"Gorman et al, 1994"}},"title":{"#tail":"\n","#text":"Can primary care physicians? questions be answered using the medical journal literature?"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Paul N Gorman"},{"#tail":"\n","#text":"Joan S Ash"},{"#tail":"\n","#text":"Leslie W Wykoff"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"note":{"#tail":"\n","#text":"Donald"},"rawString":{"#tail":"\n","#text":"Thorsten Joachims. 1998. Text categorization with Support Vector Machines: Learning with many relevant features. In Proceedings of the European Conference on Machine Learning (ECML 1998). Donald A. Lindberg, Betsy L. Humphreys, and Alexa T."},"#text":"\n","marker":{"#tail":"\n","#text":"Joachims, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"in the same domain, we present a generative approach that attempts to directly model the discourse structure of MEDLINE abstracts using Hidden Markov Models (HMMs); cf. (Barzilay and Lee, 2004). Although our results were not obtained from the same exact collection as those used by authors of these two previous studies, comparable experiments suggest that our techniques are competitive in terms of performance, and may offer additional advantages as well. Discriminative approaches (especially SVMs) have been shown to be very effective for many supervised classification tasks; see, for example, (Joachims, 1998; Ng and Jordan, 2001). However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing. Under certain conditions, generative approaches with linear complexity are preferable, even if their performance is lower than that which can be achieved through discriminative training. Since HMMs are very wellsuited to modeling sequences, our discourse modeling task lends itself naturally to this particular generative approach. In fact, we demonstrate that HMMs are competitive with SVMs, with the added advantage of lower comp","@endWordPosition":"721","@position":"4841","annotationId":"T12","@startWordPosition":"720","@citStr":"Joachims, 1998"}},"title":{"#tail":"\n","#text":"Text categorization with Support Vector Machines: Learning with many relevant features."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the European Conference on Machine Learning (ECML"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Thorsten Joachims"}}},{"volume":{"#tail":"\n","#text":"32"},"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"McCray. 1993. The Unified Medical Language System. Methods of Information in Medicine, 32(4):281? 291, August."},"journal":{"#tail":"\n","#text":"Methods of Information in Medicine,"},"#text":"\n","pages":{"#tail":"\n","#text":"291"},"issue":{"#tail":"\n","#text":"4"},"marker":{"#tail":"\n","#text":"McCray, 1993"},"title":{"#tail":"\n","#text":"The Unified Medical Language System."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"McCray"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Daniel Marcu and Abdessamad Echihabi. 2002. An unsupervised approach to recognizing discourse relations. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL 2002)."},"#text":"\n","marker":{"#tail":"\n","#text":"Marcu, Echihabi, 2002"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"y a supervised approach. Whereas Barzilay and Lee evaluated their work in the context of document summarization, the fourpart structure of medical abstracts allows us to conduct meaningful intrinsic evaluations and focus on the sentence classification task. Nevertheless, their work bolsters our claims regarding the usefulness of generative models in extrinsic tasks, which we do not describe here. Although this study falls under the general topic of discourse modeling, our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements (McKeown, 1985; Marcu and Echihabi, 2002). Our task is closer to the work of Teufel and Moens (2000), who looked at the problem of intellectual attribution in scientific texts. 6 Conclusion We believe that there are two contributions as a result of our work. From the perspective of machine learning, the assignment of sequentially-occurring labels represents an underexplored problem with respect to the generative vs. discriminative debate? previous work has mostly focused on stateless classification tasks. This paper demonstrates that Hidden Markov Models are capable of capturing discourse transitions from section to section, and are ","@endWordPosition":"3726","@position":"24229","annotationId":"T13","@startWordPosition":"3723","@citStr":"Marcu and Echihabi, 2002"}},"title":{"#tail":"\n","#text":"An unsupervised approach to recognizing discourse relations."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Daniel Marcu"},{"#tail":"\n","#text":"Abdessamad Echihabi"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Kathleen McKeown, Noemie Elhadad, and Vasileios Hatzivassiloglou. 2003. Leveraging a common representation for personalized search and summarization in a medical digital library. In Proceedings of the 3rd ACM/IEEE Joint Conference on Digital Libraries (JCDL 2003)."},"#text":"\n","marker":{"#tail":"\n","#text":"McKeown, Elhadad, Hatzivassiloglou, 2003"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"n truth, our crossvalidation experiments do not correspond to any meaningful naturally-occurring task?structured abstracts are, after all, already appropriately labeled. The true utility of content models is to structure abstracts that have no structure to begin with. Thus, our exploratory experiments in applying content models trained with structured RCTs on unstructured RCTs is a closer approximation of an extrinsically-valid measure of performance. Such a component would serve as the first stage of a clinical question answering system (Demner-Fushman and Lin, 2005) or summarization system (McKeown et al, 2003). We chose to focus on randomized controlled trials because they represent the standard benchmark by which all other clinical studies are measured. Table 3(b) shows the effectiveness of our trained content models on abstracts that had no explicit structure to begin with. We can see that although classification accuracy is lower than that from our cross-validation experiments, performance is quite respectable. Thus, our hypothesis that unstructured abstracts are not qualitatively different from structured abstracts appears to be mostly valid. 70 5 Related Work Although not the first to employ a","@endWordPosition":"3465","@position":"22512","annotationId":"T14","@startWordPosition":"3461","@citStr":"McKeown et al, 2003"}},"title":{"#tail":"\n","#text":"Leveraging a common representation for personalized search and summarization in a medical digital library."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 3rd ACM/IEEE Joint Conference on Digital Libraries (JCDL"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kathleen McKeown"},{"#tail":"\n","#text":"Noemie Elhadad"},{"#tail":"\n","#text":"Vasileios Hatzivassiloglou"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1985"},"rawString":{"#tail":"\n","#text":"Kathleen R. McKeown. 1985. Text Generation: Using Discourse Strategies and Focus Constraints to Generate Natural Language Text. Cambridge University Press, Cambridge, England."},"#text":"\n","marker":{"#tail":"\n","#text":"McKeown, 1985"},"publisher":{"#tail":"\n","#text":"Cambridge University Press,"},"location":{"#tail":"\n","#text":"Cambridge, England."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"re able to apply a supervised approach. Whereas Barzilay and Lee evaluated their work in the context of document summarization, the fourpart structure of medical abstracts allows us to conduct meaningful intrinsic evaluations and focus on the sentence classification task. Nevertheless, their work bolsters our claims regarding the usefulness of generative models in extrinsic tasks, which we do not describe here. Although this study falls under the general topic of discourse modeling, our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements (McKeown, 1985; Marcu and Echihabi, 2002). Our task is closer to the work of Teufel and Moens (2000), who looked at the problem of intellectual attribution in scientific texts. 6 Conclusion We believe that there are two contributions as a result of our work. From the perspective of machine learning, the assignment of sequentially-occurring labels represents an underexplored problem with respect to the generative vs. discriminative debate? previous work has mostly focused on stateless classification tasks. This paper demonstrates that Hidden Markov Models are capable of capturing discourse transitions from s","@endWordPosition":"3722","@position":"24202","annotationId":"T15","@startWordPosition":"3721","@citStr":"McKeown, 1985"}},"title":{"#tail":"\n","#text":"Text Generation: Using Discourse Strategies and Focus Constraints to Generate Natural Language Text."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Kathleen R McKeown"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Larry McKnight and Padmini Srinivasan. 2003. Categorization of sentence types in medical abstracts. In Proceeding of the 2003 Annual Symposium of the American Medical Informatics Association (AMIA 2003)."},"#text":"\n","marker":{"#tail":"\n","#text":"McKnight, Srinivasan, 2003"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ies physicians? needs can be found in theMEDLINE database maintained by the U.S. National Library of Medicine 65 (NLM), which also serves as a readily available corpus of abstracts for our experiments. Furthermore, the availability of rich ontological resources, in the form of the Unified Medical Language System (UMLS) (Lindberg et al, 1993), and the availability of software that leverages this knowledge? MetaMap (Aronson, 2001) for concept identification and SemRep (Rindflesch and Fiszman, 2003) for relation extraction?provide a foundation for studying the role of semantics in various tasks. McKnight and Srinivasan (2003) have previously examined the task of categorizing sentences in medical abstracts using supervised discriminative machine learning techniques. Building on the work of Ruch et al (2003) in the same domain, we present a generative approach that attempts to directly model the discourse structure of MEDLINE abstracts using Hidden Markov Models (HMMs); cf. (Barzilay and Lee, 2004). Although our results were not obtained from the same exact collection as those used by authors of these two previous studies, comparable experiments suggest that our techniques are competitive in terms of performance, an","@endWordPosition":"597","@position":"4042","annotationId":"T16","@startWordPosition":"594","@citStr":"McKnight and Srinivasan (2003)"},{"#tail":"\n","#text":" our best model, namely HMM with LDA. The results of our second set of experiments (with RCTs only) are shown in Tables 2(a) and 2(b). Table 2(a) reports the multi-way classification error rate; once again, applying the Markov assumption to model discourse transitions improves performance, and using LDA further reduces error rate. Table 2(b) reports accuracy, precision, recall, and Fmeasure for four separate binary classifiers (HMM with LDA) specifically trained for each of the sections (one per row in the table). The table also presents the closest comparable experimental results reported by McKnight and Srinivasan (2003).1 McKnight and Srinivasan (henceforth, M&S) created a test collection consisting of 37,151 RCTs from approximately 12 million MEDLINE abstracts dated between 1976 and 2001. This collection has 1After contacting the authors, we were unable to obtain the same exact dataset that they used for their experiments. 68 Model Error non-HMM .238 HMM .212 HMM + LDA .209 (a) Present study McKnight and Srinivasan Section Acc Prec Rec F Acc Prec Rec F Introduction .931 .898 .715 .807 .967 .920 .970 .945 Methods .904 .812 .847 .830 .895 .810 .830 .820 Results .902 .902 .831 .867 .860 .810 .830 .820 Conclusi","@endWordPosition":"2544","@position":"16685","annotationId":"T17","@startWordPosition":"2541","@citStr":"McKnight and Srinivasan (2003)"},{"#tail":"\n","#text":"9 .723 .731 .867 .368 .636 .502 .896 .630 .450 .524 Methods .905 .841 .793 .817 .859 .958 .589 .774 .897 .880 .730 .799 Results .899 .913 .857 .885 .892 .942 .830 .886 .872 .840 .880 .861 Conclusions .911 .639 .847 .743 .884 .361 .995 .678 .941 .830 .750 .785 (b) Table 3: Training on the structured RCT subset of the TREC 2004 MEDLINE corpus, testing on corpus of hand-annotated abstracts: multi-way classification (a) and binary classification (b). Unstructured abstracts with all four sections (complete), and with missing sections (partial) are shown. Table (b) again reproduces the results from McKnight and Srinivasan (2003) for a comparable task on a different subset of 206 unstructured abstracts. 69 significantly more training examples than our corpus of 27,075 abstracts, which could be a source of performance differences. Furthermore, details regarding their procedure for mapping structured abstract headings to one of the four general labels was not discussed in their paper. Nevertheless, our HMMbased approach is at least competitive with SVMs, perhaps better in some cases. The results of our third set of experiments (training on RCTs and testing on a held-out testset of hand-annotated abstracts) is shown in T","@endWordPosition":"2838","@position":"18469","annotationId":"T18","@startWordPosition":"2835","@citStr":"McKnight and Srinivasan (2003)"}]},"title":{"#tail":"\n","#text":"Categorization of sentence types in medical abstracts."},"booktitle":{"#tail":"\n","#text":"In Proceeding of the 2003 Annual Symposium of the American Medical Informatics Association (AMIA"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Larry McKnight"},{"#tail":"\n","#text":"Padmini Srinivasan"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"note":{"#tail":"\n","#text":"in press."},"rawString":{"#tail":"\n","#text":"Yoko Mizuta, Anna Korhonen, Tony Mullen, and Nigel Collier. 2005. Zone analysis in biology articles as a basis for information extraction. International Journal of Medical Informatics, in press."},"journal":{"#tail":"\n","#text":"International Journal of Medical Informatics,"},"#text":"\n","marker":{"#tail":"\n","#text":"Mizuta, Korhonen, Mullen, Collier, 2005"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"oduction Certain types of text follow a predictable structure, the knowledge of which would be useful in many natural language processing applications. As an example, scientific abstracts across many different fields generally follow the pattern of ?introduction?, ?methods?, ?results?, and ?conclusions? (SalangerMeyer, 1990; Swales, 1990; Ora?san, 2001). The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization (Teufel and Moens, 2000), information retrieval (Tbahriti et al, 2005), information extraction (Mizuta et al, 2005), and question answering. Although there is a trend towards analysis of full article texts, we believe that abstracts still provide a tremendous amount of information, and much value can still be extracted from them. For example, Gay et al (2005) experimented with abstracts and full article texts in the task of automatically generating index term recommendations and discovered that using full article texts yields at most a 7.4% improvement in F-score. Demner-Fushman et al (2005) found a correlation between the quality and strength of clinical conclusions in the full article texts and abstracts","@endWordPosition":"311","@position":"2232","annotationId":"T19","@startWordPosition":"308","@citStr":"Mizuta et al, 2005"}},"title":{"#tail":"\n","#text":"Zone analysis in biology articles as a basis for information extraction."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Yoko Mizuta"},{"#tail":"\n","#text":"Anna Korhonen"},{"#tail":"\n","#text":"Tony Mullen"},{"#tail":"\n","#text":"Nigel Collier"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Andrew Y. Ng and Michael Jordan. 2001. On discriminative vs. generative classifiers: A comparison of logistic regression and naive Bayes. In Advances in Neural Information Processing Systems 14."},"#text":"\n","marker":{"#tail":"\n","#text":"Ng, Jordan, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"in, we present a generative approach that attempts to directly model the discourse structure of MEDLINE abstracts using Hidden Markov Models (HMMs); cf. (Barzilay and Lee, 2004). Although our results were not obtained from the same exact collection as those used by authors of these two previous studies, comparable experiments suggest that our techniques are competitive in terms of performance, and may offer additional advantages as well. Discriminative approaches (especially SVMs) have been shown to be very effective for many supervised classification tasks; see, for example, (Joachims, 1998; Ng and Jordan, 2001). However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing. Under certain conditions, generative approaches with linear complexity are preferable, even if their performance is lower than that which can be achieved through discriminative training. Since HMMs are very wellsuited to modeling sequences, our discourse modeling task lends itself naturally to this particular generative approach. In fact, we demonstrate that HMMs are competitive with SVMs, with the added advantage of lower computational complexity. ","@endWordPosition":"725","@position":"4863","annotationId":"T20","@startWordPosition":"722","@citStr":"Ng and Jordan, 2001"}},"title":{"#tail":"\n","#text":"On discriminative vs. generative classifiers: A comparison of logistic regression and naive Bayes."},"booktitle":{"#tail":"\n","#text":"In Advances in Neural Information Processing Systems 14."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Andrew Y Ng"},{"#tail":"\n","#text":"Michael Jordan"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"note":{"#tail":"\n","#text":"Patterns in scientific abstracts."},"rawString":{"#tail":"\n","#text":"Constantin Ora?san. 2001. Patterns in scientific abstracts."},"#text":"\n","marker":{"#tail":"\n","#text":"Orasan, 2001"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Constantin Orasan"}}},{"#tail":"\n","rawString":{"#tail":"\n","#text":"In Proceedings of the 2001 Corpus Linguistics Conference."},"#text":"\n","marker":{"#tail":"\n"},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 2001 Corpus Linguistics Conference."},"@valid":"false"},{"volume":{"#tail":"\n","#text":"36"},"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Thomas C. Rindflesch and Marcelo Fiszman. 2003. The interaction of domain knowledge and linguistic structure in natural language processing: Interpreting hypernymic propositions in biomedical text. Journal of Biomedical Informatics, 36(6):462?477, December."},"journal":{"#tail":"\n","#text":"Journal of Biomedical Informatics,"},"#text":"\n","issue":{"#tail":"\n","#text":"6"},"marker":{"#tail":"\n","#text":"Rindflesch, Fiszman, 2003"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"). Retrieval techniques can have a large impact on how physicians access and leverage clinical evidence. Information that satisfies physicians? needs can be found in theMEDLINE database maintained by the U.S. National Library of Medicine 65 (NLM), which also serves as a readily available corpus of abstracts for our experiments. Furthermore, the availability of rich ontological resources, in the form of the Unified Medical Language System (UMLS) (Lindberg et al, 1993), and the availability of software that leverages this knowledge? MetaMap (Aronson, 2001) for concept identification and SemRep (Rindflesch and Fiszman, 2003) for relation extraction?provide a foundation for studying the role of semantics in various tasks. McKnight and Srinivasan (2003) have previously examined the task of categorizing sentences in medical abstracts using supervised discriminative machine learning techniques. Building on the work of Ruch et al (2003) in the same domain, we present a generative approach that attempts to directly model the discourse structure of MEDLINE abstracts using Hidden Markov Models (HMMs); cf. (Barzilay and Lee, 2004). Although our results were not obtained from the same exact collection as those used by auth","@endWordPosition":"578","@position":"3913","annotationId":"T21","@startWordPosition":"575","@citStr":"Rindflesch and Fiszman, 2003"}},"title":{"#tail":"\n","#text":"The interaction of domain knowledge and linguistic structure in natural language processing: Interpreting hypernymic propositions in biomedical text."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Thomas C Rindflesch"},{"#tail":"\n","#text":"Marcelo Fiszman"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Patrick Ruch, Christine Chichester, Gilles Cohen, Giovanni Coray, Fre?de?ric Ehrler, Hatem Ghorbel, Henning Mu?ller, and Vincenzo Pallotta. 2003. Report on the TREC 2003 experiment: Genomic track. In Proceedings of the Twelfth Text REtrieval Conference (TREC 2003)."},"journal":{"#tail":"\n","#text":"Report on the TREC"},"#text":"\n","marker":{"#tail":"\n","#text":"Ruch, Chichester, Cohen, Coray, Ehrler, Ghorbel, Muller, Pallotta, 2003"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"nts. Furthermore, the availability of rich ontological resources, in the form of the Unified Medical Language System (UMLS) (Lindberg et al, 1993), and the availability of software that leverages this knowledge? MetaMap (Aronson, 2001) for concept identification and SemRep (Rindflesch and Fiszman, 2003) for relation extraction?provide a foundation for studying the role of semantics in various tasks. McKnight and Srinivasan (2003) have previously examined the task of categorizing sentences in medical abstracts using supervised discriminative machine learning techniques. Building on the work of Ruch et al (2003) in the same domain, we present a generative approach that attempts to directly model the discourse structure of MEDLINE abstracts using Hidden Markov Models (HMMs); cf. (Barzilay and Lee, 2004). Although our results were not obtained from the same exact collection as those used by authors of these two previous studies, comparable experiments suggest that our techniques are competitive in terms of performance, and may offer additional advantages as well. Discriminative approaches (especially SVMs) have been shown to be very effective for many supervised classification tasks; see, for example, ","@endWordPosition":"625","@position":"4226","annotationId":"T22","@startWordPosition":"622","@citStr":"Ruch et al (2003)"},{"#tail":"\n","#text":"cts, 35 contained all four sections (which we refer to as ?complete?), while 14 abstracts were missing one or more sections (which we refer to as ?partial?). Two different types of experiments were conducted: the first consisted of cross-validation on the structured abstracts; the second consisted of training on the structured abstracts and testing on the unstructured abstracts. We hypothesized that structured and unstructured abstracts share the same underlying discourse patterns, and that content models trained with one can be applied to the other. 2.2 Generative Models of Content Following Ruch et al (2003) and Barzilay and Lee (2004), we employed Hidden Markov Models to model the discourse structure of MEDLINE abstracts. The four states in our HMMs correspond to the information that characterizes each section (?introduction?, ?methods?, ?results?, and ?conclusions?) and state transitions capture the discourse flow from section to section. Using the SRI language modeling toolkit, we first computed bigram language models for each of the four sections using Kneser-Ney discounting and Katz backoff. All words in the training set were downcased, all numbers were converted into a generic symbol, and a","@endWordPosition":"1732","@position":"11548","annotationId":"T23","@startWordPosition":"1729","@citStr":"Ruch et al (2003)"}]},"title":{"#tail":"\n","#text":"experiment: Genomic track."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Twelfth Text REtrieval Conference (TREC"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Patrick Ruch"},{"#tail":"\n","#text":"Christine Chichester"},{"#tail":"\n","#text":"Gilles Cohen"},{"#tail":"\n","#text":"Giovanni Coray"},{"#tail":"\n","#text":"Frederic Ehrler"},{"#tail":"\n","#text":"Hatem Ghorbel"},{"#tail":"\n","#text":"Henning Muller"},{"#tail":"\n","#text":"Vincenzo Pallotta"}]}},{"volume":{"#tail":"\n","#text":"4"},"#tail":"\n","date":{"#tail":"\n","#text":"1990"},"rawString":{"#tail":"\n","#text":"Franc?oise Salanger-Meyer. 1990. Discoursal movements in medical English abstracts and their linguistic exponents: A genre analysis study. INTERFACE: Journal of Applied Linguistics, 4(2):107?124."},"journal":{"#tail":"\n","#text":"INTERFACE: Journal of Applied Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"2"},"marker":{"#tail":"\n","#text":"Salanger-Meyer, 1990"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ted from them. For example, Gay et al (2005) experimented with abstracts and full article texts in the task of automatically generating index term recommendations and discovered that using full article texts yields at most a 7.4% improvement in F-score. Demner-Fushman et al (2005) found a correlation between the quality and strength of clinical conclusions in the full article texts and abstracts. This paper presents experiments with generative content models for analyzing the discourse structure of medical abstracts, which has been confirmed to follow the four-section pattern discussed above (Salanger-Meyer, 1990). For a variety of reasons, medicine is an interesting domain of research. The need for information systems to support physicians at the point of care has been well studied (Covell et al, 1985; Gorman et al, 1994; Ely et al, 2005). Retrieval techniques can have a large impact on how physicians access and leverage clinical evidence. Information that satisfies physicians? needs can be found in theMEDLINE database maintained by the U.S. National Library of Medicine 65 (NLM), which also serves as a readily available corpus of abstracts for our experiments. Furthermore, the availability of rich ont","@endWordPosition":"437","@position":"3055","annotationId":"T24","@startWordPosition":"436","@citStr":"Salanger-Meyer, 1990"}},"title":{"#tail":"\n","#text":"Discoursal movements in medical English abstracts and their linguistic exponents: A genre analysis study."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Francoise Salanger-Meyer"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1990"},"rawString":{"#tail":"\n","#text":"John M. Swales. 1990. Genre Analysis: English in Academic and Research Settings. Cambridge University Press, Cambridge, England."},"#text":"\n","marker":{"#tail":"\n","#text":"Swales, 1990"},"publisher":{"#tail":"\n","#text":"Cambridge University Press,"},"location":{"#tail":"\n","#text":"Cambridge, England."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ork makes two contributions: at the application level, we report good performance on an interesting task in an important domain; more generally, our results contribute to an ongoing discussion regarding the tradeoffs between generative and discriminative techniques. 1 Introduction Certain types of text follow a predictable structure, the knowledge of which would be useful in many natural language processing applications. As an example, scientific abstracts across many different fields generally follow the pattern of ?introduction?, ?methods?, ?results?, and ?conclusions? (SalangerMeyer, 1990; Swales, 1990; Ora?san, 2001). The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization (Teufel and Moens, 2000), information retrieval (Tbahriti et al, 2005), information extraction (Mizuta et al, 2005), and question answering. Although there is a trend towards analysis of full article texts, we believe that abstracts still provide a tremendous amount of information, and much value can still be extracted from them. For example, Gay et al (2005) experimented with abstracts and full article texts in the task of automat","@endWordPosition":"270","@position":"1952","annotationId":"T25","@startWordPosition":"269","@citStr":"Swales, 1990"}},"title":{"#tail":"\n","#text":"Genre Analysis: English in Academic and Research Settings."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"John M Swales"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"note":{"#tail":"\n","#text":"in press."},"rawString":{"#tail":"\n","#text":"Imad Tbahriti, Christine Chichester, Fre?de?rique Lisacek, and Patrick Ruch. 2005. Using argumentation to retrieve articles with similar citations: An inquiry into improving related articles search in the MEDLINE digital library. International Journal of Medical Informatics, in press."},"journal":{"#tail":"\n","#text":"International Journal of Medical Informatics,"},"#text":"\n","marker":{"#tail":"\n","#text":"Tbahriti, Chichester, Lisacek, Ruch, 2005"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"enerative and discriminative techniques. 1 Introduction Certain types of text follow a predictable structure, the knowledge of which would be useful in many natural language processing applications. As an example, scientific abstracts across many different fields generally follow the pattern of ?introduction?, ?methods?, ?results?, and ?conclusions? (SalangerMeyer, 1990; Swales, 1990; Ora?san, 2001). The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization (Teufel and Moens, 2000), information retrieval (Tbahriti et al, 2005), information extraction (Mizuta et al, 2005), and question answering. Although there is a trend towards analysis of full article texts, we believe that abstracts still provide a tremendous amount of information, and much value can still be extracted from them. For example, Gay et al (2005) experimented with abstracts and full article texts in the task of automatically generating index term recommendations and discovered that using full article texts yields at most a 7.4% improvement in F-score. Demner-Fushman et al (2005) found a correlation between the quality and strength of clinical conclu","@endWordPosition":"305","@position":"2187","annotationId":"T26","@startWordPosition":"302","@citStr":"Tbahriti et al, 2005"}},"title":{"#tail":"\n","#text":"Using argumentation to retrieve articles with similar citations: An inquiry into improving related articles search in the MEDLINE digital library."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Imad Tbahriti"},{"#tail":"\n","#text":"Christine Chichester"},{"#tail":"\n","#text":"Frederique Lisacek"},{"#tail":"\n","#text":"Patrick Ruch"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Simone Teufel and Marc Moens. 2000. What?s yours and what?s mine: Determining intellectual attribution in scientific text. In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC-2000)."},"#text":"\n","marker":{"#tail":"\n","#text":"Teufel, Moens, 2000"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ing discussion regarding the tradeoffs between generative and discriminative techniques. 1 Introduction Certain types of text follow a predictable structure, the knowledge of which would be useful in many natural language processing applications. As an example, scientific abstracts across many different fields generally follow the pattern of ?introduction?, ?methods?, ?results?, and ?conclusions? (SalangerMeyer, 1990; Swales, 1990; Ora?san, 2001). The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization (Teufel and Moens, 2000), information retrieval (Tbahriti et al, 2005), information extraction (Mizuta et al, 2005), and question answering. Although there is a trend towards analysis of full article texts, we believe that abstracts still provide a tremendous amount of information, and much value can still be extracted from them. For example, Gay et al (2005) experimented with abstracts and full article texts in the task of automatically generating index term recommendations and discovered that using full article texts yields at most a 7.4% improvement in F-score. Demner-Fushman et al (2005) found a correlation betwe","@endWordPosition":"299","@position":"2141","annotationId":"T27","@startWordPosition":"296","@citStr":"Teufel and Moens, 2000"},{"#tail":"\n","#text":"heir work in the context of document summarization, the fourpart structure of medical abstracts allows us to conduct meaningful intrinsic evaluations and focus on the sentence classification task. Nevertheless, their work bolsters our claims regarding the usefulness of generative models in extrinsic tasks, which we do not describe here. Although this study falls under the general topic of discourse modeling, our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements (McKeown, 1985; Marcu and Echihabi, 2002). Our task is closer to the work of Teufel and Moens (2000), who looked at the problem of intellectual attribution in scientific texts. 6 Conclusion We believe that there are two contributions as a result of our work. From the perspective of machine learning, the assignment of sequentially-occurring labels represents an underexplored problem with respect to the generative vs. discriminative debate? previous work has mostly focused on stateless classification tasks. This paper demonstrates that Hidden Markov Models are capable of capturing discourse transitions from section to section, and are at least competitive with Support Vector Machines from a pu","@endWordPosition":"3738","@position":"24288","annotationId":"T28","@startWordPosition":"3735","@citStr":"Teufel and Moens (2000)"}]},"title":{"#tail":"\n","#text":"What?s yours and what?s mine: Determining intellectual attribution in scientific text."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC-2000)."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Simone Teufel"},{"#tail":"\n","#text":"Marc Moens"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"William N. Venables and Brian D. Ripley. 1994. Modern Applied Statistics with S-Plus. Springer-Verlag."},"#text":"\n","marker":{"#tail":"\n","#text":"Venables, Ripley, 1994"},"publisher":{"#tail":"\n","#text":"Springer-Verlag."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ssians mixtures with diagonal covariance matrices. Using the section labels, the HMM was trained using the HTK toolkit (Young et al, 2002), which efficiently performs the forward-backward algorithm and BaumWelch estimation. For testing, we performed a Viterbi (maximum likelihood) estimation of the label of each test sentence/vector (also using the HTK toolkit). 67 In an attempt to further boost performance, we employed Linear Discriminant Analysis (LDA) to find a linear projection of the four-dimensional vectors that maximizes the separation of the Gaussians (corresponding to the HMM states). Venables and Ripley (1994) describe an efficient algorithm (of linear complexity in the number of training sentences) for computing the LDA transform matrix, which entails computing the within- and between-covariance matrices of the classes, and using Singular Value Decomposition (SVD) to compute the eigenvectors of the new space. Each sentence/vector is then multiplied by this matrix, and new HMM models are re-computed from the projected data. An important aspect of our work is modeling content structure using generative techniques. To assess the impact of taking discourse transitions into account, we compare our full","@endWordPosition":"2002","@position":"13315","annotationId":"T29","@startWordPosition":"1999","@citStr":"Venables and Ripley (1994)"}},"title":{"#tail":"\n","#text":"Modern Applied Statistics with S-Plus."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"William N Venables"},{"#tail":"\n","#text":"Brian D Ripley"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Steve Young, Gunnar Evermann, Thomas Hain, Dan Kershaw, Gareth Moore, Julian Odell, Dave Ollason, Dan Povey, Valtcho Valtchev, and Phil Woodland. 2002. The HTK Book. Cambridge University Press."},"#text":"\n","marker":{"#tail":"\n","#text":"Young, Evermann, Hain, Kershaw, Moore, Odell, Ollason, Povey, Valtchev, Woodland, 2002"},"publisher":{"#tail":"\n","#text":"Cambridge University Press."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"esults, each sentence was converted into a four dimensional vector, where each component represents the log probability, divided by the number of words, of the sentence under each of the four language models. We then built a four-state Hidden Markov Model that outputs these four-dimensional vectors. The transition probability matrix of the HMM was initialized with uniform probabilities over a fully connected graph. The output probabilities were modeled as four-dimensional Gaussians mixtures with diagonal covariance matrices. Using the section labels, the HMM was trained using the HTK toolkit (Young et al, 2002), which efficiently performs the forward-backward algorithm and BaumWelch estimation. For testing, we performed a Viterbi (maximum likelihood) estimation of the label of each test sentence/vector (also using the HTK toolkit). 67 In an attempt to further boost performance, we employed Linear Discriminant Analysis (LDA) to find a linear projection of the four-dimensional vectors that maximizes the separation of the Gaussians (corresponding to the HMM states). Venables and Ripley (1994) describe an efficient algorithm (of linear complexity in the number of training sentences) for computing the LD","@endWordPosition":"1929","@position":"12827","annotationId":"T30","@startWordPosition":"1926","@citStr":"Young et al, 2002"}},"title":{"#tail":"\n","#text":"The HTK Book."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Steve Young"},{"#tail":"\n","#text":"Gunnar Evermann"},{"#tail":"\n","#text":"Thomas Hain"},{"#tail":"\n","#text":"Dan Kershaw"},{"#tail":"\n","#text":"Gareth Moore"},{"#tail":"\n","#text":"Julian Odell"},{"#tail":"\n","#text":"Dave Ollason"},{"#tail":"\n","#text":"Dan Povey"},{"#tail":"\n","#text":"Valtcho Valtchev"},{"#tail":"\n","#text":"Phil Woodland"}]}}]}}]}}
