{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","listItem":[{"#tail":"\n","@confidence":"0.978010714285714","#text":"\nrent pair.\n1. Word match ? the system will propose the se-\nmantic relation(s) that have previously been as-\nsigned to a pair containing the same lemmas.\n2. Syntactic graph match ? we elaborate this\nheuristic in Section 4.\n3. Marker ? the system uses a manually built dic-\n"},{"#tail":"\n","@confidence":"0.447787526315789","#text":"\n1. CAUSAL groups relations enabling or oppos-\ning an occurrence. Examples:\ncause - H causes M: u virus;\neffect - H is the effect (was caused by) M:\nexam anxiety;\npurpose - H is for M: concert hall;\n2. CONJUNCTIVE includes relations that describe\nthe conjunction or disjunction of occurrences\n(events/act/actions/states/activities), entities or\nattributes:\nconjunction - both H and M occur or exist\n(and nothing more can be said about that\nfrom the point of view of causality or\ntemporality): running and swimming (are\ngood for you);\ndisjunction - either one or both H and M occur\nor exist: painting or drawing;\n3. PARTICIPANT groups relations between an oc-\ncurrence and its participants or circumstances.\n"}],"figure":[{"#tail":"\n","@confidence":"0.66659325","#text":"\n(compl,nil)\n(subord,when)out (v, sv)\n(com\npl,nil)\n(v,svo)\nbreathe make\ncold\nday\nyou you\n(su\nbj,\nnil\n)\n(subj,nil)\n(c\nom\npl\n,on\n)\ncloud\n"},{"#tail":"\n","@confidence":"0.9935705","#text":"\n-20\n0\n20\n40\n60\n80\n100\n120\n140\n0 100 200 300 400 500 600 700 800 900 1000\nD\niff\ner\nen\nce\nin\nn\num\nbe\nr o\nf e\nxa\nm\npl\nes\nExamples processed\n"},{"#tail":"\n","@confidence":"0.998487578947368","#text":"\n1. All syntactic levels\n0\n100\n200\n300\n400\n500\n600\n0 100 200 300 400 500 600 700 800 900 1000\nCu\nm\nm\nul\nat\nive\nn\num\nbe\nr o\nf e\nxa\nm\npl\nes\nExamples processed\naccept+choose\nsupply\n2. Clause level (CL)\n0\n5\n10\n15\n20\n25\n30\n35\n0 10 20 30 40 50 60\nCu\nm\nm\nul\nat\nive\nn\num\nbe\nr o\nf e\nxa\nm\npl\nes\nExamples processed\naccept+choose\nsupply\n3. Intra-clause level (IC)\n0\n50\n100\n150\n200\n250\n300\n350\n400\n450\n500\n0 100 200 300 400 500 600 700 800\nCu\nm\nm\nul\nat\nive\nn\num\nbe\nr o\nf e\nxa\nm\npl\nes\nExamples processed\naccept+choose\nsupply\n4. Noun phrase level\n(NP)\n0\n10\n20\n30\n40\n50\n60\n0 20 40 60 80 100 120\nCu\nm\nm\nul\nat\nive\nn\num\nbe\nr o\nf e\nxa\nm\npl\nes\nExamples processed\naccept+choose\nsupply\n"}],"equation":[{"#tail":"\n","@confidence":"0.971895","#text":"\nG(w) = {wi, edge(w,wi) or edge(wi, w)|wiappears in sent. S, and is connected to w}\nedge(w,wi) = {GRi, Coni} ; GRi ? {subject, object, complement, ...}\n"},{"#tail":"\n","@confidence":"0.9975866","#text":"\ndist(G(w1), G(w2)) =\nN\n?\nk=1\nd(edge1k , edge2k); edgeik ? G(wi), N is the number of edges in G(wi)\nd(edge1k , edge2k)=d({GR1k , Con1k}, {GR2k , Con2k})\n=d1(GR1k, GR2k) + d1(Con1k, Con2k)\nd1(x, y) =\n{ 0 : x = y\n1 : x 6= y\n"},{"#tail":"\n","@confidence":"0.9799035","#text":"\ncloudweatherman\nwatch\n(v, svo)\n(subj,nil)\n(c\nom\npl\n,n\nil)\nday and night\n(co\nmp\nl,n\nil)\n"},{"#tail":"\n","@confidence":"0.29606675","#text":"\n(v, svo)\n(subj,nil)\nknow\nair pilots bring\n(co\nmp\nl,n\nil)\nAGENT\nOB\nJE\nCT\n"}],"subsectionHeader":[{"#tail":"\n","@confidence":"0.997386","#text":"\n3.1 Input data\n"},{"#tail":"\n","@confidence":"0.998302","#text":"\n3.2 Semantic relations\n"}],"footnote":[{"#tail":"\n","@confidence":"0.9983345","#text":"\n1The sources date his work variously between the 5th and\n7th century.\n"},{"#tail":"\n","@confidence":"0.851398833333333","#text":"\n2The nil value on the edges means that no preposition or\nother connective explicitly links the two words or the corre-\nsponding syntactic structures.\n3If more detailed information is available, the system will\nchoose only networks associated with verbs that have the same\nsubcategorisation pattern (svo, svoi and so on).\n"},{"#tail":"\n","@confidence":"0.947293","#text":"\n4The time difference accounts for system processing times,\n"}],"construct":{"#tail":"\n","@confidence":"0.741657148148148","#text":"\nExamples:\nagent - M performs H: student protest;\nobject - M is acted upon by H: metal separa-\ntor;\nbeneficiary - M benefits from H: student dis-\ncount;\n4. SPATIAL groups relations that place an occur-\nrence at an absolute or relative point in space.\nExamples:\ndirection - H is directed towards M: outgoing\nmail;\nlocation - H is the location of M: home town;\nlocation at - H is located at M: desert storm;\n5. TEMPORAL groups relations that place an oc-\ncurrence at an absolute or relative point in time.\nExamples:\nfrequency - H occurs every time M occurs:\nweekly game;\ntime at - H occurs when M occurs: morning\ncoffee;\ntime through - H existed while M existed: 2-\nhour trip;\n6. QUALITY groups the remaining relations be-\ntween a verb or noun and its arguments. Exam-\nples:\nmanner - H occurs as indicated by M: stylish\nwriting;\n"},"@confidence":"0.000000","#tail":"\n","reference":{"#tail":"\n","@confidence":"0.999640619047619","#text":"\nJordi Atserias, L. Padro?, and German Rigau. 2001. Integrating\nmultiple knowledge sources for robust semantic parsing. In\nProceedings of RANLP - 2001, Tsigov Czark, Bulgaria.\nCollin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998.\nThe Berkeley FrameNet project. In COLING-ACL, pages\n86?90, Montreal, Canada.\nKen Barker, Terry Copeck, Sylvain Delisle, and Stan Szpakow-\nicz. 1997a. Systematic construction of a versatile case sys-\ntem. Journal of Natural Language Engineering, 3(4):279?\n315.\nKen Barker, Sylvain Delisle, and Stan Szpakowicz. 1997b.\nTest-driving TANKA: Evaluating a semi-automatic system\nof text analysis for knowledge acquisition. In Proceedings\nof CAI 1997, pages 60?71, Vancouver, BC, Canada.\nXavier Carreras and Lluis Marquez, editors. 2004. Introduction\nto the CoNLL-2004 Shared Task: Semantic Role Labelling.\nBoston, MA, USA.\nXavier Carreras and Lluis Marquez, editors. 2005. Introduction\nto the CoNLL-2005 Shared Task: Semantic Role Labelling.\nAnn Arbour, MI, USA.\nNoam Chomsky. 1970. Remarks on nominalizations. In Rod-\nerick Jacobs and Peter Rosenbaum, editors, Readings in En-\nglish Transformational Grammar, pages 184?221. Ginn and\nCo., Waltham, MA, USA.\nPeter Clark and Bruce Porter. 1997. Building concept reprezen-\ntations from reusable components. In AAAI, pages 367?376,\nProvidence, Rhode Island.\nSylvain Delisle and Stan Szpakowicz. 1995. Realistic pars-\ning: Practical solutions of difficult problems. In PACLING,\nBrisbane, Queensland, Australia.\nSylvain Delisle, Terry Copeck, Stan Szpakowicz, and Ken\nBarker. 1993. Pattern matching for case analysis: A com-\nputational definition of closeness. In ICCI, pages 310?315,\nSudbury, ON, Canada.\nCharles Fillmore and Beryl T. Atkins. 1998. FrameNet and\nlexicographic relevance. In Proceedings of the 1st Interna-\ntional Conference on Language Resources and Evaluation,\nGranada, Spain.\nCharles Fillmore. 1968. The case for case. In Emmond Bach\nand Robert T. Harms, editors, Universals in Linguistic The-\nory, pages 1?88. Holt, Rinehart and Winston.\nDaniel Gildea and Daniel Jurafsky. 2002. Automatic labeling\nof semantic roles. Computational Linguistics, 28(3):245?\n288.\nFernando Gomez. 1998. A representation of complex events\nand processes for the acquisition of knowledge from text.\nKowledge-Based Systems, 10(4):237?251.\nJeffrey Gruber. 1965. Studies in Lexical Relations. Ph.D.\nthesis, MIT, Cambridge, MA. Reprinted in Jeffrey Gru-\nber. 1976. Lexical Structures in Syntax and Semantics. Part\nI. North-Holland Publishing Company, Amsterdam.\nRichard D. Hull and Fernando Gomez. 1996. Semantic inter-\npretation of nominalizations. In 13th National Conference\non Artificial Intelligence, pages 1062?1068, Portland, Ore-\ngon, USA.\nKarin Kipper, Hoa Trang Dang, and Martha Palmer. 2000.\nClass-based construction of a verb lexicon. In AAAI/IAAI,\npages 691?696.\nNancy Larrick. 1961. Junior Science Book of Rain, Hail, Sleet\nand Snow. Garrard Publishing Company, Champaign, Illi-\nnois.\nBeth Levin. 1993. English Verb Classes and Alternations. Uni-\nversity of Chicago Press.\nVidya Niwas Misra. 1966. The Descriptive Technique of\nPanini. Mouton, The Hague.\nSameer Pradhan, Wayne Ward, Kadri Hacioglu, James H. Mar-\ntin, and Daniel Jurafsky. 2005. Semantic role labelling us-\ning different syntactic views. In Proceedings of ACL 2005,\npages 581?588, Ann Arbour, MI, USA.\nRandolph Quirk, Sidney Greenbaum, Geoffrey Leech, and Jan\nSvartvik. 1985. A Comprehensive Grammar of the English\nLanguage. Longman, London and New York.\nBarbara Rosario and Marti Hearst. 2001. Classifying the se-\nmantic relations in noun-compounds via a domain specific\nhierarchy. In EMNLP, pages 82?90, Pittsburg, PA, USA.\nBarbara Rosario, Marti Hearst, and Charles Fillmore. 2002.\nThe descent of hierarchy and selection in relational seman-\ntics. In ACL, Philadelphia, PA, USA.\nLei Shi and Rada Mihalcea. 2005. Putting pieces together:\nCombining framenet, verbnet and wordnet for robust seman-\ntic parsing. In Proceedings of CICLing 2005, pages 100?\n111, Mexico City, Mexico.\nLucien Tesnie`re. 1959. E?le?ments de syntaxe structurale. C.\nKlincksieck, Paris.\n"},"bodyText":[{"#tail":"\n","@confidence":"0.998656041666666","#text":"\nWe present a graph-matching algorithm\nfor semantic relation assignment. The al-\ngorithm is part of an interactive text analy-\nsis system. The system automatically ex-\ntracts pairs of syntactic units from a text\nand assigns a semantic relation to each\npair. This is an incremental learning algo-\nrithm, in which previously processed pairs\nand user feedback guide the process. Af-\nter each assignment, the system adds to its\ndatabase a syntactic-semantic graph cen-\ntered on the main element of each pair of\nunits. A graph consists of the main unit\nand all syntactic units with which it is syn-\ntactically connected. An edge contains in-\nformation both about syntax and about se-\nmantic relations for use in further process-\ning. Syntactic-semantic graph matching is\nused to produce a list of candidate assign-\nments for 63.75% of the pairs analysed,\nand in 57% of situations the correct rela-\ntions is one of the system?s suggestions;\nin 19.6% of situations it suggests only the\ncorrect relation.\n"},{"#tail":"\n","@confidence":"0.99482975","#text":"\nWhen analysing texts, it is essential to see how el-\nements of meaning are interconnected. This is an\nold idea. The first chronicled endeavour to con-\nnect text elements and organise connections between\nthem goes back to the 5th century B.C. and the work\nof Panini1. He was a grammarian who analysed San-\nskrit (Misra, 1966). The idea resurfaced forcefully\nat several points in the more recent history of lin-\nguistic research (Tesnie`re, 1959; Gruber, 1965; Fill-\nmore, 1968). Now it has the attention of many re-\nsearchers in natural language processing, as shown\nby recent research in semantic parsing and semantic\n"},{"#tail":"\n","@confidence":"0.997804636363637","#text":"\nrole labelling (Baker et al, 1998; Kipper et al, 2000;\nCarreras and Marquez, 2004; Carreras and Marquez,\n2005; Atserias et al, 2001; Shi and Mihalcea, 2005).\nGraph-like structures are a natural way of or-\nganising one?s impressions of a text seen from\nthe perspective of connections between its simpler\nconstituents of varying granularity, from sections\nthrough paragraphs, sentences, clauses, phrases,\nwords to morphemes.\nIn this work we pursue a well-known and of-\nten tacitly assumed line of thinking: connections at\nthe syntactic level reflect connections at the seman-\ntic level (in other words, syntax carries meaning).\nAnecdotal support for this stance comes from the\nfact that the grammatical notion of case is the basis\nfor semantic relations (Misra, 1966; Gruber, 1965;\nFillmore, 1968). Tesnie`re (1959), who proposes a\ngrouping of verb arguments into actants and circum-\nstances, gives a set of rules to connect specific types\nof actants ? for example, agent or instrument ? to\nsuch grammatical elements as subject, direct object,\nindirect object. This idea was expanded to include\nnouns and their modifiers through verb nominaliza-\ntions (Chomsky, 1970; Quirk et al, 1985).\nWe work with sentences, clauses, phrases and\nwords, using syntactic structures generated by a\nparser. Our system incrementally processes a text,\nand extracts pairs of text units: two clauses, a verb\nand each of its arguments, a noun and each of its\nmodifiers. For each pair of units, the system builds a\nsyntactic graph surrounding the main element (main\nclause, head verb, head noun). It then tries to find\namong the previously processed instances another\nmain element with a matching syntactic graph. If\nsuch a graph is found, then the system maps pre-\nviously assigned semantic relations onto the current\nsyntactic graph. We have a list of 47 relations that\nmanifest themselves in compound clauses, inside a\nsimple clause or in noun phrases. The list, a syn-\nthesis of a number of relation lists cited in the lit-\nerature, has been designed to be general, domain-\nindependent (Barker et al, 1997a).\nSection 2 overviews research in semantic relation\nanalysis. Section 3 describes the text we used in ex-\n"},{"#tail":"\n","@confidence":"0.9942447","#text":"\nperiments, and the semantic relation list. Section 4\nlooks in detail at the graph-matching heuristic. Sec-\ntion 5 describes the experimental setting and shows\nhow often the heuristic was used when processing\nthe input text. We show in detail our findings about\nsyntactic levels (how often graph matching helped\nassign a relation between two clauses, a verb and its\narguments, or a noun and its modifier) and about the\naccuracy of the suggestion. Discussion and conclu-\nsions appear in Section 6.\n"},{"#tail":"\n","@confidence":"0.996278333333333","#text":"\nSome methods of semantic relation analysis rely on\npredefined templates filled with information from\nprocessed texts (Baker et al, 1998). In other meth-\nods, lexical resources are specifically tailored to\nmeet the requirements of the domain (Rosario and\nHearst, 2001) or the system (Gomez, 1998). Such\nsystems extract information from some types of syn-\ntactic units (clauses in (Fillmore and Atkins, 1998;\nGildea and Jurafsky, 2002; Hull and Gomez, 1996);\nnoun phrases in (Hull and Gomez, 1996; Rosario et\nal., 2002)). Lists of semantic relations are designed\nto capture salient domain information.\nIn the Rapid Knowledge Formation Project (RKF)\na support system was developed for domain experts.\nIt helps them build complex knowledge bases by\ncombining components: events, entities and modi-\nfiers (Clark and Porter, 1997). The system?s inter-\nface facilitates the expert?s task of creating and ma-\nnipulating structures which represent domain con-\ncepts, and assigning them relations from a relation\ndictionary.\nIn current work on semantic relation analysis, the\nfocus is on semantic roles ? relations between verbs\nand their arguments. Most approaches rely on Verb-\nNet (Kipper et al, 2000) and FrameNet (Baker et\nal., 1998) to provide associations between verbs and\nsemantic roles, that are then mapped onto the cur-\nrent instance, as shown by the systems competing in\nsemantic role labelling competitions (Carreras and\nMarquez, 2004; Carreras and Marquez, 2005) and\nalso (Gildea and Jurafsky, 2002; Pradhan et al,\n2005; Shi and Mihalcea, 2005).\nThese systems share two ideas which make them\ndifferent from the approach presented here: they all\nanalyse verb-argument relations, and they all use\nmachine learning or probabilistic approaches (Prad-\nhan et al, 2005) to assign a label to a new instance.\nLabelling every instance relies on the same previ-\nously encoded knowledge (see (Carreras and Mar-\nquez, 2004; Carreras and Marquez, 2005) for an\noverview of the systems in the semantic role la-\nbelling competitions from 2004 and 2005). Pradhan\net al (2005) combine the outputs of multiple parsers\nto extract reliable syntactic information, which is\ntranslated into features for a machine learning ex-\nperiment in assigning semantic roles.\nOur system analyses incrementally pairs of units\ncoming from three syntactic levels ? clause (CL),\nintra-clause (or verb-argument, IC), noun-phrase\n(NP). There are no training and testing data sets. In-\nstead of using previously built resources, the system\nrelies on previously processed examples to find the\nmost appropriate relation for a current pair. Because\nthe system does not rely on previously processed\nor annotated data, it is flexible. It allows the user\nto customize the process for a specific domain by\nchoosing the syntactic units of interest and her own\nlist of relations that best fit the domain.\nIt is also interesting to assess, using the current\nsystem configuration, the effect of syntactic infor-\nmation and incremental learning on semantic analy-\nsis. This is described in section 5.\nBecause of these differences in the type of data\nused, and in the learning approach, the results we\nobtain cannot be compared to previous approaches.\nIn order to show that the system does learn, we show\nthat the number of examples for which it provides\nthe correct answer increases with the number of ex-\namples previously analysed.\n"},{"#tail":"\n","@confidence":"0.9997865","#text":"\nWe work with a semi-technical text on meteorolog-\nical phenomena (Larrick, 1961), meant for primary\nschool students. The text gradually introduces con-\ncepts related to precipitation, and explains them. Its\nnature makes it appropriate for the semantic analy-\nsis task in an incremental approach. The system will\nmimic the way in which a human reader accumu-\nlates knowledge and uses what was written before to\nprocess ideas introduced later in the text.\nThe text contains 513 sentences, with an average\nlength of 9.13 words. There are 4686 word tokens\nand 969 types. The difference between the num-\nber of types (2850) and tokens (573) in the extracted\npairs (which contain only open-class words) shows\nthat the same concepts recur, as expected in a didac-\ntic text.\nThe syntactic structures of the input data are\nproduced by a parser with good coverage and de-\ntailed syntactic information, DIPETT (Delisle and\nSzpakowicz, 1995). The parser, written in Prolog,\nimplements a classic constituency English grammar\nfrom Quirk et al (1985). Pairs of syntactic units\nconnected by grammatical relations are extracted\nfrom the parse trees. A dependency parser would\n"},{"#tail":"\n","@confidence":"0.983685941176471","#text":"\nproduce a similar output, but DIPETT also provides\nverb subcategorization information (such as, for ex-\nample, subject-verb-object or subject-verb-object-\nindirect object), which we use to select the (best)\nmatching syntactic structures.\nTo find pairs, we use simple structural informa-\ntion. If a unit is directly embedded in another unit,\nwe assume a subordinate relation between them; if\nthe two units are coordinate, we assume a coordinate\nrelation. These assumptions are safe if the parse is\ncorrect. A modifier is subordinate to its head noun,\nan argument to its head verb, and a clause perhaps to\nthe main clause in the sentence.\nIf we conclude that two units should interact, we\nseek an appropriate semantic relation to describe this\ninteraction. The system uses three heuristics to find\none or more semantic relation candidates for the cur-\n"},{"#tail":"\n","@confidence":"0.9428461875","#text":"\ntionary of markers (prepositions, coordinators,\nsubordinators) associated with the semantic re-\nlations they indicate. The dictionary contains\n325 markers, and a total of 662 marker-relation\nassociations.\nIf neither of the three heuristics yield results, the\nsystem will present an empty list, and expect the user\nto input the appropriate relation. When at least one\nrelation is proposed, the user can accept a unique\nrelation, choose among several options, or supply\na new one. The system records which action took\nplace, as well as the heuristic that generated the op-\ntions presented to the user. The pair is also analysed\nto determine the syntactic level from which it came,\nto allow for a more detailed analysis of the behaviour\nof the system.\n"},{"#tail":"\n","@confidence":"0.9669226","#text":"\nThe list of semantic relations with which we work\nis based on extensive literature study (Barker et al,\n1997a). Three lists of relations for three syntactic\nlevels ? inter-clause, intra-clause (case) and noun-\nmodifier relations ? were next combined based on\nsyntactic and semantic phenomena. The resulting\nlist is the one used in the experiments we present\nin this paper. The relations are grouped by general\nsimilarity into 6 relation classes (H denotes the head\nof a base NP, M denotes the modifier).\n"},{"#tail":"\n","@confidence":"0.9816316","#text":"\nmaterial - H is made of M: brick house;\nmeasure - M is a measure of H: heavy rock;\nThere is no consensus in the literature on a list of\nsemantic relations that would work in all situations.\nThis is, no doubt, because a general list of relations\nsuch as the one we use would not be appropriate for\nthe semantic analysis of texts in a specific domain,\nsuch as for example medical texts. All the relations\nin the list we use were necessary, and sufficient, for\nthe analysis of the input text.\n"},{"#tail":"\n","@confidence":"0.996355269662921","#text":"\nOur system begins operation with a minimum of\nmanually encoded knowledge, and accumulates in-\nformation as it processes the text. This design idea\nwas adopted from TANKA (Barker et al, 1997b).\nThe only manually encoded knowledge is a dictio-\nnary of markers (subordinators, coordinators, prepo-\nsitions). This resource does not affect the syntactic-\nsemantic graph-matching heuristic.\nBecause the system gradually accumulates\nknowledge as it goes through the input text, it uses a\nform of memory-based learning to make predictions\nabout the semantic relation that fits the current pair.\nThe type of knowledge that it accumulates consists\nof previously analysed pairs, together with the\nsemantic relation assigned, and a syntactic-semantic\ngraph centered on each word in a sentence which\nappears as the main element in a processed pair.\nTo process a pair P not encountered previously,\nthe system builds a graph centered on the main ele-\nment (often the head) of P . This idea was inspired\nby Delisle et al (1993), who used a list of argu-\nments surrounding the main verb together with the\nverb?s subcategorization information and previously\nprocessed examples to analyse semantic roles (case\nrelations). In recent approaches, syntactic informa-\ntion is translated into features which, together with\ninformation from FrameNet, WordNet or VerbNet,\nwill be used with ML tools to make predictions for\neach example in the test set (Carreras and Marquez,\n2004; Carreras and Marquez, 2005).\nOur system builds a (simple) graph surrounding\na head word (which may be a verb ? representing\nthe predicate of a sentence, or representing a clause\n? or noun), and matches it with previously analysed\nexamples.\nA graph G(w) centered on word w consists of\nthe following: a node for w; a set of nodes for\neach of the words wi in the sentence with which wis connected by a grammatical relation (including\nsituations when w is a modifier/argument); edges\nthat connect w with each wi, tagged with gram-\nmatical relation GR (such as subject, object, com-\nplement) and connective information Con (preposi-\ntions, coordinators, subordinators, or nil). The nodes\nalso contain part-of-speech information for the cor-\nresponding word, and other information from the\nparser (such as subcategorization structure for the\nverb, if it is available).\nGraph matching starts with the central node, and\ncontinues with edge matching. If G(w) is the graph\ncentered on word w whose pairs are currently being\nprocessed, the system selects from the collection of\npreviously stored graphs, a set of graphs {G(wi)},\nwhich satisfy the following conditions:\n? The central nodes match. The matching is\nguided by a set of contraints. We choose the\ngraphs centered on the nodes that satisfy the\nmost constraints, presented here in the order of\ntheir importance:\n? w and wi must have the same part of\nspeech.\n? w and wi have the same syntactic proper-ties. If w and wi are verbs, they must have\nthe same subcategorization structure.\n? w and wi are the same lemma. We empha-size that a graph centered on a different\nlemma, but with the same subcategoriza-\ntion structure is preferred to a graph with\nthe same lemma, but a different subcate-\ngorization structure.\n? The edge representing the word pair to which\nwe want to assign a semantic relation has a\nmatch in G(wi). From all graphs that com-ply with this constraint, the ones that have the\nlowest distance ? corresponding to the high-\nest matching score ? are chosen. The graphs\nare matched edge by edge. Two edges match\nif the grammatical relation and the connectives\nmatch. Figure 1 shows the formula that com-\nputes the distance between two graphs. We\nnote that edge matching uses only edge infor-\nmation ? grammatical and connective informa-\ntion. Using the node information as is (lemmas\nand their part of speech) is too restrictive. We\nare looking into using word similarity as a so-\nlution of node matching.\nIf no matching graph has been found, the system\nsearches for a simpler match, in which the current\nword pair is matched against previously processed\npairs, using the same formula as for edge distance,\nand preferring the pairs that have the same modifier.\nThis algorithm will retrieve the set of graphs\n{G(wi)}, which give the same score when matched\n"},{"#tail":"\n","@confidence":"0.658948","#text":"\nDefinition of a graph centered on w:\n"},{"#tail":"\n","@confidence":"0.738015","#text":"\nConi ? {at, in, on,with, for, ...}\nDistance metric between two graphs:\n"},{"#tail":"\n","@confidence":"0.862601875","#text":"\nwith the current graph. The set of possible semantic\nrelations presented to the user consists of the seman-\ntic relation on the edge of each G(wi) that matchesthe edge (of the current graph) corresponding to the\nword pair which we are analysing.\nTo the sentence:\nWhen you breathe out on a cold day, you make a\ncloud.\ncorresponds the following syntactic graph:\n"},{"#tail":"\n","@confidence":"0.990527857142857","#text":"\nWhen we focus on the graph centered on a spe-\ncific word, such as breathe, we look only at the node\ncorresponding to the word breathe, and the nodes\nadjacent to it.\nTo process a pair P = (wH , wM ), the system firstbuilds G(wH), and then searches through previouslystored graphs for those which have the same center\nwH , or have the same part of speech as wH assigned\nto its central node. For each graph found, we com-\npute a distance that gives a measure of the match\nbetween the two graphs. The best match will have\nthe smallest distance.\nFor example, for the sentence:\nWeathermen watch the clouds day and night.\nthe system builds the following network centered\non the predicate watch2:\n"},{"#tail":"\n","@confidence":"0.801606333333333","#text":"\nThe system locates among previously stored net-\nworks those centered around verbs3. For the sen-\ntence above, the system uses the following graph,\n"},{"#tail":"\n","@confidence":"0.78340775","#text":"\nbuilt from the immediately preceding sentence in the\ntext:\nAir pilots know that clouds can bring rain, hail,\nsleet and snow.\n"},{"#tail":"\n","@confidence":"0.9867792","#text":"\nAccording to the metric, the networks match and\nthe pairs (watch, weatherman) and (know, air pi-\nlots) match, so the semantic relation for the pair\n(know, air pilots) is proposed as a possible relation\nfor pair (watch, weatherman) .\n"},{"#tail":"\n","@confidence":"0.997093181818182","#text":"\nThe system processes the 513 sentences interac-\ntively. It begins by running the DIPETT parser.\nNext, it extracts syntactic units (clauses, phrases,\nwords) and pairs them up according to the informa-\ntion in the parse tree. Each unit is represented by\nits head word. Next, the system checks if the same\npair of word lemmas has already been processed, to\npropose the same relation(s) to the user as options.\nIf not, the system builds a graph centered on the\nhead word, and proceeds with the matching on pre-\nviously encountered instances, as described in sec-\ntion 4. When a set of candidates has been found, the\nsystem goes through a dialogue with the user.\nThe system generated 2020 pairs from the 513\nsentences. The experiment was run in 5 interactive\nsessions of approximately 3 hours each. The total\nnet processing time was 6 hours, 42 minutes and 52\nseconds4 . While it would have been instructive to\nrun the system several times with different users, it\nwas not feasible. The experiment was run once, with\ntwo cooperating users. They were instructed on the\nset of semantic relations, and told how the system\nworks. They discussed the semantic relation assign-\nment and, once agreed, compared the system?s sug-\ngestion with their decision.\nDIPETT did not produce a complete parse for all\nsentences. When a complete parse (correct or incor-\nrect) was not possible, DIPETT produced fragmen-\ntary parses. The semantic analyser extracted units\neven from tree fragments, although sometimes the\nfragments were too small to accommodate any pairs.\nOf the 513 input sentences, 441 had a parse tree that\nallowed the system to extract pairs.\n"},{"#tail":"\n","@confidence":"0.998989825","#text":"\nOf 2020 pairs generated, the users discarded 545\nin the dialogue step. An example of an erroneous\npair comes from the sentence:\nTiny clouds drift across like feathers on parade.\nThe semantic analyser produced the pair\n(drift,parade), because of a parsing error: pa-\nrade was parsed as a complement of drift, instead\nof a post-modifier for feathers. The correct pairing\n(feather,parade) is missing, because it cannot be\ninferred from the parse tree.\nTable 1 gives a summary of the processing statis-\ntics. We observe that graph-matching was used to\nprocess a clear majority of the total pairs extracted ?\n63.25% (933/1475) , leaving the remaining 36.75%\nfor the other two heuristics and for cases where no\nsuggestion could be made. In 57.02% of the situa-\ntions when graph-matching was used, the system?s\nsuggestion contained the correct answer (user?s ac-\ntion was either accept or choose), and in 19.61% of\nthe situations a single correct semantic relation was\nproposed (user action was accept).\nWhen the system presents multiple suggestions to\nthe user, including the correct one, the average num-\nber of suggestions is 3.75. The small number of\nsuggestions shows that the system does not simply\nadd to the list relations that it has previously encoun-\ntered, but it learns from past experience and graph-\nmatching helps it make good selections. Figure 2\nplots the difference between the number of exam-\nples for which the system gives the correct answer\n(possibly among other suggestions) and the number\nof examples when the user must supply the correct\nrelation, from the first example processed until the\nend of the experiment. We observe a steady increase\nin the number of correctly processed examples.\nOur system does not differentiate between syntac-\ntic levels, but based on the structures of the syntac-\ntic units in each pair we can decide which syntactic\nlevel it pertains to. For a more in-depth analysis, we\nhave separated the results for each syntactic level,\n"},{"#tail":"\n","@confidence":"0.978664166666667","#text":"\ncorrect relation\nand present them for comparison in Figure 3.\nWe observe that the intra-clause level ? verbs\nand their arguments ? makes the best use of graph-\nmatching, with the curve showing the cumulative\nnumber of situations in which the system makes cor-\nrect predictions becoming steeper as more text is\nprocessed. At the same time, the curve that plots the\ncumulative number of cases in which the user has to\nsupply a correct answer begins to level off. As ex-\npected, at the noun-phrase level where the syntactic\nstructures are very simple, often consisting of only\nthe noun and its modifier (without even a connec-\ntive), the graph-matching algorithm does not help as\nmuch. At the inter-clause level the heuristic helps,\nas shown by the marginally higher curve for cumula-\ntive accept/choose user actions, compared to supply\nactions.\n"},{"#tail":"\n","@confidence":"0.989561294117647","#text":"\nWe have shown through the results gathered from an\ninteractive and incremental text processing system\nthat syntactic-semantic graph-matching can be used\nwith good results for semantic analysis of texts. The\ngraph-matching heuristic clearly dominates other\nheuristics used, and it learns to make better predic-\ntions as more examples accumulate.\nGraph-matching is most useful for assigning se-\nmantic relations between verbs and their arguments,\nbut it also gives good results for inter-clause rela-\ntions. At the noun-phrase level, we could only tackle\nnoun-modifier pairs that exhibit a modicum of syn-\ntactic structure ? a connective. For base NPs there\nis practically nothing that syntactic information can\nbring to the semantic analysis process.\nThe graph-matching process could be improved\nby bringing into play freely available lexical re-\n"},{"#tail":"\n","@confidence":"0.999716","#text":"\nsources. For now, the actual words in the graph\nnodes are not used at all. We could use WordNet\nto compute word similarities, to select closer match-\ning graphs. VerbNet or FrameNet information could\nhelp choose graphs centered on verbs with simi-\nlar syntactic behaviour, as captured by Levin?s verb\ngroups (Levin, 1993) which are the basis of VerbNet.\n"}],"#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.784646","#text":"\nUniversity of Ottawa, Ottawa, Canada\n"},{"#tail":"\n","@confidence":"0.416207","#text":"\nPolish Academy of Sciences, Warsaw, Poland\n"}],"sectionHeader":[{"#tail":"\n","@confidence":"0.505706","@genericHeader":"abstract","#text":"\n2 Institute of Computer Science,\n"},{"#tail":"\n","@confidence":"0.987104","@genericHeader":"keywords","#text":"\nAbstract\n"},{"#tail":"\n","@confidence":"0.997893","@genericHeader":"introduction","#text":"\n1 Introduction\n"},{"#tail":"\n","@confidence":"0.999596","@genericHeader":"related work","#text":"\n2 Related Work\n"},{"#tail":"\n","@confidence":"0.557233","@genericHeader":"method","#text":"\n3 Input data and semantic relations\n"},{"#tail":"\n","@confidence":"0.859513","@genericHeader":"method","#text":"\n4 Syntactic-semantic graph-matching\n"},{"#tail":"\n","@confidence":"0.999132","@genericHeader":"evaluation","#text":"\n5 Experiments\n"},{"#tail":"\n","@confidence":"0.995051","@genericHeader":"conclusions","#text":"\n6 Conclusions\n"},{"#tail":"\n","@confidence":"0.991758","@genericHeader":"references","#text":"\nReferences\n"}],"tableCaption":{"#tail":"\n","@confidence":"0.999241","#text":"\nTable 1: Summary of semantic analysis\n"},"page":[{"#tail":"\n","@confidence":"0.99596","#text":"\n81\n"},{"#tail":"\n","@confidence":"0.995588","#text":"\n82\n"},{"#tail":"\n","@confidence":"0.989322","#text":"\n83\n"},{"#tail":"\n","@confidence":"0.974561","#text":"\n84\n"},{"#tail":"\n","@confidence":"0.985171","#text":"\n85\n"},{"#tail":"\n","@confidence":"0.69223","#text":"\n86\n"},{"#tail":"\n","@confidence":"0.996815","#text":"\n87\n"},{"#tail":"\n","@confidence":"0.998297","#text":"\n88\n"}],"figureCaption":[{"#tail":"\n","@confidence":"0.999059","#text":"\nFigure 1: Distance between two graphs\n"},{"#tail":"\n","@confidence":"0.847017","#text":"\nFigure 2: Difference between the number of situa-\ntions in which the user accepts or chooses from the\nsystem?s suggestions, and when it must supply the\n"},{"#tail":"\n","@confidence":"0.7783885","#text":"\nFigure 3: Graph-matching for different syntactic\nlevels\n"}],"table":[{"#tail":"\n","@confidence":"0.4239834","#text":"\nWorkshop on TextGraphs, at HLT-NAACL 2006, pages 81?88,\nNew York City, June 2006. c?2006 Association for Computational Linguistics\nMatching Syntactic-Semantic Graphs for Semantic Relation Assignment\nVivi Nastase1 and Stan Szpakowicz1,2\n1 School of Information Technology and Engineering,\n"},{"#tail":"\n","@confidence":"0.957978833333333","#text":"\nand user interaction for other steps of the analysis.\n# of analyzed examples 1475\nlevel statistics CL IC NP\n64 978 433\nuser actions accept choose supply\n459 393 623\navg. # of suggestions 2.81\ngraph-matching usage 933\nlevel/action statistics CL IC NP\naccept 183 (19.61%) 9 141 33\nchoose 349 (37.41%) 23 314 12\nsupply 401 (42.98%) 27 316 58\n"}],"email":{"#tail":"\n","@confidence":"0.950716","#text":"\n{vnastase,szpak}@site.uottawa.ca\n"}}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.851531","#tail":"\n","@no":"0","note":{"#tail":"\n","@confidence":"0.990546","#text":"Workshop on TextGraphs, at HLT-NAACL 2006, pages 81?88, New York City, June 2006. c?2006 Association for Computational Linguistics"},"address":{"#tail":"\n","@confidence":"0.962445","#text":"Polish Academy of Sciences, Warsaw, Poland"},"#text":"\n","affiliation":{"#tail":"\n","@confidence":"0.980947666666667","#text":"1 School of Information Technology and Engineering, University of Ottawa, Ottawa, Canada 2 Institute of Computer Science,"},"author":[{"#tail":"\n","@confidence":"0.993115","#text":"Vivi Nastase"},{"#tail":"\n","@confidence":"0.993115","#text":"Stan Szpakowicz"}],"abstract":{"#tail":"\n","@confidence":"0.9989518","#text":"We present a graph-matching algorithm for semantic relation assignment. The algorithm is part of an interactive text analysis system. The system automatically extracts pairs of syntactic units from a text and assigns a semantic relation to each pair. This is an incremental learning algorithm, in which previously processed pairs and user feedback guide the process. After each assignment, the system adds to its database a syntactic-semantic graph centered on the main element of each pair of units. A graph consists of the main unit and all syntactic units with which it is syntactically connected. An edge contains information both about syntax and about semantic relations for use in further processing. Syntactic-semantic graph matching is used to produce a list of candidate assignments for 63.75% of the pairs analysed, and in 57% of situations the correct relations is one of the system?s suggestions; in 19.6% of situations it suggests only the correct relation."},"title":{"#tail":"\n","@confidence":"0.975265","#text":"Matching Syntactic-Semantic Graphs for Semantic Relation Assignment"},"email":[{"#tail":"\n","@confidence":"0.996248","#text":"vnastase@site.uottawa.ca"},{"#tail":"\n","@confidence":"0.996248","#text":"szpak@site.uottawa.ca"}]}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"institution":{"#tail":"\n","#text":"Tsigov Czark, Bulgaria."},"rawString":{"#tail":"\n","#text":"Jordi Atserias, L. Padro?, and German Rigau. 2001. Integrating multiple knowledge sources for robust semantic parsing. In Proceedings of RANLP - 2001, Tsigov Czark, Bulgaria."},"#text":"\n","marker":{"#tail":"\n","#text":"Atserias, Padro, Rigau, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ons between them goes back to the 5th century B.C. and the work of Panini1. He was a grammarian who analysed Sanskrit (Misra, 1966). The idea resurfaced forcefully at several points in the more recent history of linguistic research (Tesnie`re, 1959; Gruber, 1965; Fillmore, 1968). Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic 1The sources date his work variously between the 5th and 7th century. role labelling (Baker et al, 1998; Kipper et al, 2000; Carreras and Marquez, 2004; Carreras and Marquez, 2005; Atserias et al, 2001; Shi and Mihalcea, 2005). Graph-like structures are a natural way of organising one?s impressions of a text seen from the perspective of connections between its simpler constituents of varying granularity, from sections through paragraphs, sentences, clauses, phrases, words to morphemes. In this work we pursue a well-known and often tacitly assumed line of thinking: connections at the syntactic level reflect connections at the semantic level (in other words, syntax carries meaning). Anecdotal support for this stance comes from the fact that the grammatical notion of case is the basis for sema","@endWordPosition":"356","@position":"2237","annotationId":"T1","@startWordPosition":"353","@citStr":"Atserias et al, 2001"}},"title":{"#tail":"\n","#text":"Integrating multiple knowledge sources for robust semantic parsing."},"booktitle":{"#tail":"\n","#text":"In Proceedings of RANLP -"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Jordi Atserias"},{"#tail":"\n","#text":"L Padro"},{"#tail":"\n","#text":"German Rigau"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet project. In COLING-ACL, pages 86?90, Montreal, Canada."},"#text":"\n","pages":{"#tail":"\n","#text":"86--90"},"marker":{"#tail":"\n","#text":"Baker, Fillmore, Lowe, 1998"},"location":{"#tail":"\n","#text":"Montreal, Canada."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"s is an old idea. The first chronicled endeavour to connect text elements and organise connections between them goes back to the 5th century B.C. and the work of Panini1. He was a grammarian who analysed Sanskrit (Misra, 1966). The idea resurfaced forcefully at several points in the more recent history of linguistic research (Tesnie`re, 1959; Gruber, 1965; Fillmore, 1968). Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic 1The sources date his work variously between the 5th and 7th century. role labelling (Baker et al, 1998; Kipper et al, 2000; Carreras and Marquez, 2004; Carreras and Marquez, 2005; Atserias et al, 2001; Shi and Mihalcea, 2005). Graph-like structures are a natural way of organising one?s impressions of a text seen from the perspective of connections between its simpler constituents of varying granularity, from sections through paragraphs, sentences, clauses, phrases, words to morphemes. In this work we pursue a well-known and often tacitly assumed line of thinking: connections at the syntactic level reflect connections at the semantic level (in other words, syntax carries meaning). Anecdotal sup","@endWordPosition":"340","@position":"2139","annotationId":"T2","@startWordPosition":"337","@citStr":"Baker et al, 1998"},{"#tail":"\n","#text":"ic relation list. Section 4 looks in detail at the graph-matching heuristic. Section 5 describes the experimental setting and shows how often the heuristic was used when processing the input text. We show in detail our findings about syntactic levels (how often graph matching helped assign a relation between two clauses, a verb and its arguments, or a noun and its modifier) and about the accuracy of the suggestion. Discussion and conclusions appear in Section 6. 2 Related Work Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts (Baker et al, 1998). In other methods, lexical resources are specifically tailored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge base","@endWordPosition":"792","@position":"4924","annotationId":"T3","@startWordPosition":"789","@citStr":"Baker et al, 1998"}]},"title":{"#tail":"\n","#text":"The Berkeley FrameNet project."},"booktitle":{"#tail":"\n","#text":"In COLING-ACL,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Collin F Baker"},{"#tail":"\n","#text":"Charles J Fillmore"},{"#tail":"\n","#text":"John B Lowe"}]}},{"date":{"#tail":"\n","#text":"1997"},"issue":{"#tail":"\n","#text":"4"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"r of units, the system builds a syntactic graph surrounding the main element (main clause, head verb, head noun). It then tries to find among the previously processed instances another main element with a matching syntactic graph. If such a graph is found, then the system maps previously assigned semantic relations onto the current syntactic graph. We have a list of 47 relations that manifest themselves in compound clauses, inside a simple clause or in noun phrases. The list, a synthesis of a number of relation lists cited in the literature, has been designed to be general, domainindependent (Barker et al, 1997a). Section 2 overviews research in semantic relation analysis. Section 3 describes the text we used in ex81 periments, and the semantic relation list. Section 4 looks in detail at the graph-matching heuristic. Section 5 describes the experimental setting and shows how often the heuristic was used when processing the input text. We show in detail our findings about syntactic levels (how often graph matching helped assign a relation between two clauses, a verb and its arguments, or a noun and its modifier) and about the accuracy of the suggestion. Discussion and conclusions appear in Section 6.","@endWordPosition":"670","@position":"4172","annotationId":"T4","@startWordPosition":"667","@citStr":"Barker et al, 1997"},{"#tail":"\n","#text":"ystem will present an empty list, and expect the user to input the appropriate relation. When at least one relation is proposed, the user can accept a unique relation, choose among several options, or supply a new one. The system records which action took place, as well as the heuristic that generated the options presented to the user. The pair is also analysed to determine the syntactic level from which it came, to allow for a more detailed analysis of the behaviour of the system. 3.2 Semantic relations The list of semantic relations with which we work is based on extensive literature study (Barker et al, 1997a). Three lists of relations for three syntactic levels ? inter-clause, intra-clause (case) and nounmodifier relations ? were next combined based on syntactic and semantic phenomena. The resulting list is the one used in the experiments we present in this paper. The relations are grouped by general similarity into 6 relation classes (H denotes the head of a base NP, M denotes the modifier). 1. CAUSAL groups relations enabling or opposing an occurrence. Examples: cause - H causes M: u virus; effect - H is the effect (was caused by) M: exam anxiety; purpose - H is for M: concert hall; 2. CONJUN","@endWordPosition":"1827","@position":"11322","annotationId":"T5","@startWordPosition":"1824","@citStr":"Barker et al, 1997"},{"#tail":"\n","#text":"consensus in the literature on a list of semantic relations that would work in all situations. This is, no doubt, because a general list of relations such as the one we use would not be appropriate for the semantic analysis of texts in a specific domain, such as for example medical texts. All the relations in the list we use were necessary, and sufficient, for the analysis of the input text. 4 Syntactic-semantic graph-matching Our system begins operation with a minimum of manually encoded knowledge, and accumulates information as it processes the text. This design idea was adopted from TANKA (Barker et al, 1997b). The only manually encoded knowledge is a dictionary of markers (subordinators, coordinators, prepositions). This resource does not affect the syntacticsemantic graph-matching heuristic. Because the system gradually accumulates knowledge as it goes through the input text, it uses a form of memory-based learning to make predictions about the semantic relation that fits the current pair. The type of knowledge that it accumulates consists of previously analysed pairs, together with the semantic relation assigned, and a syntactic-semantic graph centered on each word in a sentence which appears ","@endWordPosition":"2285","@position":"13949","annotationId":"T6","@startWordPosition":"2282","@citStr":"Barker et al, 1997"}]},"title":{"#tail":"\n","#text":"Systematic construction of a versatile case system."},"volume":{"#tail":"\n","#text":"3"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Ken Barker, Terry Copeck, Sylvain Delisle, and Stan Szpakowicz. 1997a. Systematic construction of a versatile case system. Journal of Natural Language Engineering, 3(4):279? 315."},"journal":{"#tail":"\n","#text":"Journal of Natural Language Engineering,"},"#text":"\n","pages":{"#tail":"\n","#text":"315"},"marker":{"#tail":"\n","#text":"Barker, Copeck, Delisle, Szpakowicz, 1997"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Ken Barker"},{"#tail":"\n","#text":"Terry Copeck"},{"#tail":"\n","#text":"Sylvain Delisle"},{"#tail":"\n","#text":"Stan Szpakowicz"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Ken Barker, Sylvain Delisle, and Stan Szpakowicz. 1997b."},"#text":"\n","marker":{"#tail":"\n","#text":"Barker, Delisle, Szpakowicz, 1997"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"r of units, the system builds a syntactic graph surrounding the main element (main clause, head verb, head noun). It then tries to find among the previously processed instances another main element with a matching syntactic graph. If such a graph is found, then the system maps previously assigned semantic relations onto the current syntactic graph. We have a list of 47 relations that manifest themselves in compound clauses, inside a simple clause or in noun phrases. The list, a synthesis of a number of relation lists cited in the literature, has been designed to be general, domainindependent (Barker et al, 1997a). Section 2 overviews research in semantic relation analysis. Section 3 describes the text we used in ex81 periments, and the semantic relation list. Section 4 looks in detail at the graph-matching heuristic. Section 5 describes the experimental setting and shows how often the heuristic was used when processing the input text. We show in detail our findings about syntactic levels (how often graph matching helped assign a relation between two clauses, a verb and its arguments, or a noun and its modifier) and about the accuracy of the suggestion. Discussion and conclusions appear in Section 6.","@endWordPosition":"670","@position":"4172","annotationId":"T7","@startWordPosition":"667","@citStr":"Barker et al, 1997"},{"#tail":"\n","#text":"ystem will present an empty list, and expect the user to input the appropriate relation. When at least one relation is proposed, the user can accept a unique relation, choose among several options, or supply a new one. The system records which action took place, as well as the heuristic that generated the options presented to the user. The pair is also analysed to determine the syntactic level from which it came, to allow for a more detailed analysis of the behaviour of the system. 3.2 Semantic relations The list of semantic relations with which we work is based on extensive literature study (Barker et al, 1997a). Three lists of relations for three syntactic levels ? inter-clause, intra-clause (case) and nounmodifier relations ? were next combined based on syntactic and semantic phenomena. The resulting list is the one used in the experiments we present in this paper. The relations are grouped by general similarity into 6 relation classes (H denotes the head of a base NP, M denotes the modifier). 1. CAUSAL groups relations enabling or opposing an occurrence. Examples: cause - H causes M: u virus; effect - H is the effect (was caused by) M: exam anxiety; purpose - H is for M: concert hall; 2. CONJUN","@endWordPosition":"1827","@position":"11322","annotationId":"T8","@startWordPosition":"1824","@citStr":"Barker et al, 1997"},{"#tail":"\n","#text":"consensus in the literature on a list of semantic relations that would work in all situations. This is, no doubt, because a general list of relations such as the one we use would not be appropriate for the semantic analysis of texts in a specific domain, such as for example medical texts. All the relations in the list we use were necessary, and sufficient, for the analysis of the input text. 4 Syntactic-semantic graph-matching Our system begins operation with a minimum of manually encoded knowledge, and accumulates information as it processes the text. This design idea was adopted from TANKA (Barker et al, 1997b). The only manually encoded knowledge is a dictionary of markers (subordinators, coordinators, prepositions). This resource does not affect the syntacticsemantic graph-matching heuristic. Because the system gradually accumulates knowledge as it goes through the input text, it uses a form of memory-based learning to make predictions about the semantic relation that fits the current pair. The type of knowledge that it accumulates consists of previously analysed pairs, together with the semantic relation assigned, and a syntactic-semantic graph centered on each word in a sentence which appears ","@endWordPosition":"2285","@position":"13949","annotationId":"T9","@startWordPosition":"2282","@citStr":"Barker et al, 1997"}]},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Ken Barker"},{"#tail":"\n","#text":"Sylvain Delisle"},{"#tail":"\n","#text":"Stan Szpakowicz"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Test-driving TANKA: Evaluating a semi-automatic system of text analysis for knowledge acquisition. In Proceedings of CAI 1997, pages 60?71, Vancouver, BC, Canada."},"#text":"\n","pages":{"#tail":"\n","#text":"60--71"},"marker":{"#tail":"\n","#text":"1997"},"location":{"#tail":"\n","#text":"Vancouver, BC,"},"title":{"#tail":"\n","#text":"Test-driving TANKA: Evaluating a semi-automatic system of text analysis for knowledge acquisition."},"booktitle":{"#tail":"\n","#text":"In Proceedings of CAI"},"@valid":"true"},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"editor":{"#tail":"\n","#text":"Xavier Carreras and Lluis Marquez, editors."},"rawString":{"#tail":"\n","#text":"Xavier Carreras and Lluis Marquez, editors. 2004. Introduction to the CoNLL-2004 Shared Task: Semantic Role Labelling. Boston, MA, USA."},"#text":"\n","marker":{"#tail":"\n","#text":"2004"},"location":{"#tail":"\n","#text":"Boston, MA, USA."},"booktitle":{"#tail":"\n","#text":"Introduction to the CoNLL-2004 Shared Task: Semantic Role Labelling."},"@valid":"true"},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"Xavier Carreras and Lluis Marquez, editors. 2005. Introduction to the CoNLL-2005 Shared Task: Semantic Role Labelling. Ann Arbour, MI, USA."},"#text":"\n","marker":{"#tail":"\n","#text":"Carreras, Marquez, editors, 2005"},"location":{"#tail":"\n","#text":"Ann Arbour, MI, USA."},"booktitle":{"#tail":"\n","#text":"Introduction to the CoNLL-2005 Shared Task: Semantic Role Labelling."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Xavier Carreras"},{"#tail":"\n","#text":"Lluis Marquez"},{"#tail":"\n","#text":"editors"}]}},{"date":{"#tail":"\n","#text":"1970"},"editor":{"#tail":"\n","#text":"In Roderick Jacobs and Peter Rosenbaum, editors,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ct connections at the semantic level (in other words, syntax carries meaning). Anecdotal support for this stance comes from the fact that the grammatical notion of case is the basis for semantic relations (Misra, 1966; Gruber, 1965; Fillmore, 1968). Tesnie`re (1959), who proposes a grouping of verb arguments into actants and circumstances, gives a set of rules to connect specific types of actants ? for example, agent or instrument ? to such grammatical elements as subject, direct object, indirect object. This idea was expanded to include nouns and their modifiers through verb nominalizations (Chomsky, 1970; Quirk et al, 1985). We work with sentences, clauses, phrases and words, using syntactic structures generated by a parser. Our system incrementally processes a text, and extracts pairs of text units: two clauses, a verb and each of its arguments, a noun and each of its modifiers. For each pair of units, the system builds a syntactic graph surrounding the main element (main clause, head verb, head noun). It then tries to find among the previously processed instances another main element with a matching syntactic graph. If such a graph is found, then the system maps previously assigned semantic","@endWordPosition":"515","@position":"3260","annotationId":"T10","@startWordPosition":"514","@citStr":"Chomsky, 1970"}},"title":{"#tail":"\n","#text":"Remarks on nominalizations."},"#tail":"\n","rawString":{"#tail":"\n","#text":"Noam Chomsky. 1970. Remarks on nominalizations. In Roderick Jacobs and Peter Rosenbaum, editors, Readings in English Transformational Grammar, pages 184?221. Ginn and Co., Waltham, MA, USA."},"#text":"\n","pages":{"#tail":"\n","#text":"184--221"},"marker":{"#tail":"\n","#text":"Chomsky, 1970"},"location":{"#tail":"\n","#text":"Waltham, MA, USA."},"booktitle":{"#tail":"\n","#text":"Readings in English Transformational Grammar,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Noam Chomsky"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Peter Clark and Bruce Porter. 1997. Building concept reprezentations from reusable components. In AAAI, pages 367?376, Providence, Rhode Island."},"#text":"\n","pages":{"#tail":"\n","#text":"367--376"},"marker":{"#tail":"\n","#text":"Clark, Porter, 1997"},"location":{"#tail":"\n","#text":"Providence, Rhode Island."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997). The system?s interface facilitates the expert?s task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary. In current work on semantic relation analysis, the focus is on semantic roles ? relations between verbs and their arguments. Most approaches rely on VerbNet (Kipper et al, 2000) and FrameNet (Baker et al., 1998) to provide associations between verbs and semantic roles, that are then mapped onto the current instance, as shown by the systems competing in semantic role labelling competitions (Carreras and Marquez, ","@endWordPosition":"898","@position":"5606","annotationId":"T11","@startWordPosition":"895","@citStr":"Clark and Porter, 1997"}},"title":{"#tail":"\n","#text":"Building concept reprezentations from reusable components."},"booktitle":{"#tail":"\n","#text":"In AAAI,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Peter Clark"},{"#tail":"\n","#text":"Bruce Porter"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"rawString":{"#tail":"\n","#text":"Sylvain Delisle and Stan Szpakowicz. 1995. Realistic parsing: Practical solutions of difficult problems. In PACLING, Brisbane, Queensland, Australia."},"#text":"\n","marker":{"#tail":"\n","#text":"Delisle, Szpakowicz, 1995"},"location":{"#tail":"\n","#text":"Brisbane, Queensland, Australia."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ch. The system will mimic the way in which a human reader accumulates knowledge and uses what was written before to process ideas introduced later in the text. The text contains 513 sentences, with an average length of 9.13 words. There are 4686 word tokens and 969 types. The difference between the number of types (2850) and tokens (573) in the extracted pairs (which contain only open-class words) shows that the same concepts recur, as expected in a didactic text. The syntactic structures of the input data are produced by a parser with good coverage and detailed syntactic information, DIPETT (Delisle and Szpakowicz, 1995). The parser, written in Prolog, implements a classic constituency English grammar from Quirk et al (1985). Pairs of syntactic units connected by grammatical relations are extracted from the parse trees. A dependency parser would 82 produce a similar output, but DIPETT also provides verb subcategorization information (such as, for example, subject-verb-object or subject-verb-objectindirect object), which we use to select the (best) matching syntactic structures. To find pairs, we use simple structural information. If a unit is directly embedded in another unit, we assume a subordinate relation","@endWordPosition":"1465","@position":"9105","annotationId":"T12","@startWordPosition":"1462","@citStr":"Delisle and Szpakowicz, 1995"}},"title":{"#tail":"\n","#text":"Realistic parsing: Practical solutions of difficult problems."},"booktitle":{"#tail":"\n","#text":"In PACLING,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Sylvain Delisle"},{"#tail":"\n","#text":"Stan Szpakowicz"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"Sylvain Delisle, Terry Copeck, Stan Szpakowicz, and Ken Barker. 1993. Pattern matching for case analysis: A computational definition of closeness. In ICCI, pages 310?315, Sudbury, ON, Canada."},"#text":"\n","pages":{"#tail":"\n","#text":"310--315"},"marker":{"#tail":"\n","#text":"Delisle, Copeck, Szpakowicz, Barker, 1993"},"location":{"#tail":"\n","#text":"Sudbury, ON,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"use the system gradually accumulates knowledge as it goes through the input text, it uses a form of memory-based learning to make predictions about the semantic relation that fits the current pair. The type of knowledge that it accumulates consists of previously analysed pairs, together with the semantic relation assigned, and a syntactic-semantic graph centered on each word in a sentence which appears as the main element in a processed pair. To process a pair P not encountered previously, the system builds a graph centered on the main element (often the head) of P . This idea was inspired by Delisle et al (1993), who used a list of arguments surrounding the main verb together with the verb?s subcategorization information and previously processed examples to analyse semantic roles (case relations). In recent approaches, syntactic information is translated into features which, together with information from FrameNet, WordNet or VerbNet, will be used with ML tools to make predictions for each example in the test set (Carreras and Marquez, 2004; Carreras and Marquez, 2005). Our system builds a (simple) graph surrounding a head word (which may be a verb ? representing the predicate of a sentence, or repre","@endWordPosition":"2415","@position":"14763","annotationId":"T13","@startWordPosition":"2412","@citStr":"Delisle et al (1993)"}},"title":{"#tail":"\n","#text":"Pattern matching for case analysis: A computational definition of closeness."},"booktitle":{"#tail":"\n","#text":"In ICCI,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Sylvain Delisle"},{"#tail":"\n","#text":"Terry Copeck"},{"#tail":"\n","#text":"Stan Szpakowicz"},{"#tail":"\n","#text":"Ken Barker"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Charles Fillmore and Beryl T. Atkins. 1998. FrameNet and lexicographic relevance. In Proceedings of the 1st International Conference on Language Resources and Evaluation, Granada, Spain."},"#text":"\n","marker":{"#tail":"\n","#text":"Fillmore, Atkins, 1998"},"location":{"#tail":"\n","#text":"Granada,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ten graph matching helped assign a relation between two clauses, a verb and its arguments, or a noun and its modifier) and about the accuracy of the suggestion. Discussion and conclusions appear in Section 6. 2 Related Work Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts (Baker et al, 1998). In other methods, lexical resources are specifically tailored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997). The system?s interface facilitates the expert?s task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary","@endWordPosition":"834","@position":"5189","annotationId":"T14","@startWordPosition":"831","@citStr":"Fillmore and Atkins, 1998"}},"title":{"#tail":"\n","#text":"FrameNet and lexicographic relevance."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 1st International Conference on Language Resources and Evaluation,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Charles Fillmore"},{"#tail":"\n","#text":"Beryl T Atkins"}]}},{"date":{"#tail":"\n","#text":"1968"},"editor":{"#tail":"\n","#text":"In Emmond Bach and Robert T. Harms, editors,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"of situations the correct relations is one of the system?s suggestions; in 19.6% of situations it suggests only the correct relation. 1 Introduction When analysing texts, it is essential to see how elements of meaning are interconnected. This is an old idea. The first chronicled endeavour to connect text elements and organise connections between them goes back to the 5th century B.C. and the work of Panini1. He was a grammarian who analysed Sanskrit (Misra, 1966). The idea resurfaced forcefully at several points in the more recent history of linguistic research (Tesnie`re, 1959; Gruber, 1965; Fillmore, 1968). Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic 1The sources date his work variously between the 5th and 7th century. role labelling (Baker et al, 1998; Kipper et al, 2000; Carreras and Marquez, 2004; Carreras and Marquez, 2005; Atserias et al, 2001; Shi and Mihalcea, 2005). Graph-like structures are a natural way of organising one?s impressions of a text seen from the perspective of connections between its simpler constituents of varying granularity, from sections through paragraphs, sentences, clauses","@endWordPosition":"299","@position":"1896","annotationId":"T15","@startWordPosition":"297","@citStr":"Fillmore, 1968"}},"title":{"#tail":"\n","#text":"The case for case."},"#tail":"\n","rawString":{"#tail":"\n","#text":"Charles Fillmore. 1968. The case for case. In Emmond Bach and Robert T. Harms, editors, Universals in Linguistic Theory, pages 1?88. Holt, Rinehart and Winston."},"#text":"\n","pages":{"#tail":"\n","#text":"1--88"},"marker":{"#tail":"\n","#text":"Fillmore, 1968"},"publisher":{"#tail":"\n","#text":"Holt, Rinehart and Winston."},"booktitle":{"#tail":"\n","#text":"Universals in Linguistic Theory,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Charles Fillmore"}}},{"date":{"#tail":"\n","#text":"2002"},"issue":{"#tail":"\n","#text":"3"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ssign a relation between two clauses, a verb and its arguments, or a noun and its modifier) and about the accuracy of the suggestion. Discussion and conclusions appear in Section 6. 2 Related Work Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts (Baker et al, 1998). In other methods, lexical resources are specifically tailored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997). The system?s interface facilitates the expert?s task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary. In current work on semant","@endWordPosition":"838","@position":"5216","annotationId":"T16","@startWordPosition":"835","@citStr":"Gildea and Jurafsky, 2002"}},"title":{"#tail":"\n","#text":"Automatic labeling of semantic roles."},"volume":{"#tail":"\n","#text":"28"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3):245? 288."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","pages":{"#tail":"\n","#text":"288"},"marker":{"#tail":"\n","#text":"Gildea, Jurafsky, 2002"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Daniel Gildea"},{"#tail":"\n","#text":"Daniel Jurafsky"}]}},{"volume":{"#tail":"\n","#text":"10"},"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Fernando Gomez. 1998. A representation of complex events and processes for the acquisition of knowledge from text. Kowledge-Based Systems, 10(4):237?251."},"journal":{"#tail":"\n","#text":"Kowledge-Based Systems,"},"#text":"\n","issue":{"#tail":"\n","#text":"4"},"marker":{"#tail":"\n","#text":"Gomez, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"d when processing the input text. We show in detail our findings about syntactic levels (how often graph matching helped assign a relation between two clauses, a verb and its arguments, or a noun and its modifier) and about the accuracy of the suggestion. Discussion and conclusions appear in Section 6. 2 Related Work Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts (Baker et al, 1998). In other methods, lexical resources are specifically tailored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997). The system?s interface facilitates the expert?s task of creating and mani","@endWordPosition":"817","@position":"5081","annotationId":"T17","@startWordPosition":"816","@citStr":"Gomez, 1998"}},"title":{"#tail":"\n","#text":"A representation of complex events and processes for the acquisition of knowledge from text."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Fernando Gomez"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1965"},"note":{"#tail":"\n","#text":"Studies in Lexical Relations. Ph.D."},"rawString":{"#tail":"\n","#text":"Jeffrey Gruber. 1965. Studies in Lexical Relations. Ph.D."},"#text":"\n","marker":{"#tail":"\n","#text":"Gruber, 1965"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"d, and in 57% of situations the correct relations is one of the system?s suggestions; in 19.6% of situations it suggests only the correct relation. 1 Introduction When analysing texts, it is essential to see how elements of meaning are interconnected. This is an old idea. The first chronicled endeavour to connect text elements and organise connections between them goes back to the 5th century B.C. and the work of Panini1. He was a grammarian who analysed Sanskrit (Misra, 1966). The idea resurfaced forcefully at several points in the more recent history of linguistic research (Tesnie`re, 1959; Gruber, 1965; Fillmore, 1968). Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic 1The sources date his work variously between the 5th and 7th century. role labelling (Baker et al, 1998; Kipper et al, 2000; Carreras and Marquez, 2004; Carreras and Marquez, 2005; Atserias et al, 2001; Shi and Mihalcea, 2005). Graph-like structures are a natural way of organising one?s impressions of a text seen from the perspective of connections between its simpler constituents of varying granularity, from sections through paragraphs, s","@endWordPosition":"296","@position":"1879","annotationId":"T18","@startWordPosition":"295","@citStr":"Gruber, 1965"}},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Jeffrey Gruber"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1976"},"note":{"#tail":"\n","#text":"Reprinted in"},"rawString":{"#tail":"\n","#text":"thesis, MIT, Cambridge, MA. Reprinted in Jeffrey Gruber. 1976. Lexical Structures in Syntax and Semantics. Part I. North-Holland Publishing Company, Amsterdam."},"#text":"\n","marker":{"#tail":"\n","#text":"thesis, Cambridge, 1976"},"publisher":{"#tail":"\n","#text":"North-Holland Publishing Company,"},"location":{"#tail":"\n","#text":"Amsterdam."},"booktitle":{"#tail":"\n","#text":"Lexical Structures in Syntax and Semantics. Part I."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"MIT thesis"},{"#tail":"\n","#text":"MA Cambridge"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"Richard D. Hull and Fernando Gomez. 1996. Semantic interpretation of nominalizations. In 13th National Conference on Artificial Intelligence, pages 1062?1068, Portland, Oregon, USA."},"#text":"\n","pages":{"#tail":"\n","#text":"1062--1068"},"marker":{"#tail":"\n","#text":"Hull, Gomez, 1996"},"location":{"#tail":"\n","#text":"Portland, Oregon, USA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"o clauses, a verb and its arguments, or a noun and its modifier) and about the accuracy of the suggestion. Discussion and conclusions appear in Section 6. 2 Related Work Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts (Baker et al, 1998). In other methods, lexical resources are specifically tailored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997). The system?s interface facilitates the expert?s task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary. In current work on semantic relation analysis, t","@endWordPosition":"842","@position":"5239","annotationId":"T19","@startWordPosition":"839","@citStr":"Hull and Gomez, 1996"}},"title":{"#tail":"\n","#text":"Semantic interpretation of nominalizations."},"booktitle":{"#tail":"\n","#text":"In 13th National Conference on Artificial Intelligence,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Richard D Hull"},{"#tail":"\n","#text":"Fernando Gomez"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Karin Kipper, Hoa Trang Dang, and Martha Palmer. 2000. Class-based construction of a verb lexicon. In AAAI/IAAI, pages 691?696."},"#text":"\n","pages":{"#tail":"\n","#text":"691--696"},"marker":{"#tail":"\n","#text":"Kipper, Dang, Palmer, 2000"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"he first chronicled endeavour to connect text elements and organise connections between them goes back to the 5th century B.C. and the work of Panini1. He was a grammarian who analysed Sanskrit (Misra, 1966). The idea resurfaced forcefully at several points in the more recent history of linguistic research (Tesnie`re, 1959; Gruber, 1965; Fillmore, 1968). Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic 1The sources date his work variously between the 5th and 7th century. role labelling (Baker et al, 1998; Kipper et al, 2000; Carreras and Marquez, 2004; Carreras and Marquez, 2005; Atserias et al, 2001; Shi and Mihalcea, 2005). Graph-like structures are a natural way of organising one?s impressions of a text seen from the perspective of connections between its simpler constituents of varying granularity, from sections through paragraphs, sentences, clauses, phrases, words to morphemes. In this work we pursue a well-known and often tacitly assumed line of thinking: connections at the syntactic level reflect connections at the semantic level (in other words, syntax carries meaning). Anecdotal support for this stance","@endWordPosition":"344","@position":"2159","annotationId":"T20","@startWordPosition":"341","@citStr":"Kipper et al, 2000"},{"#tail":"\n","#text":"apture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997). The system?s interface facilitates the expert?s task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary. In current work on semantic relation analysis, the focus is on semantic roles ? relations between verbs and their arguments. Most approaches rely on VerbNet (Kipper et al, 2000) and FrameNet (Baker et al., 1998) to provide associations between verbs and semantic roles, that are then mapped onto the current instance, as shown by the systems competing in semantic role labelling competitions (Carreras and Marquez, 2004; Carreras and Marquez, 2005) and also (Gildea and Jurafsky, 2002; Pradhan et al, 2005; Shi and Mihalcea, 2005). These systems share two ideas which make them different from the approach presented here: they all analyse verb-argument relations, and they all use machine learning or probabilistic approaches (Pradhan et al, 2005) to assign a label to a new in","@endWordPosition":"955","@position":"5968","annotationId":"T21","@startWordPosition":"952","@citStr":"Kipper et al, 2000"}]},"title":{"#tail":"\n","#text":"Class-based construction of a verb lexicon. In"},"booktitle":{"#tail":"\n","#text":"AAAI/IAAI,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Karin Kipper"},{"#tail":"\n","#text":"Hoa Trang Dang"},{"#tail":"\n","#text":"Martha Palmer"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1961"},"rawString":{"#tail":"\n","#text":"Nancy Larrick. 1961. Junior Science Book of Rain, Hail, Sleet and Snow. Garrard Publishing Company, Champaign, Illinois."},"#text":"\n","marker":{"#tail":"\n","#text":"Larrick, 1961"},"publisher":{"#tail":"\n","#text":"Garrard Publishing Company,"},"location":{"#tail":"\n","#text":"Rain, Hail, Sleet"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"sing the current system configuration, the effect of syntactic information and incremental learning on semantic analysis. This is described in section 5. Because of these differences in the type of data used, and in the learning approach, the results we obtain cannot be compared to previous approaches. In order to show that the system does learn, we show that the number of examples for which it provides the correct answer increases with the number of examples previously analysed. 3 Input data and semantic relations 3.1 Input data We work with a semi-technical text on meteorological phenomena (Larrick, 1961), meant for primary school students. The text gradually introduces concepts related to precipitation, and explains them. Its nature makes it appropriate for the semantic analysis task in an incremental approach. The system will mimic the way in which a human reader accumulates knowledge and uses what was written before to process ideas introduced later in the text. The text contains 513 sentences, with an average length of 9.13 words. There are 4686 word tokens and 969 types. The difference between the number of types (2850) and tokens (573) in the extracted pairs (which contain only open-clas","@endWordPosition":"1326","@position":"8268","annotationId":"T22","@startWordPosition":"1325","@citStr":"Larrick, 1961"}},"title":{"#tail":"\n","#text":"Junior Science Book of"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Nancy Larrick"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"Beth Levin. 1993. English Verb Classes and Alternations. University of Chicago Press."},"#text":"\n","marker":{"#tail":"\n","#text":"Levin, 1993"},"publisher":{"#tail":"\n","#text":"University of Chicago Press."},"title":{"#tail":"\n","#text":"English Verb Classes and Alternations."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Beth Levin"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1966"},"rawString":{"#tail":"\n","#text":"Vidya Niwas Misra. 1966. The Descriptive Technique of Panini. Mouton, The Hague."},"#text":"\n","marker":{"#tail":"\n","#text":"Misra, 1966"},"publisher":{"#tail":"\n","#text":"Mouton, The Hague."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"er processing. Syntactic-semantic graph matching is used to produce a list of candidate assignments for 63.75% of the pairs analysed, and in 57% of situations the correct relations is one of the system?s suggestions; in 19.6% of situations it suggests only the correct relation. 1 Introduction When analysing texts, it is essential to see how elements of meaning are interconnected. This is an old idea. The first chronicled endeavour to connect text elements and organise connections between them goes back to the 5th century B.C. and the work of Panini1. He was a grammarian who analysed Sanskrit (Misra, 1966). The idea resurfaced forcefully at several points in the more recent history of linguistic research (Tesnie`re, 1959; Gruber, 1965; Fillmore, 1968). Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic 1The sources date his work variously between the 5th and 7th century. role labelling (Baker et al, 1998; Kipper et al, 2000; Carreras and Marquez, 2004; Carreras and Marquez, 2005; Atserias et al, 2001; Shi and Mihalcea, 2005). Graph-like structures are a natural way of organising one?s impressions of a text se","@endWordPosition":"276","@position":"1748","annotationId":"T23","@startWordPosition":"275","@citStr":"Misra, 1966"}},"title":{"#tail":"\n","#text":"The Descriptive Technique of Panini."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Vidya Niwas Misra"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"Sameer Pradhan, Wayne Ward, Kadri Hacioglu, James H. Martin, and Daniel Jurafsky. 2005. Semantic role labelling using different syntactic views. In Proceedings of ACL 2005, pages 581?588, Ann Arbour, MI, USA."},"#text":"\n","pages":{"#tail":"\n","#text":"581--588"},"marker":{"#tail":"\n","#text":"Pradhan, Ward, Hacioglu, Martin, Jurafsky, 2005"},"location":{"#tail":"\n","#text":"Ann Arbour, MI, USA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary. In current work on semantic relation analysis, the focus is on semantic roles ? relations between verbs and their arguments. Most approaches rely on VerbNet (Kipper et al, 2000) and FrameNet (Baker et al., 1998) to provide associations between verbs and semantic roles, that are then mapped onto the current instance, as shown by the systems competing in semantic role labelling competitions (Carreras and Marquez, 2004; Carreras and Marquez, 2005) and also (Gildea and Jurafsky, 2002; Pradhan et al, 2005; Shi and Mihalcea, 2005). These systems share two ideas which make them different from the approach presented here: they all analyse verb-argument relations, and they all use machine learning or probabilistic approaches (Pradhan et al, 2005) to assign a label to a new instance. Labelling every instance relies on the same previously encoded knowledge (see (Carreras and Marquez, 2004; Carreras and Marquez, 2005) for an overview of the systems in the semantic role labelling competitions from 2004 and 2005). Pradhan et al (2005) combine the outputs of multiple parsers to extract reliable syntacti","@endWordPosition":"1007","@position":"6296","annotationId":"T24","@startWordPosition":"1004","@citStr":"Pradhan et al, 2005"}},"title":{"#tail":"\n","#text":"Semantic role labelling using different syntactic views."},"booktitle":{"#tail":"\n","#text":"In Proceedings of ACL"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Sameer Pradhan"},{"#tail":"\n","#text":"Wayne Ward"},{"#tail":"\n","#text":"Kadri Hacioglu"},{"#tail":"\n","#text":"James H Martin"},{"#tail":"\n","#text":"Daniel Jurafsky"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1985"},"rawString":{"#tail":"\n","#text":"Randolph Quirk, Sidney Greenbaum, Geoffrey Leech, and Jan Svartvik. 1985. A Comprehensive Grammar of the English Language. Longman, London and New York."},"journal":{"#tail":"\n","#text":"A Comprehensive Grammar of the English Language. Longman,"},"#text":"\n","marker":{"#tail":"\n","#text":"Quirk, Greenbaum, Leech, Svartvik, 1985"},"location":{"#tail":"\n","#text":"London and New York."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"at the semantic level (in other words, syntax carries meaning). Anecdotal support for this stance comes from the fact that the grammatical notion of case is the basis for semantic relations (Misra, 1966; Gruber, 1965; Fillmore, 1968). Tesnie`re (1959), who proposes a grouping of verb arguments into actants and circumstances, gives a set of rules to connect specific types of actants ? for example, agent or instrument ? to such grammatical elements as subject, direct object, indirect object. This idea was expanded to include nouns and their modifiers through verb nominalizations (Chomsky, 1970; Quirk et al, 1985). We work with sentences, clauses, phrases and words, using syntactic structures generated by a parser. Our system incrementally processes a text, and extracts pairs of text units: two clauses, a verb and each of its arguments, a noun and each of its modifiers. For each pair of units, the system builds a syntactic graph surrounding the main element (main clause, head verb, head noun). It then tries to find among the previously processed instances another main element with a matching syntactic graph. If such a graph is found, then the system maps previously assigned semantic relations onto the ","@endWordPosition":"519","@position":"3280","annotationId":"T25","@startWordPosition":"516","@citStr":"Quirk et al, 1985"},{"#tail":"\n","#text":"rocess ideas introduced later in the text. The text contains 513 sentences, with an average length of 9.13 words. There are 4686 word tokens and 969 types. The difference between the number of types (2850) and tokens (573) in the extracted pairs (which contain only open-class words) shows that the same concepts recur, as expected in a didactic text. The syntactic structures of the input data are produced by a parser with good coverage and detailed syntactic information, DIPETT (Delisle and Szpakowicz, 1995). The parser, written in Prolog, implements a classic constituency English grammar from Quirk et al (1985). Pairs of syntactic units connected by grammatical relations are extracted from the parse trees. A dependency parser would 82 produce a similar output, but DIPETT also provides verb subcategorization information (such as, for example, subject-verb-object or subject-verb-objectindirect object), which we use to select the (best) matching syntactic structures. To find pairs, we use simple structural information. If a unit is directly embedded in another unit, we assume a subordinate relation between them; if the two units are coordinate, we assume a coordinate relation. These assumptions are saf","@endWordPosition":"1481","@position":"9211","annotationId":"T26","@startWordPosition":"1478","@citStr":"Quirk et al (1985)"}]},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Randolph Quirk"},{"#tail":"\n","#text":"Sidney Greenbaum"},{"#tail":"\n","#text":"Geoffrey Leech"},{"#tail":"\n","#text":"Jan Svartvik"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Barbara Rosario and Marti Hearst. 2001. Classifying the semantic relations in noun-compounds via a domain specific hierarchy. In EMNLP, pages 82?90, Pittsburg, PA, USA."},"#text":"\n","pages":{"#tail":"\n","#text":"82--90"},"marker":{"#tail":"\n","#text":"Rosario, Hearst, 2001"},"location":{"#tail":"\n","#text":"Pittsburg, PA, USA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"and shows how often the heuristic was used when processing the input text. We show in detail our findings about syntactic levels (how often graph matching helped assign a relation between two clauses, a verb and its arguments, or a noun and its modifier) and about the accuracy of the suggestion. Discussion and conclusions appear in Section 6. 2 Related Work Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts (Baker et al, 1998). In other methods, lexical resources are specifically tailored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997). The system?s interface facilitates the expert","@endWordPosition":"812","@position":"5053","annotationId":"T27","@startWordPosition":"809","@citStr":"Rosario and Hearst, 2001"}},"title":{"#tail":"\n","#text":"Classifying the semantic relations in noun-compounds via a domain specific hierarchy."},"booktitle":{"#tail":"\n","#text":"In EMNLP,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Barbara Rosario"},{"#tail":"\n","#text":"Marti Hearst"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Barbara Rosario, Marti Hearst, and Charles Fillmore. 2002. The descent of hierarchy and selection in relational semantics. In ACL, Philadelphia, PA, USA."},"#text":"\n","marker":{"#tail":"\n","#text":"Rosario, Hearst, Fillmore, 2002"},"location":{"#tail":"\n","#text":"Philadelphia, PA, USA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"r) and about the accuracy of the suggestion. Discussion and conclusions appear in Section 6. 2 Related Work Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts (Baker et al, 1998). In other methods, lexical resources are specifically tailored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997). The system?s interface facilitates the expert?s task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary. In current work on semantic relation analysis, the focus is on semantic roles ? relations between verbs and th","@endWordPosition":"853","@position":"5301","annotationId":"T28","@startWordPosition":"850","@citStr":"Rosario et al., 2002"}},"title":{"#tail":"\n","#text":"The descent of hierarchy and selection in relational semantics."},"booktitle":{"#tail":"\n","#text":"In ACL,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Barbara Rosario"},{"#tail":"\n","#text":"Marti Hearst"},{"#tail":"\n","#text":"Charles Fillmore"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"Lei Shi and Rada Mihalcea. 2005. Putting pieces together: Combining framenet, verbnet and wordnet for robust semantic parsing. In Proceedings of CICLing 2005, pages 100? 111, Mexico City, Mexico."},"#text":"\n","pages":{"#tail":"\n","#text":"100--111"},"marker":{"#tail":"\n","#text":"Shi, Mihalcea, 2005"},"location":{"#tail":"\n","#text":"Mexico City, Mexico."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"back to the 5th century B.C. and the work of Panini1. He was a grammarian who analysed Sanskrit (Misra, 1966). The idea resurfaced forcefully at several points in the more recent history of linguistic research (Tesnie`re, 1959; Gruber, 1965; Fillmore, 1968). Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic 1The sources date his work variously between the 5th and 7th century. role labelling (Baker et al, 1998; Kipper et al, 2000; Carreras and Marquez, 2004; Carreras and Marquez, 2005; Atserias et al, 2001; Shi and Mihalcea, 2005). Graph-like structures are a natural way of organising one?s impressions of a text seen from the perspective of connections between its simpler constituents of varying granularity, from sections through paragraphs, sentences, clauses, phrases, words to morphemes. In this work we pursue a well-known and often tacitly assumed line of thinking: connections at the syntactic level reflect connections at the semantic level (in other words, syntax carries meaning). Anecdotal support for this stance comes from the fact that the grammatical notion of case is the basis for semantic relations (Misra, 19","@endWordPosition":"360","@position":"2262","annotationId":"T29","@startWordPosition":"357","@citStr":"Shi and Mihalcea, 2005"},{"#tail":"\n","#text":"es which represent domain concepts, and assigning them relations from a relation dictionary. In current work on semantic relation analysis, the focus is on semantic roles ? relations between verbs and their arguments. Most approaches rely on VerbNet (Kipper et al, 2000) and FrameNet (Baker et al., 1998) to provide associations between verbs and semantic roles, that are then mapped onto the current instance, as shown by the systems competing in semantic role labelling competitions (Carreras and Marquez, 2004; Carreras and Marquez, 2005) and also (Gildea and Jurafsky, 2002; Pradhan et al, 2005; Shi and Mihalcea, 2005). These systems share two ideas which make them different from the approach presented here: they all analyse verb-argument relations, and they all use machine learning or probabilistic approaches (Pradhan et al, 2005) to assign a label to a new instance. Labelling every instance relies on the same previously encoded knowledge (see (Carreras and Marquez, 2004; Carreras and Marquez, 2005) for an overview of the systems in the semantic role labelling competitions from 2004 and 2005). Pradhan et al (2005) combine the outputs of multiple parsers to extract reliable syntactic information, which is t","@endWordPosition":"1011","@position":"6321","annotationId":"T30","@startWordPosition":"1008","@citStr":"Shi and Mihalcea, 2005"}]},"title":{"#tail":"\n","#text":"Putting pieces together: Combining framenet, verbnet and wordnet for robust semantic parsing."},"booktitle":{"#tail":"\n","#text":"In Proceedings of CICLing 2005,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Lei Shi"},{"#tail":"\n","#text":"Rada Mihalcea"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1959"},"rawString":{"#tail":"\n","#text":"Lucien Tesnie`re. 1959. E?le?ments de syntaxe structurale. C. Klincksieck, Paris."},"journal":{"#tail":"\n","#text":"C. Klincksieck,"},"#text":"\n","marker":{"#tail":"\n","#text":"Tesnie`re, 1959"},"location":{"#tail":"\n","#text":"Paris."},"title":{"#tail":"\n","#text":"E?le?ments de syntaxe structurale."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Lucien Tesnie`re"}}}]}}]}}
