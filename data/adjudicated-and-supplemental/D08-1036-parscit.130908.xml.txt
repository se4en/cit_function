6; MacKay, 2003). Instead, rather than commiting to a single value for the parameters 0 many Bayesians often prefer to work with the full posterior distribution P(0 |d), as this naturally reflects the uncertainty in 0’s value. In all but the simplest models there is no known closed form for the posterior distribution. However, the Bayesian literature describes a number of methods for approximating the posterior P(0 |d). Monte Carlo sampling methods and Variational Bayes are two kinds of approximate inference methods that have been applied to Bayesian inference of unsupervised HMM POS taggers (Goldwater and Griffiths, 2007; Johnson, 2007). These methods can also be used to approximate other distributions that are important to us, such as the conditional distribution P(t |w) of POS tags (i.e., HMM hidden states) t given words w. This recent literature reports contradictory results about these Bayesian inference methods. Johnson (2007) compared two Bayesian inference algorithms, Variational Bayes and what we call here a point-wise collapsed Gibbs sampler, and found that Variational Bayes produced the best solution, and that the Gibbs sampler was extremely slow to converge and produced a worse solution than EM. On
on over states t0 following t and φt specifies the distribution over words w given state t. ti ti−1 = t — Multi(θt) (1) wi ti = t — Multi(φt) The Bayesian model we consider here puts a fixed uniform Dirichlet prior on these multinomials. Because Dirichlets are conjugate to multinomials, this greatly simplifies inference. θt α — Dir(α) φt α0 — Dir(α0) A multinomial θ is distributed according to the Dirichlet distribution Dir(α) iff: P(θ α) a In our experiments we set α and α0 to the uniform values (i.e., all components have the same value α or α0), but it is possible to estimate these as well (Goldwater and Griffiths, 2007). Informally, α controls the sparsity of the state-to-state transition probabilities while α0 controls the sparsity of the state-toword emission probabilities. As α0 approaches zero the prior strongly prefers models in which each state emits as few words as possible, capturing the intuition that most word types only belong to one POS mentioned earlier. 2.1 Expectation Maximization Expectation-Maximization is a procedure that iteratively re-estimates the model parameters (θ, φ), converging on a local maximum of the likelihood. Specifically, if the parameter estimate at iteration ` is (θ(`), φ(`
esampling each state ti given the corresponding word wi and the neighboring states ti−1 and ti+1 using (6). 0t |nt, α — Dir(nt + α) (5) fit |n0t,α0 — Dir(n0t + α0) P(ti |wi, t−i, 0, 0) a θti|ti−1φwi|tiθti+1|ti (6) The Dirichlet distributions in (5) are non-uniform; nt is the vector of state-to-state transition counts in t leaving state t in the current state vector t, while 347 n0t is the vector of state-to-word emission counts for state t. See Johnson et al. (2007) for a more detailed explanation, as well as an algorithm for sampling from the Dirichlet distributions in (5). The samplers that Goldwater and Griffiths (2007) and Johnson (2007) describe are pointwise collapsed Gibbs samplers. Figure 1 gives the sampling distribution for this sampler. As Johnson et al. (2007) explains, samples of the HMM parameters 0 and 0 can be obtained using (5) if required. The blocked Gibbs samplers differ from the pointwise Gibbs samplers in that they resample the POS tags for an entire sentence at a time. Besag (2004) describes the well-known dynamic programming algorithm (based on the Forward-Backward algorithm) for sampling a state sequence t given the words w and the transition and emission probabilities 0 and 0. At each 
 current state sequence for the sentence with the proposal t*, or whether to keep the current state sequence. In practice, with all but the very smallest training corpora the acceptance rate is very high; the acceptance rate for all of our collapsed blocked Gibbs samplers was over 99%. 3 Evaluation The previous section described six different unsupervised estimators for HMMs. In this section we compare their performance for English part-ofspeech tagging. One of the difficulties in evaluating unsupervised taggers such as these is mapping the system’s states to the gold-standard partsof-speech. Goldwater and Griffiths (2007) proposed an information-theoretic measure known as the Variation ofInformation (VI) described by Meilˇa (2003) as an evaluation of an unsupervised tagging. However as Goldwater (p.c.) points out, this may not be an ideal evaluation measure; e.g., a tagger which assigns all words the same single part-of-speech tag does disturbingly well under Variation of Information, suggesting that a poor tagger may score well under VI. In order to avoid this problem we focus here on evaluation measures that construct an explicit mapping between the gold-standard part-of-speech tags and the HMM’s states. Per
s a function of running time on a 3GHz dual quad-core Pentium for the four different Gibbs samplers on all data and 50 hidden states. Each iteration took approximately 96 sec. for the collapsed blocked sampler, 7.5 sec. for the collapsed pointwise sampler, 25 sec. for the explicit blocked sampler and 4.4 sec. for the explicit pointwise sampler. Greedy 1-to-1 accuracy All data, 50 states, α = α' = 0.1 collapsed,blocked collapsed, pointwise explicit, blocked explicit, pointwise 0.58 0.56 0.54 0.52 0.5 0.48 0.46 0.44 0.42 0.4 0 10000 20000 30000 40000 50000 350 accuracy. The studies presented by Goldwater and Griffiths (2007) and Johnson (2007) differed in the number of states that they used. Goldwater and Griffiths (2007) evaluated against the reduced tag set of 17 tags developed by Smith and Eisner (2005), while Johnson (2007) evaluated against the full Penn Treebank tag set. We ran all our estimators in both conditions here (thanks to Noah Smith for supplying us with his tag set). Also, the studies differed in the size of the corpora used. The largest corpus that Goldwater and Griffiths (2007) studied contained 96,000 words, while Johnson (2007) used all of the 1,173,766 words in the full Penn WSJ treebank. For
arison results because it is possible that the values we tried were good for one estimator and bad for others. Unfortunately, we do not know any efficient way of searching the optimal hyperparameters in a much wider and more fine-grained space. We leave it to future work. 4 Conclusion and future work As might be expected, our evaluation measures disagree somewhat, but the following broad tendancies seem clear. On small data sets all of the Bayesian estimators strongly outperform EM (and, to a lesser extent, VB) with respect to all of our evaluation measures, confirming the results reported in Goldwater and Griffiths (2007). This is perhaps not too surprising, as the Bayesian prior plays a comparatively stronger role with a smaller training corpus (which makes the likelihood term smaller) and the approximation used by Variational Bayes is likely to be less accurate on smaller data sets. But on larger data sets, which Goldwater et al did not study, the results are much less clear, and depend on which evaluation measure is used. Expectation Maximization does surprisingly well on larger data sets and is competitive with the Bayesian estimators at least in terms of cross-validation accuracy, confirming the results r
