h as significant, important, in conclusion and In this paper we show, while unimportant sentences contain &quot;stigma&quot; words such as hardly and impossible (Edmundson, 1968; Kupiec et al., 1995; Teufel and Moens, 1997). Other systems assume that important sentences and concepts are the highest connected entities in more or less elaborate semantic structures (Skorochodko, 1971; Hoey, 1991; Salton and Allan, 1995; Mani and Bloedorn, 1998; Barzilay and Elhadad, 1997). And, yet, others assume that important sentences and clauses are derivable from a discourse representation of texts (Ono et al., 1994; Marcu, 1997a; Marcu, 1997c). A variety of systems (Edmundson, 1968; Kupiec et al., 1995; Teufel and Moens, 1997; Lin. 1998; Mani and Bloedorn, 1998) were designed to integrate subsets of the heuristics mentioned above. In these approaches, each individual heuristic yields a probability distribution that reflects the importance of sentences. A combination of the probability distributions defined by each heuristic yields the sentences that are most likely to be included in a summary. What all these multiple heuristic-based systems have in common is that they treat texts as flat sequences of sentences — no 
dible to her; and the comprehension of the satellite increases the reader's belief in the nucleus. Rhetorical relations can be assembled into rhetorical structure trees (RS-trees) by recursively applying individual relations to spans that range in size from one clause-like unit to the whole text. Rhetorical parsing. Recent developments in computational linguistics have created the means for the automatic derivation of rhetorical structures of unrestricted texts. For example, when the text shown in (1), below, is given as input to the rhetorical parsing algorithm that is discussed in detail by Marcu (1997b; 1997c), it is broken into ten elementary units (those surrounded by square brackets). The rhetorical parsing algorithm then uses cue phrases and a simple notion of semantic similarity in order to hypothesize rhetorical relations among the elementary units. Eventually, the algorithm derives the rhetorical structure tree shown in figure 1. (I) [With its distant orbit —50 percent farther from the sun than Earth — and slim atmospheric blanket,' I [Mars experiences frigid weather conditions.2] [Surface temperatures typically average about —60 degrees Celsius (-76 degrees Fahrenheit) at the equat
 the low atmospheric pressure.6] [Although the atmosphere holds a small amount of water, and water-ice clouds sometimes develop,'] [most Martian weather involves blowing dust or carbon dioxide.8] [Each winter, for example, a blizzard of frozen carbon dioxide rages over one pole, and a few meters of this dry-ice snow accumulate as previously frozen carbon dioxide evaporates from the opposite polar cap.9] [Yet even on the summer pole, where the sun remains in the sky all day long, temperatures never warm enough to melt frozen water.`° Figure 1: The discourse tree built by the rhetorical parser (Marcu, 1997c) for text (1). This discourse structure obeys the constraints put forth by Mann and Thompson (1988) and Marcu (1996). It is a binary tree whose leaves are the elementary textual units in (1). Each node in the tree plays either the role of nucleus or satellite. In figure I, nuclei are represented by solid boxes, while satellites are represented by dotted boxes. The internal nodes of the discourse structure are labelled with names of rhetorical relations and with numbers. The numbers denote the salient or promotion units of that node; they correspond to the most important units in the subsumed
 this criterion to tree 1, we obtain the partial ordering shown in (2), below, because unit 2 is the only promotion unit associated with the root, unit 8 is the only unit found one level below the root, units 3 and 10 are the only units found two levels below the root, and so on. (2) 2 > 8 > 3,10 > 1,4,5,7,9 > 6 Using partial ordering (2) we can obtain a summary that contains k% of the original text by selecting the first k% 2 Elaboration ... 2 Elaboration 2 Justification 3 Elaboration 45 Contrast 10 Antithesis 9 8 Exemplification 207 units in the partial ordering. By applying this algorithm, Marcu (1997a; 1997c) has built a summarization system that recalled 52.77% (with precision 50.00%) of the clause-like units that were considered important by human judges in a collection of five texts. 3 An enhanced discourse-based framework for text summarization 3.1 Introduction There are two ways in which one can integrate a discourse-based measure of textual saliency, such as that described above, with measures of saliency that are based on cohesion, position, similarity with the title, etc. The simplest way is to compute a probability distribution of the importance of textual units according to the 
heories is that good texts exhibit a well-defined topical structure. In our approach, we assume that a discourse tree is &quot;better&quot; if it exhibits a high-level structure that matches as much as possible the topical boundaries of the text for which that structure is built. In order to capture this intuition, when we build discourse trees, we associate with each node of a tree a clustering score. For the leaves, this score is 0; for the internal nodes, the score is given by the similarity between the immediate children. The similarity is computed using a traditional cosine metric, in the style of Hearst (1997). We consider that a discourse tree A is &quot;better&quot; than another discourse tree B if the sum of the clustering scores associated with the nodes of .4 is higher than the sum of the clustering scores associated with the nodes of B. The marker-based metric. Naturally occurring texts use a wide range of discourse markers, which signal coherence relations between textual spans of various sizes. We assume that a discourse structure should reflect explicitly as many of the discourse relations that are signaled by discourse markers. In other words, we assume that a discourse structure .4 is better than 
e rhetorical-clustering-based score associated with the root of the same tree measures the similarity between units 2 and 8, which are the salient units that pertain to spans [1,6] and [7,10] respectively. In the light of the rhetorical-clustering-based metric, we consider that a discourse tree A is &quot;better&quot; than another discourse tree B if the sum of the rhetorical-clustering scores associated with the nodes of .4 is higher than the sum of the rhetorical-clustering scores associated with the nodes of B. The shape-based metric. The only disambiguation metric that we used in our previous work (Marcu, 1997b) was the shape-based metric, according to which the &quot;best&quot; trees are those that are skewed to the right. The explanation for this metric is that text processing is, essentially, a left-to-right process. In many genres, people write texts so that the most important ideas go first, both 208 at the paragraph and at the text levels) The more text writers add, the more they elaborate on the text that went before: as a consequence, incremental discourse building consists mostly of expansion of the right branches. According to the shape-based metric, we consider that a discourse tree A is &quot;better&quot; 
een 0 and I. Given the above formulation, our goal is to determine combinations of weights that yield discourse structures that, in turn, yield summaries that are as close as possible to those generated by humans. In discourse terms, this amounts to using empirical summarization data for discourse parsing disambiguation. 4.2 Corpora used in the study In order to evaluate the appropriateness for summarization of each of the heuristics, we have used two corpora: a corpus of 40 newspaper articles from the TREC collection (Jing et al., 1998) and a corpus of five articles from Scientific American (Marcu, 1997a). Five human judges selected sentences to be included in 10% and 20% summaries of each of the articles in the TREC corpus (see (Jing et al., 1998) for details). For each of the 40 articles and for each cutoff figure (10% and 20%), we took the set of sentences selected by at least three human judges as the &quot;gold standard&quot; for summarization. In our initial experiments, we noticed that the rhetorical parsing algorithm needed more than 1 minute in order to automatically generate summaries for seven of the 40 articles in the TREC corpus, which were highly ambiguous from a discourse perspective. I
rticles as the &quot;test corpus&quot;. However, the reader should not take the denotations associated with these referents literally, because the partitioning was not performed randomly. Rather, the reader should see the partitioning only as a means for accelerating the process that determines combinations of heuristics that yield the best summarization results for all the texts in the corpus. The second corpus consisted of five Scientific American texts whose elementary textual units (clause-like units) were labelled by 13 human judges as being very important, somewhat important, or unimportant (see (Marcu, 1997c) for the details of the experiment). For each of the five texts, we took the set of textual units for which at least seven judges agreed to be very important as the gold standard for summarization. We built automatically discourse structures for the texts in the two corpora using various combinations of weights and we compared the summaries that were derived from these structures with the gold standards. The comparison employed traditional recall and precision figures, which reflected the percent of textual units that were identified correctly by the program with respect to the gold standard
