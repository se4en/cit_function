{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","listItem":[{"#tail":"\n","@confidence":"0.932371","#text":"\n1. UMSR leads to increased efficiency of information presentation.\n2. UMSR makes information presentation more effective.\n3. UMSR enables the system to provide users with a better overview of the\noption space and leads to higher confidence in having heard about all\nrelevant options.\n"},{"#tail":"\n","@confidence":"0.790756111111111","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\n2. For discrete-valued attributes with a small number of possible values (e.g.,\nnumber-of-legs and fare-class), summarization is not an issue, because\nwhen homogeneous for a cluster the attribute values of the options are\nidentical.\n3. The third group are attributes with categorical values (e.g., airline).\nIf there are no more than three different values, we summarize using\nquantifications such as none/all/both of them, as done in Polifroni, Chung,\nand Seneff (2003). If the values are more diverse, the user model comes\n"},{"#tail":"\n","@confidence":"0.9985","#text":"\n1. Creation of a domain model: Identify entity attributes and the values\nthey can take.\n2. Adaptation of the generation pipeline: Although sentence structures\nfor presenting trade-offs between options would remain very similar,\na domain-specific vocabulary would have to be created.\n3. Acquisition of user models: Accomplished by explicit questioning of users\n"},{"#tail":"\n","@confidence":"0.99825","#text":"\n1. no KLM flight was available\n2. one KLM flight matched all the criteria\n3. one KLM flight in business class was available but required a connection\n4. one KLM flight was found but it was in economy class\n"},{"#tail":"\n","@confidence":"0.297335","#text":"\nand Susana Early. 2003. An intelligent\nprocedure assistant built using regulus\n2 and alterf. In Proceedings of the\n"}],"author":[{"#tail":"\n","@confidence":"0.99084","#text":"\nVera Demberg?\n"},{"#tail":"\n","@confidence":"0.831849","#text":"\nAndi Winterboer??\n"},{"#tail":"\n","@confidence":"0.938727","#text":"\nJohanna D. Moore?\n"}],"subsectionHeader":[{"#tail":"\n","@confidence":"0.935936","#text":"\nInformation Presentation\n2.1 Tailoring to a User Model (UM)\n"},{"#tail":"\n","@confidence":"0.986233","#text":"\n2.2 Stepwise Refinement through Clustering and Summarization (SR)\n"},{"#tail":"\n","@confidence":"0.666519","#text":"\nComputational Linguistics Volume 37, Number 3\n3.1 Implementation\n"},{"#tail":"\n","@confidence":"0.999466","#text":"\n3.2 System Architecture\n"},{"#tail":"\n","@confidence":"0.996709","#text":"\n3.3 Clustering\n"},{"#tail":"\n","@confidence":"0.957788","#text":"\n3.4 Building the Option Tree\n"},{"#tail":"\n","@confidence":"0.807427","#text":"\n3.5 Pruning the Tree Structure\n"},{"#tail":"\n","@confidence":"0.989859","#text":"\n3.6 Option Presentation\n"},{"#tail":"\n","@confidence":"0.988378","#text":"\n3.7 Adaptability to Other Domains\n"},{"#tail":"\n","@confidence":"0.998852","#text":"\n4.1 Reading Task Experiment\n"},{"#tail":"\n","@confidence":"0.925136","#text":"\n4.2 Overhearer Experiment\n"},{"#tail":"\n","@confidence":"0.979735","#text":"\n6.1 The Wizard-of-Oz Paradigm and Experimental Environment\n"},{"#tail":"\n","@confidence":"0.928414","#text":"\n6.2 Experimental Design\n"},{"#tail":"\n","@confidence":"0.546768","#text":"\n6.3 Results\n"},{"#tail":"\n","@confidence":"0.775294","#text":"\nUser Satisfaction Ratings. No statistically significant differences in terms of system pref-\n"},{"#tail":"\n","@confidence":"0.982407","#text":"\n6.4 Limitations on Evaluation\n"},{"#tail":"\n","@confidence":"0.502997","#text":"\nAssociation for Computational Linguistics\n"},{"#tail":"\n","@confidence":"0.79663","#text":"\nCourses and Lectures-International Centre for\n"},{"#tail":"\n","@confidence":"0.411363","#text":"\n41st Annual Meeting on Association\nfor Computational Linguistics,\n"},{"#tail":"\n","@confidence":"0.649797","#text":"\nInformation Presentation Strategies for\n"},{"#tail":"\n","@confidence":"0.311179","#text":"\nWalter?s User Profile\n"}],"subsubsectionHeader":[{"#tail":"\n","@confidence":"0.974813","#text":"\n3.6.2 Referring to Sets of Options. Each branch in the pruned tree corresponds to a set of\n"},{"#tail":"\n","@confidence":"0.517211","#text":"\n3.6.3 Presenting Additional Attributes to Explain Trade-Offs. In order to present trade-offs\n"},{"#tail":"\n","@confidence":"0.725526","#text":"\n3.6.4 Summarizing Properties of Options. When describing a set of flights that are in the\n"},{"#tail":"\n","@confidence":"0.947338","#text":"\n4.1.1 Experimental Design. The experiment was performed with 38 participants, mostly\n"},{"#tail":"\n","@confidence":"0.959386","#text":"\n4.1.2 Evaluation Criteria. The order of the dialogs in a pair was randomized. After read-\n"},{"#tail":"\n","@confidence":"0.890636","#text":"\n4.2.1 Experimental Design. For our second lab experiment, we recruited 40 participants,\n"},{"#tail":"\n","@confidence":"0.911286","#text":"\n4.2.2 Results. User Satisfaction. Results for overall user satisfaction were consistent with\n"},{"#tail":"\n","@confidence":"0.821376","#text":"\n4.2.3 Discussion. All the tendencies in ratings for experiments 1 and 2 were the same, the\n"}],"footnote":[{"#tail":"\n","@confidence":"0.611581333333333","#text":"\n1 This analysis was performed on the Communicator corpus which has been annotated extensively,\nincluding annotations for speech act types and timing information (Walker and Passonneau 2001;\nGeorgila et al 2009).\n"},{"#tail":"\n","@confidence":"0.60698875","#text":"\nwere used instead of the full generation pipeline, for reasons of robustness.\nTable 2\nAttribute ranking for business user.\nRank Attributes\n1 fare class (preferred value: business)\n2 arrival time, # of legs, departure time, travel time\n6 airline (preferred value: KLM)\n7 price, layover airport\n"},{"#tail":"\n","@confidence":"0.776397","#text":"\n7 Later experiments used a more sophisticated way of determining turn length, which we describe in\nSection 5.\n8 Branching nodes as opposed to unary nodes. For example, in Figure 6, the unary node in the right\nsubtree would not count as a separate level.\n"},{"#tail":"\n","@confidence":"0.882281","#text":"\n9 http://www.cereproc.com/.\n"}],"title":{"#tail":"\n","@confidence":"0.993623","#text":"\nA Strategy for Information Presentation\nin Spoken Dialog Systems\n"},"@confidence":"0.000000","reference":[{"#tail":"\n","@confidence":"0.707331","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nLanguage Resources and Evaluation,\n41(2):181?190.\nChung, Grace. 2004. Developing a flexible\nspoken dialog system using simulation.\nIn Proceedings of the 42nd Meeting of the\nAssociation for Computational Linguistics\n(ACL?04), Main Volume, pages 63?70,\nBarcelona.\nDahlba?ck, N., A. Jo?nsson, and L. Ahrenberg.\n1993. Wizard of Oz studies?why and how.\nKnowledge-Based Systems, 6(4):258?266.\nDemberg, V. and Johanna D. Moore. 2006.\nInformation presentation in spoken\ndialogue systems. In Proceedings of the 11th\nConference of the European Chapter of the\nAssociation for Computational Linguistics\n(EACL), pages 65?72, Trento.\nEhrlich, S. F. and K. Rayner. 1981. Contextual\n"},{"#tail":"\n","@confidence":"0.862857","#text":"\nComputational Linguistics Volume 37, Number 3\nRayner, K., S. C. Sereno, R. K. Morris,\nA. R. Schmauder, and C. Clifton.\n1998. Eye movements and on-line\nlanguage comprehension processes.\nLanguage and Comprehension Processes,\n4:21?49.\nRayner, Manny, Beth Ann Hockey, Jim\nHieronymus, John Dowding, Greg Aist,\n"},{"#tail":"\n","@confidence":"0.804867025641026","#text":"\nComputational Linguistics Volume 37, Number 3\nSystem: Sounds good, let me book this flight for you. This will take a moment. Thank\nyou for waiting; the electronic ticket and itinerary have been emailed to you.\nWould you like to book another flight?\nUser: No.\nSystem: OK, goodbye.\nFlight booking with UMSR system?Edinburgh to Brussels\nSystem: This is the FLIGHTS information system. I am now connected to the network.\nWould you like to book a flight?\nUser: Yes.\nSystem: Tell me what do you want to book?\nUser: I would like to go from Edinburgh to Brussels.\nSystem: Please, tell me the date on which you want to travel?\nUser: December 18th.\nSystem: There are two direct flights from Edinburgh to Brussels with availability in\nbusiness class. All other direct flights only offer availability in economy class.\nIf you are willing to make a connection there is a KLM flight with business\nclass availability arriving at 4:50 pm.\nUser: Yes, I would like that KLM flight.\nSystem: Wait . . . I found one flight from Edinburgh to Brussels with availability in\nbusiness class on KLM and it requires a connection in Amsterdam. It arrives\nat 4:50 pm with a total travel time of 3 hours and 10 minutes and costs\n187 pounds. Would you like to book the KLM flight?\nUser: Yes . . . yes.\nSystem: Sounds good, let me book this flight for you. This will take a moment. Thank\nyou for waiting; the electronic ticket and itinerary have been emailed to you.\nWould you like to book another flight?\nUser: No.\nSystem: OK, goodbye.\nFlight booking with UMSR system?Edinburgh to Brussels\nSystem: This is the FLIGHTS information system. I am now connected to the network.\nWould you like to book a flight?\nUser: Yes.\nSystem: Tell me what do you want to book?\nUser: I would like to book a flight on KLM.\nSystem: From where to where?\nUser: From Edinburgh to Brussels.\nSystem: Please, tell me the date on which you want to travel.\nUser: December 18th.\n"},{"#tail":"\n","@confidence":"0.886416615384616","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nSystem: Please wait while I look up the database. I found two direct flights from\nEdinburgh to Brussels with availability in business class. Both flights are on\nBMI. The first flight arrives at 6:30 pm with a total travel time of 1 hour and\n35 minutes. The second flight arrives at 2:40 pm with a total travel time of\n1 hour and 40 minutes. Would you like to book one of the BMI flights?\nUser: No, neither of those flights will do, I need to fly on KLM. What flights do you\nhave on KLM?\nSystem: I found one flight from Edinburgh to Brussels with availability in business\nclass on KLM and it requires a connection at Amsterdam. It arrives at 4:50 pm\nwith a total travel time of 3 hours and 10 minutes. Would you like to book the\nKLM flight?\nUser: I?d like to book the flight.\nSystem: Sounds good, let me book this flight for you. This will take a moment. Thank\nyou for waiting; the electronic ticket and itinerary have been emailed to you.\nWould you like to book another flight?\nUser: No.\nSystem: OK, goodbye.\nFlight booking with SR system?San Francisco to Prague\nSystem: This is the FLIGHTS information system. I am now connected to the network.\nWould you like to book a flight?\nUser: Yes.\nSystem: Tell me what do you want to book?\nUser: Uhh, I want a flight from San Francisco to Prague.\nSystem: Please, tell me the date on which you want to travel.\nUser: On January 30th.\n"},{"#tail":"\n","@confidence":"0.912428833333333","#text":"\nUser: No. I don?t.\nSystem: OK, goodbye.\nFlight booking with UMSR system?San Francisco to Prague\nSystem: This is the FLIGHTS information system. I am now connected to the network.\nWould you like to book a flight?\nUser: Yes, I would.\n"},{"#tail":"\n","@confidence":"0.9610955","#text":"\n9 pm. The flights are on Continental, Delta, and Lufthansa.\nUser: [Hesitation] Lufthansa, please.\nSystem: There is one direct business class flight from New York to Frankfurt flying\non Lufthansa arriving between 9:30 and 12:30 pm. The flight departs New\nYork on Lufthansa at 7:05 pm and arrives in Frankfurt at 9:55 am. It costs\n2,190 pounds. Would you like to book this flight?\nUser: Sure, please.\nSystem: Sounds good, let me book this flight for you. This will take a moment. Thank\nyou for waiting; the electronic ticket and itinerary have been emailed to you.\nWould you like to book another flight?\nUser: No.\nSystem: OK, goodbye.\n"},{"#tail":"\n","@confidence":"0.71179232","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nUser: Ok, I?ll book one of the United flights.\nSystem: There is one direct business class from New York to Frankfurt flying on United\narriving between 9:00 and 11:30 am. The flight departs New York on United at\n7:00 pm and arrives in Frankfurt at 9:10 am. It costs 3,990 pounds. Would you\nlike to book this flight?\nUser: I?ll book the flight.\nSystem: Sounds good, let me book this flight for you. This will take a moment. Thank\nyou for waiting; the electronic ticket and itinerary have been emailed to you.\nWould you like to book another flight?\nUser: No.\nSystem: OK, goodbye.\nFlight booking with UMSR system?New York to Frankfurt\nSystem: This is the FLIGHTS information system. I am now connected to the network.\nWould you like to book a flight?\nUser: Yeah, I would like to book a flight.\nSystem: Tell me what do you want to book?\nUser: Well, I want to book a flight on January 15th, uh, and that?s going to be from\nNew York to Frankfurt.\nSystem: There are six direct flights from New York to Frankfurt with availability in\nbusiness class. The only KLM flight with availability in business class arrives\nat 1:35 pm and requires a connection.\nUser: Uh, well, I don?t think that?s going to be possible. I do prefer to fly business\nclass, though. What are the other business options that will get me there in the\nlate morning?\n"},{"#tail":"\n","@confidence":"0.558473857142857","#text":"\n3,990 pounds. Would you like to book the flight?\nUser: Yes, I would like to book that one, please.\nSystem: Sounds good, let me book this flight for you. This will take a moment. Thank\nyou for waiting; the electronic ticket and itinerary have been emailed to you.\nWould you like to book another flight?\nUser: No.\nSystem: OK, goodbye.\n"}],"#tail":"\n","bodyText":[{"#tail":"\n","@confidence":"0.9333348125","#text":"\nIn spoken dialog systems, information must be presented sequentially, making it difficult to\nquickly browse through a large number of options. Recent studies have shown that user satisfac-\ntion is negatively correlated with dialog duration, suggesting that systems should be designed\nto maximize the efficiency of the interactions. Analysis of the logs of 2,000 dialogs between\nusers and nine different dialog systems reveals that a large percentage of the time is spent on\nthe information presentation phase, thus there is potentially a large pay-off to be gained from\noptimizing information presentation in spoken dialog systems.\nThis article proposes a method that improves the efficiency of coping with large numbers\nof diverse options by selecting options and then structuring them based on a model of the\nuser?s preferences. This enables the dialog system to automatically determine trade-offs between\nalternative options that are relevant to the user and present these trade-offs explicitly. Multiple\nattractive options are thereby structured such that the user can gradually refine her request to\nfind the optimal trade-off.\nTo evaluate and challenge our approach, we conducted a series of experiments that test\nthe effectiveness of the proposed strategy. Experimental results show that basing the content\nstructuring and content selection process on a user model increases the efficiency and effective-\nness of the user?s interaction. Users complete their tasks more successfully and more quickly.\nFurthermore, user surveys revealed that participants found that the user-model based system\npresents complex trade-offs understandably and increases overall user satisfaction. The experi-\nments also indicate that presenting users with a brief overview of options that do not fit their\nrequirements significantly improves the user?s overview of available options, also making them\nfeel more confident in having been presented with all relevant options.\n? Cluster of Excellence, Saarland University, Campus C7 4, 66041 Saarbru?cken, Germany.\nE-mail: vera@coli.uni-saarland.de.\n?? Intelligent Systems Lab Amsterdam, University of Amsterdam, Science Park 904, 1098 XH Amsterdam,\nThe Netherlands. E-mail: A.Winterboer@uva.nl.\n? School of Informatics, University of Edinburgh, 10 Crichton Street, Edinburgh EH8 9AB, UK.\nE-mail: j.moore@ed.ac.uk.\nSubmission received: 18 June 2009; revised submission received: 4 October 2010; accepted for\npublication: 1 December 2010.\n? 2011 Association for Computational Linguistics\nComputational Linguistics Volume 37, Number 3\n"},{"#tail":"\n","@confidence":"0.995937325581395","#text":"\nA common goal of many spoken dialog systems (SDSs) is to offer efficient and natural\naccess to applications and services, such as e-mail, calendars, travel booking, navigation\nsystems, and product recommendation, in situations where the user?s hands and/or\neyes are busy with another task, for example driving a car (Pon-Barry, Weng, and Varges\n2006) or operating equipment (Hieronymus and Dowding 2007). The naturalness and\nusability of a spoken dialog interface depends not only on its ability to recognize and\ninterpret user utterances correctly, but also on its ability to present information in ways\nthat users can understand and that help them to achieve their goals.\nOne class of SDSs that has received considerable attention from both academic\nresearch and industry are information-seeking SDSs, which are designed to enable users\nto browse the space of available options (e.g., flights, hotels, movies) and choose a suit-\nable option from a potentially large set of choices. Dialogs with such systems typically\nconsist of two main types of activity: information gathering, in which the system tries\nto establish users? constraints and preferences, and information presentation, in which\nthe system typically enumerates the set of options that match the user?s constraints.\nAn example is given in Figure 1. In some systems, these activities take place in strictly\nsequential phases: All of the information necessary to form a database query is gathered,\nand then the returned options are presented, one at a time or in small groups. In other\nsystems, the activities are interleaved, with users refining their constraints after being\npresented with some options, or a summary of the option space. In either case, when\nthe number of options to be presented is large, this process can be laborious, leading\nto reduced user satisfaction. Moreover, as Walker et al (2004) observe, having to access\nthe set of available options sequentially makes it difficult for the user to remember the\nvarious aspects of multiple options and to compare them mentally.\nAlthough much research has been conducted on the information gathering phase\nof spoken dialog systems, relatively little attention has been devoted to information\npresentation. An analysis of the Communicator corpus consisting of approximately\n2,000 dialogs with nine different spoken dialog systems found that information presen-\ntation is the main contributor to dialog duration1 (Moore 2006); see Table 1. Moreover,\nthe DARPA Communicator evaluation showed that task duration is negatively corre-\nlated with user satisfaction (r = ?0.31, p < 0.001, see Walker, Passonneau, and Boland\n[2001]). Thus, there is reason to believe that improvements in information presentation\nwill lead to improvements in spoken dialog systems.\nRecently, two approaches to information presentation that present an alternative\nto sequential information presentation have been proposed. In the user-model (UM)\nbased approach, the system identifies a small number of options that best match the\nuser?s preferences (Moore et al 2004; Walker et al 2004). In the summarize and refine\n(SR) approach, the system structures the large number of options into a small number\nof clusters that share attributes. The system then summarizes the clusters based on their\nattributes, thus prompting the user to provide additional constraints (Polifroni, Chung,\nand Seneff 2003; Chung 2004).\nIn this article, we propose an approach to information presentation which short-\nens dialog duration by combining the benefits of these two approaches (UMSR). Our\n"},{"#tail":"\n","@confidence":"0.413602","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nFigure 1\nTypical information presentation phase of a communicator dialog.\n"},{"#tail":"\n","@confidence":"0.986879166666667","#text":"\napproach integrates user modeling with automated clustering such that information is\nstructured in a way that enables users to more effectively and efficiently browse the\noption space. The system provides detail only about those options that are relevant to\nthe user, where relevance is determined by the user model. If there are multiple relevant\noptions, a cluster-based tree structure orders these options to allow for stepwise refine-\nment. The effectiveness of the tree structure, which directs the dialog flow, is optimized\nby taking the user?s preferences into account. In order to give the user a good overview\nof the option space, trade-offs between alternative options are presented explicitly. In\naddition, despite selecting only the relevant options, the algorithm also briefly accounts\nfor the remaining (irrelevant) options. We hypothesize that this approach will enable\nusers to make more informed choices. Our approach to the problem has been imple-\nmented within FLIGHTS, a spoken dialog system for flight booking (Moore et al 2004;\nWhite, Clark, and Moore 2010). Our results show that in addition to improving dialog\nefficiency (in terms of number of dialog turns) and effectiveness (in terms of successful\ntask completion), our approach increases user satisfaction.\nWe hypothesize that user modeling in combination with content selection and struc-\nturing as implemented in our UMSR strategy can improve the information presentation\nphase of spoken dialog systems in the following ways:\n"},{"#tail":"\n","@confidence":"0.836032882352941","#text":"\nComputational Linguistics Volume 37, Number 3\n4. Tailoring sentence realization to the user?s preferences, through the use\nof discourse cues and comparisons (e.g., ?the cheapest?), improves\nunderstandability.\n5. UMSR ultimately leads to greater user satisfaction.\nIn the remainder of this article, we first describe prior approaches to the problem\nof information presentation in spoken dialog systems and discuss their advantages and\nlimitations in more detail (Section 2). In Section 3, we describe our approach and its im-\nplementation within a spoken dialog system for flight information. Sections 4 through 7\npresent the user studies we have run to evaluate our approach. In Section 4, we describe\ntwo initial studies in which participants rated dialogs they read or overheard. Section 5\ndescribes a modification to the UMSR system to control the length of system-generated\ndialog turns. Section 6 reports on an experiment in which participants interacted with\nthe revised system. Results of all experiments are discussed in Section 7. Finally, we\ncomment on the relation of this system to other systems from the literature in section 8,\nand discuss implications of our findings and future directions in Section 9.\n2. Background on User Modeling and Content Structuring for\n"},{"#tail":"\n","@confidence":"0.99088964","#text":"\nPrevious work in natural language generation showed how a multi-attribute decision-\ntheoretic model of user preferences can be used in a recommender system to determine\nwhich options to mention to a particular user, as well as the attributes that the user\nwill find most relevant for choosing among the available options (Carenini and Moore\n2001). In the MATCH system, Walker et al (2004) applied this approach to information\npresentation in SDSs, and extended it to generate summaries and comparisons among\noptions. Evaluation of the MATCH system showed that tailoring recommendations and\ncomparisons to the user increases argument effectiveness and improves user satisfaction\n(Walker et al 2004).\nMATCH included content planning algorithms to determine what options and\nattributes to mention, but used a simple template-based approach to realization. For\nthe design of the FLIGHTS2 system, Moore et al (2004) focused on organizing and\nexpressing the descriptions of the selected options and attributes in ways that were\nintended to make the descriptions both easy to understand and memorable. In addition,\nto increase coherence and naturalness of the descriptions, the system reasons about\ninformation structure (Steedman 2000) to control intonation, uses referring expressions\nthat highlight attributes relevant to the user (e.g., a direct flight for a user who wants\nto minimize connections, vs. the cheapest flight for a user concerned about price), and\nsignals discourse relations (e.g., contrast) with appropriate intonational and discourse\ncues. For example, Figure 2 shows a description of options tailored to a user who prefers\nflying business class, on direct flights, and on KLM, in that order.\nThe FLIGHTS system presents a small number of options that best match the user?s\nconstraints, and points out ways in which those options satisfy user preferences. Select-\ning a small number of options and presenting only these is an appropriate strategy for\nan SDS when the number of options to be presented is small, either because the number\n"},{"#tail":"\n","@confidence":"0.955419038461538","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nFigure 2\nTailored description by FLIGHTS.\nof options is limited or because users can supply sufficient constraints to winnow down\na large set before querying the database of options.\nHowever, there are several limitations of this UM-based approach. First, selecting\na small number of options from those that best match the user model does not scale\nup to situations where the number of relevant options is large. When there are hun-\ndreds of options to consider (e.g., when choosing among consumer products, hotels, or\nrestaurants) there may be many options that fit the user?s specification and interest.\nIn addition, the user model may not contain enough information for new users, or\nusers may not be able to provide constraints until they hear more information about\nthe available options. This brings up a second problem with the UM-based approach,\nnamely, that it does not provide the user with an overview of the option space, because\noptions scoring below a specified threshold or below a certain rank are not mentioned.\nThis is related to the third problem, which is the actual or perceived risk that users might\nmiss out on options they would have chosen if they had heard about them. The last two\nproblems may reduce user confidence in the system, if users have the perception that\nthe system is not telling them about all of the available options, and a lack of confidence\nmay ultimately lead to a decrease in user satisfaction.\nFinally, the evaluation of the FLIGHTS system focused on the effectiveness of using\ninformation structure to generate more natural sounding utterances by controlling in-\ntonation, but did not include an explicit comparison to other information presentation\nstrategies. The work presented here extends the FLIGHTS approach to overcome the\nweaknesses pointed out herein, and presents a series of experiments comparing this\napproach to an approach that does not employ user modeling techniques.\n"},{"#tail":"\n","@confidence":"0.9936909","#text":"\nPolifroni, Chung, and Seneff (2003) developed an approach to information presentation\nthat structures large data sets for SR. It supports the user in narrowing in on a suitable\noption by grouping the options that match the user?s constraints into clusters of options\nwith similar features. The system then summarizes the clusters based on the attribute\nvalues they share, thus suggesting further refinement constraints to the user (Figure 3).\nThis content structuring approach presents users with summaries at run time based\non an algorithm that computes the most useful set of attributes, as dictated by the\nset of options that satisfy the current user query. For large data sets, attributes that\npartition the data into the minimal number of clusters should be chosen, so that a\nconcise summary can be presented to the user to refine.3\n"},{"#tail":"\n","@confidence":"0.98831875","#text":"\nattributes were specified in advance based on domain knowledge, not determined at run time based\nsolely on the set of options returned. Our discussion and evaluation of the SR approach is therefore based\non the ?refined? refiner strategy from Polifroni and Walker (2008), where options are clustered based on\nattributes determined at run time.\n"},{"#tail":"\n","@confidence":"0.978889942857143","#text":"\nComputational Linguistics Volume 37, Number 3\nFigure 3\nDialog between simulator (M) and the Polifroni et al (2003) system (S).\nAlthough the SR approach provides a solution to the problem of presenting infor-\nmation when there are large numbers of options in a way that is suitable for an SDS, it\nhas several limitations. First, there may be long refinement paths in the dialog structure,\nthat is, many dialog turns may be necessary to narrow in on a suitably small set of\noptions. Because the system does not know about the user?s preferences, the option\nclusters may contain irrelevant information which must be filtered out successively\nwith each refinement step. In addition, the difficulty of summarizing options typically\nincreases with their number and diversity, to the point where the summary becomes\nuninformative (e.g., I found flights on 9 airlines.).\nSecond, exploration of trade-offs is difficult with the SR approach in situations\nwhere there is no optimal option. If at least one option satisfies all of the user?s require-\nments, this option can be found efficiently with the SR strategy. However, the system\ndoes not point out trade-offs among alternatives in cases where no optimal option exists.\nFor example, in the flight booking domain, suppose the user wants a flight that is cheap\nand direct, but all the flights are either expensive and direct or cheap and indirect. In\nthe SR approach, the user will have to ask for cheap flights and direct flights separately\nbecause one of these constraints must be relaxed in each case, and thus the user has to\nexplore these refinement paths separately.\nA third drawback of the SR approach is that the attribute(s) chosen for summa-\nrization may not be relevant to the user. The procedure for choosing the attributes for\nclustering the options is designed to select attributes that generalize well over the data\n(i.e., produce large clusters of options), and thus lead to efficient summarization. Hence\nattributes that partition the data set into a small number of clusters are preferred. If\nthe attribute that is best for summarization is not of interest to a particular user, dialog\nduration is increased unnecessarily. This in turn may lead to reduced user satisfaction,\nas the results of our evaluation suggest (see Section 4.1.3).\n3. Our Approach: User Model Based Summarize and Refine (UMSR)\nOur approach, the UMSR approach first described in Demberg and Moore (2006), is\nintended to capture the complementary strengths of the two previous approaches. It\nexploits information from a user model to reduce dialog duration by selecting only\noptions that are relevant to the user. In addition, we introduce a content structuring\nalgorithm that supports stepwise refinement, as in Polifroni, Chung, and Seneff (2003),\n"},{"#tail":"\n","@confidence":"0.9959828","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nbut in which the structuring reflects the user?s preferences. Thus our approach main-\ntains the benefits of user tailoring, while also being capable of dealing with a large\nnumber of options.\nWe hypothesize that our approach will increase efficiency and effectiveness of the\ndialog and improve understandability for the user, as well as provide a better overview\nof the option space, ultimately leading to improved user satisfaction. We discuss these\ngoals in more detail in the following paragraphs.\nIncreasing Efficiency. The integration of a user model with clustering and structuring\nalleviates the three problems we identified for the SR approach. When a user model\nis available, it enables the system to determine which options and corresponding at-\ntributes are likely to be of interest to the user. The system can then select compelling\noptions, and decide not to mention options which are likely to be irrelevant to the user,\nleading to shorter refinement paths, more relevant summaries, and increased efficiency.\nIncreasing Effectiveness. The user model also allows the system to determine trade-offs\namong options. For example, suppose the user wishes to book a flight, and the user\nmodel indicates that this user prefers to fly on KLM. If the database does not contain\nany KLM flights that also match the user?s other preferences (such as preferring direct\nflights to connecting ones), the system can recognize this conflict and present an explicit\ntrade-off, as in I found a KLM flight but it requires a connection in Amsterdam. However, there\nis a direct flight on BMI. The user model also allows the identification of the attribute that\nis most relevant at each stage in the refinement process, which is used to decide whether\nto present information about arrival time or price, for example.\nOur hypothesis is that the explicit presentation of trade-offs enables the user to\nmake a more informed choice and decreases the risk of the user missing out on relevant\noptions. It thus improves the effectiveness of the spoken dialog system by helping users\nto select the most suitable option.\nImproving Understandability. Our system strives to improve understandability of the\npresentation by tailoring the presentation to the user?s interests. In the flight booking\ndomain, this corresponds to clustering the available flights into ones on airlines that the\nuser prefers versus flights on airlines that the user disprefers, or to talking about flights\nthat arrive by the requested time as opposed to ones that arrive later than specified by the\nuser.\nCreating Confidence and Providing an Overview of the Available Options. In order to make the\nuser feel more confident in the dialog system?s option selection process, we also briefly\nsummarize options that the user model determines to be irrelevant (see Section 3.5).\nBy providing users with an overview of the whole option space, we reduce the risk of\nleaving out options the user may wish to choose in a specific situation (thus overriding\nher standard user model). The level of detail that the system chooses to present options\nwhich are likely to be irrelevant to the user is a trade-off between efficiency and quality\nof overview. If a situational user model with information about the degree of urgency\nis available, such overview summaries could be left out when the user is in a hurry\n(Komatani et al 2003).\nIncreasing User Satisfaction. We hypothesize that a system that implements the features\ndiscussed here will lead to greater overall user satisfaction.\n"},{"#tail":"\n","@confidence":"0.999939076923077","#text":"\nOur approach to information presentation was implemented within FLIGHTS, a spoken\ndialog system for flight booking (Moore et al 2004). The options in the flight book-\ning domain are flight connections with the attributes arrival-time, departure-time,\nnumber-of-legs, travel-time, price, airline, fare-class, and layover-airport. A\nuser model contains a partial ordering of these attributes corresponding to the user?s\nranking, as shown in Table 2. Furthermore, the user model stores preferences (e.g., for\na certain airline or flying business class). In a real-world scenario, the user model can\nbe acquired by requiring the user to register with the system at first use (Moore et al\n2004), by building up a user model over time (Thompson, Goeker, and Langley 2004), or\nby classifying users into preference groups based on other information available about\nthem, and using the group model (Rich 1979), as is frequently done in collaborative\nfiltering. Once a user model exists, the user only needs to specify the current situational\ninformation, such as the destination, desired arrival time, and date of travel.\n"},{"#tail":"\n","@confidence":"0.998227142857143","#text":"\nA sketch of our system?s pipeline architecture focusing on the information presentation\nphase is given in Figure 4. In the version of our system that was used in evaluation,\nspeech recognition and natural language understanding were performed by a wizard\n(see Section 6.1) who also chose from a set of canned queries during the initial infor-\nmation gathering phase. The first step in natural language generation (NLG) is content\nselection and structuring. The NLG subsystem takes as input an abstract communicative\ngoal from the dialog manager. In the information presentation phase of the dialog, this\ngoal is to describe the available flights that best match the user?s constraints and prefer-\nences. This step is responsible for deciding what information should be communicated\nin the system?s response, and structuring this information based on the user?s query, the\nuser model, and the set of options returned from the database. The core of this step is\nthe algorithm for constructing and pruning the option tree, which structures all of the\noptions that satisfy the user?s query into the tree and selects the entities that should be\nmentioned.\nThe text planning step takes the pruned option tree as an input and transforms\nit into natural language. First, it determines how much information can be presented\nin one dialog turn, and how to structure the information in that turn. For example, in\nsystems that aim to influence the user?s choice, such as product recommendation sys-\ntems, the ordering can be arranged to increase the effectiveness of the recommendation\n(Carenini and Moore 2001). There exists a full generation pipeline for this system, as\ndescribed in Moore et al (2004). However, for the experiments reported here, templates\n"},{"#tail":"\n","@confidence":"0.999306130434783","#text":"\nSystem architecture with emphasis on information presentation phase.\nThe system uses the Open Agent Architecture (OAA) framework (Martin, Cheyer,\nand Moran 1999) as a communication hub. All modules are implemented as agents,\nwhose communication is managed by the DIPPER dialog manager agent (Bos et al\n2003), which invokes the different agents and stores the intermediate results from each\ncomponent.\nThe approach proposed in this article concerns the content structuring and selection\nstep of the system, and is a new design. It consists of three major steps: clustering,\nbuilding the option tree, and pruning. The first step in our content structuring algorithm\nis to cluster the values of each attribute in order to group them such that labels like\ncheap, moderate, and expensive can be assigned to values of continuous categories\nsuch as price. This clustering means that options can also be summarized more easily\nlater. Next, the system constructs the option tree. Each branch of the tree describes\na possible refinement path and will thus direct the dialog flow. The construction of\nthe option tree is driven by three factors: the user model, the options returned from\nthe database, and the attribute?value clustering. The resulting option tree determines\nhow different options relate to one another, and which ones are most attractive for\nthe user. After the option tree structure has been built up, it is pruned based on the\ninformation from the user model, which enables the system to distinguish between\noptions that are likely to be compelling to the user and those that are not. At this point,\nthe content selection and structuring process is complete, and the option presentation\nphase follows, which consists of determining turn length and deciding on realizations\nfor the information that is to be conveyed.\n"},{"#tail":"\n","@confidence":"0.999916833333333","#text":"\nWe used agglomerative group-average clustering to automatically group values for\neach attribute; a similar clustering algorithm was used in Polifroni, Chung, and Seneff\n(2003). The algorithm begins by assigning each unique attribute value to its own cluster,\nand successively merging those clusters whose means are most similar. For example,\nFigure 5 shows the prices from six flights marked as dots on the price axis. In the first\nstep, each flight is assigned to its own cluster (represented as a circle around the dots).\n"},{"#tail":"\n","@confidence":"0.990642391304348","#text":"\nComputational Linguistics Volume 37, Number 3\nFigure 5\nAgglomerative group-average clustering and labeling of options.\nIn the second step, the clusters of the two flights with the most similar prices (the ones\nclose to ?250, in our example) are merged. This procedure continues until a stopping\ncriterion is met. In our implementation, we stop when we have reduced the number\nof clusters to three.4 These clusters are then assigned predefined labels, for example,\ncheap, average-price, expensive for the price attribute. This clustering is used to\ngroup similar attribute values together and is only done once for each request (in the air\ntravel domain, a request corresponds to one origin?destination pair on a specific date)\non the basis of all database entries that satisfy the hard criteria. For further discussion of\nissues relating to this procedure, see Section 9. Categorical values are clustered using the\nuser?s valuation: For example, airlines are clustered into a group of preferred airlines,\ndispreferred airlines, and airlines the user does not-care about.\nClustering allows the algorithm to assess the similarity of options, namely, instead\nof talking about the ?51 flight and the ?48 flight, the system would refer to the cheap\nflights. This leads to more efficient summaries and enables the system to avoid pre-\nsenting large numbers of options that are very similar in all respects. Furthermore, the\nclustering process enables the system to assign labels that are sensitive to the other\noptions in the database. For example, a ?300 flight is assigned the label cheap if it is\na flight from Edinburgh to Los Angeles (because most other flights in the database are\nmore costly) but expensive if it is from Edinburgh to Amsterdam (for which there are\nmany cheaper flights in the database).\n"},{"#tail":"\n","@confidence":"0.998106333333333","#text":"\nThe tree building algorithm arranges the available options into a tree structure (Fig-\nure 6). Every branching point in the tree corresponds to a choice?for example, between\neconomy versus business class flights. The nodes of the option tree correspond to sets\nof options that share a set of attribute values. The arcs going out from a node are labeled\nwith the different attribute values. For example, in Figure 6, the root of the tree contains\nall options, and its left child contains all flights offering economy class tickets. The\n"},{"#tail":"\n","@confidence":"0.9959586","#text":"\nalgorithm that automatically chooses a ?natural? number of clusters given the data distribution could be\nused. Alternatively, domain knowledge could be employed to decide on an appropriate number of target\nclusters (and this number could of course be different for each attribute). However, choosing a larger\nnumber of clusters leads to bigger option trees, and thus there is a trade-off between the number of\nclusters and the complexity and verbosity of the summaries produced.\n"},{"#tail":"\n","@confidence":"0.9916936875","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nFigure 6\nOption tree for business user.\nchildren of this node contain complementary subsets of these options (i.e., all direct\neconomy class flights vs. all indirect economy class flights). Leaf-nodes correspond\neither to a single flight or to a set of flights, where for each attribute of an option the\nvalues are either the same or fall within the same cluster (prices of all these flights are\nmoderate, they all require one connection, they are all economy class, etc.). Each node\ncan maximally have three children in our implementation, because the algorithm works\non the clusters instead of the original values (e.g., it does not distinguish between similar\nprices, such as ?48 and ?52, if the clustering algorithm labeled both of them as cheap).\nTo maximize the efficiency and effectiveness of the dialog, the dialog structure is\ntailored to the user based on the user model. Table 2 shows the valuations of our\nprototypical ?business user.? Fare class is most important to this user, so it is ranked\nhighest. Arrival time, number of legs, departure time, and travel time are considered\nnext most important, and are therefore all assigned rank 2 (i.e., our algorithm does not\nrequire a total ordering of the user?s preferences). The airline is next most important,\nand finally, price and layover airport are least important.\nThe user?s ranking of attribute importance is crucial for dialog efficiency. If an\nirrelevant criterion is used as the branching criterion high up in the tree, interesting\ntrade-offs risk being scattered across the different branches of the tree. For example,\nit would be suboptimal to ask a business user to make a choice about cheap versus\nexpensive flights first, if she does not care about this aspect, as she would then have to\ntry to identify interesting flights among both the cheap and the expensive flights. Our\nalgorithm chooses the attribute that has the highest weight according to the user model\nas the branching criterion for the first level of the tree. For the business user, this would\nbe fare class. The next decision is about the attributes that are second most important,\nsuch as the number of legs required (refer to Table 2 and Figure 6), and so on. The system\ntherefore constructs the tree such that it presents the criteria which are most relevant for\nthe specific user first, and leaves less relevant criteria for later in the dialog (i.e., further\ndown in the tree). The advantage of this ordering is that it minimizes the probability\nthat the user needs to backtrack.\n"},{"#tail":"\n","@confidence":"0.995040875","#text":"\nComputational Linguistics Volume 37, Number 3\nA special case occurs when an attribute is homogeneous for all options in an\noption set (for instance if none or all of the business class flights happen to be on the\nuser?s preferred airline). In that case, a unary node is inserted regardless of the rank\nof its attribute (see, for example, the right subtree with the attribute airline, which is\ninserted far up in the tree despite its low rank, in Figure 6). This special case allows for\nmore efficient summarization, for example None of the business class flights are on KLM,\ninstead of having to say this in subsequent dialog turns for each of the business class\nflights that the user explores.\nIn cases where several attributes have the same rank in the user model, we follow\nthe approach taken in Polifroni, Chung, and Seneff (2003). The algorithm selects the\nattribute that partitions the data into the smallest number of sub-clusters. Consider\nagain the tree in Figure 6: number-of-legs creates only two sub-clusters for the data\nset (direct and indirect) and is therefore further up in the tree than arrival-time,\nwhich splits the set of economy class flights into three subsets (before 3 pm, 3 pm to\n5 pm, after 5 pm for a user whose preferred arrival time is by 5 pm).\nThe tree-building algorithm constitutes one of the main differences between our\nstructuring algorithm and Polifroni et al?s (2003) refinement process. The SR system\nchooses the attribute that partitions the data into the smallest set of unique groups for\nsummarization, whereas our UMSR algorithm takes the ranking of attributes in the user\nmodel into account. In the extreme case of a user who does not care about anything (the\nuser model does not specify any valuations of any attributes over others, and indicates\nthat the user does not care about price, whether it is a direct flight, etc.), our algorithm\nwould end up only using the information theoretic criteria, just like the SR system.\n"},{"#tail":"\n","@confidence":"0.973851636363636","#text":"\nAfter the tree-building step, the tree contains all the options in the database that satisfy\nthe user?s query. This tree can potentially be quite large and navigating through it would\nbe very laborious for the user. At this point, the user model comes into play again:\nBecause the system already knows which options are relevant to the user (and which\nones are not), it can prune the option tree to retain only options that it classifies as being\nrelevant to the user.\nTo determine the relevance of options, we define the notion of dominance. Domi-\nnant options are those for which there is no other option in the data set that is better on\nall attributes. A dominated option is worse on at least one attribute and equal or worse\nin all other respects than some other option in the relevant partition of the database;\nit should therefore not be of interest to any rational user. When two options are equal\nin all respects and dominate other options, both are kept in the option tree. A similar\nnotion of dominance was employed by Linden, Hanks, and Lesh (1997).5 The notion of\ndominance is also related to the decision-theoretic concept of Pareto optimality.\nPruning dominated options is crucial to our structuring process. The algorithm uses\ninformation from the user model to prune all dominated options. Paths from the root\nto a given option are thereby shortened considerably and thus dialogs with our system\n5 In their work, dominance is used to avoid presenting options that are dominated by an option that has\nalready been mentioned in the interaction with the user. During the user?system interaction sequences,\na user makes a request and the system then presents an option. If the user then specifies or modifies\nhis request, the system presents more options given the new specifications, but never ones that are\ndominated by a previously mentioned option (i.e., worse or equivalent in all respects).\n"},{"#tail":"\n","@confidence":"0.9729286","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\ncan be expected to be on average shorter than dialogs with a system employing the\nSR strategy, which does not exploit information from a user model.\nThe pruning algorithm operates directly on the option tree, and exploits the tree\nstructure in order to efficiently determine dominance relations. We first briefly outline\nthe algorithm, before describing each step in detail. The first step of the algorithm is to\norder the tree such that the best options are leftmost.6 The algorithm then traverses the\ntree in depth-first order and generates constraints during this process. These constraints\nencode the properties that options to the right of the current position in the tree would\nneed to satisfy in order not to be classified as being dominated by any of the options\nconsidered so far. A branch must fulfill the constraints that apply to it, otherwise it is\npruned. If an option (or a cluster of options) satisfies a constraint, the property that\nsatisfied the constraint is marked as the options? justification. If some, but not all, of the\nconstraints can be satisfied by an option, the constraints are propagated to the options\nthat are further to the right in the ordered option tree. Once all the dominated options\nhave been pruned from the option tree, there is a homogeneity check to ensure that\nattributes which have the same value among a set of options are annotated at a node\nthat is a common ancestor of all of these options.\nTree Ordering. The first step of the pruning algorithm is to order the tree. This step is very\nimportant, because it imposes a total ordering on the available options and arranges\nthem such that the best option of every node becomes that node?s leftmost child. For\nexample, the tree in Figure 6 is not ordered because the business user prefers business\nflights to economy flights, and thus the two subtrees under the root node must be\nexchanged (see Figure 7). The total ordering is enforced firstly by placing the attributes\nthat are most relevant to the user at the top of the tree during tree construction, and\nsecondly, by sorting the attribute values from best to worst within each node.\nConstraint Generation. After ordering the tree, the globally best option is described by\nthe leftmost branch in the option tree. In our example in Figure 7, this is flight LH1554,\nin node 7. If the globally best option in node 7 was perfect (i.e., if it was exactly what\nthe user was looking for), the option in node 7 would dominate all other options, and\nthe rest of the tree would be pruned. However, if there is an aspect of the globally\nbest option which does not match the user?s ideal, the user will have to make some\nkind of trade-off. This is what happens in our example, because the arrival time of\nthe flight in node 7 was only classified as fair, not as good, whereas there exist some\nconnections with arrival times that were classified as good. A flight with a good arrival\ntime constitutes a possibly interesting alternative. In order to find such an option and\nfilter out the others, the constraint arrival-time:good is generated.\nPruning Options from the Tree. When node 8 is reached by the depth-first traversing\nalgorithm, a constraint (arrival-time:good) has been generated by node 7. Node 8\ndoes not satisfy this constraint; this means that it is dominated by node 7 and therefore\nis pruned from the option tree (as indicated by shading in Figure 7).\nConstraint Propagation. Once the status of a node?s children has been determined, any\nunsatisfied constraints that were generated by the child nodes are propagated to the\n6 Alternatively, the tree construction algorithm could be designed to insert all options such that the\nresulting tree is already ordered.\n"},{"#tail":"\n","@confidence":"0.999733666666667","#text":"\nThis figure shows the ordered version of the option tree from Figure 6. The shaded subtrees are\ndominated because they do not fulfill constraints generated by nodes to the left in the tree, and\nare therefore pruned.\nparent. In our example, the constraint generated by node 7 is propagated up to parent\nnode 6. Because node 6 has no siblings, the constraint is again propagated up to its\nparent, node 5. The sibling of node 5, node 9, is then tested against the constraint\narrival-time:good. Because there is no information about arrival time available at\nnode 9, the constraint is passed down to its leftmost child (node 10). If that child node\ndoes not have information about arrival time, the constraint is passed down again. In\nour example, the constraint is passed down to node 11, and we find that this flight\nsatisfies the constraint. We next repeat the constraint generation step. Flight BA9898\ngenerates the constraint price:good because its own price is only classified as fair.\nAt nodes 12 and 13, both constraints arrival-time:good and price:good have to be\nsatisfied. However, they are not satisfied and therefore these two nodes are pruned.\nThe depth-first traversal continues through the tree trying to find options that satisfy\nthe constraints. When node 2 is traversed on the way up in the tree, it generates the\nconstraint airline:KLM. This constraint, as well as any constraints that were generated\nby the subtree below it and have not yet been satisfied (in our example, the complex\n"},{"#tail":"\n","@confidence":"0.99841954054054","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nconstraint price:good AND arrival-time:good) are propagated to the right branch of\nthe tree, at node 3.\nNote that the constraints allow for efficient pruning: It is not necessary to look at\nthe exact instances or properties of nodes 12 and 13 or their children. One only has to\nconsider the properties which are relevant to the constraints because the tree is ordered.\nThis allows us to conclude that all options in a specific subtree are dominated by the\noptions in branches to the right of that subtree.\nJustifications. An important by-product of the pruning algorithm is the identification of\nattributes that make an option cluster compelling with respect to alternative clusters.\nFor example, the flights in node 11 were considered compelling because they had a\nbetter arrival time than the flight in node 7. We call such an attribute the justification\nfor a cluster, as it justifies its existence?that is, it is the reason it is not pruned from\nthe tree. Node 5 in turn is kept in the tree because it is the leftmost child, which\nmeans that its attribute values best match the user?s preferences. When compared to\nthe flights in node 9, its compelling property is that it is direct (i.e., number-of-legs=1).\nThe default justification for a node is the attribute value on which the branch is based\n(e.g., fare-class for node 2 in Figure 7). This justification is used for nodes on the\nleftmost branch. Justifications are used by the generation algorithm to present trade-\noffs between alternative options explicitly (see Section 3.6.2).\nThe reasons why options have been pruned from the tree are also registered. These\nreasons contain information about which constraints the options failed to satisfy; in our\nexample, the flight in node 8 is deleted because of its bad arrival time. These pruning\nreasons are later used to provide information for the summarization of poor options in\norder to give the user a better overview of the option space (e.g., All other flights arrive\ntoo late or are more expensive). To keep summaries about irrelevant options short, we back\noff to a default statement or are undesirable in some other way if these options are very\nheterogeneous.\nHomogeneity Check. After deleting branches from the option tree, it may be the case that\nseveral options have the same attribute value, but are located in different branches in\nthe tree. For example, imagine there are three economy class flights, two direct ones\n(1 leg), and one which requires a connection (2 legs). Among the two direct ones, one\nhas a good price, and the other one is more expensive. The 2-leg flight also has a good\nprice. If the more expensive direct flight is pruned, both of the remaining options have a\ngood price, and thus this property should be above the number-of-legs branching level\nin the tree. This is important for efficient information presentation and summarization\nof options.\n"},{"#tail":"\n","@confidence":"0.99954125","#text":"\nThe user model also comes into play when determining the wording of the option\npresentation. Because the system has a model of the user?s preferences, it can effectively\ncompare and contrast alternatives by highlighting compelling aspects of an option\n(e.g., a direct flight, the KLM flight), by using intonation and comparatives (e.g., the\ncheapest flight, the only KLM flight) and by acknowledging drawbacks through the use of\ndiscourse markers (e.g., but, however, although) when generating descriptions of options.\nFor the options that were considered unattractive for the particular user, the system can\nprovide an overview to cover the option space (e.g., All other flights arrive later than 3 pm).\n"},{"#tail":"\n","@confidence":"0.962910814814815","#text":"\nComputational Linguistics Volume 37, Number 3\nFigure 8\nDiagram showing how the pruned option tree is mapped onto language. The tree on the right\nhand side corresponds to the example trees in Figures 6 and 7. The complete system utterance is\nshown in Figure 10.\nFigure 8 shows how the nodes in the pruned option tree translate to the system?s\nutterances. The different design decisions underlying sentence planning and realization\nwill be explained in the following sections.\n3.6.1 Turn Length. In any spoken dialog system, it is important not to present too much\ninformation in a single turn in order to keep the memory load on the user manageable\n(Seneff 2002). Thus, our system aims at presenting no more than two or maximally three\noptions at once. However, the pruned option tree sometimes contains more than this\ncritical number of options, and therefore needs to be broken down into smaller chunks.\nWe thus divide the pruned option tree into several smaller dialog-turn-sized subtrees.\nTypically not all of these subtrees will be presented, but only the ones between the root\nof the tree and the chosen subset of flights that the user wishes to hear more about.\nIn addition to determining the number of options to present in a single turn, the\nsystem must decide how many and which of their attributes to mention. Arguably,\nmentioning too many attributes of options will also lead to memory overload, which\nmay ultimately reduce user satisfaction. However, the system must provide enough\ninformation to fully account for what constitutes the trade-off, that is, it must give the\nreasons why an option is potentially relevant.\nFor instance, in our example, the system mentions that the direct business class\nflight arrives later than requested and contrasts this against another business class flight\nthat arrives earlier but requires a connection. The pruning process provided the system\nwith information about the relevant differences between alternative options (arrival-\ntime and number-of-legs).\n"},{"#tail":"\n","@confidence":"0.990134090909091","#text":"\nThe option tree is cut into subtrees which determine turn length.\nFigure 10\nExample dialog with our WoZ System based on the tree shown in Figure 7 and mapping to\nnatural language sentences as shown in Figure 8.\nIn order to segment the pruned tree into turn-sized subtrees, we chose a very\nsimple heuristic segmentation algorithm. Dialogs generated with this heuristic were\nevaluated in our early experiments,7 which we report in Sections 4.1 and 4.2. The\nheuristic cutoff point is visualized in Figure 9, and defined as being no deeper than\ntwo branching nodes8 and their children.\nThis heuristic produces a limited set of options to be presented in a single turn.\nThe target size is two to three options. This strategy yields a maximum of nine options\n(three options per branching level to the power of two branching levels). However, in\npractice there are typically three or fewer options in any two branching levels left after\npruning. We chose to include two layers in order to allow for informative trade-offs: If\ninformation from only one layer were available at a time, it would not be possible to\ncontrast the most relevant advantages and disadvantages of alternative options, which\nis needed to make the trade-off(s) explicit. For example, if only the first level of Figure 9\nwere to be presented, the system could only talk about fare classes, and would not be\nable to point out that there is a disadvantage with the business class flights, which the\neconomy class flights do not have.\nAt the end of the turn, the user is expected to make a choice indicating which of the\noptions she would like to hear more about (for illustration see Figure 10).\n"},{"#tail":"\n","@confidence":"0.983451285714286","#text":"\nComputational Linguistics Volume 37, Number 3\nThis definition of turn length was employed in the reading and overhearer ex-\nperiments (see Sections 4.1 and 4.2). However, it became clear in related experiments\n(Winterboer et al 2007) that this method of deciding on dialog turn length sometimes\nled to very long system turns, which were then difficult for the user to remember. We\nthus modified the algorithm in order to ease comprehension. We will return to this point\nlater, in Section 5.\n"},{"#tail":"\n","@confidence":"0.995477789473684","#text":"\noptions. These options should be referred to in an effective way. We do this by taking\ninto account both the dialog structure (i.e., structure of the argumentation) and the\nuser?s interest: The description of a set of options is based on their justification. For\nexample, the justification of the flights in the left branch of the tree in Figure 8 is their\nfare class. Therefore, they are described as flights with availability in business class. On\nthe other hand, the justification for the indirect business class flights is that they have\nan arrival time that matches the user query better. They are thus referred to by their\njustification to arrive earlier.\nIf a node is justified by several attributes, only one of them is selected for reference.\nIf one of these multiple justifications is a contextually salient attribute, this one is\npreferred over the justifications that are not salient. For example, if a node is justified\nboth by its arrival time and its price, it would be referred to by the price attribute in a\ncontext that just mentioned the price of another flight as being expensive:\n[. . . but it costs 1000 pounds.]context A [cheaper]salient flight. . .\nIf none of the attributes are particularly salient, the options in the cluster are\nreferred to by the highest ranked attribute, that is, arrival time in the example from\nFigure 8. In cases where all options in a set only share a common negative attribute, we\nacknowledge this situation using a concessive formulation: for example, If you?re willing\nto travel economy. . . ; see the last sentence in Figure 8.\n"},{"#tail":"\n","@confidence":"0.9340325","#text":"\nbetween options, it is necessary to provide information about the properties of options\nthat constitute the trade-off(s). Any of these additional properties that are not already\nmentioned as part of the referring expression are ordered to optimize coherence. First,\nall positive attributes are enumerated and contrasted against all average or negative\nattributes. These negative attributes, which are presented last, are then salient and will\nbe used in the description of an alternative option.\n"},{"#tail":"\n","@confidence":"0.8935104","#text":"\nsame cluster (e.g., because they have good arrival times), the specific attribute values of\nthe options in this cluster may vary (e.g., one flight might arrive at 3 pm and the other\nat 3:30 pm). In that case, it is necessary to generate a summarizing expression for these\nattribute values.\nThere are three main cases to be distinguished:\n1. The continuous values for attributes such as price and arrival-time\nmust be summarized, as they may differ in their values even if they are in\nthe same cluster. One way to summarize them is to use an expression that\nreflects their value range (e.g., between x and y) or that contrasts them with\nsome previously mentioned value (e.g., earlier or the cheapest flights).\n"},{"#tail":"\n","@confidence":"0.993278777777778","#text":"\nback into play to produce a tailored summary based on user preferences.\nFor a user who prefers to fly on KLM and a cluster which contains no KLM\nflights, as in Figure 8, we generate None are on KLM, which takes into\naccount the user?s preference for KLM and is more concise than\nmentioning all airline names.\nA sample dialog highlighting these realizations is shown in Figure 10. The turns marked\n?S? in this dialog were generated by our system, employing the business user model\n(see Figure 2). Note, however, that interpreting the user?s request (i.e., speech recogni-\ntion and natural language interpretation) was done by a wizard in our experiments.\n"},{"#tail":"\n","@confidence":"0.9930725","#text":"\nTo adapt our system to assist users finding options in another domain (e.g., restaurants,\ndigital cameras), the following steps would have to be taken:\n"},{"#tail":"\n","@confidence":"0.969907833333333","#text":"\nor automatic inference as in, for example, Linden, Hanks, and Lesh (1997).\nTo apply the clustering algorithm in another domain, it is necessary to define a function\nthat maps attribute values onto numeric values. This can be done by either acquiring\nthe user?s preferences, or by choosing a distance function that describes the relation\nbetween values of an attribute.\nFor the air travel domain, we used three non-relaxable constraints (i.e., constraints\nfor which we do not use a distance function but only accept options that fully match\nthese requirements): departure airport, arrival airport, and travel date. If our database\nhad contained distances between airports, our system would have been able to suggest\nflights that start from or arrive at a nearby airport (e.g., departing from Glasgow instead\nof Edinburgh). Similarly, in a restaurant recommendation system with information\nabout streets, an external resource could be used to determine which streets are in the\nsame neighborhood, in order to cluster them according to distance or the time it takes\nto travel to them using a specific means of transport.\nTo effectively summarize categorical data, it is often necessary to use an ontology,\nor some kind of ordering that is meaningful for the user. Consider for example our\nclustering of airlines: There is no information in our database that would make a KLM\nflight more similar to a Lufthansa flight than to a RyanAir flight based on the airline.\n"},{"#tail":"\n","@confidence":"0.969161125","#text":"\nComputational Linguistics Volume 37, Number 3\nTherefore, we use information from the user model to arrange options into clusters that\nare meaningful to the user by grouping together airlines that the user prefers to use,\nand those airlines that the user prefers not to use. Finally, when clusters have been\ngenerated, a set of labels must be defined for the resulting clusters.\n4. Evaluation I ? Two Pilot Experiments\nWe conducted three experiments that compared our approach to information presen-\ntation, employing content structuring and a user model (UMSR), to a system that uses\nonly content structuring (SR). The experiments were designed to test our hypotheses\nthat the UMSR approach increases user satisfaction, as well as dialog efficiency and\neffectiveness when compared to the SR approach. In this section, we discuss the first two\nexperiments, during which our participants read or overheard dialogs, as opposed to\nour second evaluation phase during which they interacted with the system in a Wizard-\nof-Oz set-up. Although the user?s turns were scripted, the SR and UMSR system turns\nwere generated by implemented information presentation components in these two\nexperiments.\n"},{"#tail":"\n","@confidence":"0.999351","#text":"\nIn the first experiment, participants were asked to read a number of dialogs, some of\nwhich were designed according to the description of the SR algorithm and some of\nwhich were generated using our UMSR algorithm. Participants were thus in the position\nof external observers, and could not interact with the system.\n"},{"#tail":"\n","@confidence":"0.998774263157895","#text":"\nstudents of the University of Edinburgh, who were either native speakers of English or\nhad a near-native proficiency level in English. They were naive with respect to dialog\nsystems and the purpose of the experiment. The experiment was conducted in the lab\nunder controlled conditions. Each subject was presented with six dialog pairs. The first\ndialog pair was used for training, and was thus not included in the analysis. Each dialog\npair consisted of one dialog with the UMSR system and one dialog designed following\nthe SR approach (see Section 2.2). The order of the dialogs in a pair was randomized to\nprevent the risk of favoring a system due to a constant ordering (in particular, because\nthe content of the database is already known when reading the second dialog, this\ndialog would be easier to understand).\nThe user models (a student, a frequent flyer, and a business traveler) were designed\nto be highly prototypical (see Figure 11) to make it easier for the participants to memo-\nrize the characteristics of the users.\nBefore each dialog, the hypothetical users who appeared in the dialogs were de-\nscribed briefly in order to communicate their preferences to the participants and put\nthem in a position to assess whether the hypothetical users were able to find the flight\nthat was optimal with respect to their specifications and preferences.\nThe dialogs with the SR system were designed manually based on the description\nin Polifroni, Chung, and Seneff (2003). All dialogs were provided as transcripts.\n"},{"#tail":"\n","@confidence":"0.99397075","#text":"\ning each dialog transcript, participants were asked to provide feedback about system\nresponses on four Likert-type scales (see Figure 12). After reading each pair of dialogs,\nthe participants were also asked the forced choice question: ?Which of the two systems\nwould you recommend to a friend?? to assess user satisfaction.\n"},{"#tail":"\n","@confidence":"0.985638","#text":"\nThe set of questions that users were asked after each dialog in order to evaluate the system.\nParticipants provided their answers using Likert-type scales. X was instantiated by the name of\nour hypothetical example users.\n4.1.3 Results. User Satisfaction. A significant preference for the UMSR system was ob-\nserved. From a total of 190 forced choices in the experiment (38 participants ? 5 dialog\npairs), UMSR was preferred 120 times (? 63%), whereas SR was preferred only 70\ntimes (? 37%). This difference is highly significant (p < 0.001) according to a two-tailed\nbinomial test. Thus, the null-hypothesis that the systems are preferred equally often can\nbe rejected with high confidence.\nOverall preference for a system is likely to be the product of many different factors.\nThe defining differences between the two systems are tailoring to the user first by\npresenting only options that are of some relevance to the user, second by explicitly\ncomparing options to one another by pointing out trade-offs, and third by briefly\nsummarizing the full option space. The goal of the experiment is to elicit the individual\ncontribution of these factors to user satisfaction by asking the questions in Figure 12.\nFigure 13 shows the average Likert scores for the UMSR and SR systems provided by\nthe users, and will be discussed in the following paragraphs.\nUnderstandability. The UMSR and SR dialogs received almost identical scores for un-\nderstandability (Question 1 in Figure 12). There is no statistically significant difference\nbetween the scores of the two systems (t(189) = ?0.049, p = 0.97, using a two-tailed\n"},{"#tail":"\n","@confidence":"0.866512074074074","#text":"\nComputational Linguistics Volume 37, Number 3\nFigure 13\nResults for Likert-type scale questions (see Figure 12) from the reading experiment.\npaired t-test). On the one hand, understandability is likely to be enhanced by UMSR\nbecause it provides explicit trade-offs, but on the other hand UMSR produces longer\nand more complex dialog turns which may hinder understandability. We therefore\ncontrol for dialog turn length between the two conditions in our later experiments; see\nSection 5.\nOverview. The evaluation confirmed our hypothesis that the UMSR system provides a\nbetter overview of the option space than the SR system. The difference in ratings, more\nthan one Likert scale point, was statistically highly significant (t(189) = 7.47, p < 0.0001,\nusing a paired t-test); see Figure 13. The better overview achieved by the UMSR system\nis attributable to the explicit trade-offs, comparative qualifications of options (e.g., the\ncheapest flight), and summaries about dominated options (e.g., all other flights arrive later\nthan you specified).\nRelevance. The third question assessed the participant?s confidence that all relevant\noptions were mentioned by the system. The UMSR system was again rated significantly\nhigher on this question in comparison to the SR system (t(189) = 2.88, p < 0.01), accord-\ning to a two-tailed paired t-test. Presenting only options that are deemed to be relevant\nby the system as well as providing summaries about the whole option space are likely\nto have led to the observed higher confidence ratings.\nEfficiency. Question 4 assessed the efficiency with which the hypothetical user was able\nto access the flight that best matched her interests. Again, the UMSR system was rated\nsignificantly higher (t(189) = 3.77, p < 0.001 in two-tailed paired t-test) than the SR\nsystem. Surprisingly, subjects reported that they felt they could access options more\nquickly with a system employing the UMSR strategy even though the dialog turns were\nlonger on average.\n"},{"#tail":"\n","@confidence":"0.993562","#text":"\nA potential criticism of the reading experiment is that reading dialogs is an artificially\nsimplified task because participants can read at their own pace and go back in the text to\n"},{"#tail":"\n","@confidence":"0.9401362","#text":"\nResults for Likert-type scale questions, overhearer experiment.\nread difficult parts again. Furthermore, there is no extra difficulty caused by imperfect\nspeech synthesis. The goal of this second experiment was therefore to quantify any\nfacilitating effect introduced through the reading modality, and to compare and validate\nresults.\n"},{"#tail":"\n","@confidence":"0.999278222222222","#text":"\nwho were mainly Edinburgh university students, native or near-native speakers of\nEnglish, and were studying for a range of different degrees. They had not taken part in\nthe previous experiment and were naive with respect to the task. The participants were\npresented with exactly the same dialog pairs as in the first experiment, and were asked\nthe identical set of questions (see Section 4.1.2). The only difference was that this time,\nparticipants overheard the dialogs instead of reading them: We used speech recordings\nfrom three different speakers to impersonate our three users?the student, the frequent\nflyer, and the business traveler. System turns were produced by a text-to-speech system\nprovided by CereProc Ltd.,9 using a voice with a Scottish accent (?Heather?).\n"},{"#tail":"\n","@confidence":"0.99632975","#text":"\nthe results from the reading experiment: Participants chose the UMSR system more\noften than the SR system when asked which system they would recommend to a friend.\nHowever, the difference did not reach significance level in the overhearer condition\n(UMSR was preferred 109 times out of 200 times). The more detailed analysis based on\nthe Likert-type scale questions (Figure 14) shows that while ratings tended to be higher\nin general, the UMSR system benefited less from the oral presentation mode than the\nSR system.\nUnderstandability. We specifically asked participants not to assess the systems on the\nspeech synthesis quality but rather on the structure and content of the presented mate-\nrial. The SR system was rated slightly higher on the understandability of the dialogs in\ncomparison with UMSR. The observed slight preference for the SR system did not reach\nsignificance level (t(199) = ?1.17, p ? 0.24 in a two-tailed paired t-test), however.\n"},{"#tail":"\n","@confidence":"0.957299727272727","#text":"\nComputational Linguistics Volume 37, Number 3\nOverview and Relevance. The second experiment confirmed the findings from the reading\ntask experiment: Users thought that the UMSR system gave them a better overview of\nthe option space (Question 2). In addition, they felt more confident that they had not\nmissed out on any relevant options (Question 3). The differences in ratings were again\nhighly statistically significant in both cases (t(199) = 2.61, p < 0.01; t(199) = 3.11, p <\n0.01), just as in the reading experiment.\nEfficiency. The UMSR system was rated better than the SR system in terms of how\nquickly the hypothetical user was able to access the optimal flight (Question 4). How-\never, this difference was smaller in the overhearer experiment, and did not reach signif-\nicance level (t(199) = 1.65, p ? 0.1).\n"},{"#tail":"\n","@confidence":"0.99967475862069","#text":"\nonly differences being that effect sizes were slightly smaller in the overhearer condition\n(see Figure 14) and that participants rated the systems consistently higher in the over-\nhearer experiment. We hypothesize that these higher scores across the board must be\ndue to the presentation mode, that is, participants were possibly more impressed with\nthe systems when they overheard the interaction as opposed to reading it, because it\nwas closer to experiencing a working system.\nAlthough these two experiments provide valuable support for our hypotheses con-\ncerning overview and relevance, and indicate better perceived efficiency of the system,\nwe are ultimately interested in how people cope when interacting with the different\ntypes of dialog systems, and how user modeling affects task efficiency and effectiveness.\nWe therefore designed a third experiment, in which participants were assigned flight\nbooking tasks and directly interacted with the dialog system (see Section 6).\nBecause UMSR employs information from a user model and content structuring\nto present only those options that are likely to be relevant to the user, and explicitly\npoints out trade-offs among options, we hypothesized that it would also consume less\ncognitive resources, that is, presentations based on UMSR would impose less cognitive\nload than those based on SR. Therefore, in parallel to our work on the interaction\ntask experiment, a companion project conducted experiments using a dual-task setting\n(driving a simulated car while using the dialog system to book flights) to investigate\nthe effects of the two strategies to information presentation (UMSR vs. SR) on cognitive\nload (Hu et al 2007). Results indicated that, contrary to expectations, the cognitive load\nplaced on users by the UMSR system was in some cases higher than the cognitive\nload placed on users in the SR condition, and that this affected performance on the\nprimary task (driving). By examining logs of the conversations, we found that the\nUMSR approach sometimes generated turns that were considerably longer than turns\nproduced by the SR approach. Because we are primarily interested in whether the\ncontent selection and structuring aspects of UMSR led to its benefits, we removed\nthe confounding factor of turn length by controlling for turn length across the two\nconditions in our third experiment.\n"},{"#tail":"\n","@confidence":"0.99728375","#text":"\nDetermining how much information to include in a dialog turn is an important factor\nin designing information presentation strategies. The results from Hu et al (2007) sug-\ngested that our initial UMSR algorithm for determining how much information to in-\nclude in a turn needed improvement. In addition, controlling for dialog turn length and\n"},{"#tail":"\n","@confidence":"0.983084833333333","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nthe number of information units conveyed in each dialog turn is important for making\na fair comparison between the aspects of information presentation we are interested in,\nthat is, content selection (which attributes are included in a summary) and structuring.\nPresenting much complex information in a single turn can cause a significant memory\nburden on the user, and thus disturb the variables we want to measure. Furthermore,\nwe hypothesize that a large memory burden will not only overwhelm the user, and thus\naffect user satisfaction, but can also cause a degradation in efficiency (because users may\nhave to ask for repetition or clarification of information) and/or effectiveness (because\nusers may forget pieces of information that are critical for making the best choice).\nDialog turn length in our system is defined by the algorithm that divides the tree\ninto separate chunks, as explained in Section 3.6.1. The original naive heuristic can\nsometimes cause long system turns if the branching factor of an option tree is large\neven after the pruning step. In order to balance message length between the two condi-\ntions, we modified the content selection method to control the amount of information\npresented in each turn, as follows:\n The strategy for determining turn length (see Section 3.6.1) was revised\nso that the initial option tree is divided into smaller chunks. Recall that\nthe tree was cut after a maximum of two branching nodes and their\ncorresponding children in the original implementation. In the new\nimplementation, the tree is now split into smaller trees if a threshold\nnumber of attribute values conveyed is exceeded.\n Fewer attributes are mentioned per presentation (for instance, by using a\nvery general formulation that will get you there on time instead of that arrives\nbetween 3 pm and 6 pm once the user had specified a specific time she\nwished to arrive, because this mentions a smaller number of facts).\n The generation component was modified so that a maximum of four\nsentences were presented per turn.\n Information that can be inferred from other pieces of information that have\nalready been presented (e.g., travel time, once departure and arrival time\nare known) was left out to minimize the number of pieces of information\nthat have to be remembered.\n Presenting the details of more than two flights in one system turn was\ngenerally considered not manageable for a user, because each flight\npresentation must contain at least the airline name, the arrival time, the\ntravel time, and the number of legs. If there are more than two flights in\na cluster, we only present attributes that distinguish the flights (e.g., The\nthree direct flights are on Continental, Lufthansa, and Delta. They arrive at\n9:55 am, 10:15 am, and 11:15 am).\nFinally, we compared the dialogs for the SR and UMSR approaches to make sure\nthat at each step, the turn length and information density would be roughly the same\nfor both conditions.\n"},{"#tail":"\n","@confidence":"0.9027175","#text":"\nDue to the complexity of building a working end-to-end SDS, our previous experi-\nments employed an ?overhearer? evaluation methodology, in which participants read\n"},{"#tail":"\n","@confidence":"0.976922181818182","#text":"\nComputational Linguistics Volume 37, Number 3\nor listened to pre-recorded dialogs with a scripted user. This limits the evaluation\ncriteria that can be applied to users? perceptions (e.g., understandability, goodness of\noverview of options, and so on). Our third experiment, a short summary of which\nwas first reported in Winterboer and Moore (2007), compares the two systems in a\nmore interesting setting, in which users actively interact with the dialog systems. This\nsetting allows us to measure the systems? impact on effectiveness of the interaction (as\nmeasured by task success) and efficiency (as measured by dialog duration), in addition\nto user satisfaction. In this experiment, we compare the revised UMSR approach, which\ncontrols the amount of information presented in each turn, to the SR approach as\ndescribed previously.\n"},{"#tail":"\n","@confidence":"0.998449115384615","#text":"\nThe interaction task experiment presented here followed the Wizard-of-Oz (WoZ) par-\nadigm (Dahlba?ck, Jo?nsson, and Ahrenberg 1993) which enables us to test hypotheses\nabout not yet implemented or not sufficiently robust systems by simulating them.\nThe systems used in this experiment have fully implemented information presentation\ncomponents, including content selection and structuring, text planning, and template-\nbased realization. The wizard?s role was limited to language understanding, making\nsure all obligatory slots (e.g., departure airport, destination airport, travel dates) were\nfilled, and keeping the dialog going if the user was silent.\nWe used a database-driven Web interface which generated system responses on-\nthe-fly based on either the SR or the UMSR strategy to presenting information. The\nwizard sat on the opposite side of the room, hidden behind a partition that prevented\nparticipants from seeing or hearing the wizard during the experiment. The integrated\nSQL-based database system contained actual flight information as provided by airlines.\nThe wizard used drop-down menus to perform stepwise queries according to a partic-\nipant?s requests until a satisfying flight was found and booked. The generated textual\ninformation provided by the Web interface was copied-and-pasted to Speechify, a text-\nto-speech (TTS) application provided by Nuance Communications, Inc. All participants\nheard a synthetic voice of their own gender speaking British English. This choice was\nmotivated by the work of Nass and Brave (2005), which shows that the gender of the\nvoice used for TTS plays a significant role in terms of user preferences and trust in the\ninformation provided (users prefer a voice that matches their gender). Participants were\nencouraged to speak naturally rather than merely to respond to system prompts. The\nwizard used very few questions as prompts (e.g., What would you like me to book for you?)\nand would only add additional questions (e.g., Do you have a preferred arrival time?) if\nthe participant remained silent for more than five seconds after a round of information\npresentation by the system.\n"},{"#tail":"\n","@confidence":"0.999333","#text":"\nA total of 34 participants were paid to participate in the experiment. About half of\nparticipants were students of the University of Edinburgh (but not with a computer\nscience background), the other half were recruited via a Web site for one-off jobs. The\naverage age of the 17 female and 17 male participants was 24 years. All participants\nwere naive to the purpose of the experiment and native English speakers.\nEach participant was asked to book four flights. In order to enable reliable and\nrigorous comparisons, all participants were briefed to act as a business traveler for the\nflight booking task. As described in Section 4.1.1, the business traveler, in descending\n"},{"#tail":"\n","@confidence":"0.96794075","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\norder of importance, (1) prefers flying business class, (2) is concerned about arrival\ntime, travel time, and number of legs, and (3) wants to fly on KLM if possible.\nAfter being briefed about the role they were to play, participants were assigned the\ntask of booking flights and received detailed instructions concerning the two flights to\nbe booked in the first part of the experiment. To make the booking process more realistic,\nthe four routes (i.e., pairs of cities) were carefully chosen in order to guarantee that each\nparticipant experienced four different scenarios:\n"},{"#tail":"\n","@confidence":"0.9932783","#text":"\nBoth the order in which the four flights were booked and the order of the information\npresentation strategies (UMSR and SR) were randomized to counter-balance possible\norder effects. For the first two dialogs, half of the participants obtained flight informa-\ntion presented from the system adopting the SR approach; the other half received search\nresults as determined by the UMSR approach. In the second part of the experiment,\nparticipants who received flight information with SR in the first half of the experiment\nwere provided with information based on UMSR and vice versa. After completing the\ndialogs with a specific system (i.e., after the second and fourth dialog), participants\nwere asked to fill in a questionnaire to provide judgments on the four user satisfaction\nquestions (see Figure 12).\n"},{"#tail":"\n","@confidence":"0.9892925","#text":"\nDialog recordings and questionnaire answers were analyzed. For the questionnaire\ndata, we used seven-point Likert-type scales.\nEfficiency. There was a highly significant difference in the average number of turns\nparticipants required for booking a flight when the system adopted the SR approach as\ncompared to the system adopting the UMSR approach. Using a two-tailed paired t-test\nwe found that participants interacting with the UMSR-based system took significantly\nfewer turns than when using the SR-based system (t(31) = ?5.57; p < 0.0001; indicated\nwith ** in Table 3).\nMoreover, a two-tailed paired t-test revealed that dialog duration was significantly\nshorter for bookings made with presentations based on UMSR as opposed to SR (t(29) =\n"},{"#tail":"\n","@confidence":"0.970405727272727","#text":"\nComputational Linguistics Volume 37, Number 3\nEffectiveness. We hypothesized that UMSR, which explicitly points out trade-offs\namong options, would lead to improved task success. To this end, we extracted\ninformation about flights (e.g., flight times, airlines, number of layovers) from\nhttp://www.expedia.co.uk and chose our scenarios carefully to ensure that there was\none flight that best matched the requirements we presented to participants. We then\ncounted how often the flight best matching the business traveler?s profile was chosen in\neach condition. Using the UMSR-based system, participants succeeded in booking the\nbest-matching flight significantly more often. They booked the optimal flight 62 times\nout of 68 (91.18% success rate) with the UMSR system, but they only succeeded in doing\nso 50 out of 68 times (73.53% success rate) when interacting with the SR system.\n"},{"#tail":"\n","@confidence":"0.999798416666667","#text":"\nerence were found between genders. In the questionnaire data (see Figure 15) we found\na general preference for UMSR-based recommendations on all four evaluation criteria.\nHowever, only differences between answers to Questions 1 and 4 (?Did the system give\nthe information in a way that was easy to understand??, t(33) = ?2.85; p < 0.05; ?How\nquickly did the system allow the user to find the optimal flight??, t(33) = ?2.98; p <\n0.005) were statistically significant. We believe that the lack of a significant difference\nbetween systems on Questions 2 (overview) and 3 (relevance) is related to the fact that\nthe new version of UMSR controlled for turn length. In the revised version, information\nabout alternative or competing options was only included if the turn length allowed for\nit. Thus, there is trade-off between understandability and presenting information that\nis intended to improve the user?s overview of the option space. Further investigation of\nthis trade-off should be carried out as part of future research.\n"},{"#tail":"\n","@confidence":"0.5485674","#text":"\nAlthough the WoZ method allows us to evaluate our information presentation strategy\nin the context of an actual interaction, there are still a number of shortcomings. An\nideal user evaluation would use actual automatic speech recognition and language\nFigure 15\nResults for all questions, interaction experiment.\n"},{"#tail":"\n","@confidence":"0.990736","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nunderstanding instead of the wizard performing these actions. In addition, it would\nuse the actual model of each user rather than ask them to role-play.\nAlthough role-playing is an often used methodology in SDS evaluations (Polifroni\nand Walker 2008) and corpus collection (Carletta 2007), we recognize that there are\nconcerns with respect to assigning subjects a user model as opposed to using the\nparticipants? own models. Possible problems with role-playing include the fact that\nparticipants may have incorrect expectations about the needs and preferences of the\nrole they are supposed to play, and that they might not adopt the role sufficiently.\nFurthermore, a scenario where participants are role-playing cannot test how good the\nuser model is, or how robust a user-adaptation system is.\nWe chose role-playing as a method despite these concerns because it allows us to\nmore closely control conditions and guarantee that every participant will be exposed to\nthe same number and constellation of trade-offs (see Section 6.2).\nIn future work, we wish to perform an evaluation where the user?s own model is\nused.\n"},{"#tail":"\n","@confidence":"0.997032034482758","#text":"\nWe ran over 100 participants in three experiments and obtained very stable results in\nfavor of the UMSR approach to information presentation. In this section, we summarize\nour findings from the three experiments with respect to our initially stated hypotheses.\nDid the UMSR Approach Increase the Efficiency of Information Presentation? Overall, both in\nterms of the subjectively perceived efficiency, and in terms of the objectively measurable\nefficiency, the UMSR system significantly outperformed the SR system. Task duration\nwas significantly lower in the UMSR condition than in the SR condition in the interac-\ntion experiment, with the UMSR system also requiring fewer dialog turns. Furthermore,\nparticipants reported that they felt the optimal option was accessed more quickly in the\nUMSR condition than in the SR condition in all three experiments.\nDid the UMSR Approach Make Information Presentation More Effective? This hypothesis\nwas tested in the interaction task experiment by measuring task success. We found that\nusers chose the option that was best for the role they were playing more often in the\ninteraction experiment. These findings also agree with results obtained in other work,\nusing a dual-task method (Hu et al 2007; Winterboer et al 2007). Thus, we conclude\nthat information access with the UMSR approach is more effective than with the SR\napproach.\nDid UMSR Provide a Better Overview of the Option Space and Was Higher Confidence\nAchieved with UMSR? Questions 2 (?Did the system give X a good overview of the\navailable options??) and 3 (?Do you think there may be flights that are better options\nfor X that the system did not tell X about??) of the questionnaire were designed to\nassess this aspect. The first two experiments showed a clear preference for the UMSR\nsystem in comparison with the SR system. Participants in the interaction experiment\nalso exhibited a preference for the UMSR system, but the difference in ratings did not\nreach significance level. The smaller effect size in the third experiment is likely due to\ncontrolling dialog length: The overview of options deemed uninteresting to the user\nwas sometimes omitted to reduce turn length. This omission seems to negatively affect\nthe user?s overview of the option space and their confidence in having heard about all\nrelevant options.\n"},{"#tail":"\n","@confidence":"0.989143205882353","#text":"\nComputational Linguistics Volume 37, Number 3\nWas the Understandability of the System Improved? Understandability was the single aspect\nin which the SR system was not outperformed by the UMSR system for the first two\nexperiments (differences in ratings were marginal). Our hypothesis had been that the\nuser model improves understandability by tailoring the presentation of the options to\nthe user. This seemed to be outweighed by the larger amount of information presented\nin the original implementation of UMSR, however. In the interaction task experiment, in\nwhich dialog turn length was kept constant across the SR and UMSR conditions, turns\nin the two conditions contained a similar number of information units. In this case, the\nUMSR system achieved better understandability than the SR system.\nFinally, Did We Achieve Higher User Satisfaction? For all conditions, users preferred the\nUMSR strategy over the SR strategy, and on no aspect was the SR system found to be\nsignificantly better than the UMSR system in our experiments.\nWe conclude that our hypotheses were largely confirmed, and that a challenge for future\nwork lies in the development of methods that allow the system to predict and control\nfor the cognitive load induced by system utterances. We believe that this is particularly\nimportant because dialog systems are frequently used in situations in which the user?s\nhands and eyes are busy. For example, NASA is interested in spoken dialog technology\nfor use in spacecraft (Rayner et al 2003), and automobile manufacturers are integrating\nan ever-increasing number of voice services into their products.\nIn subsequent work, an end-to-end dialog system following the UMSR strategy was\nimplemented in the context of the TownInfo system (Paksima, Georgila, and Moore\n2009), which allows users to search for restaurants in the city of Edinburgh. The system\nwas evaluated with participants interacting directly with the system (as opposed to a\nWOZ setting), and was compared to a system that implemented the typical sequential\nenumeration approach to information presentation. In the UMSR condition, both per-\nceived task completion (90.7% vs. 85.2%) and actual task completion (74.1% vs. 62.9%)\nwere higher than in the traditional sequential enumeration condition. Furthermore,\ndialogs with the UMSR system required significantly fewer turns to complete the task\n(9.24 for UMSR and 17.78 for the sequential system), and conciseness, accessibility,\nand efficiency were all rated more highly in the UMSR condition than the sequential\nenumeration condition. In addition, overall user satisfaction was significantly higher\nfor the UMSR system. Finally, the UMSR system outperformed the sequential system\nparticularly clearly in cases where a trade-off among options existed.\n"},{"#tail":"\n","@confidence":"0.999711818181818","#text":"\nOur experiments evaluate the UMSR model against the SR model described in Polifroni,\nChung, and Seneff (2003). Recently, Polifroni and Walker (2008) developed several\nvariants of the SR approach that differ in how they choose and structure attributes in the\nsummaries presented to the user. That is, they differ in the way they rank attributes for\npresentation and the method used for clustering. There are two approaches to ranking,\none based on the original refiner approach (which chooses to cluster on attributes for\nwhich a small number of clusters account for most of the options) and the other based on\na user model (which chooses attributes for clustering based on the ranking in the user\nmodel). For clustering, they added an ?associative mode? in which association rules\namong attributes are automatically determined and the summary statements produced\ndescribe the associations. Imagine that all options in a cluster with property X also\n"},{"#tail":"\n","@confidence":"0.994016","#text":"\nhappen to have property Y. Association then means that both properties X and Y are\nmentioned for the cluster (see Figure 16).\nPolifroni and Walker (2008) evaluated the different versions of the refiner strategy\napproach in a reading experiment, similar to our first experiment. However, they eval-\nuated only the first system turn in the dialog for the different conditions presented. The\nexperimental conditions contrasted structuring with versus without a user model, and\nwith versus without associative clustering. They found that users preferred the system\nutterances that were generated based on a user model when there were a large number\nof options available, and that the associative mode was beneficial when tailoring the\nsummaries to the user. Their results hence support our approach: The version of the\nsystem that included user modeling and associative clustering led to dialogs that are\nthe most similar to those of our UMSR approach.\nThere remain, however, a number of differences between their refined refiner with\nuser modeling and associative clustering and our UMSR model. First, in UMSR the\nuser model is not only used to structure, but also to select options (via pruning of the\noption tree). Second, Polifroni and Walker?s (2008) approach contains two clustering\nsteps: one for clustering attribute values, which is the same as in our UMSR approach,\nand a second one for clustering options following each query. This second clustering\nstep corresponds to our tree structuring step. Whereas Polifroni and Walker re-cluster\nat every system turn, we only build up the option tree once (unless the user changes\ntheir query, e.g., by wanting to fly on another day, or asking to fly on another airline).\nFinally, their notion of associative clustering (i.e., grouping together attributes\nwhose values are connected, such as short flight duration and direct flights) is realized\nin our system as well, but in a less explicit way: In the tree structuring phase, attributes\nthat have identical values for a set of options (this would for example apply if all flights\nwith short travel time turned out to have only one leg) are moved up in the tree even if\nthe attribute has a low rank (see Section 3.4). A difference is that our UMSR model treats\nthe user?s valuation as a more important feature for dialog structuring than associations.\nCoping with Under- and Over-constrained User Queries. One frequent problem in spoken\ndialogs is caused by under- and over-constrained queries. In under-constrained queries,\nthe database returns too many results to be presented at once, and the system must\nsupport users in further refining their query. In an over-constrained query, there are no\n"},{"#tail":"\n","@confidence":"0.991275958333333","#text":"\nComputational Linguistics Volume 37, Number 3\nentries in the database that match the query exactly, and the system thus has to get the\nuser to relax a constraint, or itself choose a constraint to relax.\nOur UMSR system differentiates between cases that concern missing information\nabout obligatory slots (e.g., origin, destination, and date) and underspecified prefer-\nences (concerning preferred airlines, etc.). To fill the obligatory slots, simple slot-filling\nquestions such as When do you want to leave? are asked. For all other cases of over-\nor under-constrained queries, constraint relaxation and specification is inherent in the\nUMSR structuring approach. For underspecified preferences, the user model provides\ndefault specifications. In the case of over-constrained queries, we can think of constraint\nrelaxation in terms of the tree structure: Constraints that are less important to the user\n(e.g., price for our example business user) are automatically relaxed simply because they\nare located further down in the option tree. Constraint values, namely, good arrival time\nbeing changed to fair, are automatically relaxed due to the ordering of the branches\nwithin the option tree.\nVarious strategies for coping with over- and under-constrained queries have been\ndeveloped in the literature. Systems proactively suggest additional refinements for\nunderconstrained queries, as in You could try to look for cuisine type? (Pon-Barry, Weng,\nand Varges 2006; Varges, Weng, and Pon-Barry 2006), or relaxations for over-constrained\nqueries, as in Would a slightly more expensive flight work for you? (Qu and Beale 1999; Pon-\nBarry, Weng, and Varges 2006). Additionally, constraints can be relaxed automatically\nbased an ontology (Varges, Weng, and Pon-Barry 2006) or by predefining relaxation sets\n(e.g., from a specific street for a restaurant to the broader neighborhood) or categorical\nones (e.g., relaxing Chinese to Asian) (Chung 2004).\n"},{"#tail":"\n","@confidence":"0.999576208333333","#text":"\nThe research presented in this article addresses the issue of how to scale information\npresentation strategies for spoken dialog systems to situations where many diverse\noptions are available.\nWe developed an approach that combines content selection with content structur-\ning, and showed how a user model can inform both of these steps to optimize efficiency\nand effectiveness of the information presentation phase in spoken dialog systems. The\nknowledge derived from the user model can be used to enable a dialog system to auto-\nmatically present trade-offs between the relevant entities explicitly, thus improving the\nuser?s overview of the option space, and contrast options using linguistic and discourse\ncues. In our experiments, we found that the user model?directed approach led to shorter\ndialogs and that it improved task success: Users found the optimal option more often\nand were more satisfied with their experience. We tested this with three studies, a\nreading experiment, an overhearer experiment, and a Wizard-of-Oz experiment, thus\nproviding what we believe is the first large-scale evaluation of alternative information\npresentation strategies that actually investigates how users interact with the dialog\nsystem to perform a task.\nOne significant contribution of the UMSR approach for intelligent information\npresentation is that it guides users through the dialog by presenting only options that\nare likely to be of high relevance to them, thus reducing the reliance on user speech.\nUMSR exploits information from the user model to provide users with the opportunity\nto select between the most suitable options available. It computes the trade-offs between\noptions to most effectively narrow down the number of options. This way, considerably\nfewer turns are required per dialog in comparison with the SR approach, the average\ndialog duration is shorter, and the optimal option (i.e., flight) is booked more often.\n"},{"#tail":"\n","@confidence":"0.959574916666667","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nWe conclude that combining a summarize and refine approach with user modeling\nis a very promising approach to improving the user experience in terms of achieving\nhigher task success and increasing efficiency. However, there are also other parts of\nthe presentation that could be tailored to the user (e.g., in adaptive option clustering).\nAlthough we used heuristics for how to exploit the information from the user model\nfor content structuring, a very important next step would be to analyze the relationship\nbetween the user?s valuations and how they explore the option space. It is conceivable\nthat other ways of organizing the options could lead to even shorter refinement paths\nand quicker interactions. Concerning dialog turn length and complexity, we believe\nthat better formal methods are needed in order to automatically estimate the cognitive\nburden placed on a user during the dialog interaction. We now briefly address these\nissues.\nTailored Clustering. The user model can also be used for further tailoring the system\nresponses to the user by taking into account the user?s valuations during the clustering\nstep. Instead of using a fixed number of target clusters, it would be better to use a flexible\nnumber of natural clusters that the data fall into. This would make the labeling more\ndifficult, but would make clusters (and therefore descriptions of option properties) more\nmeaningful. Furthermore, the distance function used for clustering could be sensitive\nto the user model. For instance, the price axis used during clustering for a student who\ncares very much about price could be more fine-grained in the most relevant low price\nrange.\nAn Adaptive User Model for Turn Length. We learned from our experiments and related\nwork that turn length is important to control. Although we found that our system\ntended to produce turns that were often rather complex, in a study about choosing the\noptimal amount of information to convey to users, Whittaker, Walker, and Maloor (2003)\nfound that subjects are biased towards more information. This means that providing\nan insufficient amount of information is perceived as worse than presenting too many\ndetails. Whittaker, Walker, and Maloor?s results also indicated that conciseness should\nbe tailored to users, because some users appreciate conciseness more than others. Our\nsystem does not currently tailor turn length to specific users, because our user model\ndoes not contain information about a user?s conciseness preferences, or situational data,\nsuch as whether they are in a hurry, or can only devote a limited amount of attention\non the task. Furthermore, Polifroni and Walker (2008) found in their user study that\npeople who are not very familiar with the available options (e.g., tourists in a foreign\ncity searching the restaurant domain) appreciate potentially longer, tailored summaries\nmore than users who are very familiar with the data and know more precisely what\nthey are looking for?such users preferred a simple refinement strategy or refinement\nwith association over a user model?based recommendation.\nExploring the Relationship between the User Model and Optimal Dialog Structure (Minimize\nExploration Need). We have shown that presenting users first with those options that are\nmost relevant according to their user model improved efficiency over using an order\nwhich minimizes entropy but does not take into account the user model. However, we\nhave not shown that this is necessarily the best possible order. Therefore, it would be\ninteresting to run a more large-scale user experiment in which users use the system in an\neven more natural setting for booking flights that match their own interests, analyzing\nhow often users explore more than one branch in the tree as a function of the tree\nstructure. Having to investigate different branches of the tree is an indicator that the\n"},{"#tail":"\n","@confidence":"0.982417921052631","#text":"\nComputational Linguistics Volume 37, Number 3\ntree structure is not optimal. This information could then be used to improve on the\ncontent structuring algorithm and learn more about the relationship between the user\nmodel and users? exploration strategies and interests when performing the task.\nMeasures of Cognitive Load. An interesting aspect in information presentation is also how\nmuch cognitive load the system-generated utterances place on the user. In this work,\nwe try to manage cognitive load by controlling how many pieces of information are\nconveyed in one system turn. This is, however, a very coarse measure, as different\nlinguistic factors have also been shown to affect cognitive load on users. For example,\nsurprising or incoherent information structure has been observed to be more difficult to\nprocess (Vauras, Hyo?na?, and Niemi 1992; Van Gompel, Liversedge, and Pearson 2004),\nand complex syntactic structures (e.g., long-distance dependencies) have been shown\nto impose difficulty (Gibson 1998). Language processing difficulty is also affected by\nfrequency: Less frequent structures and words are more difficult to process than more\nfrequent ones (Ehrlich and Rayner 1981; Rayner 1998; Rayner et al 1998). Furthermore,\nlexical access (Pollatsek and Rayner 1990) and word predictability (Rayner et al 2001)\nhave also been shown to play a role. Finally, deciding what is an information unit and\nestimating how difficult they are to remember (and recall) for a particular user is not\na trivial task, and is highly dependent on individual differences in affect, aptitude,\nintelligence, episodic memory, and so on.\nTherefore, a more fine-grained estimation of the cognitive load imposed on a user\nbased on the number of information units to remember, the syntactic structure of the\ngenerated sentences, and their semantic coherence would allow the system to adapt to\nsituational constraints (e.g., generate less complex but potentially less efficient interac-\ntions if the user is performing another task simultaneously), or to a specific user in order\nto account for age or disabilities.\nIn order to begin addressing some of these issues, and to gain further insight into\nwhat makes presentations based on the UMSR approach so successful, we have recently\nperformed experiments investigating the role of linguistic devices to explicitly point out\ntrade-offs among options (e.g., but, also, just, only), which are used in UMSR presenta-\ntions to highlight relations among and trade-offs between options. We found that in\nboth written and spoken presentations of options, those that include these linguistic\ndevices facilitate recall for comparisons among options, when compared to a condition\nin which presentations do not include such linguistic cues (Winterboer 2009; Winterboer\net al 2011). In future work, we plan to consider how the syntactic complexity of the\nsentences in a presentation affects cognitive load, and how this interacts with both the\nnumber of options and attributes presented, and the use of linguistic devices to point\nout trade-offs.\n"},{"#tail":"\n","@confidence":"0.99971","#text":"\nWe would like to thank the anonymous\nreviewers for their helpful comments. Vera\nDemberg was supported by Evangelisches\nStudienwerk e.V. Villigst. Andi Winterboer\nwas funded by the Edinburgh-Stanford Link.\n"},{"#tail":"\n","@confidence":"0.864438266666667","#text":"\nBos, Johan, Ewan Klein, Oliver Lemon, and\nTetsushi Oka. 2003. Dipper: Description\nand formalisation of an information-state\nupdate dialogue system architecture.\nIn 4th SIGdial Workshop on Discourse and\nDialogue, pages 115?124, Sapporo.\nCarenini, Giuseppe and Johanna D. Moore.\n2001. An empirical study of the influence\nof user tailoring on evaluative argument\neffectiveness. In Proceedings of the 17th\nInternational Joint Conference on Artificial\nIntelligence, pages 1307?1314, Seattle, WA.\nCarletta, Jean. 2007. Unleashing the killer\ncorpus: Experiences in creating the\nmulti-everything ami meeting corpus.\n"},{"#tail":"\n","@confidence":"0.936424733333333","#text":"\neffects on word recognition and eye\nmovements during reading. Journal of\nVerbal Learning and Verbal Behaviour,\n20:641?655.\nGeorgila, Kallirroi, Oliver Lemon, James\nHenderson, and Johanna D. Moore. 2009.\nAutomatic annotation of context and\nspeech acts for dialogue corpora. Natural\nLanguage Engineering, 15(3):315?353.\nGibson, Edward. 1998. Linguistic\ncomplexity?locality of syntactic\ndependencies. Cognition, 68:1?76.\nHieronymus, James L. and John Dowding.\n2007. Clarissa spoken dialogue system\nfor procedure reading and navigation.\n"},{"#tail":"\n","@confidence":"0.799799384615385","#text":"\nHu, J., A. Winterboer, C. I. Nass, J. D. Moore,\nand R. Illowsky. 2007. Context and\nusability testing: User-modeled\ninformation presentation in easy and\ndifficult driving conditions. In Proceedings\nof the SIGCHI Conference on Human Factors\nin Computing Systems, pages 1343?1346,\nSan Jose, CA.\nKomatani, Kazunori, Shinichi Ueno, Tatsuya\nKawahara, and Hiroshi G. Okuno. 2003.\nFlexible guidance generation using user\nmodel in spoken dialogue systems. In\nProceedings of the 41st Annual Meeting of the\n"},{"#tail":"\n","@confidence":"0.980162","#text":"\n(ACL-2003), pages 256?263, Sapporo.\nLinden, G., S. Hanks, and N. Lesh. 1997.\nInteractive assessment of user preference\nmodels: The automated travel assistant.\n"},{"#tail":"\n","@confidence":"0.954482111111111","#text":"\nMechanical Sciences, pages 67?78.\nMartin, David L., Adam J. Cheyer, and\nDouglas B. Moran. 1999. The open agent\narchitecture: A framework for building\ndistributed software systems. Applied\nArtificial Intelligence, 91?128.\nMoore, Johanna D. 2006. Natural language\ngeneration for information presentation.\nPaper presented at the Spoken Language\n"},{"#tail":"\n","@confidence":"0.9898985","#text":"\nPaksima, T., K. Georgila, and J. D. Moore.\n2009. Evaluating the effectiveness of\ninformation presentation in a full\nend-to-end dialogue system. In Proceedings\nof the SIGDIAL 2009 Conference, pages 1?10,\nLondon.\nPolifroni, Joseph, Grace Chung, and\nStephanie Seneff. 2003. Towards automatic\ngeneration of mixed-initiative dialogue\nsystems from web content. In Proceedings\nof Eurospeech ?03, pages 193?196, Geneva.\nPolifroni, Joseph and Marilyn Walker. 2008.\nIntensional summaries as cooperative\nresponses in dialogue: Automation and\nevaluation. In Proceedings of ACL-08: HLT,\npages 479?487, Columbus, OH.\nPollatsek, A. and K. Rayner. 1990. Eye\nmovements and lexical access in reading.\nIn D. A. Balota, G. B. Flores d?Arcais, and\nK. Rayner, editors, Comprehension Processes\nin Reading. Erlbaum, Hillsdale, NJ,\npages 143?163.\nPon-Barry, Heather, Fuliang Weng, and\nSebastian Varges. 2006. Evaluation of\ncontent presentation strategies for an\nin-car spoken dialogue system. In\nInterspeech 2006 ? ICSLP, pages 1930?1933,\nPittsburgh, PA.\nQu, Y. and S. Beale. 1999. A constraint-based\nmodel for cooperative response generation\nin information dialogues. In AAAI/IAAI\n1999, pages 148?155, Orlando, FL.\nRayner, K. 1998. Eye movements in reading\nand information processing. Psychological\nBulletin, 124:327?422.\nRayner, K., K. S. Binder, J. Ashby, and\nA. Pollatsek. 2001. Eye movement control\nin reading: Word predictability has little\ninfluence on initial landing positions in\nwords. Vision Research, 41:943?954.\n"},{"#tail":"\n","@confidence":"0.93668702739726","#text":"\npages 193?196, Sapporo.\nRich, Elaine. 1979. User modeling via\nstereotypes. Cognitive Science, 3(4):329?354.\nSeneff, Stephanie. 2002. Response planning\nand generation in the mercury flight\nreservation system. Computer Speech &\nLanguage, 16(3?4):283?312.\nSteedman, M. 2000. Information structure\nand the syntax?phonology interface.\nLinguistic Inquiry, 31(4):649?689.\nThompson, C., M. Goeker, and P. Langley.\n2004. A personalized system for\nconversational recommendations. Journal\nof Artificial Intelligence Research (JAIR),\n21:393?428.\nVan Gompel, R. P. G., S. P. Liversedge, and\nJ. Pearson. 2004. Antecedent typicality\neffects in the processing of noun\nphrase anaphors. In M. Carreiras and\nC. E. Clifton, editors, The On-line Study of\nSentence Comprehension: Eyetracking, ERP\nand Beyond. Psychology Press, New York,\npages 119?137.\nVarges, Sebastian, Fuliang Weng, and\nHeather Pon-Barry. 2006. Interactive\nquestion answering and constraint\nrelaxation in spoken dialogue systems. In\nProceedings of the 7th SIGdial Workshop on\nDiscourse and Dialogue, pages 28?35,\nSydney.\nVauras, M., J. Hyo?na?, and P. Niemi. 1992.\nComprehending coherent and incoherent\ntexts: Evidence from eye movement\npatterns and recall performance. Journal of\nResearch in Reading, 15(1):39?54.\nWalker, M. A., S. J. Whittaker, A. Stent,\nP. Maloor, J. Moore, M. Johnston, and\nG. Vasireddy. 2004. Generation and\nevaluation of user tailored responses in\nmultimodal dialogue. Cognitive Science,\n28(5):811?840.\nWalker, Marilyn and Rebecca Passonneau.\n2001. Date: A dialogue act tagging scheme\nfor evaluation of spoken dialogue systems.\nIn HLT ?01: Proceedings of the First\nInternational Conference on Human Language\nTechnology Research, pages 1?8,\nMorristown, NJ.\nWalker, Marilyn A., Rebecca Passonneau,\nand Julie E. Boland. 2001. Quantitative\nand qualitative evaluation of darpa\ncommunicator spoken dialogue systems.\nIn Proceedings of 39th Annual Meeting of the\nAssociation for Computational Linguistics,\npages 515?522, Toulouse.\nWhite, Michael, Robert A. J. Clark, and\nJohanna D. Moore. 2010. Generating\ntailored, comparative descriptions with\ncontextually appropriate intonation.\nComputational Linguistics, 36(2):159?201.\nWhittaker, Stephen, Marilyn Walker, and\nPreetam Maloor. 2003. Should I tell all?:\nAn experiment on conciseness in spoken\ndialogue. In EUROSPEECH: European\nConference on Speech Processing,\npages 1685?1689, Geneva.\nWinterboer, A., J. Hu, Johanna D. Moore,\nand Clifford I. Nass. 2007. The influence of\nuser tailoring and cognitive load on user\nperformance in spoken dialogue systems.\nIn Proceedings of the Interspeech 2007\nConference, pages 2717?2720, Antwerp.\nWinterboer, Andi. 2009. Evaluating\n"},{"#tail":"\n","@confidence":"0.908960466666667","#text":"\nSpoken Dialogue Systems. Ph.D. thesis,\nSchool of Informatics, University of\nEdinburgh.\nWinterboer, Andi and Johanna D. Moore.\n2007. Evaluating information presentation\nstrategies for spoken recommendations.\nIn Proceedings of the 2007 ACM Conference\non Recommender Systems, pages 157?160,\nMinneapolis, MN.\nWinterboer, Andi, Martin I. Tietze, Maria\nWolters, and Johanna D. Moore. 2011.\nThe user model-based summarize and\nrefine approach improves information\npresentation in spoken dialog systems.\nComputer Speech and Language, 25:175?191.\n"},{"#tail":"\n","@confidence":"0.987764666666667","#text":"\nYou?re going to read the transcripts of dialogues between a customer, Steve, and two dif-\nferent automated travel agents. When asked to fill out a form indicating his preferences\nfor air travel, here?s what Steve said:\n?I?m a student, so the most important thing to me is to get a cheap flight. Otherwise\nI?m pretty flexible. I have no preferred airline and I don?t care about particular layover\nairports.?\nA: Dialogue between Steve and UMSR system:\nSteve: Hello. I need a cheap flight from Edinburgh to San Francisco on Thursday,\n22nd September. I?d like to arrive by 6 pm.\nSystem: I found three flights. They all have a short travel time but require a connection.\nThe cheapest flight is on Air France. It arrives at 3:45 pm and costs just\n304 pounds.\nIf you prefer to arrive closer to 6 pm, there are two British Airways Flights\nto choose from, but they both cost 586 pounds. All other flights are more\nexpensive or arrive too late.\nSteve: Tell me more about the cheap flight, please.\nSystem: The Air France flight leaves Edinburgh at 9:05 am and requires a connection\nin Paris. The total travel-time is 14 hours and 40 minutes.\nB: Dialogue between Steve and SR system:\nSteve: Hello. I need a cheap flight from Edinburgh to San Francisco on Thursday,\n22nd September. I?d like to arrive by 6 pm.\nSystem: There are three cheap flights from Edinburgh to San Francisco that arrive\nbetween 3 and 6 pm. One of them is on Air France and costs 304 pounds. It\narrives at 3:45 pm. The second one is a KLM flight that arrives at 4:20 and costs\n349 pounds. The third flight is on Continental Airlines. It arrives at 4:35 pm\nand costs 389 pounds.\nSteve: Can you give me more detailed information about the flight for 304 pounds,\nplease?\nSystem: It leaves Edinburgh at 9:05 am and requires a connection in Paris. The total\ntravel time is 14 hours 40 minutes.\nScenario 1 (Carol)\nCarol?s user profile:\nYou?re going to read the transcripts of dialogues between a customer, Carol, and\ntwo different automated travel agents. When asked to fill out a form indicating her\npreferences for air travel, here?s what Carol said: ?I?m a frequent flier and collect\nfrequent flier points with KLM, so the most important thing when booking a flight is\nthe airline. Second most important are the arrival time and the number of legs. Third\nmost important is the travel time. I?m not too concerned about the price or the layover\nairport, although I prefer not to connect in London Heathrow.?\n"},{"#tail":"\n","@confidence":"0.956168","#text":"\nComputational Linguistics Volume 37, Number 3\nA: Dialogue between Carol and UMSR system:\nCarol: Hello. I would like to book a flight from Edinburgh to San Francisco for\nThursday, 27th July, preferably leaving Edinburgh after 11 am. If at all pos-\nsible, I?d like to fly on KLM.\nSystem: Do you have any preferences for airports?\nCarol: I?d rather not connect in London Heathrow.\nSystem: I found two flights that both require a connection. There? s a KLM flight for\nonly 348 pounds with a connection in Amsterdam, but it takes 18 hours and\n20 minutes and leaves at 7:30 am.\nTo leave later and travel faster, you can take the Flybe flight that leaves only\nat 11:45 am and has a total travel time of only 15 hours 40 minutes. But you?d\nneed to connect in London and the price is 580 pounds.\nB: Dialogue between Carol and SR system:\nCarol: Hello. I would like to book a flight from Edinburgh to San Francisco for\nThursday, 27th July, preferably leaving Edinburgh after 11 am. If at all pos-\nsible, I?d like to fly on KLM.\nSystem: There are no flights that leave Edinburgh after 11 am and that are on KLM.\nHowever, there is a KLM flight leaving at 7:30 am.\nCarol: Are there any flights on other airlines that leave Edinburgh after 11 am?\nSystem: There are 7 flights that leave Edinburgh after 11 am. All of them have avail-\nability in business class.\nCarol: Do you have information about the travel time of these flights?\nSystem: Most of the flights take between 18 hours and 20 hours, one has a travel time\nof less than 16 hours.\nCarol: Please tell me about that flight with under 16 hours travel time.\nSystem: The Flybe flight leaves Edinburgh at 11:45 am and arrives San Francisco at\n11 pm. It has a total of 15 hours 40 minutes and costs 580 pounds. You?d need\nto connect in London Heathrow.\nScenario 2 (Walter)\nWalter?s user profile:\nYou?re going to read the transcripts of dialogues between a customer, Walter, and\ntwo different automated travel agents. When asked to fill out a form indicating his\npreferences for air travel, here?s what Walter said: ?I?m a business traveller, so the most\nimportant thing for me is to fly business class. I need to get to my meetings in time and\ndon?t want to spend too much time in airports, so second most important to me are\narrival time, travel time, and number of legs. Third most important is to fly on KLM,\nbecause I collect bonus miles. I?m not concerned about travelling cheaply.?\nA: Dialogue between Walter and UMSR system:\nWalter: Hello. I?d like to book a flight from Edinburgh to Brussels for tomorrow. I need\nto get there at around 3 pm and I?d prefer to fly business class.\nSystem: Do you have any airline preferences?\nWalter: Yes, KLM. And I?d rather not connect in London, if at all possible.\n"},{"#tail":"\n","@confidence":"0.941531933333333","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nSystem: There are four flights with availability in business class. None are on KLM.\nThe only direct flight arrives at 5:30 pm, which is later than you requested. To\narrive earlier, you?ll have to make a connection.\nIf you?re willing to travel economy, there is a direct flight on BMI, arriving\nat 1:10 pm. There?s also a KLM flight arriving at 1:50 pm, but it requires a\nconnection in Amsterdam.\nAll other economy flights take longer or arrive later than 4 pm.\nWalter: Can you tell me more about the business class flights that arrive earlier?\nSystem: The two flights with shortest travel time are both on British Airways and cost\n308 pounds. The first takes 4 hours and 20 minutes and arrives at 1:20 pm. The\nother takes 4 hours and 30 minutes and arrives at 3:30 pm. There?s a cheaper\nflight on Lufthansa. It arrives at 3:10 pm and costs just 270 pounds, but it takes\n5 hours and 35 minutes. All other business class flights arrive much too early\nor very late.\nB: Dialogue between Walter and SR System:\nWalter: I?d like to book a flight from Edinburgh to Brussels for tomorrow.\nSystem: There are 28 flights from Edinburgh to Brussels. Most of them require a\nconnection and cost between 100 and 230 pounds.\nWalter: Are there any direct flights with availability in business class that arrive\naround 3 pm?\nSystem: There are no direct business class flights that arrive around 3 pm. However,\nthere is one direct business class flight that arrives at 5:30. It costs 111 pounds.\nWalter: No, that?s too late . . . what about connecting business class flights that arrive\naround 3 pm?\nSystem: There are three business class flights that require a connection and arrive\naround 3 pm. Two of them are on British Airways and arrive at 1:20 and 3:30.\nThe third is on Lufthansa and arrives at 3:10.\nWalter: How long do these flights take?\nSystem: The British Airways flights take 3 hours and 20 minutes and the Lufthansa\nflight takes 4 hours and 35 minutes.\nWalter: Are there any direct economy flights?\nSystem: Yes, there?s a direct flight on BMI. It arrives at 1:10 pm and has a travel time of\n1 hour 35 minutes.\nScenario 3 (Carol)\nCarol?s user profile:\nIt?s Carol again. This time she wants information about flights to Brussels. Remember\nwhat she said in her user profile: ?I?m a frequent flier, so the first most important thing\nfor me is the airline, because I collect frequent flier points with KLM. Second most\nimportant to me is arrival time and number of legs. Third most important is travel time.\nI?m not too concerned about the price or the layover airport, although I prefer not to\nconnect in London Heathrow.?\nA: Dialogue between Carol and UMSR system:\nCarol: Hello. I would like to book a flight from Edinburgh to Brussels for Thursday,\n27th July, arriving at about noon. I prefer KLM flights.\n"},{"#tail":"\n","@confidence":"0.960502804878049","#text":"\nComputational Linguistics Volume 37, Number 3\nSystem: I found three flights with a good price. Two of them are on KLM. They both\ncost 111 pounds, but require a connection in Amsterdam. If you want to fly\ndirect, there?s a BMI flight arriving Brussels at 9:40 am that costs 107 pounds.\nAll other flights arrive after noon.\nCarol: Please tell me more about the KLM flights.\nSystem: One of them arrives at 11:20 am but has a travel time of 4 hours 15 minutes.\nThe other takes just 3 hours 10 minutes but arrives only at 4:40 pm.\nB: Dialogue between Carol and SR system:\nCarol: Hello. I would like to book a flight from Edinburgh to Brussels for Thursday,\n27th July, arriving at about noon. I prefer KLM flights.\nSystem: I found one KLM flight that arrives Brussels at 11:20 am. It takes 4 hours\n15 minutes.\nCarol: Please tell me more about that flight.\nSystem: It leaves Edinburgh at 6:05 am and costs 111 pounds. You need to make a\nconnection in Amsterdam.\nScenario 4 (Steve)\nSteve?s user profile:\nIt?s Steve again. This time he wants to go to San Francisco. Remember Steve?s user\nprofile: ?I?m a student, so the most important thing to me is to get a cheap flight.\nOtherwise I?m pretty flexible. I have no preferred airline and I don?t care about\nparticular layover airports.?\nA: Dialogue between Steve and UMSR system:\nSteve: Hello. I would like to book a flight from Edinburgh to Brussels for Thursday,\n27th July. Please find me a cheap flight.\nSystem: What is your desired arrival time?\nSteve: Ahm . . . in the early afternoon.\nSystem: Ryan Air offers the cheapest flights to Brussels. They cost just 49 pounds, but\nyou would have to connect in Dublin. There are two flights to choose from.\nThere?s an early flight, leaving Edinburgh at 8:05 am and arriving at 12:45 pm,\nwith a travel time of only 3 hours 30 minutes. If you prefer to arrive at 5:30 pm,\nyour total travel time would be 5 hours 30 minutes, leaving Edinburgh at\n1 pm. If you want to fly direct, there?s a flight on BMI that takes just 1 hour\nand 35 minutes. It arrives at 1:35 pm and costs 112 pounds. All other direct\nflights are more expensive.\nB: Dialogue between Steve and SR System:\nSteve: Hello. I would like to book a flight from Edinburgh to Brussels for Thursday,\n27th July. Please find me a cheap flight.\nSystem: There are three flights for only 49 pounds on Ryan Air. They all require a\nconnection in Dublin.\nSteve: Is there also a cheap *direct* flight?\n"},{"#tail":"\n","@confidence":"0.570725714285714","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nSystem: The cheapest direct flight is on BMI and costs 112 pounds.\nSteve: Okay . . . what are the departure and arrival times of the three RyanAir flights?\nSystem: The first Ryan Air leaves Edinburgh at 8:05 am and arrives at 12:45 pm. The\nnext one leaves at 1 pm and arrives at 5:30 pm. The last one leaves Edinburgh\nat 4:25 pm and arrives at 9:25 pm.\nScenario 5 (Walter)\n"},{"#tail":"\n","@confidence":"0.992928657142857","#text":"\nIt?s Walter again. This time he has another request. Remember his preferences: ?I?m a\nbusiness traveller, so the most important thing for me is to fly business class. I need\nto get to my meetings in time and don?t want to spend too much time in airports, so\nsecond most important to me are arrival time, travel time, and number of legs. Third\nmost important is to fly on KLM, because I collect bonus miles. I?m not concerned about\ntravelling cheaply.?\nA: Dialogue between Walter and UMSR system:\nWalter: Hello. I would like to book a flight from Edinburgh to San Francisco for\ntomorrow, arriving around 4 pm. It?s important for me to fly on business class.\nA KLM flight would be nice.\nSystem: There are two flights that arrive in San Francisco at 3:45 and 4:35 but neither\nof them is direct. They both have availability in business class and take under\n15 hours. One of them is on Continental Airlines and the other is on Air\nFrance. There?s also a KLM flight, but its travel time is 18 hours 20 minutes.\nAll other flights arrive later than you requested.\nWalter: Please tell me more about the Air France flight.\nSystem: The Air France flight leaves Edinburgh at 9:05 am and arrives San Francisco\nat 3:45 pm. You need to connect in Paris. The flight costs 1,611 pounds on\nbusiness class.\nB: Dialogue between Walter and SR system:\nWalter: I?d like to book a flight from Edinburgh to San Francisco for tomorrow, arriv-\ning around 4 pm. It?s important for me to fly on business class. A KLM flight\nwould be nice.\nSystem: I found one KLM flight with availability in business class. It arrives at 3:45.\nYou?d need to connect in Amsterdam.\nWalter: Are there any direct flights that arrive around 4 pm?\nSystem: There are no direct flights from Edinburgh to San Francisco. However, there\nare 7 flights that arrive San Francisco between 3 and 5 pm. They all have\navailability in business class.\nWalter: How long does the KLM flight take?\nSystem: The KLM flight has a travel time of 18 hours 20.\nWalter: 18 h is very long. Are any of those other 7 flights faster?\nSystem: There are three flights that take under 15 hours. The British Airways flight\narrives at 4:10 pm, the Continental Airways flight arrives at 4:35 pm and the\nAir France flight arrives at 3:45 pm.\n"},{"#tail":"\n","@confidence":"0.76015875","#text":"\nYou?d like to arrive by 6 pm so that you can make it to dinner with your\npossible new employer.\nTask C: You?re going from New York to Frankfurt departing on June 1st. You?d like to\narrive in the late morning so that you can make it to a meeting that begins at\n"},{"#tail":"\n","@confidence":"0.970366620689655","#text":"\nTask D: You need to book a flight from San Francisco to Prague departing on\nJune 14th. You have to attend a meeting in the late afternoon, so you need\nto arrive before 3 pm.\nFlight booking with SR system?Edinburgh to San Francisco\nSystem: This is the FLIGHTS information system. I am now connected to the network.\nWould you like to book a flight?\nUser: I?d like to book a flight from Edinburgh to San Francisco.\nSystem: Please, tell me the date on which you want to travel.\nUser: January 3rd.\nSystem: I found 20 flights from Edinburgh to San Francisco. All these flights require\nconnection. There are flights available in economy, business, and first class.\nI also have information about arrival times.\nUser: I?d like to fly business class.\nSystem: I found 5 business class flights from Edinburgh to San Francisco. All these\nflights require a connection. There are flights on American Airlines, Lufthansa,\nand United Airlines. I also have information about arrival times.\nUser: What is their arrival times?\nSystem: Tell me your preferred arrival time?\nUser: 4:00 pm.\nSystem: There are two business class flights from Edinburgh to San Francisco arriving\nbetween 2:00 and 4:30 pm. The first flight departs Edinburgh on Lufthansa\nat 5:40 am and arrives in San Francisco at 3:38 pm and requires a connection\nin Frankfurt. It costs 2,708 pounds. The second flight departs Edinburgh on\nUnited Airlines at 8:30 am and arrives in San Francisco at 3:18 pm and requires\na connection at London Heathrow. It costs 4,452 pounds. Would you like to\nbook one of these flights?\nUser: Yes.\nSystem: Which one do you want me to book for you?\nUser: The first one.\n"},{"#tail":"\n","@confidence":"0.994436673469388","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nSystem: Sounds good, let me book this flight for you. This will take a moment. Thank\nyou for waiting; the electronic ticket and itinerary have been emailed to you.\nWould you like to book another flight?\nUser: No.\nSystem: OK, goodbye.\nFlight booking with SR system?Edinburgh to San Francisco\nSystem: This is the FLIGHTS information system. I am now connected to the network.\nWould you like to book a flight?\nUser: Yeah, I?d like to book another flight on January 3rd from Edinburgh to\nSan Francisco.\nSystem: I found 20 flights from Edinburgh to San Francisco. All these flights require a\nconnection. There are flights available in economy, business, and first class. I\nalso have information about arrival times.\nUser: I?d like to fly business class and, uh, I?d like to arrive around 4:00 pm.\nSystem: There are two business class flights from Edinburgh to San Francisco arriving\nbetween 2:00 and 4:30 pm. The first flight departs Edinburgh on Lufthansa\nat 5:40 am and arrives in San Francisco at 3:38 pm and requires a connection\nat Frankfurt. It costs 2,708 pounds. The second flight departs Edinburgh on\nUnited at 8:30 am and arrives in San Francisco at 3:18 pm and requires a\nconnection in London. It costs 4,452 pounds. Would you like to book one of\nthese flights?\nUser: Do you have any flights on KLM that get in around 4:00 pm that are also\nbusiness?\nSystem: I found no business class flights from Edinburgh to San Francisco flying on\nKLM arriving between 2:00 and 4:30 pm.\nUser: Ok, can you repeat the options for business class flights that arrive around\n4:00 pm?\nSystem: There are 2 business class flights from Edinburgh to San Francisco arriving\nbetween 2:00 and 4:30 pm. The first flight departs Edinburgh on Lufthansa\nat 5:40 am and arrives in San Francisco at 3:38 pm and requires a connection\nin Frankfurt. It costs 2,708 pounds. The second flight departs Edinburgh on\nUnited at 8:30 am and arrives in San Francisco at 3:18 pm and requires a\nconnection at London. It costs 4,452 pounds. Would you like to book one of\nthese flights?\nUser: 4:00 pm.\nSystem: There are two business class flights from Edinburgh to San Francisco arriving\nbetween 2:00 and 4:30 pm. The first flight departs Edinburgh on Lufthansa\nat 5:40 am and arrives in San Francisco at 3:38 pm and requires a connection\nin Frankfurt. It costs 2,708 pounds. The second flight departs Edinburgh on\nUnited Airlines at 8:30 am and arrives in San Francisco at 3:18 pm and requires\na connection at London Heathrow. It costs 4,452 pounds. Would you like to\nbook one of these flights?\nUser: Yeah, I would like to book the first one on Lufthansa.\nSystem: Sounds good, let me book this flight for you. This will take a moment. Thank\nyou for waiting; the electronic ticket and itinerary have been emailed to you.\nWould you like to book another flight?\nUser: No. That?s it. Thank you.\nSystem: OK, goodbye.\n"},{"#tail":"\n","@confidence":"0.994158291666667","#text":"\nComputational Linguistics Volume 37, Number 3\nFlight booking with UMSR system?Edinburgh to San Francisco\nSystem: This is the FLIGHTS information system. I am now connected to the network.\nWould you like to book a flight?\nUser: Could I please go from Edinburgh to San Francisco on May 12th in business\nclass?\nSystem: I found three flights from Edinburgh to San Francisco with availability in\nbusiness class. They are on Lufthansa and United.\nUser: Excellent, I would like to arrive in San Francisco at 3 or 4 pm, is there anything\nlike that?\nSystem: There are two flights with availability in business class. One is on United and\narrives at 3:18 pm with a total travel time of only 14 hours and 48 minutes.\nThe other flight is on Lufthansa and arrives at 3:45 pm, but it has a longer\ntotal travel time of 17 hours and 58 minutes. Would you like to book one of\nthese flights?\nUser: Yes, I?d like the one with the shorter travel time, please.\nSystem: Sounds good, let me book this flight for you. This will take a moment. Thank\nyou for waiting; the electronic ticket and itinerary have been emailed to you.\nWould you like to book another flight?\nUser: No, thanks.\nSystem: OK, goodbye.\nFlight booking with UMSR system?Edinburgh to San Francisco\nSystem: This is the FLIGHTS information system. I am now connected to the network.\nWould you like to book a flight?\nUser: I would like to book a flight from Edinburgh to San Francisco.\nSystem: Please, tell me the date on which you want to travel.\nUser: January 3rd.\nSystem: There are no direct flights from Edinburgh to San Francisco but I found\n3 flights with availability in business class. However, none of these 3 is on\nKLM. To travel on KLM you?ll have to fly economy.\nUser: Um, ok, I?ll fly business class with another airline.\nSystem: Please wait while I look up the database . . . . I found 3 flights from Edinburgh\nto San Francisco with availability in business class. They are on Lufthansa and\nUnited. Do you have preferred departure or arrival time?\nUser: I?d like to arrive around 4:00 pm.\nSystem: There are 2 flights with availability in business class. One is on United and\narrives at 3:18 pm with a total travel time of only 14 hours and 48 minutes. It\ncosts 4,452 pounds. The other flight is on Lufthansa and arrives at 3:38 pm\nbut it has a longer total travel time of 17 hours and 58 minutes. It costs\n2,708 pounds. Would you like to book one of these flights?\nUser: 4:00 pm.\nSystem: There are two business class flights from Edinburgh to San Francisco arriving\nbetween 2:00 and 4:30 pm. The first flight departs Edinburgh on Lufthansa\nat 5:40 am and arrives in San Francisco at 3:38 pm and requires a connection\nin Frankfurt. It costs 2,708 pounds. The second flight departs Edinburgh on\nUnited Airlines at 8:30 am and arrives in San Francisco at 3:18 pm and requires\na connection at London Heathrow. It costs 4,452 pounds. Would you like to\nbook one of these flights?\n"},{"#tail":"\n","@confidence":"0.996286066666667","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nUser: I?ll book the United flight. Get nice food.\nSystem: Sounds good, let me book this flight for you. This will take a moment. Thank\nyou for waiting; the electronic ticket and itinerary have been emailed to you.\nWould you like to book another flight?\nUser: No. Thanks.\nSystem: OK, goodbye.\nFlight booking with SR system?Edinburgh to Brussels\nSystem: This is the FLIGHTS information system. I am now connected to the network.\nWould you like to book a flight?\nUser: Yes, please.\nSystem: What would you like to book?\nUser: I would like to book a flight from Edinburg to Brussels.\nSystem: Please, tell me the date on which you want to travel.\nUser: On December 18th.\nSystem: I found 21 flights from Edinburgh to Brussels. There are flights available in\neconomy and business class. There are direct flights as well as flights that\nrequire a connection.\nUser: I?d like a direct flight in business class.\nSystem: There are two direct business class flights from Edinburgh to Brussels. The\nfirst flight departs Edinburgh on BMI at 12 pm and arrives in Brussels at\n2:40 pm. It costs 452 pounds. The second flight departs Edinburgh at 3:55 pm\nand arrives in Brussels at 6:15 pm. It costs 446 pounds. Would you like to book\none of these flights?\nUser: Yes.\nSystem: Which one do you want me to book for you?\nUser: The first one.\nSystem: Sounds good, let me book this flight for you. This will take a moment. Thank\nyou for waiting; the electronic ticket and itinerary have been emailed to you.\nWould you like to book another flight?\nUser: No.\nSystem: OK, goodbye.\nFlight booking with SR system?Edinburgh to Brussels\nSystem: This is the FLIGHTS information system. I am now connected to the network.\nWould you like to book a flight?\nUser: Yes, from Edinburgh to Brussels on December 18th.\nSystem: I found 21 flights from Edinburgh to Brussels. There are flights available in\neconomy and business class. There are direct flights as well as flights that\nrequire connection.\nUser: I would like to fly business class on KLM.\nSystem: There is one business class flight from Edinburgh to Brussels flying on KLM.\nThe flight departs Edinburgh on KLM at 12:40 pm and arrives in Brussels at\n4:50 pm and requires a connection at Amsterdam. It costs 187 pounds. Would\nyou like to book this flight?\nUser: Yes, please.\n"},{"#tail":"\n","@confidence":"0.857677","#text":"\nSystem: There are two direct flights from Edinburgh to Brussels with availability in\nbusiness class. All other direct flights only offer availability in economy class.\nIf you are willing to make a connection, there is a KLM flight with business\nclass availability arriving at 4:50 pm.\nUser: What time do the direct business flights arrive?\n"},{"#tail":"\n","@confidence":"0.928778272727273","#text":"\nSystem: I found 21 flights from San Francisco to Prague. All these flights require a\nconnection. There are flights available in economy, business, and first class. I\nalso have information about price range.\nUser: I?d like business class.\nSystem: I found 11 business class flights from San Francisco to Prague. All these flights\nrequire connection. There are flights in the expensive and moderate price\nrange. I also have information about arrival times.\nUser: Arrival around 3:00 pm.\nSystem: I found six business class flights from San Francisco to Prague, all arriving\nbetween 1:00 and 3:30 pm. All these flights require a connection. I have infor-\nmation about departure times. I also have information about price ranges.\nUser: A flight on KLM?\nSystem: There is one business class flight from San Francisco to Prague flying on KLM,\narriving between 1:00 and 2:30 pm. The flight departs San Francisco on KLM\nat 3:20 pm and arrives in Prague at 2:20 pm and requires a connection in\nAmsterdam. It costs 4,574 pounds. Would you like to book this flight?\nUser: Yes.\nSystem: Sounds good, let me book this flight for you. This will take a moment. Thank\nyou for waiting; the electronic ticket and itinerary have been emailed to you.\nWould you like to book another flight?\nUser: No.\nSystem: OK, goodbye.\n"},{"#tail":"\n","@confidence":"0.96422495","#text":"\nComputational Linguistics Volume 37, Number 3\nFlight booking with SR system?San Francisco to Prague\nSystem: This is the FLIGHTS information system. I am now connected to the network.\nWould you like to book a flight?\nUser: Yes, from San Francisco to Prague on January 30th.\nSystem: I found 21 flights from San Francisco to Prague. All these flights require\nconnection. There are flights available in economy, business, and first class.\nI also have information about price range.\nUser: I would like to fly business class on KLM.\nSystem: There are two business class flights from San Francisco to Prague flying on\nKLM. The first flight departs San Francisco on KLM at 3:20 pm and ar-\nrives in Prague at 2:20 pm and requires a connection at Amsterdam. It costs\n4,574 pounds. The second flight departs San Francisco on KLM at 11:20 am\nand arrives in Prague at 2:45 pm and requires a connection at Amsterdam. It\ncosts 4,574 pounds. Would you like to book one of these flights?\nUser: What time does the first flight arrive in Prague again?\nSystem: The first flight departs San Francisco on KLM at 3:20 pm and arrives in Prague\nat 2:20 pm and requires a connection at Amsterdam.\nUser: I?d like to book that flight.\nSystem: Sounds good, let me book this flight for you. This will take a moment. Thank\nyou for waiting; the electronic ticket and itinerary have been emailed to you.\nWould you like to book another flight?\nUser: No.\nSystem: OK, goodbye.\nFlight booking with UMSR system?San Francisco to Prague\nSystem: This is the FLIGHTS information system. I am now connected to the network.\nWould you like to book a flight?\nUser: I do. I need to go from San Francisco to Prague on June 14th.\nSystem: There are no direct flights from Edinburgh to Prague, but I found 14 flights\nwith availability in business class. Two of these are on KLM.\nUser: OK, I would like to go there on KLM and I have a meeting there at 4 pm. Do\nyou have something coming in at around noon, or 1 pm?\nSystem: I found only one KLM flight with availability in business class that will get\nyou there on time. It arrives at 2:20 pm with a total travel time of just 14 hours\nbut it requires a connection in Amsterdam and costs 4,574 pounds. All other\nflights take longer. Would you like to book the KLM flight?\nUser: Yes, please.\nSystem: Sounds good, let me book this flight for you. This will take a moment. Thank\nyou for waiting; the electronic ticket and itinerary have been emailed to you.\nWould you like to book another flight?\n"},{"#tail":"\n","@confidence":"0.975237571428571","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nSystem: Tell me what do you want to book?\nUser: I?d like to book a flight from San Francisco to Prague.\nSystem: Tell me the date on which you want to travel, please.\nUser: January 30th.\nSystem: There are no direct flights from San Francisco to Prague but I found 11 flights\nwith availability in business class. Two of these are on KLM.\nUser: I would like a business class flight on KLM, do you have anything arriving\nbefore 3:00 pm?\nSystem: There are two business class flights from San Francisco to Prague on KLM that\nwill get you there on time. The first flight arrives at 2:45 pm with a total travel\ntime of 18 hours and 25 minutes. The second flight arrives at 2:20 pm with a\ntotal travel time of only 14 hours.\nUser: I would like the second flight please.\nSystem: Sounds good, let me book this flight for you. This will take a moment. Thank\nyou for waiting; the electronic ticket and itinerary have been emailed to you.\nWould you like to book another flight?\nUser: No.\nSystem: OK, goodbye.\nFlight booking with SR system?New York to Frankfurt\nSystem: This is the FLIGHTS information system. I am now connected to the network.\nWould you like to book a flight?\nUser: I?d like to depart New York on June 1st and go to Frankfurt, please.\nSystem: I found 23 flights from New York to Frankfurt. There are direct flights as well\nas flights that require a connection. I also have information about fare classes.\nUser: I?d like a business class flight arriving before 2 pm, sorry, arriving before noon.\nSystem: I found 13 business class flights from New York to Frankfurt arriving between\n9 and 11:30 am. There are direct flights as well as flights that require a connec-\ntion. I also have information about departure times.\nUser: I?d like a direct flight and if there is anything on KLM?\nSystem: I found no direct business class flights from New York to Frankfurt flying on\nKLM arriving between 9:30 am and 12:30 pm.\nUser: I?ll just take a direct flight then between 9:30 and 12:30 pm, please.\nSystem: I found four direct business class flights from New York to Frankfurt. All these\nflights are in the moderate price range. All these flights depart between 6 and\n"},{"#tail":"\n","@confidence":"0.637547869565217","#text":"\nComputational Linguistics Volume 37, Number 3\nFlight booking with UMSR system?New York to Frankfurt\nSystem: This is the FLIGHTS information system. I am now connected to the network.\nWould you like to book a flight?\nUser: Yes.\nSystem: Tell me what do you want to book?\nUser: I would like to book a business class flight from New York to Frankfurt on\nKLM.\nSystem: Tell me the date on which you want to travel?\nUser: January 15th.\nSystem: There are six direct flights from New York to Frankfurt with availability in\nbusiness class. The only KLM flight with availability in business class arrives\nat 1:35 pm and requires a connection.\nUser: Tell me about the KLM flight.\nSystem: I found one flight with availability on business class from New York to\nFrankfurt on KLM. It arrives at 1:35 pm with a total travel time of 12 hours\nand 35 minutes and costs 1,260 pounds. Would you like to book the KLM\nflight?\nUser: Yes, please.\nSystem: Sounds good, let me book this flight for you. This will take a moment. Thank\nyou for waiting; the electronic ticket and itinerary have been emailed to you.\nWould you like to book another flight?\nUser: No.\nSystem: OK, goodbye.\nFlight booking with SR system?New York to Frankfurt\nSystem: This is the FLIGHTS information system. I am now connected to the network.\nWould you like to book a flight?\nUser: Yes, I would like to book a flight from New York to Frankfurt on January 15th.\nSystem: I found 23 flights from New York to Frankfurt. There are direct flights as well\nas flights that require connection. I also have information about fare classes.\nUser: I need a business class flight.\nSystem: I found 17 business class flights from New York to Frankfurt. I have informa-\ntion about arrival times. There are direct flights as well as flights that require\nconnection.\nUser: It should arrive in the late morning, around 11:00.\nSystem: I found 13 business class flights from New York to Frankfurt arriving between\n9:00 and 11:30 am. There are direct flights as well as flights that require\nconnection. I also have information about departure times.\nUser: How many of those flights are direct?\nSystem: I found 4 direct business class flights from New York to Frankfurt arriving\nbetween 9:00 and 11:30 am. All these flights are in the moderate price range.\nAll these flights depart between 6:00 and 9:00 pm. The flights are on United,\nContinental, and Delta.\nUser: Are any on KLM?\nSystem: I found no direct business class flight from New York to Frankfurt flying on\nKLM arriving between 9:00 and 11:30 am.\n"},{"#tail":"\n","@confidence":"0.936570833333333","#text":"\nSystem: I found three direct flights from New York to Frankfurt with availability in\nbusiness class that will get you there on time. But none are on KLM. If you\ndon?t mind arriving earlier there is a shorter direct flight on United.\nUser: When is that going to be?\nSystem: I found one direct United flight that departs at 7:00 pm and arrives at 9:10 am.\nIt has the shortest total travel time of only 8 hours and 10 minutes and costs\n"}],"#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.9943","#text":"\nSaarland University\n"},{"#tail":"\n","@confidence":"0.982155","#text":"\nUniversity of Amsterdam\n"},{"#tail":"\n","@confidence":"0.978579","#text":"\nUniversity of Edinburgh\n"}],"sectionHeader":[{"#tail":"\n","@confidence":"0.990274","@genericHeader":"abstract","#text":"\n1. Introduction\n"},{"#tail":"\n","@confidence":"0.601657","@genericHeader":"keywords","#text":"\n2 FLIGHTS expands as Fancy Linguistically Informed Generation of Highly Tailored Speech.\n"},{"#tail":"\n","@confidence":"0.894397","@genericHeader":"introduction","#text":"\n3 In the original implementation as reported in Polifroni, Chung, and Seneff (2003), however, the cluster\n"},{"#tail":"\n","@confidence":"0.897811","@genericHeader":"method","#text":"\n4 The choice of a maximum of three clusters as a stopping criterion is somewhat arbitrary. A clustering\n"},{"#tail":"\n","@confidence":"0.929428","@genericHeader":"method","#text":"\n5. Controlling Dialog Turn Length\n"},{"#tail":"\n","@confidence":"0.294071","@genericHeader":"method","#text":"\n6. Evaluation II ? User Interaction Study\n"},{"#tail":"\n","@confidence":"0.707213","@genericHeader":"method","#text":"\n7. Discussion\n"},{"#tail":"\n","@confidence":"0.719005","@genericHeader":"method","#text":"\n8. Related Work\n"},{"#tail":"\n","@confidence":"0.883911","@genericHeader":"conclusions","#text":"\n9. Conclusions and Future Work\n"},{"#tail":"\n","@confidence":"0.910217","@genericHeader":"acknowledgments","#text":"\nAcknowledgments\n"},{"#tail":"\n","@confidence":"0.846937","@genericHeader":"references","#text":"\nReferences\n"},{"#tail":"\n","@confidence":"0.429076","@genericHeader":"references","#text":"\n2 pm.\n"}],"tableCaption":{"#tail":"\n","@confidence":"0.818988","#text":"\nTable 1\nSystem contributions: Requesting and presenting information in Communicator systems.\n"},"page":[{"#tail":"\n","@confidence":"0.996228","#text":"\n490\n"},{"#tail":"\n","@confidence":"0.993163","#text":"\n491\n"},{"#tail":"\n","@confidence":"0.998566","#text":"\n492\n"},{"#tail":"\n","@confidence":"0.99856","#text":"\n493\n"},{"#tail":"\n","@confidence":"0.998881","#text":"\n494\n"},{"#tail":"\n","@confidence":"0.99847","#text":"\n495\n"},{"#tail":"\n","@confidence":"0.999589","#text":"\n496\n"},{"#tail":"\n","@confidence":"0.998099","#text":"\n497\n"},{"#tail":"\n","@confidence":"0.998231","#text":"\n498\n"},{"#tail":"\n","@confidence":"0.998539","#text":"\n499\n"},{"#tail":"\n","@confidence":"0.970176","#text":"\n500\n"},{"#tail":"\n","@confidence":"0.995242","#text":"\n501\n"},{"#tail":"\n","@confidence":"0.994277","#text":"\n502\n"},{"#tail":"\n","@confidence":"0.994398","#text":"\n503\n"},{"#tail":"\n","@confidence":"0.997681","#text":"\n504\n"},{"#tail":"\n","@confidence":"0.997176","#text":"\n505\n"},{"#tail":"\n","@confidence":"0.997315","#text":"\n506\n"},{"#tail":"\n","@confidence":"0.988014","#text":"\n507\n"},{"#tail":"\n","@confidence":"0.997382","#text":"\n508\n"},{"#tail":"\n","@confidence":"0.993111","#text":"\n509\n"},{"#tail":"\n","@confidence":"0.984441","#text":"\n510\n"},{"#tail":"\n","@confidence":"0.9908","#text":"\n511\n"},{"#tail":"\n","@confidence":"0.981253","#text":"\n512\n"},{"#tail":"\n","@confidence":"0.989088","#text":"\n513\n"},{"#tail":"\n","@confidence":"0.991754","#text":"\n514\n"},{"#tail":"\n","@confidence":"0.940101","#text":"\n515\n"},{"#tail":"\n","@confidence":"0.995124","#text":"\n516\n"},{"#tail":"\n","@confidence":"0.980737","#text":"\n517\n"},{"#tail":"\n","@confidence":"0.99761","#text":"\n518\n"},{"#tail":"\n","@confidence":"0.990553","#text":"\n519\n"},{"#tail":"\n","@confidence":"0.948785","#text":"\n520\n"},{"#tail":"\n","@confidence":"0.984115","#text":"\n521\n"},{"#tail":"\n","@confidence":"0.99613","#text":"\n522\n"},{"#tail":"\n","@confidence":"0.998943","#text":"\n523\n"},{"#tail":"\n","@confidence":"0.997459","#text":"\n524\n"},{"#tail":"\n","@confidence":"0.987555","#text":"\n525\n"},{"#tail":"\n","@confidence":"0.99212","#text":"\n526\n"},{"#tail":"\n","@confidence":"0.961981","#text":"\n527\n"},{"#tail":"\n","@confidence":"0.969159","#text":"\n528\n"},{"#tail":"\n","@confidence":"0.99134","#text":"\n529\n"},{"#tail":"\n","@confidence":"0.904329","#text":"\n530\n"},{"#tail":"\n","@confidence":"0.963173","#text":"\n531\n"},{"#tail":"\n","@confidence":"0.966136","#text":"\n532\n"},{"#tail":"\n","@confidence":"0.994567","#text":"\n533\n"},{"#tail":"\n","@confidence":"0.996136","#text":"\n534\n"},{"#tail":"\n","@confidence":"0.98513","#text":"\n535\n"},{"#tail":"\n","@confidence":"0.99553","#text":"\n536\n"},{"#tail":"\n","@confidence":"0.95862","#text":"\n537\n"},{"#tail":"\n","@confidence":"0.992718","#text":"\n538\n"},{"#tail":"\n","@confidence":"0.998441","#text":"\n539\n"}],"figureCaption":[{"#tail":"\n","@confidence":"0.559623","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nFigure 4\n"},{"#tail":"\n","@confidence":"0.6465165","#text":"\nComputational Linguistics Volume 37, Number 3\nFigure 7\n"},{"#tail":"\n","@confidence":"0.5482615","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nFigure 9\n"},{"#tail":"\n","@confidence":"0.76035875","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nFigure 11\nDescriptive versions of example user models used in our experiments.\nFigure 12\n"},{"#tail":"\n","@confidence":"0.5982815","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nFigure 14\n"},{"#tail":"\n","@confidence":"0.76475175","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nFigure 16\nExample summaries based on association rule clustering, without and with user-model based\nranking, from Polifroni and Walker (2008).\n"}],"table":[{"#tail":"\n","@confidence":"0.92510025","#text":"\nSystem Requesting info Presenting info Other\nUtterances 43% 25% 32%\nTime 31% 54% 15%\nWords 28% 50% 22%\n"},{"#tail":"\n","@confidence":"0.840473857142857","#text":"\n?6.39; p < 0.0001; Table 3).\nTable 3\nNumber of turns per booking and average dialog duration for two bookings (in seconds) for SR\nand UMSR.\nSR UMSR\nTurns 14.53** 10.53**\nDuration (sec) 391.65** 252.55**\n"},{"#tail":"\n","@confidence":"0.320507","#text":"\nTechnical Report IAC-04-T.3.07, NASA\nAmes Research Center, Mountain\nView, CA.\n"},{"#tail":"\n","@confidence":"0.797609642857143","#text":"\nTechnology Workshop SLT ?06, December,\nAruba.\nMoore, Johanna D., Mary Ellen Foster,\nOliver Lemon, and Michael White. 2004.\nGenerating tailored, comparative\ndescriptions in spoken dialogue. In\nProceedings of the Seventeenth International\nFlorida Artificial Intelligence Research Sociey\nConference, AAAI Press, pages 917?922,\nMiami Beach, FL.\nNass, C. and S. Brave. 2005. Wired for Speech:\nHow Voice Activates and Advances the\nHuman?Computer Relationship. The MIT\nPress, Cambridge, MA.\n"},{"#tail":"\n","@confidence":"0.679732","#text":"\nDemberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs\nAppendix 1: Dialogue Scripts for Experiments 1 and 2\nTraining Scenario (Steve)\nSteve?s user profile:\n"},{"#tail":"\n","@confidence":"0.688200333333333","#text":"\nComputational Linguistics Volume 37, Number 3\nWalter: Please tell me more about the Air France Flight.\nSystem: The Air France flight leaves Edinburgh at 9:05 am and arrives San Francisco\nat 3:45 pm. You need to connect in Paris. The flight costs 1,611 pounds on\nbusiness class.\nAppendix 2: Dialogue Samples for Experiment 3\nTask descriptions for participants:\nTask A: You need to book a flight from Edinburgh to San Francisco departing on\nMay 12th. You?d like to fly business class and arrive in San Francisco around\n4 pm, so that you have time to check into your hotel and shower before your\n7 o?clock dinner meeting.\nTask B: You need to book a flight from Edinburgh to Brussels departing on May 20th.\n"}]}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.245894","#tail":"\n","@no":"0","note":{"#tail":"\n","@confidence":"0.980907","#text":"Submission received: 18 June 2009; revised submission received: 4 October 2010; accepted for publication: 1 December 2010. ? 2011 Association for Computational Linguistics Computational Linguistics Volume 37, Number 3"},"address":[{"#tail":"\n","@confidence":"0.761643","#text":"Cluster of Excellence, Saarland University, Campus C7 4, 66041 Saarbru?cken, Germany."},{"#tail":"\n","@confidence":"0.9410735","#text":"The Netherlands. E-mail: A.Winterboer@uva.nl. ? School of Informatics, University of Edinburgh, 10 Crichton Street, Edinburgh EH8 9AB, UK."}],"#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.999986","#text":"Saarland University"},{"#tail":"\n","@confidence":"0.997307","#text":"University of Amsterdam"},{"#tail":"\n","@confidence":"0.999165","#text":"University of Edinburgh"},{"#tail":"\n","@confidence":"0.98397","#text":"Intelligent Systems Lab Amsterdam, University of Amsterdam, Science Park 904, 1098 XH Amsterdam,"}],"author":[{"#tail":"\n","@confidence":"0.983334","#text":"Vera Demberg"},{"#tail":"\n","@confidence":"0.791296","#text":"Andi Winterboer"},{"#tail":"\n","@confidence":"0.533984","#text":"Johanna D Moore"}],"abstract":{"#tail":"\n","@confidence":"0.999069","#text":"In spoken dialog systems, information must be presented sequentially, making it difficult to quickly browse through a large number of options. Recent studies have shown that user satisfaction is negatively correlated with dialog duration, suggesting that systems should be designed to maximize the efficiency of the interactions. Analysis of the logs of 2,000 dialogs between users and nine different dialog systems reveals that a large percentage of the time is spent on the information presentation phase, thus there is potentially a large pay-off to be gained from optimizing information presentation in spoken dialog systems. This article proposes a method that improves the efficiency of coping with large numbers of diverse options by selecting options and then structuring them based on a model of the user?s preferences. This enables the dialog system to automatically determine trade-offs between alternative options that are relevant to the user and present these trade-offs explicitly. Multiple attractive options are thereby structured such that the user can gradually refine her request to find the optimal trade-off. To evaluate and challenge our approach, we conducted a series of experiments that test the effectiveness of the proposed strategy. Experimental results show that basing the content structuring and content selection process on a user model increases the efficiency and effectiveness of the user?s interaction. Users complete their tasks more successfully and more quickly. Furthermore, user surveys revealed that participants found that the user-model based system presents complex trade-offs understandably and increases overall user satisfaction. The experiments also indicate that presenting users with a brief overview of options that do not fit their requirements significantly improves the user?s overview of available options, also making them feel more confident in having been presented with all relevant options."},"title":{"#tail":"\n","@confidence":"0.999424","#text":"A Strategy for Information Presentation in Spoken Dialog Systems"},"email":[{"#tail":"\n","@confidence":"0.996714","#text":"E-mail:vera@coli.uni-saarland.de."},{"#tail":"\n","@confidence":"0.959752","#text":"E-mail:j.moore@ed.ac.uk."}]}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Bos, Johan, Ewan Klein, Oliver Lemon, and Tetsushi Oka. 2003. Dipper: Description and formalisation of an information-state update dialogue system architecture. In 4th SIGdial Workshop on Discourse and Dialogue, pages 115?124, Sapporo."},"#text":"\n","pages":{"#tail":"\n","#text":"115--124"},"marker":{"#tail":"\n","#text":"Bos, Klein, Lemon, Oka, 2003"},"location":{"#tail":"\n","#text":"Sapporo."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" Table 2 Attribute ranking for business user. Rank Attributes 1 fare class (preferred value: business) 2 arrival time, # of legs, departure time, travel time 6 airline (preferred value: KLM) 7 price, layover airport 496 Demberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs Figure 4 System architecture with emphasis on information presentation phase. The system uses the Open Agent Architecture (OAA) framework (Martin, Cheyer, and Moran 1999) as a communication hub. All modules are implemented as agents, whose communication is managed by the DIPPER dialog manager agent (Bos et al 2003), which invokes the different agents and stores the intermediate results from each component. The approach proposed in this article concerns the content structuring and selection step of the system, and is a new design. It consists of three major steps: clustering, building the option tree, and pruning. The first step in our content structuring algorithm is to cluster the values of each attribute in order to group them such that labels like cheap, moderate, and expensive can be assigned to values of continuous categories such as price. This clustering means that options can also be summarized ","@endWordPosition":"3967","@position":"25539","annotationId":"T1","@startWordPosition":"3964","@citStr":"Bos et al 2003"}},"title":{"#tail":"\n","#text":"Dipper: Description and formalisation of an information-state update dialogue system architecture."},"booktitle":{"#tail":"\n","#text":"In 4th SIGdial Workshop on Discourse and Dialogue,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Johan Bos"},{"#tail":"\n","#text":"Ewan Klein"},{"#tail":"\n","#text":"Oliver Lemon"},{"#tail":"\n","#text":"Tetsushi Oka"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Carenini, Giuseppe and Johanna D. Moore. 2001. An empirical study of the influence of user tailoring on evaluative argument effectiveness. In Proceedings of the 17th International Joint Conference on Artificial Intelligence, pages 1307?1314, Seattle, WA."},"#text":"\n","pages":{"#tail":"\n","#text":"1307--1314"},"marker":{"#tail":"\n","#text":"Carenini, Moore, 2001"},"location":{"#tail":"\n","#text":"Seattle, WA."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"t on the relation of this system to other systems from the literature in section 8, and discuss implications of our findings and future directions in Section 9. 2. Background on User Modeling and Content Structuring for Information Presentation 2.1 Tailoring to a User Model (UM) Previous work in natural language generation showed how a multi-attribute decisiontheoretic model of user preferences can be used in a recommender system to determine which options to mention to a particular user, as well as the attributes that the user will find most relevant for choosing among the available options (Carenini and Moore 2001). In the MATCH system, Walker et al (2004) applied this approach to information presentation in SDSs, and extended it to generate summaries and comparisons among options. Evaluation of the MATCH system showed that tailoring recommendations and comparisons to the user increases argument effectiveness and improves user satisfaction (Walker et al 2004). MATCH included content planning algorithms to determine what options and attributes to mention, but used a simple template-based approach to realization. For the design of the FLIGHTS2 system, Moore et al (2004) focused on organizing and expressin","@endWordPosition":"1555","@position":"10357","annotationId":"T2","@startWordPosition":"1552","@citStr":"Carenini and Moore 2001"},{"#tail":"\n","#text":" for constructing and pruning the option tree, which structures all of the options that satisfy the user?s query into the tree and selects the entities that should be mentioned. The text planning step takes the pruned option tree as an input and transforms it into natural language. First, it determines how much information can be presented in one dialog turn, and how to structure the information in that turn. For example, in systems that aim to influence the user?s choice, such as product recommendation systems, the ordering can be arranged to increase the effectiveness of the recommendation (Carenini and Moore 2001). There exists a full generation pipeline for this system, as described in Moore et al (2004). However, for the experiments reported here, templates were used instead of the full generation pipeline, for reasons of robustness. Table 2 Attribute ranking for business user. Rank Attributes 1 fare class (preferred value: business) 2 arrival time, # of legs, departure time, travel time 6 airline (preferred value: KLM) 7 price, layover airport 496 Demberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs Figure 4 System architecture with emphasis on information presentation phas","@endWordPosition":"3838","@position":"24698","annotationId":"T3","@startWordPosition":"3835","@citStr":"Carenini and Moore 2001"}]},"title":{"#tail":"\n","#text":"An empirical study of the influence of user tailoring on evaluative argument effectiveness."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 17th International Joint Conference on Artificial Intelligence,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Giuseppe Carenini"},{"#tail":"\n","#text":"Johanna D Moore"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Carletta, Jean. 2007. Unleashing the killer corpus: Experiences in creating the multi-everything ami meeting corpus. Demberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs Language Resources and Evaluation, 41(2):181?190."},"#text":"\n","pages":{"#tail":"\n","#text":"41--2"},"marker":{"#tail":"\n","#text":"Carletta, 2007"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ation strategy in the context of an actual interaction, there are still a number of shortcomings. An ideal user evaluation would use actual automatic speech recognition and language Figure 15 Results for all questions, interaction experiment. 516 Demberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs understanding instead of the wizard performing these actions. In addition, it would use the actual model of each user rather than ask them to role-play. Although role-playing is an often used methodology in SDS evaluations (Polifroni and Walker 2008) and corpus collection (Carletta 2007), we recognize that there are concerns with respect to assigning subjects a user model as opposed to using the participants? own models. Possible problems with role-playing include the fact that participants may have incorrect expectations about the needs and preferences of the role they are supposed to play, and that they might not adopt the role sufficiently. Furthermore, a scenario where participants are role-playing cannot test how good the user model is, or how robust a user-adaptation system is. We chose role-playing as a method despite these concerns because it allows us to more closely","@endWordPosition":"13248","@position":"82810","annotationId":"T4","@startWordPosition":"13247","@citStr":"Carletta 2007"}},"title":{"#tail":"\n","#text":"Unleashing the killer corpus: Experiences in creating the multi-everything ami meeting corpus. Demberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs Language Resources and Evaluation,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Jean Carletta"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Chung, Grace. 2004. Developing a flexible spoken dialog system using simulation. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL?04), Main Volume, pages 63?70, Barcelona."},"#text":"\n","pages":{"#tail":"\n","#text":"63--70"},"marker":{"#tail":"\n","#text":"Chung, 2004"},"location":{"#tail":"\n","#text":"Barcelona."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"approaches to information presentation that present an alternative to sequential information presentation have been proposed. In the user-model (UM) based approach, the system identifies a small number of options that best match the user?s preferences (Moore et al 2004; Walker et al 2004). In the summarize and refine (SR) approach, the system structures the large number of options into a small number of clusters that share attributes. The system then summarizes the clusters based on their attributes, thus prompting the user to provide additional constraints (Polifroni, Chung, and Seneff 2003; Chung 2004). In this article, we propose an approach to information presentation which shortens dialog duration by combining the benefits of these two approaches (UMSR). Our 1 This analysis was performed on the Communicator corpus which has been annotated extensively, including annotations for speech act types and timing information (Walker and Passonneau 2001; Georgila et al 2009). 490 Demberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs Figure 1 Typical information presentation phase of a communicator dialog. Table 1 System contributions: Requesting and presenting information ","@endWordPosition":"913","@position":"6161","annotationId":"T5","@startWordPosition":"912","@citStr":"Chung 2004"},{"#tail":"\n","#text":"additional refinements for underconstrained queries, as in You could try to look for cuisine type? (Pon-Barry, Weng, and Varges 2006; Varges, Weng, and Pon-Barry 2006), or relaxations for over-constrained queries, as in Would a slightly more expensive flight work for you? (Qu and Beale 1999; PonBarry, Weng, and Varges 2006). Additionally, constraints can be relaxed automatically based an ontology (Varges, Weng, and Pon-Barry 2006) or by predefining relaxation sets (e.g., from a specific street for a restaurant to the broader neighborhood) or categorical ones (e.g., relaxing Chinese to Asian) (Chung 2004). 9. Conclusions and Future Work The research presented in this article addresses the issue of how to scale information presentation strategies for spoken dialog systems to situations where many diverse options are available. We developed an approach that combines content selection with content structuring, and showed how a user model can inform both of these steps to optimize efficiency and effectiveness of the information presentation phase in spoken dialog systems. The knowledge derived from the user model can be used to enable a dialog system to automatically present trade-offs between the","@endWordPosition":"15088","@position":"94594","annotationId":"T6","@startWordPosition":"15087","@citStr":"Chung 2004"}]},"title":{"#tail":"\n","#text":"Developing a flexible spoken dialog system using simulation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL?04), Main Volume,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Grace Chung"}}},{"volume":{"#tail":"\n","#text":"6"},"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"Dahlba?ck, N., A. Jo?nsson, and L. Ahrenberg. 1993. Wizard of Oz studies?why and how. Knowledge-Based Systems, 6(4):258?266."},"journal":{"#tail":"\n","#text":"Knowledge-Based Systems,"},"#text":"\n","issue":{"#tail":"\n","#text":"4"},"marker":{"#tail":"\n","#text":"Dahlback, Jonsson, Ahrenberg, 1993"},"title":{"#tail":"\n","#text":"Wizard of Oz studies?why and how."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"N Dahlback"},{"#tail":"\n","#text":"A Jonsson"},{"#tail":"\n","#text":"L Ahrenberg"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Demberg, V. and Johanna D. Moore. 2006. Information presentation in spoken dialogue systems. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL), pages 65?72, Trento."},"#text":"\n","pages":{"#tail":"\n","#text":"65--72"},"marker":{"#tail":"\n","#text":"Demberg, Moore, 2006"},"location":{"#tail":"\n","#text":"Trento."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"signed to select attributes that generalize well over the data (i.e., produce large clusters of options), and thus lead to efficient summarization. Hence attributes that partition the data set into a small number of clusters are preferred. If the attribute that is best for summarization is not of interest to a particular user, dialog duration is increased unnecessarily. This in turn may lead to reduced user satisfaction, as the results of our evaluation suggest (see Section 4.1.3). 3. Our Approach: User Model Based Summarize and Refine (UMSR) Our approach, the UMSR approach first described in Demberg and Moore (2006), is intended to capture the complementary strengths of the two previous approaches. It exploits information from a user model to reduce dialog duration by selecting only options that are relevant to the user. In addition, we introduce a content structuring algorithm that supports stepwise refinement, as in Polifroni, Chung, and Seneff (2003), 494 Demberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs but in which the structuring reflects the user?s preferences. Thus our approach maintains the benefits of user tailoring, while also being capable of dealing with a large ","@endWordPosition":"2765","@position":"17948","annotationId":"T7","@startWordPosition":"2762","@citStr":"Demberg and Moore (2006)"}},"title":{"#tail":"\n","#text":"Information presentation in spoken dialogue systems."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"V Demberg"},{"#tail":"\n","#text":"Johanna D Moore"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1981"},"rawString":{"#tail":"\n","#text":"Ehrlich, S. F. and K. Rayner. 1981. Contextual effects on word recognition and eye movements during reading. Journal of Verbal Learning and Verbal Behaviour, 20:641?655."},"journal":{"#tail":"\n","#text":"Journal of Verbal Learning and Verbal Behaviour,"},"#text":"\n","pages":{"#tail":"\n","#text":"20--641"},"marker":{"#tail":"\n","#text":"Ehrlich, Rayner, 1981"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ystem turn. This is, however, a very coarse measure, as different linguistic factors have also been shown to affect cognitive load on users. For example, surprising or incoherent information structure has been observed to be more difficult to process (Vauras, Hyo?na?, and Niemi 1992; Van Gompel, Liversedge, and Pearson 2004), and complex syntactic structures (e.g., long-distance dependencies) have been shown to impose difficulty (Gibson 1998). Language processing difficulty is also affected by frequency: Less frequent structures and words are more difficult to process than more frequent ones (Ehrlich and Rayner 1981; Rayner 1998; Rayner et al 1998). Furthermore, lexical access (Pollatsek and Rayner 1990) and word predictability (Rayner et al 2001) have also been shown to play a role. Finally, deciding what is an information unit and estimating how difficult they are to remember (and recall) for a particular user is not a trivial task, and is highly dependent on individual differences in affect, aptitude, intelligence, episodic memory, and so on. Therefore, a more fine-grained estimation of the cognitive load imposed on a user based on the number of information units to remember, the syntactic structure o","@endWordPosition":"16191","@position":"101709","annotationId":"T8","@startWordPosition":"16188","@citStr":"Ehrlich and Rayner 1981"}},"title":{"#tail":"\n","#text":"Contextual effects on word recognition and eye movements during reading."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"S F Ehrlich"},{"#tail":"\n","#text":"K Rayner"}]}},{"volume":{"#tail":"\n","#text":"15"},"#tail":"\n","date":{"#tail":"\n","#text":"2009"},"rawString":{"#tail":"\n","#text":"Georgila, Kallirroi, Oliver Lemon, James Henderson, and Johanna D. Moore. 2009. Automatic annotation of context and speech acts for dialogue corpora. Natural Language Engineering, 15(3):315?353."},"journal":{"#tail":"\n","#text":"Natural Language Engineering,"},"#text":"\n","issue":{"#tail":"\n","#text":"3"},"marker":{"#tail":"\n","#text":"Georgila, Lemon, Henderson, Moore, 2009"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"e number of options into a small number of clusters that share attributes. The system then summarizes the clusters based on their attributes, thus prompting the user to provide additional constraints (Polifroni, Chung, and Seneff 2003; Chung 2004). In this article, we propose an approach to information presentation which shortens dialog duration by combining the benefits of these two approaches (UMSR). Our 1 This analysis was performed on the Communicator corpus which has been annotated extensively, including annotations for speech act types and timing information (Walker and Passonneau 2001; Georgila et al 2009). 490 Demberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs Figure 1 Typical information presentation phase of a communicator dialog. Table 1 System contributions: Requesting and presenting information in Communicator systems. System Requesting info Presenting info Other Utterances 43% 25% 32% Time 31% 54% 15% Words 28% 50% 22% approach integrates user modeling with automated clustering such that information is structured in a way that enables users to more effectively and efficiently browse the option space. The system provides detail only about those options that are","@endWordPosition":"969","@position":"6534","annotationId":"T9","@startWordPosition":"966","@citStr":"Georgila et al 2009"}},"title":{"#tail":"\n","#text":"Automatic annotation of context and speech acts for dialogue corpora."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kallirroi Georgila"},{"#tail":"\n","#text":"Oliver Lemon"},{"#tail":"\n","#text":"James Henderson"},{"#tail":"\n","#text":"Johanna D Moore"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Gibson, Edward. 1998. Linguistic complexity?locality of syntactic dependencies. Cognition, 68:1?76."},"journal":{"#tail":"\n","#text":"Cognition,"},"#text":"\n","pages":{"#tail":"\n","#text":"68--1"},"marker":{"#tail":"\n","#text":"Gibson, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"d the system-generated utterances place on the user. In this work, we try to manage cognitive load by controlling how many pieces of information are conveyed in one system turn. This is, however, a very coarse measure, as different linguistic factors have also been shown to affect cognitive load on users. For example, surprising or incoherent information structure has been observed to be more difficult to process (Vauras, Hyo?na?, and Niemi 1992; Van Gompel, Liversedge, and Pearson 2004), and complex syntactic structures (e.g., long-distance dependencies) have been shown to impose difficulty (Gibson 1998). Language processing difficulty is also affected by frequency: Less frequent structures and words are more difficult to process than more frequent ones (Ehrlich and Rayner 1981; Rayner 1998; Rayner et al 1998). Furthermore, lexical access (Pollatsek and Rayner 1990) and word predictability (Rayner et al 2001) have also been shown to play a role. Finally, deciding what is an information unit and estimating how difficult they are to remember (and recall) for a particular user is not a trivial task, and is highly dependent on individual differences in affect, aptitude, intelligence, episodic mem","@endWordPosition":"16165","@position":"101532","annotationId":"T10","@startWordPosition":"16164","@citStr":"Gibson 1998"}},"title":{"#tail":"\n","#text":"Linguistic complexity?locality of syntactic dependencies."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Edward Gibson"}}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Technical Report IAC-04-T.3.07,"},"date":{"#tail":"\n","#text":"2007"},"institution":{"#tail":"\n","#text":"NASA Ames Research Center,"},"rawString":{"#tail":"\n","#text":"Hieronymus, James L. and John Dowding. 2007. Clarissa spoken dialogue system for procedure reading and navigation. Technical Report IAC-04-T.3.07, NASA Ames Research Center, Mountain View, CA."},"#text":"\n","marker":{"#tail":"\n","#text":"Hieronymus, Dowding, 2007"},"location":{"#tail":"\n","#text":"Mountain View, CA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"n received: 18 June 2009; revised submission received: 4 October 2010; accepted for publication: 1 December 2010. ? 2011 Association for Computational Linguistics Computational Linguistics Volume 37, Number 3 1. Introduction A common goal of many spoken dialog systems (SDSs) is to offer efficient and natural access to applications and services, such as e-mail, calendars, travel booking, navigation systems, and product recommendation, in situations where the user?s hands and/or eyes are busy with another task, for example driving a car (Pon-Barry, Weng, and Varges 2006) or operating equipment (Hieronymus and Dowding 2007). The naturalness and usability of a spoken dialog interface depends not only on its ability to recognize and interpret user utterances correctly, but also on its ability to present information in ways that users can understand and that help them to achieve their goals. One class of SDSs that has received considerable attention from both academic research and industry are information-seeking SDSs, which are designed to enable users to browse the space of available options (e.g., flights, hotels, movies) and choose a suitable option from a potentially large set of choices. Dialogs with such sys","@endWordPosition":"451","@position":"3161","annotationId":"T11","@startWordPosition":"448","@citStr":"Hieronymus and Dowding 2007"}},"title":{"#tail":"\n","#text":"Clarissa spoken dialogue system for procedure reading and navigation."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"James L Hieronymus"},{"#tail":"\n","#text":"John Dowding"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Hu, J., A. Winterboer, C. I. Nass, J. D. Moore, and R. Illowsky. 2007. Context and usability testing: User-modeled information presentation in easy and difficult driving conditions. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pages 1343?1346, San Jose, CA."},"#text":"\n","pages":{"#tail":"\n","#text":"1343--1346"},"marker":{"#tail":"\n","#text":"Hu, Winterboer, Nass, Moore, Illowsky, 2007"},"location":{"#tail":"\n","#text":"San Jose, CA."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" only those options that are likely to be relevant to the user, and explicitly points out trade-offs among options, we hypothesized that it would also consume less cognitive resources, that is, presentations based on UMSR would impose less cognitive load than those based on SR. Therefore, in parallel to our work on the interaction task experiment, a companion project conducted experiments using a dual-task setting (driving a simulated car while using the dialog system to book flights) to investigate the effects of the two strategies to information presentation (UMSR vs. SR) on cognitive load (Hu et al 2007). Results indicated that, contrary to expectations, the cognitive load placed on users by the UMSR system was in some cases higher than the cognitive load placed on users in the SR condition, and that this affected performance on the primary task (driving). By examining logs of the conversations, we found that the UMSR approach sometimes generated turns that were considerably longer than turns produced by the SR approach. Because we are primarily interested in whether the content selection and structuring aspects of UMSR led to its benefits, we removed the confounding factor of turn length by ","@endWordPosition":"11139","@position":"69443","annotationId":"T12","@startWordPosition":"11136","@citStr":"Hu et al 2007"},{"#tail":"\n","#text":"ment, with the UMSR system also requiring fewer dialog turns. Furthermore, participants reported that they felt the optimal option was accessed more quickly in the UMSR condition than in the SR condition in all three experiments. Did the UMSR Approach Make Information Presentation More Effective? This hypothesis was tested in the interaction task experiment by measuring task success. We found that users chose the option that was best for the role they were playing more often in the interaction experiment. These findings also agree with results obtained in other work, using a dual-task method (Hu et al 2007; Winterboer et al 2007). Thus, we conclude that information access with the UMSR approach is more effective than with the SR approach. Did UMSR Provide a Better Overview of the Option Space and Was Higher Confidence Achieved with UMSR? Questions 2 (?Did the system give X a good overview of the available options??) and 3 (?Do you think there may be flights that are better options for X that the system did not tell X about??) of the questionnaire were designed to assess this aspect. The first two experiments showed a clear preference for the UMSR system in comparison with the SR system. Partici","@endWordPosition":"13573","@position":"84889","annotationId":"T13","@startWordPosition":"13570","@citStr":"Hu et al 2007"}]},"title":{"#tail":"\n","#text":"Context and usability testing: User-modeled information presentation in easy and difficult driving conditions."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"J Hu"},{"#tail":"\n","#text":"A Winterboer"},{"#tail":"\n","#text":"C I Nass"},{"#tail":"\n","#text":"J D Moore"},{"#tail":"\n","#text":"R Illowsky"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Komatani, Kazunori, Shinichi Ueno, Tatsuya Kawahara, and Hiroshi G. Okuno. 2003."},"#text":"\n","marker":{"#tail":"\n","#text":"Komatani, Ueno, Kawahara, Okuno, 2003"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ptions that the user model determines to be irrelevant (see Section 3.5). By providing users with an overview of the whole option space, we reduce the risk of leaving out options the user may wish to choose in a specific situation (thus overriding her standard user model). The level of detail that the system chooses to present options which are likely to be irrelevant to the user is a trade-off between efficiency and quality of overview. If a situational user model with information about the degree of urgency is available, such overview summaries could be left out when the user is in a hurry (Komatani et al 2003). Increasing User Satisfaction. We hypothesize that a system that implements the features discussed here will lead to greater overall user satisfaction. 495 Computational Linguistics Volume 37, Number 3 3.1 Implementation Our approach to information presentation was implemented within FLIGHTS, a spoken dialog system for flight booking (Moore et al 2004). The options in the flight booking domain are flight connections with the attributes arrival-time, departure-time, number-of-legs, travel-time, price, airline, fare-class, and layover-airport. A user model contains a partial ordering of these a","@endWordPosition":"3377","@position":"21748","annotationId":"T14","@startWordPosition":"3374","@citStr":"Komatani et al 2003"}},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kazunori Komatani"},{"#tail":"\n","#text":"Shinichi Ueno"},{"#tail":"\n","#text":"Tatsuya Kawahara"},{"#tail":"\n","#text":"Hiroshi G Okuno"}]}},{"#tail":"\n","rawString":{"#tail":"\n","#text":"Flexible guidance generation using user model in spoken dialogue systems. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL-2003), pages 256?263, Sapporo."},"#text":"\n","pages":{"#tail":"\n","#text":"256--263"},"marker":{"#tail":"\n"},"location":{"#tail":"\n","#text":"Sapporo."},"title":{"#tail":"\n","#text":"Flexible guidance generation using user model in spoken dialogue systems."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL-2003),"},"@valid":"false"},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Linden, G., S. Hanks, and N. Lesh. 1997. Interactive assessment of user preference models: The automated travel assistant. Courses and Lectures-International Centre for Mechanical Sciences, pages 67?78."},"#text":"\n","pages":{"#tail":"\n","#text":"67--78"},"marker":{"#tail":"\n","#text":"Linden, Hanks, Lesh, 1997"},"title":{"#tail":"\n","#text":"Interactive assessment of user preference models: The automated travel assistant. Courses and Lectures-International Centre for Mechanical Sciences,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"G Linden"},{"#tail":"\n","#text":"S Hanks"},{"#tail":"\n","#text":"N Lesh"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"Martin, David L., Adam J. Cheyer, and Douglas B. Moran. 1999. The open agent architecture: A framework for building distributed software systems. Applied Artificial Intelligence, 91?128."},"journal":{"#tail":"\n","#text":"Applied Artificial Intelligence,"},"#text":"\n","pages":{"#tail":"\n","#text":"91--128"},"marker":{"#tail":"\n","#text":"Martin, Cheyer, Moran, 1999"},"title":{"#tail":"\n","#text":"The open agent architecture: A framework for building distributed software systems."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"David L Martin"},{"#tail":"\n","#text":"Adam J Cheyer"},{"#tail":"\n","#text":"Douglas B Moran"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Moore, Johanna D. 2006. Natural language generation for information presentation. Paper presented at the Spoken Language Technology Workshop SLT ?06, December, Aruba."},"#text":"\n","marker":{"#tail":"\n","#text":"Moore, 2006"},"location":{"#tail":"\n","#text":"December, Aruba."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"on. Moreover, as Walker et al (2004) observe, having to access the set of available options sequentially makes it difficult for the user to remember the various aspects of multiple options and to compare them mentally. Although much research has been conducted on the information gathering phase of spoken dialog systems, relatively little attention has been devoted to information presentation. An analysis of the Communicator corpus consisting of approximately 2,000 dialogs with nine different spoken dialog systems found that information presentation is the main contributor to dialog duration1 (Moore 2006); see Table 1. Moreover, the DARPA Communicator evaluation showed that task duration is negatively correlated with user satisfaction (r = ?0.31, p < 0.001, see Walker, Passonneau, and Boland [2001]). Thus, there is reason to believe that improvements in information presentation will lead to improvements in spoken dialog systems. Recently, two approaches to information presentation that present an alternative to sequential information presentation have been proposed. In the user-model (UM) based approach, the system identifies a small number of options that best match the user?s preferences (Mo","@endWordPosition":"769","@position":"5205","annotationId":"T15","@startWordPosition":"768","@citStr":"Moore 2006"},{"#tail":"\n","#text":"lect attributes that generalize well over the data (i.e., produce large clusters of options), and thus lead to efficient summarization. Hence attributes that partition the data set into a small number of clusters are preferred. If the attribute that is best for summarization is not of interest to a particular user, dialog duration is increased unnecessarily. This in turn may lead to reduced user satisfaction, as the results of our evaluation suggest (see Section 4.1.3). 3. Our Approach: User Model Based Summarize and Refine (UMSR) Our approach, the UMSR approach first described in Demberg and Moore (2006), is intended to capture the complementary strengths of the two previous approaches. It exploits information from a user model to reduce dialog duration by selecting only options that are relevant to the user. In addition, we introduce a content structuring algorithm that supports stepwise refinement, as in Polifroni, Chung, and Seneff (2003), 494 Demberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs but in which the structuring reflects the user?s preferences. Thus our approach maintains the benefits of user tailoring, while also being capable of dealing with a large ","@endWordPosition":"2765","@position":"17948","annotationId":"T16","@startWordPosition":"2764","@citStr":"Moore (2006)"}]},"title":{"#tail":"\n","#text":"Natural language generation for information presentation."},"booktitle":{"#tail":"\n","#text":"Paper presented at the Spoken Language Technology Workshop SLT ?06,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Johanna D Moore"}}},{"date":{"#tail":"\n","#text":"2004"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"6); see Table 1. Moreover, the DARPA Communicator evaluation showed that task duration is negatively correlated with user satisfaction (r = ?0.31, p < 0.001, see Walker, Passonneau, and Boland [2001]). Thus, there is reason to believe that improvements in information presentation will lead to improvements in spoken dialog systems. Recently, two approaches to information presentation that present an alternative to sequential information presentation have been proposed. In the user-model (UM) based approach, the system identifies a small number of options that best match the user?s preferences (Moore et al 2004; Walker et al 2004). In the summarize and refine (SR) approach, the system structures the large number of options into a small number of clusters that share attributes. The system then summarizes the clusters based on their attributes, thus prompting the user to provide additional constraints (Polifroni, Chung, and Seneff 2003; Chung 2004). In this article, we propose an approach to information presentation which shortens dialog duration by combining the benefits of these two approaches (UMSR). Our 1 This analysis was performed on the Communicator corpus which has been annotated extensively, ","@endWordPosition":"860","@position":"5819","annotationId":"T17","@startWordPosition":"857","@citStr":"Moore et al 2004"},{"#tail":"\n","#text":"se refinement. The effectiveness of the tree structure, which directs the dialog flow, is optimized by taking the user?s preferences into account. In order to give the user a good overview of the option space, trade-offs between alternative options are presented explicitly. In addition, despite selecting only the relevant options, the algorithm also briefly accounts for the remaining (irrelevant) options. We hypothesize that this approach will enable users to make more informed choices. Our approach to the problem has been implemented within FLIGHTS, a spoken dialog system for flight booking (Moore et al 2004; White, Clark, and Moore 2010). Our results show that in addition to improving dialog efficiency (in terms of number of dialog turns) and effectiveness (in terms of successful task completion), our approach increases user satisfaction. We hypothesize that user modeling in combination with content selection and structuring as implemented in our UMSR strategy can improve the information presentation phase of spoken dialog systems in the following ways: 1. UMSR leads to increased efficiency of information presentation. 2. UMSR makes information presentation more effective. 3. UMSR enables the sy","@endWordPosition":"1181","@position":"7933","annotationId":"T18","@startWordPosition":"1178","@citStr":"Moore et al 2004"},{"#tail":"\n","#text":" among the available options (Carenini and Moore 2001). In the MATCH system, Walker et al (2004) applied this approach to information presentation in SDSs, and extended it to generate summaries and comparisons among options. Evaluation of the MATCH system showed that tailoring recommendations and comparisons to the user increases argument effectiveness and improves user satisfaction (Walker et al 2004). MATCH included content planning algorithms to determine what options and attributes to mention, but used a simple template-based approach to realization. For the design of the FLIGHTS2 system, Moore et al (2004) focused on organizing and expressing the descriptions of the selected options and attributes in ways that were intended to make the descriptions both easy to understand and memorable. In addition, to increase coherence and naturalness of the descriptions, the system reasons about information structure (Steedman 2000) to control intonation, uses referring expressions that highlight attributes relevant to the user (e.g., a direct flight for a user who wants to minimize connections, vs. the cheapest flight for a user concerned about price), and signals discourse relations (e.g., contrast) with a","@endWordPosition":"1638","@position":"10921","annotationId":"T19","@startWordPosition":"1635","@citStr":"Moore et al (2004)"},{"#tail":"\n","#text":"e irrelevant to the user is a trade-off between efficiency and quality of overview. If a situational user model with information about the degree of urgency is available, such overview summaries could be left out when the user is in a hurry (Komatani et al 2003). Increasing User Satisfaction. We hypothesize that a system that implements the features discussed here will lead to greater overall user satisfaction. 495 Computational Linguistics Volume 37, Number 3 3.1 Implementation Our approach to information presentation was implemented within FLIGHTS, a spoken dialog system for flight booking (Moore et al 2004). The options in the flight booking domain are flight connections with the attributes arrival-time, departure-time, number-of-legs, travel-time, price, airline, fare-class, and layover-airport. A user model contains a partial ordering of these attributes corresponding to the user?s ranking, as shown in Table 2. Furthermore, the user model stores preferences (e.g., for a certain airline or flying business class). In a real-world scenario, the user model can be acquired by requiring the user to register with the system at first use (Moore et al 2004), by building up a user model over time (Thomp","@endWordPosition":"3427","@position":"22103","annotationId":"T20","@startWordPosition":"3424","@citStr":"Moore et al 2004"},{"#tail":"\n","#text":" user?s query into the tree and selects the entities that should be mentioned. The text planning step takes the pruned option tree as an input and transforms it into natural language. First, it determines how much information can be presented in one dialog turn, and how to structure the information in that turn. For example, in systems that aim to influence the user?s choice, such as product recommendation systems, the ordering can be arranged to increase the effectiveness of the recommendation (Carenini and Moore 2001). There exists a full generation pipeline for this system, as described in Moore et al (2004). However, for the experiments reported here, templates were used instead of the full generation pipeline, for reasons of robustness. Table 2 Attribute ranking for business user. Rank Attributes 1 fare class (preferred value: business) 2 arrival time, # of legs, departure time, travel time 6 airline (preferred value: KLM) 7 price, layover airport 496 Demberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs Figure 4 System architecture with emphasis on information presentation phase. The system uses the Open Agent Architecture (OAA) framework (Martin, Cheyer, and Moran 199","@endWordPosition":"3854","@position":"24791","annotationId":"T21","@startWordPosition":"3851","@citStr":"Moore et al (2004)"}]},"title":{"#tail":"\n","#text":"Generating tailored, comparative descriptions in spoken dialogue."},"#tail":"\n","rawString":{"#tail":"\n","#text":"Moore, Johanna D., Mary Ellen Foster, Oliver Lemon, and Michael White. 2004. Generating tailored, comparative descriptions in spoken dialogue. In Proceedings of the Seventeenth International Florida Artificial Intelligence Research Sociey Conference, AAAI Press, pages 917?922, Miami Beach, FL."},"#text":"\n","pages":{"#tail":"\n","#text":"917--922"},"marker":{"#tail":"\n","#text":"Moore, Foster, Lemon, White, 2004"},"publisher":{"#tail":"\n","#text":"AAAI Press,"},"location":{"#tail":"\n","#text":"Miami Beach, FL."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Seventeenth International Florida Artificial Intelligence Research Sociey Conference,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Johanna D Moore"},{"#tail":"\n","#text":"Mary Ellen Foster"},{"#tail":"\n","#text":"Oliver Lemon"},{"#tail":"\n","#text":"Michael White"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"Nass, C. and S. Brave. 2005. Wired for Speech: How Voice Activates and Advances the Human?Computer Relationship. The MIT Press, Cambridge, MA."},"#text":"\n","marker":{"#tail":"\n","#text":"Nass, Brave, 2005"},"publisher":{"#tail":"\n","#text":"The MIT Press,"},"location":{"#tail":"\n","#text":"Cambridge, MA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"eing or hearing the wizard during the experiment. The integrated SQL-based database system contained actual flight information as provided by airlines. The wizard used drop-down menus to perform stepwise queries according to a participant?s requests until a satisfying flight was found and booked. The generated textual information provided by the Web interface was copied-and-pasted to Speechify, a textto-speech (TTS) application provided by Nuance Communications, Inc. All participants heard a synthetic voice of their own gender speaking British English. This choice was motivated by the work of Nass and Brave (2005), which shows that the gender of the voice used for TTS plays a significant role in terms of user preferences and trust in the information provided (users prefer a voice that matches their gender). Participants were encouraged to speak naturally rather than merely to respond to system prompts. The wizard used very few questions as prompts (e.g., What would you like me to book for you?) and would only add additional questions (e.g., Do you have a preferred arrival time?) if the participant remained silent for more than five seconds after a round of information presentation by the system. 6.2 Ex","@endWordPosition":"12198","@position":"76175","annotationId":"T22","@startWordPosition":"12195","@citStr":"Nass and Brave (2005)"}},"title":{"#tail":"\n","#text":"Wired for Speech: How Voice Activates and Advances the Human?Computer Relationship."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"C Nass"},{"#tail":"\n","#text":"S Brave"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2009"},"rawString":{"#tail":"\n","#text":"Paksima, T., K. Georgila, and J. D. Moore. 2009. Evaluating the effectiveness of information presentation in a full end-to-end dialogue system. In Proceedings of the SIGDIAL 2009 Conference, pages 1?10, London."},"#text":"\n","pages":{"#tail":"\n","#text":"1--10"},"marker":{"#tail":"\n","#text":"Paksima, Georgila, Moore, 2009"},"location":{"#tail":"\n","#text":"London."},"title":{"#tail":"\n","#text":"Evaluating the effectiveness of information presentation in a full end-to-end dialogue system."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the SIGDIAL 2009 Conference,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"T Paksima"},{"#tail":"\n","#text":"K Georgila"},{"#tail":"\n","#text":"J D Moore"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Polifroni, Joseph, Grace Chung, and Stephanie Seneff. 2003. Towards automatic generation of mixed-initiative dialogue systems from web content. In Proceedings of Eurospeech ?03, pages 193?196, Geneva."},"#text":"\n","pages":{"#tail":"\n","#text":"193--196"},"marker":{"#tail":"\n","#text":"Polifroni, Chung, Seneff, 2003"},"location":{"#tail":"\n","#text":"Geneva."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"cise summary can be presented to the user to refine.3 3 In the original implementation as reported in Polifroni, Chung, and Seneff (2003), however, the cluster attributes were specified in advance based on domain knowledge, not determined at run time based solely on the set of options returned. Our discussion and evaluation of the SR approach is therefore based on the ?refined? refiner strategy from Polifroni and Walker (2008), where options are clustered based on attributes determined at run time. 493 Computational Linguistics Volume 37, Number 3 Figure 3 Dialog between simulator (M) and the Polifroni et al (2003) system (S). Although the SR approach provides a solution to the problem of presenting information when there are large numbers of options in a way that is suitable for an SDS, it has several limitations. First, there may be long refinement paths in the dialog structure, that is, many dialog turns may be necessary to narrow in on a suitably small set of options. Because the system does not know about the user?s preferences, the option clusters may contain irrelevant information which must be filtered out successively with each refinement step. In addition, the difficulty of summarizing options","@endWordPosition":"2385","@position":"15633","annotationId":"T23","@startWordPosition":"2382","@citStr":"Polifroni et al (2003)"}},"title":{"#tail":"\n","#text":"Towards automatic generation of mixed-initiative dialogue systems from web content."},"booktitle":{"#tail":"\n","#text":"In Proceedings of Eurospeech ?03,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Joseph Polifroni"},{"#tail":"\n","#text":"Grace Chung"},{"#tail":"\n","#text":"Stephanie Seneff"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2008"},"rawString":{"#tail":"\n","#text":"Polifroni, Joseph and Marilyn Walker. 2008. Intensional summaries as cooperative responses in dialogue: Automation and evaluation. In Proceedings of ACL-08: HLT, pages 479?487, Columbus, OH."},"#text":"\n","pages":{"#tail":"\n","#text":"479--487"},"marker":{"#tail":"\n","#text":"Polifroni, Walker, 2008"},"location":{"#tail":"\n","#text":"Columbus, OH."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"s, as dictated by the set of options that satisfy the current user query. For large data sets, attributes that partition the data into the minimal number of clusters should be chosen, so that a concise summary can be presented to the user to refine.3 3 In the original implementation as reported in Polifroni, Chung, and Seneff (2003), however, the cluster attributes were specified in advance based on domain knowledge, not determined at run time based solely on the set of options returned. Our discussion and evaluation of the SR approach is therefore based on the ?refined? refiner strategy from Polifroni and Walker (2008), where options are clustered based on attributes determined at run time. 493 Computational Linguistics Volume 37, Number 3 Figure 3 Dialog between simulator (M) and the Polifroni et al (2003) system (S). Although the SR approach provides a solution to the problem of presenting information when there are large numbers of options in a way that is suitable for an SDS, it has several limitations. First, there may be long refinement paths in the dialog structure, that is, many dialog turns may be necessary to narrow in on a suitably small set of options. Because the system does not know about the ","@endWordPosition":"2355","@position":"15441","annotationId":"T24","@startWordPosition":"2352","@citStr":"Polifroni and Walker (2008)"},{"#tail":"\n","#text":"thod allows us to evaluate our information presentation strategy in the context of an actual interaction, there are still a number of shortcomings. An ideal user evaluation would use actual automatic speech recognition and language Figure 15 Results for all questions, interaction experiment. 516 Demberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs understanding instead of the wizard performing these actions. In addition, it would use the actual model of each user rather than ask them to role-play. Although role-playing is an often used methodology in SDS evaluations (Polifroni and Walker 2008) and corpus collection (Carletta 2007), we recognize that there are concerns with respect to assigning subjects a user model as opposed to using the participants? own models. Possible problems with role-playing include the fact that participants may have incorrect expectations about the needs and preferences of the role they are supposed to play, and that they might not adopt the role sufficiently. Furthermore, a scenario where participants are role-playing cannot test how good the user model is, or how robust a user-adaptation system is. We chose role-playing as a method despite these concern","@endWordPosition":"13243","@position":"82772","annotationId":"T25","@startWordPosition":"13240","@citStr":"Polifroni and Walker 2008"},{"#tail":"\n","#text":"equired significantly fewer turns to complete the task (9.24 for UMSR and 17.78 for the sequential system), and conciseness, accessibility, and efficiency were all rated more highly in the UMSR condition than the sequential enumeration condition. In addition, overall user satisfaction was significantly higher for the UMSR system. Finally, the UMSR system outperformed the sequential system particularly clearly in cases where a trade-off among options existed. 8. Related Work Our experiments evaluate the UMSR model against the SR model described in Polifroni, Chung, and Seneff (2003). Recently, Polifroni and Walker (2008) developed several variants of the SR approach that differ in how they choose and structure attributes in the summaries presented to the user. That is, they differ in the way they rank attributes for presentation and the method used for clustering. There are two approaches to ranking, one based on the original refiner approach (which chooses to cluster on attributes for which a small number of clusters account for most of the options) and the other based on a user model (which chooses attributes for clustering based on the ranking in the user model). For clustering, they added an ?associative ","@endWordPosition":"14203","@position":"88930","annotationId":"T26","@startWordPosition":"14200","@citStr":"Polifroni and Walker (2008)"},{"#tail":"\n","#text":"towards more information. This means that providing an insufficient amount of information is perceived as worse than presenting too many details. Whittaker, Walker, and Maloor?s results also indicated that conciseness should be tailored to users, because some users appreciate conciseness more than others. Our system does not currently tailor turn length to specific users, because our user model does not contain information about a user?s conciseness preferences, or situational data, such as whether they are in a hurry, or can only devote a limited amount of attention on the task. Furthermore, Polifroni and Walker (2008) found in their user study that people who are not very familiar with the available options (e.g., tourists in a foreign city searching the restaurant domain) appreciate potentially longer, tailored summaries more than users who are very familiar with the data and know more precisely what they are looking for?such users preferred a simple refinement strategy or refinement with association over a user model?based recommendation. Exploring the Relationship between the User Model and Optimal Dialog Structure (Minimize Exploration Need). We have shown that presenting users first with those options","@endWordPosition":"15819","@position":"99297","annotationId":"T27","@startWordPosition":"15816","@citStr":"Polifroni and Walker (2008)"}]},"title":{"#tail":"\n","#text":"Intensional summaries as cooperative responses in dialogue: Automation and evaluation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of ACL-08: HLT,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Joseph Polifroni"},{"#tail":"\n","#text":"Marilyn Walker"}]}},{"date":{"#tail":"\n","#text":"1990"},"editor":{"#tail":"\n","#text":"D. A. Balota, G. B. Flores d?Arcais, and K. Rayner, editors,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ve also been shown to affect cognitive load on users. For example, surprising or incoherent information structure has been observed to be more difficult to process (Vauras, Hyo?na?, and Niemi 1992; Van Gompel, Liversedge, and Pearson 2004), and complex syntactic structures (e.g., long-distance dependencies) have been shown to impose difficulty (Gibson 1998). Language processing difficulty is also affected by frequency: Less frequent structures and words are more difficult to process than more frequent ones (Ehrlich and Rayner 1981; Rayner 1998; Rayner et al 1998). Furthermore, lexical access (Pollatsek and Rayner 1990) and word predictability (Rayner et al 2001) have also been shown to play a role. Finally, deciding what is an information unit and estimating how difficult they are to remember (and recall) for a particular user is not a trivial task, and is highly dependent on individual differences in affect, aptitude, intelligence, episodic memory, and so on. Therefore, a more fine-grained estimation of the cognitive load imposed on a user based on the number of information units to remember, the syntactic structure of the generated sentences, and their semantic coherence would allow the system to adapt to","@endWordPosition":"16204","@position":"101799","annotationId":"T28","@startWordPosition":"16201","@citStr":"Pollatsek and Rayner 1990"}},"title":{"#tail":"\n","#text":"Eye movements and lexical access in reading. In"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Pollatsek, A. and K. Rayner. 1990. Eye movements and lexical access in reading. In D. A. Balota, G. B. Flores d?Arcais, and K. Rayner, editors, Comprehension Processes in Reading. Erlbaum, Hillsdale, NJ, pages 143?163."},"#text":"\n","pages":{"#tail":"\n","#text":"143--163"},"marker":{"#tail":"\n","#text":"Pollatsek, Rayner, 1990"},"location":{"#tail":"\n","#text":"Hillsdale, NJ,"},"booktitle":{"#tail":"\n","#text":"Comprehension Processes in Reading. Erlbaum,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A Pollatsek"},{"#tail":"\n","#text":"K Rayner"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Pon-Barry, Heather, Fuliang Weng, and Sebastian Varges. 2006. Evaluation of content presentation strategies for an in-car spoken dialogue system. In Interspeech 2006 ? ICSLP, pages 1930?1933, Pittsburgh, PA."},"#text":"\n","pages":{"#tail":"\n","#text":"1930--1933"},"marker":{"#tail":"\n","#text":"Pon-Barry, Weng, Varges, 2006"},"location":{"#tail":"\n","#text":"Pittsburgh, PA."},"title":{"#tail":"\n","#text":"Evaluation of content presentation strategies for an in-car spoken dialogue system."},"booktitle":{"#tail":"\n","#text":"In Interspeech 2006 ? ICSLP,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Heather Pon-Barry"},{"#tail":"\n","#text":"Fuliang Weng"},{"#tail":"\n","#text":"Sebastian Varges"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"Qu, Y. and S. Beale. 1999. A constraint-based model for cooperative response generation in information dialogues. In AAAI/IAAI 1999, pages 148?155, Orlando, FL."},"#text":"\n","pages":{"#tail":"\n","#text":"148--155"},"marker":{"#tail":"\n","#text":"Qu, Beale, 1999"},"location":{"#tail":"\n","#text":"Orlando, FL."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" further down in the option tree. Constraint values, namely, good arrival time being changed to fair, are automatically relaxed due to the ordering of the branches within the option tree. Various strategies for coping with over- and under-constrained queries have been developed in the literature. Systems proactively suggest additional refinements for underconstrained queries, as in You could try to look for cuisine type? (Pon-Barry, Weng, and Varges 2006; Varges, Weng, and Pon-Barry 2006), or relaxations for over-constrained queries, as in Would a slightly more expensive flight work for you? (Qu and Beale 1999; PonBarry, Weng, and Varges 2006). Additionally, constraints can be relaxed automatically based an ontology (Varges, Weng, and Pon-Barry 2006) or by predefining relaxation sets (e.g., from a specific street for a restaurant to the broader neighborhood) or categorical ones (e.g., relaxing Chinese to Asian) (Chung 2004). 9. Conclusions and Future Work The research presented in this article addresses the issue of how to scale information presentation strategies for spoken dialog systems to situations where many diverse options are available. We developed an approach that combines content selecti","@endWordPosition":"15041","@position":"94274","annotationId":"T29","@startWordPosition":"15038","@citStr":"Qu and Beale 1999"}},"title":{"#tail":"\n","#text":"A constraint-based model for cooperative response generation in information dialogues."},"booktitle":{"#tail":"\n","#text":"In AAAI/IAAI"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Y Qu"},{"#tail":"\n","#text":"S Beale"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Rayner, K. 1998. Eye movements in reading and information processing. Psychological Bulletin, 124:327?422."},"journal":{"#tail":"\n","#text":"Psychological Bulletin,"},"#text":"\n","pages":{"#tail":"\n","#text":"124--327"},"marker":{"#tail":"\n","#text":"Rayner, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ver, a very coarse measure, as different linguistic factors have also been shown to affect cognitive load on users. For example, surprising or incoherent information structure has been observed to be more difficult to process (Vauras, Hyo?na?, and Niemi 1992; Van Gompel, Liversedge, and Pearson 2004), and complex syntactic structures (e.g., long-distance dependencies) have been shown to impose difficulty (Gibson 1998). Language processing difficulty is also affected by frequency: Less frequent structures and words are more difficult to process than more frequent ones (Ehrlich and Rayner 1981; Rayner 1998; Rayner et al 1998). Furthermore, lexical access (Pollatsek and Rayner 1990) and word predictability (Rayner et al 2001) have also been shown to play a role. Finally, deciding what is an information unit and estimating how difficult they are to remember (and recall) for a particular user is not a trivial task, and is highly dependent on individual differences in affect, aptitude, intelligence, episodic memory, and so on. Therefore, a more fine-grained estimation of the cognitive load imposed on a user based on the number of information units to remember, the syntactic structure of the generat","@endWordPosition":"16193","@position":"101722","annotationId":"T30","@startWordPosition":"16192","@citStr":"Rayner 1998"}},"title":{"#tail":"\n","#text":"Eye movements in reading and information processing."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"K Rayner"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Rayner, K., K. S. Binder, J. Ashby, and A. Pollatsek. 2001. Eye movement control in reading: Word predictability has little influence on initial landing positions in words. Vision Research, 41:943?954."},"journal":{"#tail":"\n","#text":"Vision Research,"},"#text":"\n","pages":{"#tail":"\n","#text":"41--943"},"marker":{"#tail":"\n","#text":"Rayner, Binder, Ashby, Pollatsek, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":". For example, surprising or incoherent information structure has been observed to be more difficult to process (Vauras, Hyo?na?, and Niemi 1992; Van Gompel, Liversedge, and Pearson 2004), and complex syntactic structures (e.g., long-distance dependencies) have been shown to impose difficulty (Gibson 1998). Language processing difficulty is also affected by frequency: Less frequent structures and words are more difficult to process than more frequent ones (Ehrlich and Rayner 1981; Rayner 1998; Rayner et al 1998). Furthermore, lexical access (Pollatsek and Rayner 1990) and word predictability (Rayner et al 2001) have also been shown to play a role. Finally, deciding what is an information unit and estimating how difficult they are to remember (and recall) for a particular user is not a trivial task, and is highly dependent on individual differences in affect, aptitude, intelligence, episodic memory, and so on. Therefore, a more fine-grained estimation of the cognitive load imposed on a user based on the number of information units to remember, the syntactic structure of the generated sentences, and their semantic coherence would allow the system to adapt to situational constraints (e.g., generate les","@endWordPosition":"16211","@position":"101843","annotationId":"T31","@startWordPosition":"16208","@citStr":"Rayner et al 2001"}},"title":{"#tail":"\n","#text":"Eye movement control in reading: Word predictability has little influence on initial landing positions in words."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"K Rayner"},{"#tail":"\n","#text":"K S Binder"},{"#tail":"\n","#text":"J Ashby"},{"#tail":"\n","#text":"A Pollatsek"}]}},{"date":{"#tail":"\n","#text":"1998"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"oarse measure, as different linguistic factors have also been shown to affect cognitive load on users. For example, surprising or incoherent information structure has been observed to be more difficult to process (Vauras, Hyo?na?, and Niemi 1992; Van Gompel, Liversedge, and Pearson 2004), and complex syntactic structures (e.g., long-distance dependencies) have been shown to impose difficulty (Gibson 1998). Language processing difficulty is also affected by frequency: Less frequent structures and words are more difficult to process than more frequent ones (Ehrlich and Rayner 1981; Rayner 1998; Rayner et al 1998). Furthermore, lexical access (Pollatsek and Rayner 1990) and word predictability (Rayner et al 2001) have also been shown to play a role. Finally, deciding what is an information unit and estimating how difficult they are to remember (and recall) for a particular user is not a trivial task, and is highly dependent on individual differences in affect, aptitude, intelligence, episodic memory, and so on. Therefore, a more fine-grained estimation of the cognitive load imposed on a user based on the number of information units to remember, the syntactic structure of the generated sentences, and th","@endWordPosition":"16197","@position":"101742","annotationId":"T32","@startWordPosition":"16194","@citStr":"Rayner et al 1998"}},"title":{"#tail":"\n","#text":"Eye movements and on-line language comprehension processes."},"volume":{"#tail":"\n","#text":"37"},"#tail":"\n","institution":{"#tail":"\n","#text":"Computational Linguistics"},"rawString":{"#tail":"\n","#text":"Computational Linguistics Volume 37, Number 3 Rayner, K., S. C. Sereno, R. K. Morris, A. R. Schmauder, and C. Clifton. 1998. Eye movements and on-line language comprehension processes. Language and Comprehension Processes, 4:21?49."},"#text":"\n","pages":{"#tail":"\n","#text":"4--21"},"marker":{"#tail":"\n","#text":"Rayner, Sereno, Morris, Schmauder, Clifton, 1998"},"booktitle":{"#tail":"\n","#text":"Language and Comprehension Processes,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"K Rayner"},{"#tail":"\n","#text":"S C Sereno"},{"#tail":"\n","#text":"R K Morris"},{"#tail":"\n","#text":"A R Schmauder"},{"#tail":"\n","#text":"C Clifton"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Rayner, Manny, Beth Ann Hockey, Jim Hieronymus, John Dowding, Greg Aist, and Susana Early. 2003. An intelligent procedure assistant built using regulus 2 and alterf. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics, pages 193?196, Sapporo."},"#text":"\n","pages":{"#tail":"\n","#text":"193--196"},"marker":{"#tail":"\n","#text":"Rayner, Hockey, Hieronymus, Dowding, Aist, Early, 2003"},"location":{"#tail":"\n","#text":"Sapporo."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"R strategy over the SR strategy, and on no aspect was the SR system found to be significantly better than the UMSR system in our experiments. We conclude that our hypotheses were largely confirmed, and that a challenge for future work lies in the development of methods that allow the system to predict and control for the cognitive load induced by system utterances. We believe that this is particularly important because dialog systems are frequently used in situations in which the user?s hands and eyes are busy. For example, NASA is interested in spoken dialog technology for use in spacecraft (Rayner et al 2003), and automobile manufacturers are integrating an ever-increasing number of voice services into their products. In subsequent work, an end-to-end dialog system following the UMSR strategy was implemented in the context of the TownInfo system (Paksima, Georgila, and Moore 2009), which allows users to search for restaurants in the city of Edinburgh. The system was evaluated with participants interacting directly with the system (as opposed to a WOZ setting), and was compared to a system that implemented the typical sequential enumeration approach to information presentation. In the UMSR conditio","@endWordPosition":"13994","@position":"87493","annotationId":"T33","@startWordPosition":"13991","@citStr":"Rayner et al 2003"}},"title":{"#tail":"\n","#text":"An intelligent procedure assistant built using regulus 2 and alterf."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Manny Rayner"},{"#tail":"\n","#text":"Beth Ann Hockey"},{"#tail":"\n","#text":"Jim Hieronymus"},{"#tail":"\n","#text":"John Dowding"},{"#tail":"\n","#text":"Greg Aist"},{"#tail":"\n","#text":"Susana Early"}]}},{"volume":{"#tail":"\n","#text":"3"},"#tail":"\n","date":{"#tail":"\n","#text":"1979"},"rawString":{"#tail":"\n","#text":"Rich, Elaine. 1979. User modeling via stereotypes. Cognitive Science, 3(4):329?354."},"journal":{"#tail":"\n","#text":"Cognitive Science,"},"#text":"\n","issue":{"#tail":"\n","#text":"4"},"marker":{"#tail":"\n","#text":"Rich, 1979"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"line, fare-class, and layover-airport. A user model contains a partial ordering of these attributes corresponding to the user?s ranking, as shown in Table 2. Furthermore, the user model stores preferences (e.g., for a certain airline or flying business class). In a real-world scenario, the user model can be acquired by requiring the user to register with the system at first use (Moore et al 2004), by building up a user model over time (Thompson, Goeker, and Langley 2004), or by classifying users into preference groups based on other information available about them, and using the group model (Rich 1979), as is frequently done in collaborative filtering. Once a user model exists, the user only needs to specify the current situational information, such as the destination, desired arrival time, and date of travel. 3.2 System Architecture A sketch of our system?s pipeline architecture focusing on the information presentation phase is given in Figure 4. In the version of our system that was used in evaluation, speech recognition and natural language understanding were performed by a wizard (see Section 6.1) who also chose from a set of canned queries during the initial information gathering phase","@endWordPosition":"3545","@position":"22868","annotationId":"T34","@startWordPosition":"3544","@citStr":"Rich 1979"}},"title":{"#tail":"\n","#text":"User modeling via stereotypes."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Elaine Rich"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Seneff, Stephanie. 2002. Response planning and generation in the mercury flight reservation system. Computer Speech & Language, 16(3?4):283?312."},"journal":{"#tail":"\n","#text":"Computer Speech & Language,"},"#text":"\n","pages":{"#tail":"\n","#text":"16--3"},"marker":{"#tail":"\n","#text":"Seneff, 2002"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ure 8 Diagram showing how the pruned option tree is mapped onto language. The tree on the right hand side corresponds to the example trees in Figures 6 and 7. The complete system utterance is shown in Figure 10. Figure 8 shows how the nodes in the pruned option tree translate to the system?s utterances. The different design decisions underlying sentence planning and realization will be explained in the following sections. 3.6.1 Turn Length. In any spoken dialog system, it is important not to present too much information in a single turn in order to keep the memory load on the user manageable (Seneff 2002). Thus, our system aims at presenting no more than two or maximally three options at once. However, the pruned option tree sometimes contains more than this critical number of options, and therefore needs to be broken down into smaller chunks. We thus divide the pruned option tree into several smaller dialog-turn-sized subtrees. Typically not all of these subtrees will be presented, but only the ones between the root of the tree and the chosen subset of flights that the user wishes to hear more about. In addition to determining the number of options to present in a single turn, the system must","@endWordPosition":"7500","@position":"46795","annotationId":"T35","@startWordPosition":"7499","@citStr":"Seneff 2002"}},"title":{"#tail":"\n","#text":"Response planning and generation in the mercury flight reservation system."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Stephanie Seneff"}}},{"volume":{"#tail":"\n","#text":"31"},"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Steedman, M. 2000. Information structure and the syntax?phonology interface. Linguistic Inquiry, 31(4):649?689."},"journal":{"#tail":"\n","#text":"Linguistic Inquiry,"},"#text":"\n","issue":{"#tail":"\n","#text":"4"},"marker":{"#tail":"\n","#text":"Steedman, 2000"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ncreases argument effectiveness and improves user satisfaction (Walker et al 2004). MATCH included content planning algorithms to determine what options and attributes to mention, but used a simple template-based approach to realization. For the design of the FLIGHTS2 system, Moore et al (2004) focused on organizing and expressing the descriptions of the selected options and attributes in ways that were intended to make the descriptions both easy to understand and memorable. In addition, to increase coherence and naturalness of the descriptions, the system reasons about information structure (Steedman 2000) to control intonation, uses referring expressions that highlight attributes relevant to the user (e.g., a direct flight for a user who wants to minimize connections, vs. the cheapest flight for a user concerned about price), and signals discourse relations (e.g., contrast) with appropriate intonational and discourse cues. For example, Figure 2 shows a description of options tailored to a user who prefers flying business class, on direct flights, and on KLM, in that order. The FLIGHTS system presents a small number of options that best match the user?s constraints, and points out ways in which","@endWordPosition":"1684","@position":"11240","annotationId":"T36","@startWordPosition":"1683","@citStr":"Steedman 2000"}},"title":{"#tail":"\n","#text":"Information structure and the syntax?phonology interface."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"M Steedman"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Thompson, C., M. Goeker, and P. Langley. 2004. A personalized system for conversational recommendations. Journal of Artificial Intelligence Research (JAIR), 21:393?428."},"journal":{"#tail":"\n","#text":"Journal of Artificial Intelligence Research (JAIR),"},"#text":"\n","pages":{"#tail":"\n","#text":"21--393"},"marker":{"#tail":"\n","#text":"Thompson, Goeker, Langley, 2004"},"title":{"#tail":"\n","#text":"A personalized system for conversational recommendations."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"C Thompson"},{"#tail":"\n","#text":"M Goeker"},{"#tail":"\n","#text":"P Langley"}]}},{"date":{"#tail":"\n","#text":"2004"},"editor":{"#tail":"\n","#text":"In M. Carreiras and C. E. Clifton, editors,"},"title":{"#tail":"\n","#text":"Antecedent typicality effects in the processing of noun phrase anaphors."},"#tail":"\n","rawString":{"#tail":"\n","#text":"Van Gompel, R. P. G., S. P. Liversedge, and J. Pearson. 2004. Antecedent typicality effects in the processing of noun phrase anaphors. In M. Carreiras and C. E. Clifton, editors, The On-line Study of Sentence Comprehension: Eyetracking, ERP and Beyond. Psychology Press, New York, pages 119?137."},"#text":"\n","pages":{"#tail":"\n","#text":"119--137"},"marker":{"#tail":"\n","#text":"Van Gompel, Liversedge, Pearson, 2004"},"publisher":{"#tail":"\n","#text":"Psychology Press,"},"location":{"#tail":"\n","#text":"New York,"},"booktitle":{"#tail":"\n","#text":"The On-line Study of Sentence Comprehension: Eyetracking, ERP and Beyond."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"R P G Van Gompel"},{"#tail":"\n","#text":"S P Liversedge"},{"#tail":"\n","#text":"J Pearson"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Varges, Sebastian, Fuliang Weng, and Heather Pon-Barry. 2006. Interactive question answering and constraint relaxation in spoken dialogue systems. In Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 28?35, Sydney."},"#text":"\n","pages":{"#tail":"\n","#text":"28--35"},"marker":{"#tail":"\n","#text":"Varges, Weng, Pon-Barry, 2006"},"location":{"#tail":"\n","#text":"Sydney."},"title":{"#tail":"\n","#text":"Interactive question answering and constraint relaxation in spoken dialogue systems."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Sebastian Varges"},{"#tail":"\n","#text":"Fuliang Weng"},{"#tail":"\n","#text":"Heather Pon-Barry"}]}},{"volume":{"#tail":"\n","#text":"15"},"#tail":"\n","date":{"#tail":"\n","#text":"1992"},"rawString":{"#tail":"\n","#text":"Vauras, M., J. Hyo?na?, and P. Niemi. 1992. Comprehending coherent and incoherent texts: Evidence from eye movement patterns and recall performance. Journal of Research in Reading, 15(1):39?54."},"journal":{"#tail":"\n","#text":"Journal of Research in Reading,"},"#text":"\n","issue":{"#tail":"\n","#text":"1"},"marker":{"#tail":"\n","#text":"Vauras, Hyona, Niemi, 1992"},"title":{"#tail":"\n","#text":"Comprehending coherent and incoherent texts: Evidence from eye movement patterns and recall performance."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"M Vauras"},{"#tail":"\n","#text":"J Hyona"},{"#tail":"\n","#text":"P Niemi"}]}},{"volume":{"#tail":"\n","#text":"28"},"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Walker, M. A., S. J. Whittaker, A. Stent, P. Maloor, J. Moore, M. Johnston, and G. Vasireddy. 2004. Generation and evaluation of user tailored responses in multimodal dialogue. Cognitive Science, 28(5):811?840."},"journal":{"#tail":"\n","#text":"Cognitive Science,"},"#text":"\n","issue":{"#tail":"\n","#text":"5"},"marker":{"#tail":"\n","#text":"Walker, Whittaker, Stent, Maloor, Moore, Johnston, Vasireddy, 2004"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ch the user?s constraints. An example is given in Figure 1. In some systems, these activities take place in strictly sequential phases: All of the information necessary to form a database query is gathered, and then the returned options are presented, one at a time or in small groups. In other systems, the activities are interleaved, with users refining their constraints after being presented with some options, or a summary of the option space. In either case, when the number of options to be presented is large, this process can be laborious, leading to reduced user satisfaction. Moreover, as Walker et al (2004) observe, having to access the set of available options sequentially makes it difficult for the user to remember the various aspects of multiple options and to compare them mentally. Although much research has been conducted on the information gathering phase of spoken dialog systems, relatively little attention has been devoted to information presentation. An analysis of the Communicator corpus consisting of approximately 2,000 dialogs with nine different spoken dialog systems found that information presentation is the main contributor to dialog duration1 (Moore 2006); see Table 1. Moreover, ","@endWordPosition":"685","@position":"4630","annotationId":"T37","@startWordPosition":"682","@citStr":"Walker et al (2004)"},{"#tail":"\n","#text":"ms from the literature in section 8, and discuss implications of our findings and future directions in Section 9. 2. Background on User Modeling and Content Structuring for Information Presentation 2.1 Tailoring to a User Model (UM) Previous work in natural language generation showed how a multi-attribute decisiontheoretic model of user preferences can be used in a recommender system to determine which options to mention to a particular user, as well as the attributes that the user will find most relevant for choosing among the available options (Carenini and Moore 2001). In the MATCH system, Walker et al (2004) applied this approach to information presentation in SDSs, and extended it to generate summaries and comparisons among options. Evaluation of the MATCH system showed that tailoring recommendations and comparisons to the user increases argument effectiveness and improves user satisfaction (Walker et al 2004). MATCH included content planning algorithms to determine what options and attributes to mention, but used a simple template-based approach to realization. For the design of the FLIGHTS2 system, Moore et al (2004) focused on organizing and expressing the descriptions of the selected options","@endWordPosition":"1563","@position":"10399","annotationId":"T38","@startWordPosition":"1560","@citStr":"Walker et al (2004)"}]},"title":{"#tail":"\n","#text":"Generation and evaluation of user tailored responses in multimodal dialogue."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"M A Walker"},{"#tail":"\n","#text":"S J Whittaker"},{"#tail":"\n","#text":"A Stent"},{"#tail":"\n","#text":"P Maloor"},{"#tail":"\n","#text":"J Moore"},{"#tail":"\n","#text":"M Johnston"},{"#tail":"\n","#text":"G Vasireddy"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Walker, Marilyn and Rebecca Passonneau. 2001. Date: A dialogue act tagging scheme for evaluation of spoken dialogue systems. In HLT ?01: Proceedings of the First International Conference on Human Language Technology Research, pages 1?8, Morristown, NJ."},"#text":"\n","pages":{"#tail":"\n","#text":"1--8"},"marker":{"#tail":"\n","#text":"Walker, Passonneau, 2001"},"location":{"#tail":"\n","#text":"Morristown, NJ."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"e system structures the large number of options into a small number of clusters that share attributes. The system then summarizes the clusters based on their attributes, thus prompting the user to provide additional constraints (Polifroni, Chung, and Seneff 2003; Chung 2004). In this article, we propose an approach to information presentation which shortens dialog duration by combining the benefits of these two approaches (UMSR). Our 1 This analysis was performed on the Communicator corpus which has been annotated extensively, including annotations for speech act types and timing information (Walker and Passonneau 2001; Georgila et al 2009). 490 Demberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs Figure 1 Typical information presentation phase of a communicator dialog. Table 1 System contributions: Requesting and presenting information in Communicator systems. System Requesting info Presenting info Other Utterances 43% 25% 32% Time 31% 54% 15% Words 28% 50% 22% approach integrates user modeling with automated clustering such that information is structured in a way that enables users to more effectively and efficiently browse the option space. The system provides detail only about ","@endWordPosition":"965","@position":"6512","annotationId":"T39","@startWordPosition":"962","@citStr":"Walker and Passonneau 2001"}},"title":{"#tail":"\n","#text":"Date: A dialogue act tagging scheme for evaluation of spoken dialogue systems."},"booktitle":{"#tail":"\n","#text":"In HLT ?01: Proceedings of the First International Conference on Human Language Technology Research,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Marilyn Walker"},{"#tail":"\n","#text":"Rebecca Passonneau"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Walker, Marilyn A., Rebecca Passonneau, and Julie E. Boland. 2001. Quantitative and qualitative evaluation of darpa communicator spoken dialogue systems. In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics, pages 515?522, Toulouse."},"#text":"\n","pages":{"#tail":"\n","#text":"515--522"},"marker":{"#tail":"\n","#text":"Walker, Passonneau, Boland, 2001"},"location":{"#tail":"\n","#text":"Toulouse."},"title":{"#tail":"\n","#text":"Quantitative and qualitative evaluation of darpa communicator spoken dialogue systems."},"booktitle":{"#tail":"\n","#text":"In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Marilyn A Walker"},{"#tail":"\n","#text":"Rebecca Passonneau"},{"#tail":"\n","#text":"Julie E Boland"}]}},{"volume":{"#tail":"\n","#text":"36"},"#tail":"\n","date":{"#tail":"\n","#text":"2010"},"rawString":{"#tail":"\n","#text":"White, Michael, Robert A. J. Clark, and Johanna D. Moore. 2010. Generating tailored, comparative descriptions with contextually appropriate intonation. Computational Linguistics, 36(2):159?201."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"2"},"marker":{"#tail":"\n","#text":"White, Clark, Moore, 2010"},"title":{"#tail":"\n","#text":"Generating tailored, comparative descriptions with contextually appropriate intonation."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Michael White"},{"#tail":"\n","#text":"Robert A J Clark"},{"#tail":"\n","#text":"Johanna D Moore"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Whittaker, Stephen, Marilyn Walker, and Preetam Maloor. 2003. Should I tell all?: An experiment on conciseness in spoken dialogue. In EUROSPEECH: European Conference on Speech Processing, pages 1685?1689, Geneva."},"#text":"\n","pages":{"#tail":"\n","#text":"1685--1689"},"marker":{"#tail":"\n","#text":"Whittaker, Walker, Maloor, 2003"},"location":{"#tail":"\n","#text":"Geneva."},"title":{"#tail":"\n","#text":"Should I tell all?: An experiment on conciseness in spoken dialogue. In"},"booktitle":{"#tail":"\n","#text":"EUROSPEECH: European Conference on Speech Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Stephen Whittaker"},{"#tail":"\n","#text":"Marilyn Walker"},{"#tail":"\n","#text":"Preetam Maloor"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Winterboer, A., J. Hu, Johanna D. Moore, and Clifford I. Nass. 2007. The influence of user tailoring and cognitive load on user performance in spoken dialogue systems."},"#text":"\n","marker":{"#tail":"\n","#text":"Winterboer, Hu, Moore, Nass, 2007"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ser is expected to make a choice indicating which of the options she would like to hear more about (for illustration see Figure 10). 7 Later experiments used a more sophisticated way of determining turn length, which we describe in Section 5. 8 Branching nodes as opposed to unary nodes. For example, in Figure 6, the unary node in the right subtree would not count as a separate level. 505 Computational Linguistics Volume 37, Number 3 This definition of turn length was employed in the reading and overhearer experiments (see Sections 4.1 and 4.2). However, it became clear in related experiments (Winterboer et al 2007) that this method of deciding on dialog turn length sometimes led to very long system turns, which were then difficult for the user to remember. We thus modified the algorithm in order to ease comprehension. We will return to this point later, in Section 5. 3.6.2 Referring to Sets of Options. Each branch in the pruned tree corresponds to a set of options. These options should be referred to in an effective way. We do this by taking into account both the dialog structure (i.e., structure of the argumentation) and the user?s interest: The description of a set of options is based on their justifi","@endWordPosition":"8092","@position":"50377","annotationId":"T40","@startWordPosition":"8089","@citStr":"Winterboer et al 2007"},{"#tail":"\n","#text":"UMSR system also requiring fewer dialog turns. Furthermore, participants reported that they felt the optimal option was accessed more quickly in the UMSR condition than in the SR condition in all three experiments. Did the UMSR Approach Make Information Presentation More Effective? This hypothesis was tested in the interaction task experiment by measuring task success. We found that users chose the option that was best for the role they were playing more often in the interaction experiment. These findings also agree with results obtained in other work, using a dual-task method (Hu et al 2007; Winterboer et al 2007). Thus, we conclude that information access with the UMSR approach is more effective than with the SR approach. Did UMSR Provide a Better Overview of the Option Space and Was Higher Confidence Achieved with UMSR? Questions 2 (?Did the system give X a good overview of the available options??) and 3 (?Do you think there may be flights that are better options for X that the system did not tell X about??) of the questionnaire were designed to assess this aspect. The first two experiments showed a clear preference for the UMSR system in comparison with the SR system. Participants in the interaction","@endWordPosition":"13577","@position":"84913","annotationId":"T41","@startWordPosition":"13574","@citStr":"Winterboer et al 2007"}]},"title":{"#tail":"\n","#text":"The influence of user tailoring and cognitive load on user performance in spoken dialogue systems."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A Winterboer"},{"#tail":"\n","#text":"J Hu"},{"#tail":"\n","#text":"Johanna D Moore"},{"#tail":"\n","#text":"Clifford I Nass"}]}},{"#tail":"\n","rawString":{"#tail":"\n","#text":"In Proceedings of the Interspeech 2007 Conference, pages 2717?2720, Antwerp."},"#text":"\n","pages":{"#tail":"\n","#text":"2717--2720"},"marker":{"#tail":"\n"},"location":{"#tail":"\n","#text":"Antwerp."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Interspeech 2007 Conference,"},"@valid":"false"},{"#tail":"\n","tech":{"#tail":"\n","#text":"Ph.D. thesis,"},"date":{"#tail":"\n","#text":"2009"},"institution":{"#tail":"\n","#text":"School of Informatics, University of Edinburgh."},"rawString":{"#tail":"\n","#text":"Winterboer, Andi. 2009. Evaluating Information Presentation Strategies for Spoken Dialogue Systems. Ph.D. thesis, School of Informatics, University of Edinburgh."},"#text":"\n","marker":{"#tail":"\n","#text":"Winterboer, 2009"},"title":{"#tail":"\n","#text":"Evaluating Information Presentation Strategies for Spoken Dialogue Systems."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Andi Winterboer"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Winterboer, Andi and Johanna D. Moore. 2007. Evaluating information presentation strategies for spoken recommendations."},"#text":"\n","marker":{"#tail":"\n","#text":"Winterboer, Moore, 2007"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"and information density would be roughly the same for both conditions. 6. Evaluation II ? User Interaction Study Due to the complexity of building a working end-to-end SDS, our previous experiments employed an ?overhearer? evaluation methodology, in which participants read 513 Computational Linguistics Volume 37, Number 3 or listened to pre-recorded dialogs with a scripted user. This limits the evaluation criteria that can be applied to users? perceptions (e.g., understandability, goodness of overview of options, and so on). Our third experiment, a short summary of which was first reported in Winterboer and Moore (2007), compares the two systems in a more interesting setting, in which users actively interact with the dialog systems. This setting allows us to measure the systems? impact on effectiveness of the interaction (as measured by task success) and efficiency (as measured by dialog duration), in addition to user satisfaction. In this experiment, we compare the revised UMSR approach, which controls the amount of information presented in each turn, to the SR approach as described previously. 6.1 The Wizard-of-Oz Paradigm and Experimental Environment The interaction task experiment presented here followed","@endWordPosition":"11892","@position":"74094","annotationId":"T42","@startWordPosition":"11889","@citStr":"Winterboer and Moore (2007)"}},"title":{"#tail":"\n","#text":"Evaluating information presentation strategies for spoken recommendations."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Andi Winterboer"},{"#tail":"\n","#text":"Johanna D Moore"}]}},{"#tail":"\n","rawString":{"#tail":"\n","#text":"In Proceedings of the 2007 ACM Conference on Recommender Systems, pages 157?160, Minneapolis, MN."},"#text":"\n","pages":{"#tail":"\n","#text":"157--160"},"marker":{"#tail":"\n"},"location":{"#tail":"\n","#text":"Minneapolis, MN."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 2007 ACM Conference on Recommender Systems,"},"@valid":"false"},{"#tail":"\n","date":{"#tail":"\n","#text":"2011"},"note":{"#tail":"\n","#text":"in SDSs"},"rawString":{"#tail":"\n","#text":"Winterboer, Andi, Martin I. Tietze, Maria Wolters, and Johanna D. Moore. 2011. The user model-based summarize and refine approach improves information presentation in spoken dialog systems. Computer Speech and Language, 25:175?191. Demberg, Winterboer, and Moore A Strategy for Information Presentation in SDSs"},"#text":"\n","marker":{"#tail":"\n","#text":"Winterboer, Tietze, Wolters, Moore, 2011"},"title":{"#tail":"\n","#text":"The user model-based summarize and refine approach improves information presentation in spoken dialog systems. Computer Speech and Language, 25:175?191. Demberg, Winterboer, and Moore A Strategy for Information Presentation"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Andi Winterboer"},{"#tail":"\n","#text":"Martin I Tietze"},{"#tail":"\n","#text":"Maria Wolters"},{"#tail":"\n","#text":"Johanna D Moore"}]}}]}}]}}
