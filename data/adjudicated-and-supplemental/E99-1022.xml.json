{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","note":{"#tail":"\n","@confidence":"0.379601","#text":"\nProceedings of EACL '99\n"},"listItem":{"#tail":"\n","@confidence":"0.810405","#text":"\n(2) constituent( \\[PHON ( ,,,,y ) /xGR ,h.~-,,.~\\] )&quot;\n(3) constituent( |PHON (,leCp,)\n/AGR ,h,.~-.,.~ I ). LSEM sleep J\n(4) append((), F'~' ~)&quot; (5) append( 3 |\n"},"figure":[{"#tail":"\n","@confidence":"0.54748825","#text":"\nProceedings of EACL '99\nSelective Magic HPSG Parsing\nGuido Minnen*\nCognitive and Computing Sciences, University of Sussex\nFalmer, Brighton BN1 9QH\nUnited Kingdom\nGuido.Minnen@cogs.susx.ac.uk\nwww.cogs.susx.ac.uk/lab/nlp/minnen/minnen.html\n"},{"#tail":"\n","@confidence":"0.483804833333333","#text":"\n+\\] constituent~ IP&quot;O. ):- \\[SZM\nmagic_constituent ~) ,\nPHON constituent( \\[AGR )'\nI.Sr,~ FEAT&quot; \\]\nconstituent( \\[AGR )'\nLsE \\[suBJ Ell\n"},{"#tail":"\n","@confidence":"0.990347857142857","#text":"\nProceedings of EACL '99\nCAT ~p \\]\n(i) magic_constituent( |AGR|PEON agr|list ):_\nLSEM sere A\n\\[c T , \\]\nmagic_constituent(|PHON z.,, ).\n\\[sEg ,era 1\n/PHON\n(2) magic_constituent( /AGR ):-\nLs~g \\[S,BJ \\[7\\]\\]\nmagic_constituent( |PEON ),\n\\[SEM\nI PHON constituent( AGR )' .SEM\n(3) magic_append (\\[~1,\\[~\\],\\[~\\]) :-\nmagic_constituent(/PEON ),\ntszg\nPEON\nconstituent( I AGR ),\nI.SZg\nPHON\nconstituent( \\]AGR )&quot;\n"},{"#tail":"\n","@confidence":"0.968807931034483","#text":"\nsemi_naive_interpret (Goal):-\ninitialization(Agenda,TableO),\nupdat e_t able (Agenda, Table0, Table),\nmember (edge (Goal, \\[\\] ) ,Table) .\nupdate_table ( \\[\\] ,Table ,Table).\nupdate_table(\\[EdgelAgenda0\\],Table0,Table):-\nupdate_table_w_edge(Edge,Edges,\nTableO,Tablel),\nappend(Edges,Agenda0,Agenda),\nupdate_table(Agenda,Tablel,Table).\nupdate_tableJ_edge(Edge,Edges,Table0,Table):-\nfindall( NewEdge,\nmatah(Edge,NewEdge,Table0),\nEdges),\nstore(Edges,Table0,Table).\nstore(\\[\\],Table,Table):-\nstore(\\[EdgelEdges\\],TableO,Table):-\nmember(GenEdge,Table0),\n\\+ subsumes(GemEdge,Edge),\nstore(Edges,\\[EdgelTable0\\] ,Table).\nstore(\\[_lEdges\\],TableO,Table):-\nstore(Edges,Table0,Table).\ninitialization(Edges,Edges):-\nfindall( edge(Head, \\[\\] ),\ndefinite_clause((Head:- \\[\\])),\nEdges).\ncompletion(Edge,edge(Goal,\\[\\]),Table):-\ndefinite_clause((Goal :- Body)),\nEdge = edge(F,\\[\\]),\n"},{"#tail":"\n","@confidence":"0.631501571428571","#text":"\n170\nProceedings of EACL '99\ni nput :\nI magic compilation I\non p~rse type\nc laoses\npreselection I\nof re levant\nlex ica l entries\nextended se~-na?ve\nbot tom-up ~nterpreta~ion\nof parse type c lauses\ncombined with advanced\ntop-doom interpreta=ion\n"}],"equation":[{"#tail":"\n","@confidence":"0.808566333333333","#text":"\n(1) constituent( \\[PHON ):-\nLSEM\nPHON\nconstituent( \\[ AGR )'\nI_Sr~M\nteAT? 1\nconstituent( |AGR )'\nappend(\\[~,\\[~,\\[~).\nrCAT ?, \\]\n"},{"#tail":"\n","@confidence":"0.735843285714286","#text":"\nProceedings of EACL '99\nT\n\\ ~ ~ IPHON list \\[\n? k ~ . IAGR agr\\[\nmary / / relation / liY~st elist /g r ~ r -\n/ ~ nelistk~ &quot;st\\[ th+d-sing mary If sleep~_LIBJ sem--\\]\ns np v\n"},{"#tail":"\n","@confidence":"0.5077565","#text":"\nCAT s 1 magic_constituent( IPHON (m~r~,sl,ep,)).\n\\[SZM ,,~ J\n"}],"subsectionHeader":[{"#tail":"\n","@confidence":"0.757587","#text":"\nBottom-up Interpretation of\nMagic-compiled Typed Feature\nGrammars\n"},{"#tail":"\n","@confidence":"0.979543","#text":"\n2.1 Typed Feature Grammars\n"},{"#tail":"\n","@confidence":"0.993975","#text":"\n2.2 Magic Compi la t ion\n"},{"#tail":"\n","@confidence":"0.992157","#text":"\n2.3 Semi-naive Bot tom-up In terpretat ion\n"},{"#tail":"\n","@confidence":"0.999687","#text":"\n3.1 Parse Type Specif ication\n"},{"#tail":"\n","@confidence":"0.998226","#text":"\n3.2 Select ive Magic Compi la t ion\n"},{"#tail":"\n","@confidence":"0.99913","#text":"\n3.3 Advanced Top-down Control\n"},{"#tail":"\n","@confidence":"0.965402","#text":"\n3.4 Adapted Semi-naive Bottom-up\nInterpretat ion\n"}],"subsubsectionHeader":{"#tail":"\n","@confidence":"0.602748","#text":"\nProceedings of EACL '99\n"},"@confidence":"0.000000","#tail":"\n","reference":{"#tail":"\n","@confidence":"0.999617372093023","#text":"\nBob Carpenter and Gerald Penn. 1994. ALE -\nThe Attribute Logic Engine, User's guide, ver-\nsion 2.0.2. Technical report, Carnegie Mellon\nUniversity, Pittsburgh, Pennsylvania, USA.\nBob Carpenter. 1992. The Logic of Typed Fea-\nture Structures - With Applications to Unifica-\ntion Grammars, Logic Programs and Constraint\nResolution. Cambridge University Press, New\nYork, USA.\nAlain Colmerauer. 1982. PrologII: Manuel de\nr@f~rence t module th@orique. Technical re-\nport, Groupe d'Intelligence Artificielle, Facult~\nde Sciences de Luminy, Marseille, France.\nJochen DSrre. 1993. Generalizing Earley Deduc-\ntion for Constraint-based Grammars. In Jochen\nDSrre and Michael Dorna (eds.), 1993. Compu-\ntational Aspects of Constraint-Based Linguistic\nDescription L DYANA-2, Deliverable R1.2.A.\nDale Gerdemann. 1995. Term Encoding of\nTyped Feature Structures. In Proceedings of\nthe Fourth International Workshop on Parsing\nTechnologies, Prague, Czech Republic.\nThilo GStz and Detmar Meurers. 1997a. In-\nterleaving Universal Principles and Relational\nConstraints over Typed Feature Logic. In\nA CL/EACL Proceedings, Madrid, Spain.\nThilo GStz and Detmar Meurers. 1997b. The\nConTroll System as Large Grammar Develop-\nment Platform. In Proceedings of the ACL\nWorkshop on Computational Environments for\nGrammar Development and Linguistic Engi-\nneering, Madrid, Spain.\nThilo GStz. 1994. A Normal Form for Typed\nFeature Structures. Technical report SFB 340\nnr. 40, University of Tfibingen, Germany.\nThilo GStz. 1995. Compiling HPSG Constraint\nGrammars into Logic Programs. In Proceedings\nof the Workshop on Computational Logic for\nNatural Language Processing, Edinburgh, UK.\nErhard Hinrichs, Detmar Meurers, Frank Richter,\nManfred Sailer, and Heike Winhart. 1997. Ein\nHPSG-fragment des Deutschen, Tell 1: Theo-\nrie. Technical report SFB 340 95, University of\nTiibingen, Germany.\nMarkus HShfeld and Gert Smolka. 1988. Definite\nRelations over Constraint Languages. Technical\nReport 53, IBM, Germany.\nMark Johnson and Jochen DSrre. 1995. Memo-\nization of Coroutined Constraints. In A CL Pro-\nceedings, Cambridge, Massachusetts, USA.\nPaul King. 1994. Typed Feature Structures as\nDescriptions. In Proceedings of of the 15th Con-\nference on Computational Linguistics, Kyoto,\nJapan.\nDetmar Meurers and Guido Minnen. 1997. A\nComputational Treatment of Lexical Rules in\nHPSG as Covariation in Lexical Entries. Com-\nputational Linguistics, 23(4).\nGuido Minnen. 1996. Magic for Filter Optimiza-\ntion in Dynamic Bottom-up Processing. In ACL\nProceedings, Santa Cruz, California, USA.\nGuido Minnen. 1998. Off-line Compilation for Ef-\nficient Processing with Constraint-logic Gram-\nmars. Ph.D. thesis, University of Tfibingen,\nGermany. Technical report SFB 340 nr. 130.\nLee Naish. 1986. Negation and Control in Prolog.\nSpringer-Verlag, Berlin, Germany.\nUlf Nilsson and Jan Matuszynski. 1995. Logic,\nProgramming and Prolog. John Wiley  Sons,\nChichester, UK, 2nd edition.\nCarl Pollard and Ivan Sag. 1994. Head-Driven\nPhrase Structure Grammar. University of\nChicago Press, Chicago, Illinois, USA.\nRaghu Ramakrishnan, Divesh Srivastava, and\nS. Sudarshan. 1992. Efficient Bottom-up\nEvaluation of Logic Programs. In Joos Van-\ndewalle (ed.), 1992. The State of the Art in\nComputer Systems and Software Engineering.\nKluwer Academic Publishers.\nStuart Shieber, Yves Schabes, and Fernando\nPereira. 1995. Principles and Implementation\nof Deductive Parsing. Journal of Logic Pro-\ngramming, 24(1-2).\nGertjan van Noord. 1997. An Efficient Imple-\nmentation of the Head-corner Parser. Compu-\ntational Linguistics, 23(3).\n"},"bodyText":[{"#tail":"\n","@confidence":"0.993031866666666","#text":"\nWe propose a parser for constraint-\nlogic grammars implementing HPSG\nthat combines the advantages of dy-\nnamic bottom-up and advanced top-\ndown control. The parser allows the\nuser to apply magic compilation to spe-\ncific constraints in a grammar which as\na result can be processed dynamically\nin a bottom-up and goal-directed fash-\nion. State of the art top-down process-\ning techniques are used to deal with the\nremaining constraints. We discuss vari-\nous aspects concerning the implementa-\ntion of the parser as part of a grammar\ndevelopment system.\n"},{"#tail":"\n","@confidence":"0.983008896551724","#text":"\nIn case of large grammars the space requirements\nof dynamic parsing often outweigh the benefit of\nnot duplicating sub-computations. We propose a\nparser that avoids this drawback through combin-\ning the advantages of dynamic bottom-up and ad-\nvanced top-down control. 1 The underlying idea is\nto achieve faster parsing by avoiding tabling on\nsub-computations which are not expensive. The\nso-called selective magic parser allows the user to\napply magic compilation to specific constraints in\na grammar which as a result can be processed y-\nnamically in a bottom-up and goal-directed fash-\nion. State of the art top-down processing tech-\nniques are used to deal with the remaining con-\nstraints.\nMagic is a compilation technique originally de-\nveloped for goal-directed bottom-up rocessing of\nlogic programs. See, among others, (Ramakrish-\nnan et al 1992). As shown in (Minnen, 1996)\n*The presented research was carried out at the Uni-\nversity of Tfibingen, Germany, as part of the Sonder-\nforschungsbereich 340.\n1A more detailed iscussion of various aspects of\nthe proposed parser can be found in (Minnen, 1998).\nmagic is an interesting technique with respect o\nnatural language processing as it incorporates fil-\ntering into the logic underlying the grammar and\nenables elegant control independent filtering im-\nprovements. In this paper we investigate the se-\nlective application of magic to typed feature gram-\nmars a type of constraint-logic grammar based on\nTyped Feature Logic (Tgv?:; GStz, 1995). Typed\nfeature grammars can be used as the basis for\nimplementations of Head-driven Phrase Structure\nGrammar (HPSG; Pollard and Sag, 1994) as dis-\ncussed in (GStz and Meurers, 1997a) and (Meur-\ners and Minnen, 1997). Typed feature grammar\nconstraints that are inexpensive to resolve are\ndealt with using the top-down interpreter of the\nConTroll grammar development system (GStz and\nMeurers, 1997b) which uses an advanced search\nfunction, an advanced selection function and in-\ncorporates a coroutining mechanism which sup-\nports delayed interpretation.\nThe proposed parser is related to the so-called\nLemma Table deduction system (Johnson and\nDSrre, 1995) which allows the user to specify\nwhether top-down sub-computations are to be\ntabled. In contrast to Johnson and DSrre's deduc-\ntion system, though, the selective magic parsing\napproach combines top-down and bottom-up con-\ntrol strategies. As such it resembles the parser\nof the grammar development system Attribute\nLanguage Engine (ALE) of (Carpenter and Penn,\n1994). Unlike the ALE parser, though, the selec-\ntive magic parser does not presuppose a phrase\nstructure backbone and is more flexible as to\nwhich sub-computations are tabled/filtered.\n"},{"#tail":"\n","@confidence":"0.999858","#text":"\nWe describe typed feature grammars and discuss\ntheir use in implementing HPSG grammars. Sub-\nsequently we present magic compilation of typed\n"},{"#tail":"\n","@confidence":"0.9990745","#text":"\nfeature grammars on the basis of an example and\nintroduce a dynamic bottom-up interpreter that\ncan be used for goM-directed interpretation of\nmagic-compiled typed feature grammars.\n"},{"#tail":"\n","@confidence":"0.983137133333333","#text":"\nA typed feature grammar consists of a signa-\nture and a set of definite clauses over the con-\nstraint language of equations o fTY? (GStz, 1995)\nterms (HShfeld and Smolka, 1988) which we will\nrefer to as Torz: definite clauses. Equations over\nTJr? terms can be solved using (graph) unifica-\ntion provided they are in normal form. (GStz,\n1994) describes a normal form for ir~r? terms,\nwhere typed feature structures are interpreted as\nsatisfiable normal form T~r?: terms. 2 The signa-\nture consists of a type hierarchy and a set of ap-\npropriateness conditions.\nExample 1 The signature specified in figure 1\nand 2 and the T~r?: definite clauses in figure 3\nconstitute an example of a typed feature gram-\n"},{"#tail":"\n","@confidence":"0.992181","#text":"\nas typed feature structures. In addition, uninfor-\nmative feature specifications are ignored and typ-\ning is left implicit when immaterial to the example\nat hand. Equations between typed feature struc-\ntures are removed by simple substitution or tags\nindicating structure sharing. Notice that we also\nuse non-numerical tags such as ~ and ~ . In\ngeneral all boxed items indicate structure sharing.\nFor expository reasons we represent he ARGn\nfeatures of the append relation as separate argu-\nments.\nTyped feature grammars can be used as the\nbasis for implementations of Head-driven Phrase\nStructure Grammar (Pollard and Sag, 1994). 3\n(Meurers and Minnen, 1997) propose a compi-\nlation of lexical rules into T~r/: definite clauses\n2This view of typed feature structures differs from\nthe perspective on typed feature structures as mod-\nehng partial information as in (Carpenter, 1992).\nTyped feature structures as normal form ir~'~E terms\nare merely syntactic objects.\naSee (King, 1994) for a discussion of the appro-\npriateness of T~-?: for HPSG and a comparison with\nother feature logic approaches designed for HPSG.\n"},{"#tail":"\n","@confidence":"0.9630426","#text":"\nwhich are used to restrict lexical entries. (GStz\nand Meurers, 1997b) describe a method for com-\npiling implicational constraints into typed feature\ngrammars and interleaving them with relational\nconstraints. 4 Because of space limitations we have\nto refrain from an example. The ConTroll gram-\nmar development system as described in (GStz\nand Meurers, 1997b) implements the above men-\ntioned techniques for compiling an HPSG theory\ninto typed feature grammars.\n"},{"#tail":"\n","@confidence":"0.995494833333333","#text":"\nMagic is a compilation technique for goal-directed\nbottom-up processing of logic programs. See,\namong others, (Ramakrishnan et al 1992). Be-\ncause magic compilation does not refer to the spe-\ncific constraint language adopted, its application\nis not limited to logic programs/grammars: It can\nbe applied to relational extensions of other con-\nstraint languages such as typed feature grammars\nwithout further adaptions.\nDue to space limitations we discuss magic com-\npilation by example only. The interested reader\nis referred to (Nilsson and Maluszynski, 1995) for\nan introduction.\nExample 2 We illustrate magic compilation of\ntyped feature grammars with respect to definite\n4 (GStz, 1995) proves that this compilation method\nis sound in the general case and defines the large class\nof type constraints for which it is complete.\n"},{"#tail":"\n","@confidence":"0.9666435","#text":"\nclause 1 in figure 3. Consider the TJ:? definite\nclause in figure 4. As a result of magic compi-\n"},{"#tail":"\n","@confidence":"0.990956","#text":"\nure 3\nlation a magic literal is added to the right-hand\nside of the original definite clause. Intuitively un-\nderstood, this magic literal &quot;guards&quot; the applica-\ntion of the definite clause. The clause is applied\nonly when there exists a fact that unifies with this\nmagic l iteral) The resulting definite clause is also\nreferred to as the magic variant of the original def-\ninite clause.\nThe definite clause in figure 5 is the so-called\nseed which is used to make the bindings as pro-\nvided by the initial goal available for bottom-up\nprocessing. In this case the seed corresponds to\nthe initial goal of parsing the string 'mary sleeps'.\nIntuitively understood, the seed makes available\nthe bindings of the initial goal to the magic vari-\nSA fact can be a unit clause, i. e., a TJr? definite\nclause without right-hand side literals, from the gram-\nmar or derived using the rules in the grammar. In the\nlatter case one also speaks of a passive dge.\n"},{"#tail":"\n","@confidence":"0.997474411764706","#text":"\nparsing the string 'mary sleeps'\nants of the definite clauses defining a particular\ninitial goal; in this case the magic variant of the\ndefinite clause defining a constituent of category\n's'. Only when their magic literal unifies with the\nseed are these clauses applied. 6\nThe so-cMled magic rules in figure 6 are derived\nin order to be able to use the bindings provided by\nthe seed to derive new facts that provide the bind-\nings which allow for a goal-directed application of\nthe definite clauses in the grammar not directly\ndefining the initial goal. Definite clause 3, for\nexample, can be used to derive a magic_append\nfact which percolates the relevant bindings of the\nseed/initial goal to restrict the application of the\nmagic variant of definite clauses 4 and 5 in figure 3\n(which are not displayed).\n"},{"#tail":"\n","@confidence":"0.994664416666667","#text":"\nMagic-compiled logic programs/grammars can be\ninterpreted in a bottom-up fashion without losing\nany of the goal-directedness normally associated\nwith top-down interpretation using a so-called\nsemi-naive bottom-up interpreter: A dynamic in-\nterpreter that tables only complete intermediate\nresults, i. e., facts or passive edges, and uses\nan agenda to avoid redundant sub-computations.\nThe Prolog predicates in figure 7 implement a\n~The creation of the seed can be postponed until\nrun time, such that the grammar does not need to be\ncompiled for every possible initial goal.\n"},{"#tail":"\n","@confidence":"0.967198965517241","#text":"\nmagic compilation to definite clause 1 in figure 3\nsemi-naive bottom-up interpreter. 7 In this inter-\npreter both the table and the agenda are repre-\nsented using lists, s The agenda keeps track of the\nfacts that have not yet been used to update the\ntable. It is important o notice that in order to\nuse the interpreter for typed feature grammars it\nhas to be adapted to perform graph unification. 9\nWe refrain from making the necessary adaptions\nto the code for expository reasons.\nThe table is initialized with the facts from the\ngrammar. Facts are combined using a operation\ncalled match. The match operation unifies all but\none of the right-hand side literals of a definite\nclause in the grammar with facts in the table. The\n7Definite clauses serving as data are en-\ncoded using the predicate definite_clause/l:\ndefinite_clause((Lhs :-B/Is))., where Khs is a\n(possibly empty) list of literals.\nSThere are various other--more fficient--ways to\nimplement a dynamic ontrol strategy in Prolog. See,\nfor example, (Shieber et el., 1995).\n9A term encoding of typed feature structures would\nenable the use of term unification instead. See, for\nexample, (Gerdemann, 1995).\nremaining right-hand side literal is unified with a\nnewly derived fact, i. e., a fact from the agenda.\nBy doing this, repeated erivation of facts from\nthe same earlier derived facts is avoided.\n"},{"#tail":"\n","@confidence":"0.998519636363636","#text":"\nIn case of large grammars the huge space require-\nments of dynamic processing often nullify the ben-\nefit of tabling intermediate r sults. By combin-\ning control strategies and allowing the user to\nspecify how to process particular constraints in\nthe grammar the selective magic parser avoids\nthis problem. This solution is based on the ob-\nservation that there are sub-computations that\nare relatively cheap and as a result do not need\ntabling (Johnson and D6rre, 1995; van Noord,\n1997).\n"},{"#tail":"\n","@confidence":"0.9991895","#text":"\nCombining control strategies depends on a way\nto differentiate between types of constraints. For\n"},{"#tail":"\n","@confidence":"0.99080976","#text":"\nexample, the ALE parser (Carpenter and Penn,\n1994) presupposes a phrase structure backbone\nwhich can be used to determine whether a con-\nstraint is to be interpreted bottom-up or top-\ndown. In the case of selective magic parsing we\nuse so-called parse types which allow the user to\nspecify how constraints in the grammar are to be\ninterpreted. A literal (goal) is considered a parse\nlype literal (goal) if it has as its single argument\na typed feature structure of a type specified as a\nparse type. 1?\nAll types in the type hierarchy can be used\nas parse types. This way parse type specifica-\ntion supports a flexible filtering component which\nallows us to experiment with the role of filter-\ning. However, in the remainder we will concen-\ntrate on a specific class of parse types: We as-\nsume the specification of type sign and its sub-\ntypes as parse types. 11 This choice is based on\nthe observation that the constraints on type sign\nand its sub-types play an important guiding role\nin the parsing process and are best interpreted\nbottom-up given the lexical orientation of I-IPSG.\nThe parsing process corresponding tosuch a parse\ntype specification is represented schematically in\n"},{"#tail":"\n","@confidence":"0.972029388888889","#text":"\nmagic parsing process\nthe :r~'L definite clauses that specify the word\nobjects in the grammar, phrases are built bottom-\nup by matching the parse type literals of the def-\ninite clauses in the grammar against he edges in\nthe table. The non-parse type literals are pro-\ncessed according to the top-down control strategy\n1?The notion of a parse type literal is closely related\nto that of a memo literal as in (Johnson and DSrre,\n1995).\nl~When a type is specified as a parse type, all its\nsub-types are considered as parse types as well. This is\nnecessary as otherwise there may e.xist magic variants\nof definite clauses defining a parse type goal for which\nno magic facts can be derived which means that the\nmagic literal of these clauses can be interpreted nei-\nther top-down nor bottom-up.\ndescribed in section 3.3.\n"},{"#tail":"\n","@confidence":"0.999838769230769","#text":"\nIn order to process parse type goals according to a\nsemi-naive magic control strategy, we apply magic\ncompilation selectively. Only the T~-L definite\nclauses in a typed feature grammar which define\nparse type goals are subject to magic compilation.\nThe compilation applied to these clauses is iden-\ntical to the magic compilation illustrated in sec-\ntion 2.1 except hat we derive magic rules only for\nthe right-hand side literals in a clause which are of\na parse type. The definite clauses in the grammar\ndefining non-parse type goals are not compiled as\nthey will be processed using the top-down inter-\npreter described in the next section.\n"},{"#tail":"\n","@confidence":"0.967109756756757","#text":"\nNon-parse type goals are interpreted using the\nstandard interpreter of the ConTroll grammar de-\nvelopment system (G5tz and Meurers, 1997b) as\ndeveloped and implemented by Thilo GStz. This\nadvanced top-down interpreter uses a search func-\ntion that allows the user to specify the information\non which the definite clauses in the grammar are\nindexed. An important advantage of deep multi-\nple indexing is that the linguist does not have to\ntake into account of processing criteria with re-\nspect to the organization of her/his data as is the\ncase with a standard Prolog search function which\nindexes on the functor of the first argument.\nAnother important feature of the top-down in-\nterpreter is its use of a selection function that\ninterprets deterministic goals, i. e., goals which\nunify with the left-hand side literal of exactly\none definite clause in the grammar, prior to non-\ndeterministic goals. This is often referred to as\nincorporating delerministic closure (DSrre, 1993).\nDeterministic losure accomplishes a reduction of\nthe number of choice points that need to be set\nduring processing to a minimum. Furthermore, it\nleads to earlier failure detection.\nFinally, the used top-down interpreter imple-\nments a powerful coroutining mechanism: 12 At\nrun time the processing of a goal is postponed\nin case it is insufficiently instantiated. Whether\nor not a goal is sufficiently instantiated is deter-\nmined on the basis of so-called delay palierns. 13\nThese are specifications provided by the user that\n12Coroutining appears under many different guises,\nlike for example, suspension, residuation, (goal) freez-\ning, and blocking. See also (Colmerauer, 1982; Naish,\n1986).\n13In the literature delay patterns are sometimes also\nreferred to as wait declarations or .block statements.\n"},{"#tail":"\n","@confidence":"0.795829333333333","#text":"\nProceedings ofEACL '99\nindicate which restricting information has to be\navailable before a goal is processed.\n"},{"#tail":"\n","@confidence":"0.9952875","#text":"\nThe definite clauses resulting from selective magic\ntransformation are interpreted using a semi-naive\nbottom-up interpreter that is adapted in two re-\nspects. It ensures that non-parse type goals are\ninterpreted using the advanced top-down inter-\npreter, and it allows non-parse type goals that\nremain delayed locally to be passed in and out\nof sub-computations i a similar fashion as pro-\nposed by (Johnson and DSrre, 1995). In order\nto accommodate these changes the adapted semi-\nnaive interpreter enables the use of edges which\nspecify delayed goals.\n"},{"#tail":"\n","@confidence":"0.982467764705883","#text":"\ndefinite clause under consideration to the ad-\nvanced top-down interpreter via the call to\nadvanced_td_interpret/2 as the list of goals\nTopDown. 14 The second efining clause of match/3\nis added to ensure all right-hand side literals are\ndirectly passed to the advanced top-down inter-\npreter if none of them are of a parse type.\nAllowing edges which specify delayed goals\nnecessitates the adaption of the definition of\nedges/3. When a parse type literal is matched\nagainst an edge in the table, the delayed goals\nspecified by that edge need to be passed to the\ntop-down interpreter. Consider the definition of\nthe predicate dges in figure 11. The third argu-\nment of the definition of edges/4 is used to collect\ndelayed goals. When there are no more parse type\nliterals in the right-hand side of the definite clause\nunder consideration, the second defining clause\nof edges/4 appends the collected delayed goals\nZ4The definition of match/3 assumes that there ex-\nists a strict ordering of the right-hand side literals in\nthe definite clauses in the grammar, i. e., parse type\nliterals always preced enon-parse type literals.\nedges(\\[Lit\\[Lits\\],Table,Delayed0,TopDown):-\nparse_type(Lit),\nmember(edge(Lit,Delayedl),Table),\nappend(Delayed0,Delayedl,Delayed).\nedges(Lit,Table,Delayed,TopDown).\nedges(\\[\\],_,Delayed,TopDown):-\nappend(Delayed,Lit,TopDown).\nFigure lh Adapted efinition of edges/4\nto the remaining non-parse type literals. Subse-\nquently, the resulting list of literals is passed up\nagain for advanced top-down interpretation.\n"},{"#tail":"\n","@confidence":"0.999536575","#text":"\nThe described parser was implemented aspart of\nthe ConTroll grammar development system (GStz\nand Meurers, 1997b). Figure 10 shows the over-\nall setup of the ConTroll magic component. The\nControll magic component presupposes a parse\ntype specification and a set of delay patterns to\ndetermine when non-parse type constraints are to\nbe interpreted. At run-time the goal-directedness\nof the selective magic parser is further increased\nby means of using the phonology of the natural\nlanguage xpression to be parsed as specified by\nthe initial goal to restrict he number of facts that\nare added to the table during initialization. Only\nthose facts in the grammar corresponding to lex-\nical entries that have a value for their phonology\nfeature that appears as part of the input string\nare used to initialize the table.\nThe ConTroll magic omponent was tested with\na larger (> 5000 lines) HPSG grammar of a size-\nable fragment of German. This grammar provides\nan analysis for simple and complex verb-second,\nverb-first and verb-last sentences with scrambling\nin the mittelfeld, extraposition phenomena, wh-\nmovement and topicalization, integrated verb-first\nparentheticals, and an interface to an illocution\ntheory, as well as the three kinds of infinitive con-\nstructions, nominal phrases, and adverbials (Hin-\nrichs et al, 1997).\nAs the test grammar combines sub-strings in a\nnon-concatenative fashion, a preprocessor is used\nthat chunks the input string into linearization do-\nmains. This way the standard ConTroll inter-\npreter (as described in section 3.3) achieves pars-\ning times of around 1-5 seconds for 5 word sen-\ntences and 10-60 seconds for 12 word sentences) s\nThe use of magic compilation on all grammar\nconstraints, i.e., tabling of all sub-computations,\nlSParsing with such a grammar is difficult in any\nsystem as it does neither have nor allow the extraction\nof a phrase structure backbone.\n"},{"#tail":"\n","@confidence":"0.993350538461539","#text":"\nsignificant speedup in many cases. For example,\nparsing with the module of the grammar imple-\nmenting the analysis of nominal phrases is up to\nnine times faster. At the same time though se-\nlective magic HPSG parsing is sometimes signifi-\ncantly slower. For example, parsing of particular\nsentences exhibiting adverbial subordinate clauses\nand long extraction is sometimes more than nine\ntimes slower. We conjecture that these ambigu-\nous results are due to the use of coroutining: As\nthe test grammar was implemented using the stan-\ndard ConTroll interpreter, the delay patterns used\npresuppose a data-flow corresponding to advanced\ntop-down control and are not fine-tuned with re-\nspect to the data-flow corresponding to the selec-\ntive magic parser.\nCoroutining is a flexible and powerful facility\nused in many grammar development systems and\nit will probably remain indispensable in dealing\nwith many control problems despite its various\ndisadvantages) 6 The test results discussed above\nindicate that the comparison of parsing strategies\ncan be seriously hampered by fine-tuning parsing\nusing delay patterns. We believe therefore that\nfurther research into the systematics underlying\ncoroutining would be desirable.\n"},{"#tail":"\n","@confidence":"0.998573466666667","#text":"\nWe described a selective magic parser for typed\nfeature grammars implementing HPSG that com-\nbines the advantages of dynamic bottom-up and\nadvanced top-down control. As a result the parser\navoids the efficiency problems resulting from the\nhuge space requirements of storing intermediate\nresults in parsing with large grammars. The\nparser allows the user to apply magic compilation\nto specific constraints in a grammar which as a\n16Coroutining has a significant run-time overhead\ncaused by the necessity to check the instantiation sta-\ntus of a literal/goal. In addition, it demands the pro-\ncedural annotation of an otherwise declarative gram-\nmar. Finally, coroutining presupposes that a grammar\nwriter possesses substantial processing expertise.\n"},{"#tail":"\n","@confidence":"0.925087375","#text":"\nProceedings of EACL '99\nresult can be processed ynamically in a bottom-\nup and goal-directed fashion. State of the art\ntop-down processing techniques are used to deal\nwith the remaining constraints. We discussed var-\nious aspects concerning the implementation f the\nparser which was developed as part of the gram-\nmar development system ConTroll.\n"},{"#tail":"\n","@confidence":"0.970371083333333","#text":"\nThe author gratefully acknowledges the support\nof the SFB 340 project B4 &quot;From Constraints to\nRules: Efficient Compilation of ttPSG&quot; funded by\nthe German Science Foundation and the project\n&quot;PSET: Practical Simplification of English Text&quot;,\na three-year project funded by the UK Engi-\nneering and Physical Sciences Research Council\n(GR/L53175), and Apple Computer Inc.. The au-\nthor wishes to thank Dale Gerdemann and Erhard\nHinrichs and the anonymous reviewers for com-\nments and discussion. Of course, the author is\nresponsible for all remaining errors.\n"}],"#text":"\n","sectionHeader":[{"#tail":"\n","@confidence":"0.931361","@genericHeader":"abstract","#text":"\nAbstract\n"},{"#tail":"\n","@confidence":"0.997339","@genericHeader":"introduction","#text":"\n1 Introduction\n"},{"#tail":"\n","@confidence":"0.988533","@genericHeader":"method","#text":"\n3 Selective Magic HPSG Parsing\n"},{"#tail":"\n","@confidence":"0.797968","@genericHeader":"method","#text":"\n4 Imp lementat ion\n"},{"#tail":"\n","@confidence":"0.895547","@genericHeader":"method","#text":"\n5 Conc lud ing Remarks\n"},{"#tail":"\n","@confidence":"0.966906","@genericHeader":"acknowledgments","#text":"\nAcknowledgments\n"},{"#tail":"\n","@confidence":"0.991392","@genericHeader":"references","#text":"\nReferences\n"}],"page":[{"#tail":"\n","@confidence":"0.998995","#text":"\n165\n"},{"#tail":"\n","@confidence":"0.997024","#text":"\n166\n"},{"#tail":"\n","@confidence":"0.97481","#text":"\n167\n"},{"#tail":"\n","@confidence":"0.993874","#text":"\n168\n"},{"#tail":"\n","@confidence":"0.99752","#text":"\n169\n"},{"#tail":"\n","@confidence":"0.988894","#text":"\n171\n"},{"#tail":"\n","@confidence":"0.99901","#text":"\n172\n"}],"figureCaption":[{"#tail":"\n","@confidence":"0.62024875","#text":"\nmar. We write T~r? terms in normal form, i. e.,\nrelation\nFigure 2: Example of a typed feature grammar\nsignature (part 2)\n"},{"#tail":"\n","@confidence":"0.659109","#text":"\na.ppend(F'x- ~,~, ~Y's\\])-\nFigure 3: Example of a set of T:7:? definite clauses\n"},{"#tail":"\n","@confidence":"0.723516","#text":"\nFigure h Example of a typed feature grammar signature (part 1)\n"},{"#tail":"\n","@confidence":"0.78803","#text":"\nappendG,D,Vl).\nFigure 4: Magic variant of definite clause 1 in fig-\n"},{"#tail":"\n","@confidence":"0.99864","#text":"\nFigure 5: Seed corresponding tothe initial goal of\n"},{"#tail":"\n","@confidence":"0.999632","#text":"\nFigure 6: Magic rules resulting from applying\n"},{"#tail":"\n","@confidence":"0.765345428571429","#text":"\nselect(F,Body,R),\nedges(R,Table).\nedges(\\[\\],_).\nedges(\\[Lit\\[Lits\\],Table):-\nmember(edge(Lit,\\[\\]),Table),\nedges(Lits,Table).\nFigure 7: Semi-naive bottom-up interpreter\n"},{"#tail":"\n","@confidence":"0.995543","#text":"\nfigure 8. Starting from the lexical entries, i. e.,\nword word word\nFigure 8: Schematic representation ofthe selective\n"},{"#tail":"\n","@confidence":"0.490426857142857","#text":"\nFigure 9 illustrates the adapted match op-\neration. The first defining clause of match/3\nmatch(Edge,edge(Goal,Delayed),Table):-\ndefinite_clause((Goal :- Body)),\nselect(Lit,Body,Lits),\nparse_type(Lit),\nEdge = edge(Lit,DelayedO),\nedges(Lit,Table,DelayedO,TopDown),\nadvancechtd_interpret(TopDown,Delayed).\nmatch(Edge,edge(Goal,Delayed),Table):-\ndefinite~lause((Goal :- TopDown)),\nadvanced_td_interpret(TopDown,Delayed).\nFigure 9: Adapted efinition of mat, oh/3\npasses delayed and non-parse type goals of the\n"},{"#tail":"\n","@confidence":"0.874966","#text":"\nFigure 10: Setup of the ConTroll magic omponent\nleads to an vast increase of parsing times. The\nselective magic HPSG parser, however, exhibits a\n"}]}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.516114","#tail":"\n","@no":"0","note":{"#tail":"\n","@confidence":"0.757602","#text":"Proceedings of EACL '99"},"address":{"#tail":"\n","@confidence":"0.9105895","#text":"Falmer, Brighton BN1 9QH United Kingdom"},"#text":"\n","affiliation":{"#tail":"\n","@confidence":"0.986561","#text":"Cognitive and Computing Sciences, University of Sussex"},"author":{"#tail":"\n","@confidence":"0.997389","#text":"Guido Minnen"},"abstract":{"#tail":"\n","@confidence":"0.9984415","#text":"We propose a parser for constraintlogic grammars implementing HPSG that combines the advantages of dynamic bottom-up and advanced topdown control. The parser allows the user to apply magic compilation to specific constraints in a grammar which as a result can be processed dynamically in a bottom-up and goal-directed fashion. State of the art top-down processing techniques are used to deal with the remaining constraints. We discuss various aspects concerning the implementation of the parser as part of a grammar development system."},"title":{"#tail":"\n","@confidence":"0.998382","#text":"Selective Magic HPSG Parsing"},"email":{"#tail":"\n","@confidence":"0.894865","#text":"Guido.Minnen@cogs.susx.ac.ukwww.cogs.susx.ac.uk/lab/nlp/minnen/minnen.html"}}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","tech":{"#tail":"\n","#text":"Technical report,"},"date":{"#tail":"\n","#text":"1994"},"institution":{"#tail":"\n","#text":"Carnegie Mellon University,"},"rawString":{"#tail":"\n","#text":"Bob Carpenter and Gerald Penn. 1994. ALE -The Attribute Logic Engine, User's guide, version 2.0.2. Technical report, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA."},"#text":"\n","marker":{"#tail":"\n","#text":"Carpenter, Penn, 1994"},"location":{"#tail":"\n","#text":"Pittsburgh, Pennsylvania, USA."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" which uses an advanced search function, an advanced selection function and in- corporates a coroutining mechanism which sup- ports delayed interpretation. The proposed parser is related to the so-called Lemma Table deduction system (Johnson and DSrre, 1995) which allows the user to specify whether top-down sub-computations are to be tabled. In contrast to Johnson and DSrre's deduc- tion system, though, the selective magic parsing approach combines top-down and bottom-up con- trol strategies. As such it resembles the parser of the grammar development system Attribute Language Engine (ALE) of (Carpenter and Penn, 1994). Unlike the ALE parser, though, the selec- tive magic parser does not presuppose a phrase structure backbone and is more flexible as to which sub-computations are tabled/filtered. Bottom-up Interpretation of Magic-compiled Typed Feature Grammars We describe typed feature grammars and discuss their use in implementing HPSG grammars. Sub- sequently we present magic compilation of typed 165 Proceedings of EACL '99 feature grammars on the basis of an example and introduce a dynamic bottom-up interpreter that can be used for goM-directed interpretation of magic-compiled typed feature grammars. 2.1","@endWordPosition":"502","@position":"3337","annotationId":"T1","@startWordPosition":"499","@citStr":"Carpenter and Penn, 1994"},{"#tail":"\n","#text":"ocessing often nullify the ben- efit of tabling intermediate r sults. By combin- ing control strategies and allowing the user to specify how to process particular constraints in the grammar the selective magic parser avoids this problem. This solution is based on the ob- servation that there are sub-computations that are relatively cheap and as a result do not need tabling (Johnson and D6rre, 1995; van Noord, 1997). 3.1 Parse Type Specif ication Combining control strategies depends on a way to differentiate between types of constraints. For 168 Proceedings of EACL '99 example, the ALE parser (Carpenter and Penn, 1994) presupposes a phrase structure backbone which can be used to determine whether a con- straint is to be interpreted bottom-up or top- down. In the case of selective magic parsing we use so-called parse types which allow the user to specify how constraints in the grammar are to be interpreted. A literal (goal) is considered a parse lype literal (goal) if it has as its single argument a typed feature structure of a type specified as a parse type. 1? All types in the type hierarchy can be used as parse types. This way parse type specifica- tion supports a flexible filtering component which allows","@endWordPosition":"2164","@position":"14184","annotationId":"T2","@startWordPosition":"2161","@citStr":"Carpenter and Penn, 1994"}]},"title":{"#tail":"\n","#text":"ALE -The Attribute Logic Engine, User's guide, version 2.0.2."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Bob Carpenter"},{"#tail":"\n","#text":"Gerald Penn"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1992"},"rawString":{"#tail":"\n","#text":"Bob Carpenter. 1992. The Logic of Typed Feature Structures - With Applications to Unification Grammars, Logic Programs and Constraint Resolution. Cambridge University Press, New York, USA."},"#text":"\n","marker":{"#tail":"\n","#text":"Carpenter, 1992"},"publisher":{"#tail":"\n","#text":"Cambridge University Press,"},"location":{"#tail":"\n","#text":"New York, USA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ucture sharing. Notice that we also use non-numerical tags such as ~ and ~ . In general all boxed items indicate structure sharing. For expository reasons we represent he ARGn features of the append relation as separate argu- ments. Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar (Pollard and Sag, 1994). 3 (Meurers and Minnen, 1997) propose a compi- lation of lexical rules into T~r/: definite clauses 2This view of typed feature structures differs from the perspective on typed feature structures as mod- ehng partial information as in (Carpenter, 1992). Typed feature structures as normal form ir~'~E terms are merely syntactic objects. aSee (King, 1994) for a discussion of the appro- priateness of T~-?: for HPSG and a comparison with other feature logic approaches designed for HPSG. (1) constituent( \\[PHON ):- LSEM PHON constituent( \\[ AGR )' I_Sr~M teAT? 1 constituent( |AGR )' append(\\[~,\\[~,\\[~). rCAT ?, \\] (2) constituent( \\[PHON ( ,,,,y ) /xGR ,h.~-,,.~\\] )&quot; (3) constituent( |PHON (,leCp,) /AGR ,h,.~-.,.~ I ). LSEM sleep J (4) append((), F'~' ~)&quot; (5) append( 3 | a.ppend(F'x- ~,~, ~Y's\\])- Figure 3: Example of a set of T:7:? definite clau","@endWordPosition":"871","@position":"5665","annotationId":"T3","@startWordPosition":"870","@citStr":"Carpenter, 1992"}},"title":{"#tail":"\n","#text":"The Logic of Typed Feature Structures - With Applications to Unification Grammars, Logic Programs and Constraint Resolution."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Bob Carpenter"}}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Technical report,"},"date":{"#tail":"\n","#text":"1982"},"rawString":{"#tail":"\n","#text":"Alain Colmerauer. 1982. PrologII: Manuel de r@f~rence t module th@orique. Technical report, Groupe d'Intelligence Artificielle, Facult~ de Sciences de Luminy, Marseille, France."},"#text":"\n","marker":{"#tail":"\n","#text":"Colmerauer, 1982"},"location":{"#tail":"\n","#text":"Marseille, France."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"choice points that need to be set during processing to a minimum. Furthermore, it leads to earlier failure detection. Finally, the used top-down interpreter imple- ments a powerful coroutining mechanism: 12 At run time the processing of a goal is postponed in case it is insufficiently instantiated. Whether or not a goal is sufficiently instantiated is deter- mined on the basis of so-called delay palierns. 13 These are specifications provided by the user that 12Coroutining appears under many different guises, like for example, suspension, residuation, (goal) freez- ing, and blocking. See also (Colmerauer, 1982; Naish, 1986). 13In the literature delay patterns are sometimes also referred to as wait declarations or .block statements. 169 Proceedings ofEACL '99 indicate which restricting information has to be available before a goal is processed. 3.4 Adapted Semi-naive Bottom-up Interpretat ion The definite clauses resulting from selective magic transformation are interpreted using a semi-naive bottom-up interpreter that is adapted in two re- spects. It ensures that non-parse type goals are interpreted using the advanced top-down inter- preter, and it allows non-parse type goals that remain delayed lo","@endWordPosition":"2895","@position":"18623","annotationId":"T4","@startWordPosition":"2894","@citStr":"Colmerauer, 1982"}},"title":{"#tail":"\n","#text":"PrologII: Manuel de r@f~rence t module th@orique."},"booktitle":{"#tail":"\n","#text":"Groupe d'Intelligence Artificielle, Facult~ de Sciences de Luminy,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Alain Colmerauer"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"Jochen DSrre. 1993. Generalizing Earley Deduction for Constraint-based Grammars. In Jochen DSrre and Michael Dorna (eds.), 1993. Computational Aspects of Constraint-Based Linguistic Description L DYANA-2, Deliverable R1.2.A. Dale Gerdemann. 1995. Term Encoding of Typed Feature Structures. In Proceedings of the Fourth International Workshop on Parsing Technologies, Prague, Czech Republic."},"#text":"\n","marker":{"#tail":"\n","#text":"DSrre, 1993"},"location":{"#tail":"\n","#text":"Prague, Czech Republic."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ge of deep multi- ple indexing is that the linguist does not have to take into account of processing criteria with re- spect to the organization of her/his data as is the case with a standard Prolog search function which indexes on the functor of the first argument. Another important feature of the top-down in- terpreter is its use of a selection function that interprets deterministic goals, i. e., goals which unify with the left-hand side literal of exactly one definite clause in the grammar, prior to non- deterministic goals. This is often referred to as incorporating delerministic closure (DSrre, 1993). Deterministic losure accomplishes a reduction of the number of choice points that need to be set during processing to a minimum. Furthermore, it leads to earlier failure detection. Finally, the used top-down interpreter imple- ments a powerful coroutining mechanism: 12 At run time the processing of a goal is postponed in case it is insufficiently instantiated. Whether or not a goal is sufficiently instantiated is deter- mined on the basis of so-called delay palierns. 13 These are specifications provided by the user that 12Coroutining appears under many different guises, like for example, sus","@endWordPosition":"2792","@position":"17942","annotationId":"T5","@startWordPosition":"2791","@citStr":"DSrre, 1993"}},"title":{"#tail":"\n","#text":"Generalizing Earley Deduction for Constraint-based Grammars."},"booktitle":{"#tail":"\n","#text":"In Jochen DSrre and Michael Dorna (eds.), 1993. Computational Aspects of Constraint-Based Linguistic Description L DYANA-2, Deliverable R1.2.A. Dale Gerdemann."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Jochen DSrre"}}},{"#tail":"\n","date":{"#tail":"\n"},"rawString":{"#tail":"\n","#text":"Thilo GStz and Detmar Meurers. 1997a. Interleaving Universal Principles and Relational Constraints over Typed Feature Logic. In A CL/EACL Proceedings, Madrid, Spain."},"#text":"\n","marker":{"#tail":"\n"},"location":{"#tail":"\n","#text":"Madrid,"},"title":{"#tail":"\n","#text":"Thilo GStz and Detmar Meurers. 1997a. Interleaving Universal Principles and Relational Constraints over Typed Feature Logic."},"booktitle":{"#tail":"\n","#text":"In A CL/EACL Proceedings,"},"@valid":"true"},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Thilo GStz and Detmar Meurers. 1997b. The ConTroll System as Large Grammar Development Platform. In Proceedings of the ACL Workshop on Computational Environments for Grammar Development and Linguistic Engineering, Madrid, Spain."},"#text":"\n","marker":{"#tail":"\n","#text":"GStz, Meurers, 1997"},"location":{"#tail":"\n","#text":"Madrid,"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"the proposed parser can be found in (Minnen, 1998). magic is an interesting technique with respect o natural language processing as it incorporates fil- tering into the logic underlying the grammar and enables elegant control independent filtering im- provements. In this paper we investigate the se- lective application of magic to typed feature gram- mars a type of constraint-logic grammar based on Typed Feature Logic (Tgv?:; GStz, 1995). Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar (HPSG; Pollard and Sag, 1994) as dis- cussed in (GStz and Meurers, 1997a) and (Meur- ers and Minnen, 1997). Typed feature grammar constraints that are inexpensive to resolve are dealt with using the top-down interpreter of the ConTroll grammar development system (GStz and Meurers, 1997b) which uses an advanced search function, an advanced selection function and in- corporates a coroutining mechanism which sup- ports delayed interpretation. The proposed parser is related to the so-called Lemma Table deduction system (Johnson and DSrre, 1995) which allows the user to specify whether top-down sub-computations are to be tabled. In contrast to Johnson and DSrre's dedu","@endWordPosition":"378","@position":"2495","annotationId":"T6","@startWordPosition":"375","@citStr":"GStz and Meurers, 1997"},{"#tail":"\n","#text":"terms are merely syntactic objects. aSee (King, 1994) for a discussion of the appro- priateness of T~-?: for HPSG and a comparison with other feature logic approaches designed for HPSG. (1) constituent( \\[PHON ):- LSEM PHON constituent( \\[ AGR )' I_Sr~M teAT? 1 constituent( |AGR )' append(\\[~,\\[~,\\[~). rCAT ?, \\] (2) constituent( \\[PHON ( ,,,,y ) /xGR ,h.~-,,.~\\] )&quot; (3) constituent( |PHON (,leCp,) /AGR ,h,.~-.,.~ I ). LSEM sleep J (4) append((), F'~' ~)&quot; (5) append( 3 | a.ppend(F'x- ~,~, ~Y's\\])- Figure 3: Example of a set of T:7:? definite clauses which are used to restrict lexical entries. (GStz and Meurers, 1997b) describe a method for com- piling implicational constraints into typed feature grammars and interleaving them with relational constraints. 4 Because of space limitations we have to refrain from an example. The ConTroll gram- mar development system as described in (GStz and Meurers, 1997b) implements the above men- tioned techniques for compiling an HPSG theory into typed feature grammars. 2.2 Magic Compi la t ion Magic is a compilation technique for goal-directed bottom-up processing of logic programs. See, among others, (Ramakrishnan et al 1992). Be- cause magic compilation does not refer ","@endWordPosition":"980","@position":"6336","annotationId":"T7","@startWordPosition":"977","@citStr":"GStz and Meurers, 1997"},{"#tail":"\n","#text":" the grammar, i. e., parse type literals always preced enon-parse type literals. edges(\\[Lit\\[Lits\\],Table,Delayed0,TopDown):- parse_type(Lit), member(edge(Lit,Delayedl),Table), append(Delayed0,Delayedl,Delayed). edges(Lit,Table,Delayed,TopDown). edges(\\[\\],_,Delayed,TopDown):- append(Delayed,Lit,TopDown). Figure lh Adapted efinition of edges/4 to the remaining non-parse type literals. Subse- quently, the resulting list of literals is passed up again for advanced top-down interpretation. 4 Imp lementat ion The described parser was implemented aspart of the ConTroll grammar development system (GStz and Meurers, 1997b). Figure 10 shows the over- all setup of the ConTroll magic component. The Controll magic component presupposes a parse type specification and a set of delay patterns to determine when non-parse type constraints are to be interpreted. At run-time the goal-directedness of the selective magic parser is further increased by means of using the phonology of the natural language xpression to be parsed as specified by the initial goal to restrict he number of facts that are added to the table during initialization. Only those facts in the grammar corresponding to lex- ical entries that have a value","@endWordPosition":"3305","@position":"21635","annotationId":"T8","@startWordPosition":"3302","@citStr":"GStz and Meurers, 1997"}]},"title":{"#tail":"\n","#text":"The ConTroll System as Large Grammar Development Platform."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the ACL Workshop on Computational Environments for Grammar Development and Linguistic Engineering,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Thilo GStz"},{"#tail":"\n","#text":"Detmar Meurers"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Technical report SFB 340 nr. 40,"},"date":{"#tail":"\n","#text":"1994"},"institution":{"#tail":"\n","#text":"University of Tfibingen,"},"rawString":{"#tail":"\n","#text":"Thilo GStz. 1994. A Normal Form for Typed Feature Structures. Technical report SFB 340 nr. 40, University of Tfibingen, Germany."},"#text":"\n","marker":{"#tail":"\n","#text":"GStz, 1994"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"resent magic compilation of typed 165 Proceedings of EACL '99 feature grammars on the basis of an example and introduce a dynamic bottom-up interpreter that can be used for goM-directed interpretation of magic-compiled typed feature grammars. 2.1 Typed Feature Grammars A typed feature grammar consists of a signa- ture and a set of definite clauses over the con- straint language of equations o fTY? (GStz, 1995) terms (HShfeld and Smolka, 1988) which we will refer to as Torz: definite clauses. Equations over TJr? terms can be solved using (graph) unifica- tion provided they are in normal form. (GStz, 1994) describes a normal form for ir~r? terms, where typed feature structures are interpreted as satisfiable normal form T~r?: terms. 2 The signa- ture consists of a type hierarchy and a set of ap- propriateness conditions. Example 1 The signature specified in figure 1 and 2 and the T~r?: definite clauses in figure 3 constitute an example of a typed feature gram- mar. We write T~r? terms in normal form, i. e., relation Figure 2: Example of a typed feature grammar signature (part 2) as typed feature structures. In addition, uninfor- mative feature specifications are ignored and typ- ing is left impl","@endWordPosition":"651","@position":"4302","annotationId":"T9","@startWordPosition":"650","@citStr":"GStz, 1994"}},"title":{"#tail":"\n","#text":"A Normal Form for Typed Feature Structures."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Thilo GStz"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"rawString":{"#tail":"\n","#text":"Thilo GStz. 1995. Compiling HPSG Constraint Grammars into Logic Programs. In Proceedings of the Workshop on Computational Logic for Natural Language Processing, Edinburgh, UK."},"#text":"\n","marker":{"#tail":"\n","#text":"GStz, 1995"},"location":{"#tail":"\n","#text":"Edinburgh, UK."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"sented research was carried out at the Uni- versity of Tfibingen, Germany, as part of the Sonder- forschungsbereich 340. 1A more detailed iscussion of various aspects of the proposed parser can be found in (Minnen, 1998). magic is an interesting technique with respect o natural language processing as it incorporates fil- tering into the logic underlying the grammar and enables elegant control independent filtering im- provements. In this paper we investigate the se- lective application of magic to typed feature gram- mars a type of constraint-logic grammar based on Typed Feature Logic (Tgv?:; GStz, 1995). Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar (HPSG; Pollard and Sag, 1994) as dis- cussed in (GStz and Meurers, 1997a) and (Meur- ers and Minnen, 1997). Typed feature grammar constraints that are inexpensive to resolve are dealt with using the top-down interpreter of the ConTroll grammar development system (GStz and Meurers, 1997b) which uses an advanced search function, an advanced selection function and in- corporates a coroutining mechanism which sup- ports delayed interpretation. The proposed parser is related to the so-calle","@endWordPosition":"349","@position":"2314","annotationId":"T10","@startWordPosition":"348","@citStr":"GStz, 1995"},{"#tail":"\n","#text":"ons are tabled/filtered. Bottom-up Interpretation of Magic-compiled Typed Feature Grammars We describe typed feature grammars and discuss their use in implementing HPSG grammars. Sub- sequently we present magic compilation of typed 165 Proceedings of EACL '99 feature grammars on the basis of an example and introduce a dynamic bottom-up interpreter that can be used for goM-directed interpretation of magic-compiled typed feature grammars. 2.1 Typed Feature Grammars A typed feature grammar consists of a signa- ture and a set of definite clauses over the con- straint language of equations o fTY? (GStz, 1995) terms (HShfeld and Smolka, 1988) which we will refer to as Torz: definite clauses. Equations over TJr? terms can be solved using (graph) unifica- tion provided they are in normal form. (GStz, 1994) describes a normal form for ir~r? terms, where typed feature structures are interpreted as satisfiable normal form T~r?: terms. 2 The signa- ture consists of a type hierarchy and a set of ap- propriateness conditions. Example 1 The signature specified in figure 1 and 2 and the T~r?: definite clauses in figure 3 constitute an example of a typed feature gram- mar. We write T~r? terms in normal form, ","@endWordPosition":"618","@position":"4104","annotationId":"T11","@startWordPosition":"617","@citStr":"GStz, 1995"},{"#tail":"\n","#text":"ic programs. See, among others, (Ramakrishnan et al 1992). Be- cause magic compilation does not refer to the spe- cific constraint language adopted, its application is not limited to logic programs/grammars: It can be applied to relational extensions of other con- straint languages such as typed feature grammars without further adaptions. Due to space limitations we discuss magic com- pilation by example only. The interested reader is referred to (Nilsson and Maluszynski, 1995) for an introduction. Example 2 We illustrate magic compilation of typed feature grammars with respect to definite 4 (GStz, 1995) proves that this compilation method is sound in the general case and defines the large class of type constraints for which it is complete. 166 Proceedings of EACL '99 T \\ ~ ~ IPHON list \\[ ? k ~ . IAGR agr\\[ mary / / relation / liY~st elist /g r ~ r - / ~ nelistk~ &quot;st\\[ th+d-sing mary If sleep~_LIBJ sem--\\] s np v Figure h Example of a typed feature grammar signature (part 1) clause 1 in figure 3. Consider the TJ:? definite clause in figure 4. As a result of magic compi- +\\] constituent~ IP&quot;O. ):- \\[SZM magic_constituent ~) , PHON constituent( \\[AGR )' I.Sr,~ FEAT&quot; \\] constituent( \\[AGR )' Ls","@endWordPosition":"1147","@position":"7445","annotationId":"T12","@startWordPosition":"1146","@citStr":"GStz, 1995"}]},"title":{"#tail":"\n","#text":"Compiling HPSG Constraint Grammars into Logic Programs."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Workshop on Computational Logic for Natural Language Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Thilo GStz"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"institution":{"#tail":"\n","#text":"University of Tiibingen,"},"rawString":{"#tail":"\n","#text":"Erhard Hinrichs, Detmar Meurers, Frank Richter, Manfred Sailer, and Heike Winhart. 1997. Ein HPSG-fragment des Deutschen, Tell 1: Theorie. Technical report SFB 340 95, University of Tiibingen, Germany."},"#text":"\n","marker":{"#tail":"\n","#text":"Hinrichs, Meurers, Richter, Sailer, Winhart, 1997"},"booktitle":{"#tail":"\n","#text":"Ein HPSG-fragment des Deutschen, Tell 1: Theorie. Technical report SFB 340 95,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Erhard Hinrichs"},{"#tail":"\n","#text":"Detmar Meurers"},{"#tail":"\n","#text":"Frank Richter"},{"#tail":"\n","#text":"Manfred Sailer"},{"#tail":"\n","#text":"Heike Winhart"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Technical Report 53, IBM,"},"date":{"#tail":"\n","#text":"1988"},"rawString":{"#tail":"\n","#text":"Markus HShfeld and Gert Smolka. 1988. Definite Relations over Constraint Languages. Technical Report 53, IBM, Germany."},"#text":"\n","marker":{"#tail":"\n","#text":"HShfeld, Smolka, 1988"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ered. Bottom-up Interpretation of Magic-compiled Typed Feature Grammars We describe typed feature grammars and discuss their use in implementing HPSG grammars. Sub- sequently we present magic compilation of typed 165 Proceedings of EACL '99 feature grammars on the basis of an example and introduce a dynamic bottom-up interpreter that can be used for goM-directed interpretation of magic-compiled typed feature grammars. 2.1 Typed Feature Grammars A typed feature grammar consists of a signa- ture and a set of definite clauses over the con- straint language of equations o fTY? (GStz, 1995) terms (HShfeld and Smolka, 1988) which we will refer to as Torz: definite clauses. Equations over TJr? terms can be solved using (graph) unifica- tion provided they are in normal form. (GStz, 1994) describes a normal form for ir~r? terms, where typed feature structures are interpreted as satisfiable normal form T~r?: terms. 2 The signa- ture consists of a type hierarchy and a set of ap- propriateness conditions. Example 1 The signature specified in figure 1 and 2 and the T~r?: definite clauses in figure 3 constitute an example of a typed feature gram- mar. We write T~r? terms in normal form, i. e., relation Figure 2: Example","@endWordPosition":"623","@position":"4137","annotationId":"T13","@startWordPosition":"620","@citStr":"HShfeld and Smolka, 1988"}},"title":{"#tail":"\n","#text":"Definite Relations over Constraint Languages."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Markus HShfeld"},{"#tail":"\n","#text":"Gert Smolka"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"rawString":{"#tail":"\n","#text":"Mark Johnson and Jochen DSrre. 1995. Memoization of Coroutined Constraints. In A CL Proceedings, Cambridge, Massachusetts, USA."},"#text":"\n","marker":{"#tail":"\n","#text":"Johnson, DSrre, 1995"},"location":{"#tail":"\n","#text":"Cambridge, Massachusetts, USA."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"used as the basis for implementations of Head-driven Phrase Structure Grammar (HPSG; Pollard and Sag, 1994) as dis- cussed in (GStz and Meurers, 1997a) and (Meur- ers and Minnen, 1997). Typed feature grammar constraints that are inexpensive to resolve are dealt with using the top-down interpreter of the ConTroll grammar development system (GStz and Meurers, 1997b) which uses an advanced search function, an advanced selection function and in- corporates a coroutining mechanism which sup- ports delayed interpretation. The proposed parser is related to the so-called Lemma Table deduction system (Johnson and DSrre, 1995) which allows the user to specify whether top-down sub-computations are to be tabled. In contrast to Johnson and DSrre's deduc- tion system, though, the selective magic parsing approach combines top-down and bottom-up con- trol strategies. As such it resembles the parser of the grammar development system Attribute Language Engine (ALE) of (Carpenter and Penn, 1994). Unlike the ALE parser, though, the selec- tive magic parser does not presuppose a phrase structure backbone and is more flexible as to which sub-computations are tabled/filtered. Bottom-up Interpretation of Magic-compiled Typed Fea","@endWordPosition":"447","@position":"2970","annotationId":"T14","@startWordPosition":"444","@citStr":"Johnson and DSrre, 1995"},{"#tail":"\n","#text":"ponding tosuch a parse type specification is represented schematically in figure 8. Starting from the lexical entries, i. e., word word word Figure 8: Schematic representation ofthe selective magic parsing process the :r~'L definite clauses that specify the word objects in the grammar, phrases are built bottom- up by matching the parse type literals of the def- inite clauses in the grammar against he edges in the table. The non-parse type literals are pro- cessed according to the top-down control strategy 1?The notion of a parse type literal is closely related to that of a memo literal as in (Johnson and DSrre, 1995). l~When a type is specified as a parse type, all its sub-types are considered as parse types as well. This is necessary as otherwise there may e.xist magic variants of definite clauses defining a parse type goal for which no magic facts can be derived which means that the magic literal of these clauses can be interpreted nei- ther top-down nor bottom-up. described in section 3.3. 3.2 Select ive Magic Compi la t ion In order to process parse type goals according to a semi-naive magic control strategy, we apply magic compilation selectively. Only the T~-L definite clauses in a typed feature gra","@endWordPosition":"2451","@position":"15869","annotationId":"T15","@startWordPosition":"2448","@citStr":"Johnson and DSrre, 1995"},{"#tail":"\n","#text":"t declarations or .block statements. 169 Proceedings ofEACL '99 indicate which restricting information has to be available before a goal is processed. 3.4 Adapted Semi-naive Bottom-up Interpretat ion The definite clauses resulting from selective magic transformation are interpreted using a semi-naive bottom-up interpreter that is adapted in two re- spects. It ensures that non-parse type goals are interpreted using the advanced top-down inter- preter, and it allows non-parse type goals that remain delayed locally to be passed in and out of sub-computations i a similar fashion as pro- posed by (Johnson and DSrre, 1995). In order to accommodate these changes the adapted semi- naive interpreter enables the use of edges which specify delayed goals. Figure 9 illustrates the adapted match op- eration. The first defining clause of match/3 match(Edge,edge(Goal,Delayed),Table):- definite_clause((Goal :- Body)), select(Lit,Body,Lits), parse_type(Lit), Edge = edge(Lit,DelayedO), edges(Lit,Table,DelayedO,TopDown), advancechtd_interpret(TopDown,Delayed). match(Edge,edge(Goal,Delayed),Table):- definite~lause((Goal :- TopDown)), advanced_td_interpret(TopDown,Delayed). Figure 9: Adapted efinition of mat, oh/3 passes delay","@endWordPosition":"3002","@position":"19335","annotationId":"T16","@startWordPosition":"2999","@citStr":"Johnson and DSrre, 1995"}]},"title":{"#tail":"\n","#text":"Memoization of Coroutined Constraints."},"booktitle":{"#tail":"\n","#text":"In A CL Proceedings,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Mark Johnson"},{"#tail":"\n","#text":"Jochen DSrre"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Paul King. 1994. Typed Feature Structures as Descriptions. In Proceedings of of the 15th Conference on Computational Linguistics, Kyoto, Japan."},"#text":"\n","marker":{"#tail":"\n","#text":"King, 1994"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"icate structure sharing. For expository reasons we represent he ARGn features of the append relation as separate argu- ments. Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar (Pollard and Sag, 1994). 3 (Meurers and Minnen, 1997) propose a compi- lation of lexical rules into T~r/: definite clauses 2This view of typed feature structures differs from the perspective on typed feature structures as mod- ehng partial information as in (Carpenter, 1992). Typed feature structures as normal form ir~'~E terms are merely syntactic objects. aSee (King, 1994) for a discussion of the appro- priateness of T~-?: for HPSG and a comparison with other feature logic approaches designed for HPSG. (1) constituent( \\[PHON ):- LSEM PHON constituent( \\[ AGR )' I_Sr~M teAT? 1 constituent( |AGR )' append(\\[~,\\[~,\\[~). rCAT ?, \\] (2) constituent( \\[PHON ( ,,,,y ) /xGR ,h.~-,,.~\\] )&quot; (3) constituent( |PHON (,leCp,) /AGR ,h,.~-.,.~ I ). LSEM sleep J (4) append((), F'~' ~)&quot; (5) append( 3 | a.ppend(F'x- ~,~, ~Y's\\])- Figure 3: Example of a set of T:7:? definite clauses which are used to restrict lexical entries. (GStz and Meurers, 1997b) describe a method for com- p","@endWordPosition":"886","@position":"5767","annotationId":"T17","@startWordPosition":"885","@citStr":"King, 1994"}},"title":{"#tail":"\n","#text":"Typed Feature Structures as Descriptions."},"booktitle":{"#tail":"\n","#text":"In Proceedings of of the 15th Conference on Computational Linguistics, Kyoto,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Paul King"}}},{"volume":{"#tail":"\n","#text":"23"},"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Detmar Meurers and Guido Minnen. 1997. A Computational Treatment of Lexical Rules in HPSG as Covariation in Lexical Entries. Computational Linguistics, 23(4)."},"#text":"\n","issue":{"#tail":"\n","#text":"4"},"marker":{"#tail":"\n","#text":"Meurers, Minnen, 1997"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"dition, uninfor- mative feature specifications are ignored and typ- ing is left implicit when immaterial to the example at hand. Equations between typed feature struc- tures are removed by simple substitution or tags indicating structure sharing. Notice that we also use non-numerical tags such as ~ and ~ . In general all boxed items indicate structure sharing. For expository reasons we represent he ARGn features of the append relation as separate argu- ments. Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar (Pollard and Sag, 1994). 3 (Meurers and Minnen, 1997) propose a compi- lation of lexical rules into T~r/: definite clauses 2This view of typed feature structures differs from the perspective on typed feature structures as mod- ehng partial information as in (Carpenter, 1992). Typed feature structures as normal form ir~'~E terms are merely syntactic objects. aSee (King, 1994) for a discussion of the appro- priateness of T~-?: for HPSG and a comparison with other feature logic approaches designed for HPSG. (1) constituent( \\[PHON ):- LSEM PHON constituent( \\[ AGR )' I_Sr~M teAT? 1 constituent( |AGR )' append(\\[~,\\[~,\\[~). rCAT ?, \\] (2) constituen","@endWordPosition":"837","@position":"5443","annotationId":"T18","@startWordPosition":"834","@citStr":"Meurers and Minnen, 1997"}},"booktitle":{"#tail":"\n","#text":"A Computational Treatment of Lexical Rules in HPSG as Covariation in Lexical Entries. Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Detmar Meurers"},{"#tail":"\n","#text":"Guido Minnen"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"Guido Minnen. 1996. Magic for Filter Optimization in Dynamic Bottom-up Processing. In ACL Proceedings, Santa Cruz, California, USA."},"#text":"\n","marker":{"#tail":"\n","#text":"Minnen, 1996"},"location":{"#tail":"\n","#text":"Santa Cruz, California, USA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"1 The underlying idea is to achieve faster parsing by avoiding tabling on sub-computations which are not expensive. The so-called selective magic parser allows the user to apply magic compilation to specific constraints in a grammar which as a result can be processed y- namically in a bottom-up and goal-directed fash- ion. State of the art top-down processing tech- niques are used to deal with the remaining con- straints. Magic is a compilation technique originally de- veloped for goal-directed bottom-up rocessing of logic programs. See, among others, (Ramakrish- nan et al 1992). As shown in (Minnen, 1996) *The presented research was carried out at the Uni- versity of Tfibingen, Germany, as part of the Sonder- forschungsbereich 340. 1A more detailed iscussion of various aspects of the proposed parser can be found in (Minnen, 1998). magic is an interesting technique with respect o natural language processing as it incorporates fil- tering into the logic underlying the grammar and enables elegant control independent filtering im- provements. In this paper we investigate the se- lective application of magic to typed feature gram- mars a type of constraint-logic grammar based on Typed Feature Logic","@endWordPosition":"253","@position":"1694","annotationId":"T19","@startWordPosition":"252","@citStr":"Minnen, 1996"}},"title":{"#tail":"\n","#text":"Magic for Filter Optimization in Dynamic Bottom-up Processing."},"booktitle":{"#tail":"\n","#text":"In ACL Proceedings,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Guido Minnen"}}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Ph.D. thesis,"},"date":{"#tail":"\n","#text":"1998"},"institution":{"#tail":"\n","#text":"University of Tfibingen, Germany."},"rawString":{"#tail":"\n","#text":"Guido Minnen. 1998. Off-line Compilation for Efficient Processing with Constraint-logic Grammars. Ph.D. thesis, University of Tfibingen, Germany. Technical report SFB 340 nr. 130."},"#text":"\n","pages":{"#tail":"\n","#text":"130"},"marker":{"#tail":"\n","#text":"Minnen, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"mar which as a result can be processed y- namically in a bottom-up and goal-directed fash- ion. State of the art top-down processing tech- niques are used to deal with the remaining con- straints. Magic is a compilation technique originally de- veloped for goal-directed bottom-up rocessing of logic programs. See, among others, (Ramakrish- nan et al 1992). As shown in (Minnen, 1996) *The presented research was carried out at the Uni- versity of Tfibingen, Germany, as part of the Sonder- forschungsbereich 340. 1A more detailed iscussion of various aspects of the proposed parser can be found in (Minnen, 1998). magic is an interesting technique with respect o natural language processing as it incorporates fil- tering into the logic underlying the grammar and enables elegant control independent filtering im- provements. In this paper we investigate the se- lective application of magic to typed feature gram- mars a type of constraint-logic grammar based on Typed Feature Logic (Tgv?:; GStz, 1995). Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar (HPSG; Pollard and Sag, 1994) as dis- cussed in (GStz and Meurers, 1997a) and (Meur- ers and Minnen","@endWordPosition":"290","@position":"1923","annotationId":"T20","@startWordPosition":"289","@citStr":"Minnen, 1998"}},"title":{"#tail":"\n","#text":"Off-line Compilation for Efficient Processing with Constraint-logic Grammars."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Guido Minnen"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1986"},"rawString":{"#tail":"\n","#text":"Lee Naish. 1986. Negation and Control in Prolog. Springer-Verlag, Berlin, Germany."},"#text":"\n","marker":{"#tail":"\n","#text":"Naish, 1986"},"publisher":{"#tail":"\n","#text":"Springer-Verlag,"},"location":{"#tail":"\n","#text":"Berlin, Germany."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" need to be set during processing to a minimum. Furthermore, it leads to earlier failure detection. Finally, the used top-down interpreter imple- ments a powerful coroutining mechanism: 12 At run time the processing of a goal is postponed in case it is insufficiently instantiated. Whether or not a goal is sufficiently instantiated is deter- mined on the basis of so-called delay palierns. 13 These are specifications provided by the user that 12Coroutining appears under many different guises, like for example, suspension, residuation, (goal) freez- ing, and blocking. See also (Colmerauer, 1982; Naish, 1986). 13In the literature delay patterns are sometimes also referred to as wait declarations or .block statements. 169 Proceedings ofEACL '99 indicate which restricting information has to be available before a goal is processed. 3.4 Adapted Semi-naive Bottom-up Interpretat ion The definite clauses resulting from selective magic transformation are interpreted using a semi-naive bottom-up interpreter that is adapted in two re- spects. It ensures that non-parse type goals are interpreted using the advanced top-down inter- preter, and it allows non-parse type goals that remain delayed locally to be pa","@endWordPosition":"2897","@position":"18637","annotationId":"T21","@startWordPosition":"2896","@citStr":"Naish, 1986"}},"booktitle":{"#tail":"\n","#text":"Negation and Control in Prolog."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Lee Naish"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"note":{"#tail":"\n","#text":"2nd edition."},"rawString":{"#tail":"\n","#text":"Ulf Nilsson and Jan Matuszynski. 1995. Logic, Programming and Prolog. John Wiley  Sons, Chichester, UK, 2nd edition."},"#text":"\n","marker":{"#tail":"\n","#text":"Nilsson, Matuszynski, 1995"},"publisher":{"#tail":"\n","#text":"John Wiley  Sons,"},"location":{"#tail":"\n","#text":"Chichester, UK,"},"title":{"#tail":"\n","#text":"Logic, Programming and Prolog."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Ulf Nilsson"},{"#tail":"\n","#text":"Jan Matuszynski"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Carl Pollard and Ivan Sag. 1994. Head-Driven Phrase Structure Grammar. University of Chicago Press, Chicago, Illinois, USA."},"#text":"\n","marker":{"#tail":"\n","#text":"Pollard, Sag, 1994"},"publisher":{"#tail":"\n","#text":"University of Chicago Press,"},"location":{"#tail":"\n","#text":"Chicago, Illinois, USA."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" detailed iscussion of various aspects of the proposed parser can be found in (Minnen, 1998). magic is an interesting technique with respect o natural language processing as it incorporates fil- tering into the logic underlying the grammar and enables elegant control independent filtering im- provements. In this paper we investigate the se- lective application of magic to typed feature gram- mars a type of constraint-logic grammar based on Typed Feature Logic (Tgv?:; GStz, 1995). Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar (HPSG; Pollard and Sag, 1994) as dis- cussed in (GStz and Meurers, 1997a) and (Meur- ers and Minnen, 1997). Typed feature grammar constraints that are inexpensive to resolve are dealt with using the top-down interpreter of the ConTroll grammar development system (GStz and Meurers, 1997b) which uses an advanced search function, an advanced selection function and in- corporates a coroutining mechanism which sup- ports delayed interpretation. The proposed parser is related to the so-called Lemma Table deduction system (Johnson and DSrre, 1995) which allows the user to specify whether top-down sub-computations are to be table","@endWordPosition":"370","@position":"2453","annotationId":"T22","@startWordPosition":"367","@citStr":"Pollard and Sag, 1994"},{"#tail":"\n","#text":"d feature structures. In addition, uninfor- mative feature specifications are ignored and typ- ing is left implicit when immaterial to the example at hand. Equations between typed feature struc- tures are removed by simple substitution or tags indicating structure sharing. Notice that we also use non-numerical tags such as ~ and ~ . In general all boxed items indicate structure sharing. For expository reasons we represent he ARGn features of the append relation as separate argu- ments. Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar (Pollard and Sag, 1994). 3 (Meurers and Minnen, 1997) propose a compi- lation of lexical rules into T~r/: definite clauses 2This view of typed feature structures differs from the perspective on typed feature structures as mod- ehng partial information as in (Carpenter, 1992). Typed feature structures as normal form ir~'~E terms are merely syntactic objects. aSee (King, 1994) for a discussion of the appro- priateness of T~-?: for HPSG and a comparison with other feature logic approaches designed for HPSG. (1) constituent( \\[PHON ):- LSEM PHON constituent( \\[ AGR )' I_Sr~M teAT? 1 constituent( |AGR )' append(\\[~,\\[~,\\","@endWordPosition":"832","@position":"5413","annotationId":"T23","@startWordPosition":"829","@citStr":"Pollard and Sag, 1994"}]},"title":{"#tail":"\n","#text":"Head-Driven Phrase Structure Grammar."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Carl Pollard"},{"#tail":"\n","#text":"Ivan Sag"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1992"},"editor":{"#tail":"\n","#text":"In Joos Vandewalle (ed.),"},"rawString":{"#tail":"\n","#text":"Raghu Ramakrishnan, Divesh Srivastava, and S. Sudarshan. 1992.  Efficient Bottom-up Evaluation of Logic Programs. In Joos Vandewalle (ed.), 1992. The State of the Art in Computer Systems and Software Engineering. Kluwer Academic Publishers."},"#text":"\n","marker":{"#tail":"\n","#text":"Ramakrishnan, Srivastava, Sudarshan, 1992"},"publisher":{"#tail":"\n","#text":"Kluwer Academic Publishers."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"s which are used to restrict lexical entries. (GStz and Meurers, 1997b) describe a method for com- piling implicational constraints into typed feature grammars and interleaving them with relational constraints. 4 Because of space limitations we have to refrain from an example. The ConTroll gram- mar development system as described in (GStz and Meurers, 1997b) implements the above men- tioned techniques for compiling an HPSG theory into typed feature grammars. 2.2 Magic Compi la t ion Magic is a compilation technique for goal-directed bottom-up processing of logic programs. See, among others, (Ramakrishnan et al 1992). Be- cause magic compilation does not refer to the spe- cific constraint language adopted, its application is not limited to logic programs/grammars: It can be applied to relational extensions of other con- straint languages such as typed feature grammars without further adaptions. Due to space limitations we discuss magic com- pilation by example only. The interested reader is referred to (Nilsson and Maluszynski, 1995) for an introduction. Example 2 We illustrate magic compilation of typed feature grammars with respect to definite 4 (GStz, 1995) proves that this compilation method is sound ","@endWordPosition":"1063","@position":"6891","annotationId":"T24","@startWordPosition":"1060","@citStr":"Ramakrishnan et al 1992"}},"title":{"#tail":"\n","#text":"Efficient Bottom-up Evaluation of Logic Programs."},"booktitle":{"#tail":"\n","#text":"The State of the Art in Computer Systems and Software Engineering."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Raghu Ramakrishnan"},{"#tail":"\n","#text":"Divesh Srivastava"},{"#tail":"\n","#text":"S Sudarshan"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"rawString":{"#tail":"\n","#text":"Stuart Shieber, Yves Schabes, and Fernando Pereira. 1995. Principles and Implementation of Deductive Parsing. Journal of Logic Programming, 24(1-2)."},"journal":{"#tail":"\n","#text":"Journal of Logic Programming,"},"#text":"\n","pages":{"#tail":"\n","#text":"24--1"},"marker":{"#tail":"\n","#text":"Shieber, Schabes, Pereira, 1995"},"title":{"#tail":"\n","#text":"Principles and Implementation of Deductive Parsing."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Stuart Shieber"},{"#tail":"\n","#text":"Yves Schabes"},{"#tail":"\n","#text":"Fernando Pereira"}]}},{"volume":{"#tail":"\n","#text":"23"},"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Gertjan van Noord. 1997. An Efficient Implementation of the Head-corner Parser. Computational Linguistics, 23(3)."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"3"},"marker":{"#tail":"\n","#text":"van Noord, 1997"},"title":{"#tail":"\n","#text":"An Efficient Implementation of the Head-corner Parser."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Gertjan van Noord"}}}]}}]}}
