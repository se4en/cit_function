 Dutch, German, Italian, and French fall into that category. 1 Furthermore, since lexical rules in such an approach only serve in a precompilation step, the generalizations captured by the lexical rules cannot be used at run-time. Finally, all such treatments of lexical rules currently available pre- suppose a fully explicit notation of lexical rule specifications that transfer properties not changed by the lexical rules to the newly created lexical entry. This conflicts with the standard assumption made in HPSG that only the properties changed by a lexical rule need be mentioned. As shown in Meurers (1994) this is a well-motivated conven- tion since it avoids splitting up lexical rules to transfer the specifications that must be preserved for different lexical entries. ? The authors are listed alphabetically. SFB 340, Kleine Wilhelmstr. 113, D-72074 Tiibingen, Germany. email: {dm,minnen}@sfs.nphil.uni-tuebingen.de URL: http://www.sfs.nphil.uni-tuebingen.de/sfb /b4home.html 1 This is, for example, the case for all proposals working with verbal exical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction 
nly the properties changed by a lexical rule need be mentioned. As shown in Meurers (1994) this is a well-motivated conven- tion since it avoids splitting up lexical rules to transfer the specifications that must be preserved for different lexical entries. ? The authors are listed alphabetically. SFB 340, Kleine Wilhelmstr. 113, D-72074 Tiibingen, Germany. email: {dm,minnen}@sfs.nphil.uni-tuebingen.de URL: http://www.sfs.nphil.uni-tuebingen.de/sfb /b4home.html 1 This is, for example, the case for all proposals working with verbal exical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements. Also an analysis treating adjunct extraction via lexical rules (van Noord and Bouma 1994) results in an infinite lexicon. (~) 1997 Association for Computational Linguistics Computational Linguistics Volume 23, Number 4 Treatments of lexical rules as unary phrase structure rules also require their fully explicit specification, which entails the last problem mentioned above. In addition, computat
l-motivated conven- tion since it avoids splitting up lexical rules to transfer the specifications that must be preserved for different lexical entries. ? The authors are listed alphabetically. SFB 340, Kleine Wilhelmstr. 113, D-72074 Tiibingen, Germany. email: {dm,minnen}@sfs.nphil.uni-tuebingen.de URL: http://www.sfs.nphil.uni-tuebingen.de/sfb /b4home.html 1 This is, for example, the case for all proposals working with verbal exical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements. Also an analysis treating adjunct extraction via lexical rules (van Noord and Bouma 1994) results in an infinite lexicon. (~) 1997 Association for Computational Linguistics Computational Linguistics Volume 23, Number 4 Treatments of lexical rules as unary phrase structure rules also require their fully explicit specification, which entails the last problem mentioned above. In addition, computationally treating lexical rules on a par with phrase structure rules fails to take computational ad
to transfer the specifications that must be preserved for different lexical entries. ? The authors are listed alphabetically. SFB 340, Kleine Wilhelmstr. 113, D-72074 Tiibingen, Germany. email: {dm,minnen}@sfs.nphil.uni-tuebingen.de URL: http://www.sfs.nphil.uni-tuebingen.de/sfb /b4home.html 1 This is, for example, the case for all proposals working with verbal exical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements. Also an analysis treating adjunct extraction via lexical rules (van Noord and Bouma 1994) results in an infinite lexicon. (~) 1997 Association for Computational Linguistics Computational Linguistics Volume 23, Number 4 Treatments of lexical rules as unary phrase structure rules also require their fully explicit specification, which entails the last problem mentioned above. In addition, computationally treating lexical rules on a par with phrase structure rules fails to take computational advantage of their specific properties. For example, the interaction 
ume 23, Number 4 Treatments of lexical rules as unary phrase structure rules also require their fully explicit specification, which entails the last problem mentioned above. In addition, computationally treating lexical rules on a par with phrase structure rules fails to take computational advantage of their specific properties. For example, the interaction of lexical rules is explored at run-time, even though the possible interaction can be determined at compile-time given the information available in the lexical rules and the base lexical entries. 2 Based on the research results reported in Meurers and Minnen (1995, 1996), we propose a new computational treatment of lexical rules that overcomes these short- comings and results in a more efficient processing of lexical rules as used in HPSG. We developed a compiler that takes as its input a set of lexical rules, deduces the nec- essary transfer of properties not changed by the individual lexical rules, and encodes the set of lexical rules and their interaction i to definite relations constraining lexical entries. Each lexical entry is automatically extended with a definite clause encoding of the lexical rule applications which the entry can undergo. The 
in lexical entries. Definite relations are a convenient way of encoding the interaction of lexical rules, as they readily support various program transformations to improve the encoding: We show that the definite relations produced by the compiler can be refined by program transformation techniques to increase fficiency. The resulting encoding allows the execution of lexical rules on-the-fly, i.e., coroutined with other constraints at some time after lexical lookup. The computational treatment of lexical rules proposed can be seen as an extension to the principled method discussed by G6tz and Meurers (1995, 1996, 1997b) for encoding the main building block of HPSG grammars--the implicative constraints--as logic program. The structure of the paper is as follows: We start with a brief introduction of the formal background on which our approach is based in Section 2. We then describe (Section 3) how lexical rules and their interaction can be encoded in a definite clause encoding that expresses systematic covariation in lexical entries. We show how the encoding of lexical rule interaction can be improved by specializing it for different word classes and, in Section 4, focus on an improvement of thi
 to on-the-fly application of lexical rules is presented in Section 5. In Section 6, we dis- cuss implementation results and illustrate the efficiency of the proposed encoding. A comparison with other computational approaches to lexical rules (Section 7) and some concluding remarks (Section 8) end the paper. 2. Background In this section we introduce the formal setup of HPSG grammars that we assume and discuss two ways to formalize a lexical rule mechanism and their consequences for a computational treatment. 2.1 A Formal Setup for HPSG Grammars An HPSG grammar formally consists of two parts (Pollard and Sag 1994): The signature defines the ontology of linguistic objects, and the theory, i.e., the usually implicative constraints encoding the grammatical principles, describes the subset of those linguistic 2 This is not to say that a special precompilation treatment along those lines would not be profitable for phrase structure ules. In fact, such a proposal ismade by Torisawa nd Tsuji (1996). 544 Meurers and Minnen Covariation Approach to HPSG Lexical Rules objects that are grammatical. The constraints constituting the theory are expressions of a formal language that define the set of grammatical objec
 the sense that every grammatical object is described by every principle in the theory. The signature consists of the type hierarchy defining which types of objects ex- ist and the appropriateness conditions pecifying which objects have which features defined on them to represent their properties. 3 A signature is interpreted as follows: Every object is assigned exactly one most specific type, and in case a feature is ap- propriate for some object of a certain type, then it is appropriate for all objects of this type. 4 A logic that provides the formal architecture required by Pollard and Sag (1994) was defined by King (1989, 1994). The formal language of King allows the expression of grammatical principles using type assignments to refer to the type of an object and path equalities to require the (token) identity of objects. These atomic expressions can be combined using conjunction, disjunction, and negation. The expressions are interpreted by a set-theoretical semantics. 2.2 Lexical Rules in HPSG While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special inguistic mechanisms like lexical rules fit into this formal setup. Two formal
grammatical object is described by every principle in the theory. The signature consists of the type hierarchy defining which types of objects ex- ist and the appropriateness conditions pecifying which objects have which features defined on them to represent their properties. 3 A signature is interpreted as follows: Every object is assigned exactly one most specific type, and in case a feature is ap- propriate for some object of a certain type, then it is appropriate for all objects of this type. 4 A logic that provides the formal architecture required by Pollard and Sag (1994) was defined by King (1989, 1994). The formal language of King allows the expression of grammatical principles using type assignments to refer to the type of an object and path equalities to require the (token) identity of objects. These atomic expressions can be combined using conjunction, disjunction, and negation. The expressions are interpreted by a set-theoretical semantics. 2.2 Lexical Rules in HPSG While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special inguistic mechanisms like lexical rules fit into this formal setup. Two formalizations of lexical rules 
es using type assignments to refer to the type of an object and path equalities to require the (token) identity of objects. These atomic expressions can be combined using conjunction, disjunction, and negation. The expressions are interpreted by a set-theoretical semantics. 2.2 Lexical Rules in HPSG While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special inguistic mechanisms like lexical rules fit into this formal setup. Two formalizations of lexical rules as used by HPSG linguists have been proposed, the meta-level lexical rules (MLRs; Calcagno 1995; Calcagno and Pollard 1995) and the .description-level l xical rules (DLRs; Meurers 1995). 5 2.2.1 Meta-Level Lexical Rules. The MLR approach sees lexical rules in the more traditional sense as relations between lexical entries, i.e., descriptions of word objects. The set of lexical entries constituting the lexicon is closed under the application of lexical rules, which results in a (possibly infinite) set of lexical entries. In order to be grammatical, every word object occurring in a sentence has to be described by one of the descriptions in this expanded lexicon set. In the MLR setup, lexi
ssignments to refer to the type of an object and path equalities to require the (token) identity of objects. These atomic expressions can be combined using conjunction, disjunction, and negation. The expressions are interpreted by a set-theoretical semantics. 2.2 Lexical Rules in HPSG While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special inguistic mechanisms like lexical rules fit into this formal setup. Two formalizations of lexical rules as used by HPSG linguists have been proposed, the meta-level lexical rules (MLRs; Calcagno 1995; Calcagno and Pollard 1995) and the .description-level l xical rules (DLRs; Meurers 1995). 5 2.2.1 Meta-Level Lexical Rules. The MLR approach sees lexical rules in the more traditional sense as relations between lexical entries, i.e., descriptions of word objects. The set of lexical entries constituting the lexicon is closed under the application of lexical rules, which results in a (possibly infinite) set of lexical entries. In order to be grammatical, every word object occurring in a sentence has to be described by one of the descriptions in this expanded lexicon set. In the MLR setup, lexical rules are thus external 
 the (token) identity of objects. These atomic expressions can be combined using conjunction, disjunction, and negation. The expressions are interpreted by a set-theoretical semantics. 2.2 Lexical Rules in HPSG While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special inguistic mechanisms like lexical rules fit into this formal setup. Two formalizations of lexical rules as used by HPSG linguists have been proposed, the meta-level lexical rules (MLRs; Calcagno 1995; Calcagno and Pollard 1995) and the .description-level l xical rules (DLRs; Meurers 1995). 5 2.2.1 Meta-Level Lexical Rules. The MLR approach sees lexical rules in the more traditional sense as relations between lexical entries, i.e., descriptions of word objects. The set of lexical entries constituting the lexicon is closed under the application of lexical rules, which results in a (possibly infinite) set of lexical entries. In order to be grammatical, every word object occurring in a sentence has to be described by one of the descriptions in this expanded lexicon set. In the MLR setup, lexical rules are thus external to the rest of the theory, they only serve to provide an expan
erving as input to a lexical rule can be enforced that cannot be executed on the basis of the information present in the lexical entry alone, 6and second, grammars including lexical rules that, under the MLR formalization, result in an infinite lexicon, can only 3 The terminology used in the literature varies. Types are also referred to as sorts, appropriateness conditions as feature declarations, and features as attributes. To avoid confusion, we will only use the terminology introduced in the text. 4 This interpretation f the signature is sometimes referred to as closed world (Gerdemann and King 1994; Gerdemann 1995). 5 An in-depth discussion including a comparison of both approaches i provided in Calcagno, Meurers, and Pollard (in preparation). 6 The Partial-VP Topicalization Lexical Rule proposed by Hinrichs and Nakazawa (1994, 10) is a linguistic example. The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries erving as its input. In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement. 545 Computational Linguistics Volume 23, Number 4 sim
nput to a lexical rule can be enforced that cannot be executed on the basis of the information present in the lexical entry alone, 6and second, grammars including lexical rules that, under the MLR formalization, result in an infinite lexicon, can only 3 The terminology used in the literature varies. Types are also referred to as sorts, appropriateness conditions as feature declarations, and features as attributes. To avoid confusion, we will only use the terminology introduced in the text. 4 This interpretation f the signature is sometimes referred to as closed world (Gerdemann and King 1994; Gerdemann 1995). 5 An in-depth discussion including a comparison of both approaches i provided in Calcagno, Meurers, and Pollard (in preparation). 6 The Partial-VP Topicalization Lexical Rule proposed by Hinrichs and Nakazawa (1994, 10) is a linguistic example. The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries erving as its input. In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement. 545 Computational Linguistics Volume 23, Number 4 simple-word ---* LE1
zation, result in an infinite lexicon, can only 3 The terminology used in the literature varies. Types are also referred to as sorts, appropriateness conditions as feature declarations, and features as attributes. To avoid confusion, we will only use the terminology introduced in the text. 4 This interpretation f the signature is sometimes referred to as closed world (Gerdemann and King 1994; Gerdemann 1995). 5 An in-depth discussion including a comparison of both approaches i provided in Calcagno, Meurers, and Pollard (in preparation). 6 The Partial-VP Topicalization Lexical Rule proposed by Hinrichs and Nakazawa (1994, 10) is a linguistic example. The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries erving as its input. In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement. 545 Computational Linguistics Volume 23, Number 4 simple-word ---* LE1 v . . ? V LEn derived-word ~ (\[IN LRl-in\] A LRl-out) V . . . V (\[IN LRm-in\] A LRm-oUt) Figure 1 The extended lexicon under the DLR approach. partially be dealt with, for example, by using a depth bound on lexica
nfinite lexicon, can only 3 The terminology used in the literature varies. Types are also referred to as sorts, appropriateness conditions as feature declarations, and features as attributes. To avoid confusion, we will only use the terminology introduced in the text. 4 This interpretation f the signature is sometimes referred to as closed world (Gerdemann and King 1994; Gerdemann 1995). 5 An in-depth discussion including a comparison of both approaches i provided in Calcagno, Meurers, and Pollard (in preparation). 6 The Partial-VP Topicalization Lexical Rule proposed by Hinrichs and Nakazawa (1994, 10) is a linguistic example. The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries erving as its input. In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement. 545 Computational Linguistics Volume 23, Number 4 simple-word ---* LE1 v . . ? V LEn derived-word ~ (\[IN LRl-in\] A LRl-out) V . . . V (\[IN LRm-in\] A LRm-oUt) Figure 1 The extended lexicon under the DLR approach. partially be dealt with, for example, by using a depth bound on lexical rul
 application, it also grounds the recursion in a word described by a base lexical entry. Contrary to the MLR setup, the DLR formalization therefore requires all words feeding lexical rules to be grammatical with respect o the theory. Since lexical rules are expressed in the theory just like any other part of the theory, they are represented in the same way, as unary immediate dominance schemata. 8 This conception of lexical rules thus can be understood as underlying the computational approach that treats lexical rules as unary phrase structure rules as, for example, adopted in the LKB system (Copestake 1992). Both the input and output of a lexical rule, i.e., the mother and the daughter of a phrase structure rule, are available during a generation or parsing process. As a result, in addition to the information present in the lexical entry, syntactic information can be accessed to execute the constraints on the input of a lexical rule. The computational treatment of lexical rules that we propose in this paper is essentially a domain-specific refinement of such an approach to lexical rules. 9 2.2.3 Lexical Rule Specification and Framing. An important difference between unary immediate dominance sch
 perspective on lexical rules. 546 Meurers and Minnen Covariation Approach to HPSG Lexical Rules sl \] LOC\] CAT LOC\[CAT HEAD VAL HAVrFbVFOOpsP tlJ su , INDEX \[VAL (IL 'CONT LCOMpS /\[LOC\]CONTll NDEX \[~\]1 \[\] t---+ VFORM pas\] SUBJ / \[LOC\] CONT \[ INDEX \[\]\]/ / (\[LOC ICATI HEAD prep\[ PFORM COMPS \[\] O L CONT\]INDEX \[\] Figure 2 A passivization lexical rule. written as fully specified relations between words, rather, only what is supposed to be changed is specified. Consider, for example, the lexical rule in Figure 2, which encodes a passive lexicai rule like the one presented by Pollard and Sag (1987, 215) in terms of the setup of Pollard and Sag (1994, ch. 9). This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form2 ?The rule takes the index of the least oblique complement of the input and assigns it to the subject of the output. The index that the subject bore in the input is assigned to an optional prepositional complement in the output. Only the verb form and some indices are specified to be changed, and thus other input properties, like the phonology, the semantics, or the nonlocal specifications, are preserved in the out
lexical rules. 546 Meurers and Minnen Covariation Approach to HPSG Lexical Rules sl \] LOC\] CAT LOC\[CAT HEAD VAL HAVrFbVFOOpsP tlJ su , INDEX \[VAL (IL 'CONT LCOMpS /\[LOC\]CONTll NDEX \[~\]1 \[\] t---+ VFORM pas\] SUBJ / \[LOC\] CONT \[ INDEX \[\]\]/ / (\[LOC ICATI HEAD prep\[ PFORM COMPS \[\] O L CONT\]INDEX \[\] Figure 2 A passivization lexical rule. written as fully specified relations between words, rather, only what is supposed to be changed is specified. Consider, for example, the lexical rule in Figure 2, which encodes a passive lexicai rule like the one presented by Pollard and Sag (1987, 215) in terms of the setup of Pollard and Sag (1994, ch. 9). This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form2 ?The rule takes the index of the least oblique complement of the input and assigns it to the subject of the output. The index that the subject bore in the input is assigned to an optional prepositional complement in the output. Only the verb form and some indices are specified to be changed, and thus other input properties, like the phonology, the semantics, or the nonlocal specifications, are preserved in the output. T
 Covariation Approach to HPSG Lexical Rules sl \] LOC\] CAT LOC\[CAT HEAD VAL HAVrFbVFOOpsP tlJ su , INDEX \[VAL (IL 'CONT LCOMpS /\[LOC\]CONTll NDEX \[~\]1 \[\] t---+ VFORM pas\] SUBJ / \[LOC\] CONT \[ INDEX \[\]\]/ / (\[LOC ICATI HEAD prep\[ PFORM COMPS \[\] O L CONT\]INDEX \[\] Figure 2 A passivization lexical rule. written as fully specified relations between words, rather, only what is supposed to be changed is specified. Consider, for example, the lexical rule in Figure 2, which encodes a passive lexicai rule like the one presented by Pollard and Sag (1987, 215) in terms of the setup of Pollard and Sag (1994, ch. 9). This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form2 ?The rule takes the index of the least oblique complement of the input and assigns it to the subject of the output. The index that the subject bore in the input is assigned to an optional prepositional complement in the output. Only the verb form and some indices are specified to be changed, and thus other input properties, like the phonology, the semantics, or the nonlocal specifications, are preserved in the output. This is so since the lexical rule in Figure 2 &quot;(
ubject bore in the input is assigned to an optional prepositional complement in the output. Only the verb form and some indices are specified to be changed, and thus other input properties, like the phonology, the semantics, or the nonlocal specifications, are preserved in the output. This is so since the lexical rule in Figure 2 &quot;(like all lexical rules in HPSG) preserves all properties of the input not mentioned in the rule.&quot; (Pollard and Sag \[1994, 314\], following Flickinger \[1987\]). This idea of preserving properties can be considered an instance of the well-known frame problem in AI (McCarthy and Hayes 1969), and we will therefore refer to the specifications left implicit by the linguist as the frame specification, or simply frame, of a lexical rule. Not having to represent the frame explicitly not only enables the linguist to express only the relevant hings, but also allows a more compact representation f lexical rules where explicit framing would require the rules to be split up (Meurers 1994). One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory. The formalization of DLRs provided by Meur
t mentioned in the rule.&quot; (Pollard and Sag \[1994, 314\], following Flickinger \[1987\]). This idea of preserving properties can be considered an instance of the well-known frame problem in AI (McCarthy and Hayes 1969), and we will therefore refer to the specifications left implicit by the linguist as the frame specification, or simply frame, of a lexical rule. Not having to represent the frame explicitly not only enables the linguist to express only the relevant hings, but also allows a more compact representation f lexical rules where explicit framing would require the rules to be split up (Meurers 1994). One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory. The formalization of DLRs provided by Meurers (1995) defines aformal exical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification i to a fully explicit description of the kind shown in Figure 1. This description can then be given the standard set-theoretical interpretation f King (1989, 1994). 11 10 Note that the passivization lexical rule in Figu
969), and we will therefore refer to the specifications left implicit by the linguist as the frame specification, or simply frame, of a lexical rule. Not having to represent the frame explicitly not only enables the linguist to express only the relevant hings, but also allows a more compact representation f lexical rules where explicit framing would require the rules to be split up (Meurers 1994). One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory. The formalization of DLRs provided by Meurers (1995) defines aformal exical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification i to a fully explicit description of the kind shown in Figure 1. This description can then be given the standard set-theoretical interpretation f King (1989, 1994). 11 10 Note that the passivization lexical rule in Figure 2 is only intended to illustrate the mechanism. We do not make the linguistic claim that passives hould be analyzed using such a lexical rule. For space reasons, the SYNSEM feature is abbreviated by its first let
re explicit framing would require the rules to be split up (Meurers 1994). One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory. The formalization of DLRs provided by Meurers (1995) defines aformal exical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification i to a fully explicit description of the kind shown in Figure 1. This description can then be given the standard set-theoretical interpretation f King (1989, 1994). 11 10 Note that the passivization lexical rule in Figure 2 is only intended to illustrate the mechanism. We do not make the linguistic claim that passives hould be analyzed using such a lexical rule. For space reasons, the SYNSEM feature is abbreviated by its first letter. The traditional (First I Rest) list notation is used, and the operator ? stands for the append relation in the usual way. 1l Manandhar (1995) proposes to unify these two steps by including an update operator in the 547 Computational Linguistics Volume 23, Number 4 The computational treatment we discuss in the rest o
plicit framing would require the rules to be split up (Meurers 1994). One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory. The formalization of DLRs provided by Meurers (1995) defines aformal exical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification i to a fully explicit description of the kind shown in Figure 1. This description can then be given the standard set-theoretical interpretation f King (1989, 1994). 11 10 Note that the passivization lexical rule in Figure 2 is only intended to illustrate the mechanism. We do not make the linguistic claim that passives hould be analyzed using such a lexical rule. For space reasons, the SYNSEM feature is abbreviated by its first letter. The traditional (First I Rest) list notation is used, and the operator ? stands for the append relation in the usual way. 1l Manandhar (1995) proposes to unify these two steps by including an update operator in the 547 Computational Linguistics Volume 23, Number 4 The computational treatment we discuss in the rest of the p
ches the lexical rule specification i to a fully explicit description of the kind shown in Figure 1. This description can then be given the standard set-theoretical interpretation f King (1989, 1994). 11 10 Note that the passivization lexical rule in Figure 2 is only intended to illustrate the mechanism. We do not make the linguistic claim that passives hould be analyzed using such a lexical rule. For space reasons, the SYNSEM feature is abbreviated by its first letter. The traditional (First I Rest) list notation is used, and the operator ? stands for the append relation in the usual way. 1l Manandhar (1995) proposes to unify these two steps by including an update operator in the 547 Computational Linguistics Volume 23, Number 4 The computational treatment we discuss in the rest of the paper follows this setup in that it automatically computes, for each lexical rule specification, the frames neces- sary to preserve the properties not changed by it. 12 We will show that the detection and specification of frames and the use of program transformation to advance their integration into the lexicon encoding is one of the key ingredients of the covariation approach to HPSG lexical rules. 3. Lexical Cova
 suppose the lexical rule specification shown in Figure 5.14 This lexical rule applies to base lexical entries that unify 15 wi th the in-specification, i.e., lexical entries specifying B and Y as - . The derived lexical entry licenses word objects with + as the value of x and Y, and b as that of A. The translation of the lexical rule into a predicate is trivial. The result is displayed description language. 12 In order to focus on the computational aspects of the covariation approach, in this paper we will not go into a discussion of the full lexical rule specification language introduced in Meurers (1995). The reader interested in that language and its precise interpretation can find the relevant details in that paper. 13 A more detailed presentation can be found in Minnen (in preparation). 14 We use rather abstract lexical rules in the examples to be able to focus on the relevant aspects. 15 Hinrichs and Nakazawa (1996) show that the question of whether the application criterion of lexical rules should be a subsumption ra unification test is an important question deserving of more attention. We here assume unification as the application criterion, which formally corresponds tothe conjunction 
nslation of the lexical rule into a predicate is trivial. The result is displayed description language. 12 In order to focus on the computational aspects of the covariation approach, in this paper we will not go into a discussion of the full lexical rule specification language introduced in Meurers (1995). The reader interested in that language and its precise interpretation can find the relevant details in that paper. 13 A more detailed presentation can be found in Minnen (in preparation). 14 We use rather abstract lexical rules in the examples to be able to focus on the relevant aspects. 15 Hinrichs and Nakazawa (1996) show that the question of whether the application criterion of lexical rules should be a subsumption ra unification test is an important question deserving of more attention. We here assume unification as the application criterion, which formally corresponds tothe conjunction ofdescriptions and their conversion to normal form (G6tz 1994). Computationally, a subsumption test could equally well be used in our compiler. 548 Meurers and Minnen Covariation Approach to HPSG Lexical Rules input : output : Figure 3 The compiler setup. ~ x i c o ~ + translation I of lexical rules into definite relatio
se paths in words serving as input to a lexical rule that occur in the out-specification f the lexical rule but are not assigned a type value. For example, the lexical rule 1 of Figure 6 applies to word objects with tl as their c value and to those having t2 as their c value. With respect o frame specification this means that there can be lexical entries, such as the one in Figure 7, for which we need to make sure that tl as the value of c gets transferred. 16 One would think that the type information tl, which is more specific than that 16 A linguistic example based on the signature given by Pollard and Sag (1994) would be a lexical rule deriving predicative signs from nonpredicative ones, i.e., changing the PRD value of substantive signs from - to +, much like the lexical rule for NPs given by Pollard and Sag (1994, p. 360, fn. 20). In such a Predicative Lexical Rule (which we only note as an example and not as a linguistic proposal) the subtype of the head object undergoing the rule as well as the value of the features only appropriate for the subtypes of substantive either is lost or must be specified by a separate rule for each of the subtypes. 550 Meurers and Minnen Covariation Approach to HPSG Le
s of which have to be preserved. In particular, in case the lexical entry has t2 as the value of c, we need to ensure that the value of the feature z is transferred properly. To ensure that no information is lost as a result of applying a lexical rule, it seems to be necessary to split up the lexical rule to make each instance deal with a specific case. In the above example, this would result in two lexical rules: one for words with tl as their c value and one for those with t2 as their c value. In the latter case, we can also take care of transferring the value of z. However, as discussed by Meurers (1994), creating several instances of lexical rules can be avoided. Instead, the disjunctive possibilities introduced by the frame specification are attached as a constraint o a lexical rule. This is accomplished by having each lexical rule predicate call a so-called frame predicate, which can have multiple defining clauses. So for the lexical rule 1, the frame specification is taken care of by extending the predicate in Figure 6 with a call to a frame predicate, as shown in Figure 8.17 On the basis of the lexical rule specification and the signature, the compiler de- duces the frame predicates with
 the lexical entry of Figure 15. The base lexical entry is fed into the first argument of the call to the interaction predicate q_l. For each solution to a call to q_l the value of ~ is a derived lexical entry. Encoding a finite-state automaton as definite relations is rather straightforward. In fact, one can view the representations as notational variants of one another. Each transition in the automaton is translated into a definite relation in which the corre- sponding lexical rule predicate is called, and each final state is encoded by a unit clause. Using an accumulator passing technique (O'Keefe 1990), we ensure that upon execution of a call to the interaction predicate q_l a new lexical entry is derived as the result of successive application of a number of lexical rules. Because of the word class specialization step discussed in Section 3.3, the execution avoids trying out many lexical rule applications that are guaranteed to fail. We illustrate the encoding with the finite-state automaton of Figure 16. As the lexical rules themselves are already translated into a definite clause representation in the first compilation step, the interaction predicates only need to ensure that the right c
ate ncoding the finite-state automaton of Figure 16 is shown in Figure 18. 28 We now have a first complete ncoding of the lexical rules and their interaction repre- sented as covariation i lexical entries. The encoding consists of three types of definite clause predicates: 1. Lexical rule predicates representing the lexical rules; 2. Frame predicates specifying the frame for the lexical rule predicates; and 3. Interaction predicates encoding lexical rule interaction for the natural classes of lexical entries in the lexicon. The way these predicates interconnect is represented in Figure 19. 27 Briscoe and Copestake (1996) argue that semi-productivity of lexical rules, which can be understood as a generalization of exceptions to lexical rules, can be integrated with our approach by assigning probabilities to the automaton associated with a particular lexical entry. 28 In order to distinguish the different interaction predicates for the different classes of lexical entries, the compiler indexes the names of the interaction predicates. Since for expository reasons we will only discuss one kind of lexical entry in this paper, we will not show those indices in the examples given. 557 Computational Linguistics Volum
tries to which a lexical rule can be applied. During word class specialization, though, when the finite-state automaton representing global lexical rule application is pruned with respect o a particular base lexical entry, we know which subclass we are dealing with. For each interaction defini- tion we can therefore check which of the flame clauses are applicable and discard the non-applicable ones. We thereby eliminate the redundant nondeterminism resulting from multiply defined frame predicates. The elimination of redundant nondeterminism is based on Unfold/Fold trans- formation techniques (Tamaki and Sato 1984). 29 The unfolding transformation is also referred to as partial execution, for example, by Pereira and Shieber (1987). Intuitively understood, unfolding comprises the evaluation of a particular literal in the body of a clause at compile-time. As a result, the literal can be removed from the body of 29 This improvement of the covariation encoding can also be viewed as an instance of the program transformation technique r ferred to as deletion of clauses with a finitely failed body (Pettorossi and Proietti 1994). 558 Meurers and Minnen Covariation Approach to HPSG Lexical Rules extended lexical
omaton representing global lexical rule application is pruned with respect o a particular base lexical entry, we know which subclass we are dealing with. For each interaction defini- tion we can therefore check which of the flame clauses are applicable and discard the non-applicable ones. We thereby eliminate the redundant nondeterminism resulting from multiply defined frame predicates. The elimination of redundant nondeterminism is based on Unfold/Fold trans- formation techniques (Tamaki and Sato 1984). 29 The unfolding transformation is also referred to as partial execution, for example, by Pereira and Shieber (1987). Intuitively understood, unfolding comprises the evaluation of a particular literal in the body of a clause at compile-time. As a result, the literal can be removed from the body of 29 This improvement of the covariation encoding can also be viewed as an instance of the program transformation technique r ferred to as deletion of clauses with a finitely failed body (Pettorossi and Proietti 1994). 558 Meurers and Minnen Covariation Approach to HPSG Lexical Rules extended lexical entries call I .~ interaction predicates call unfolding c unfolding Figure 20 Schematic representation f the successi
limination of redundant nondeterminism is based on Unfold/Fold trans- formation techniques (Tamaki and Sato 1984). 29 The unfolding transformation is also referred to as partial execution, for example, by Pereira and Shieber (1987). Intuitively understood, unfolding comprises the evaluation of a particular literal in the body of a clause at compile-time. As a result, the literal can be removed from the body of 29 This improvement of the covariation encoding can also be viewed as an instance of the program transformation technique r ferred to as deletion of clauses with a finitely failed body (Pettorossi and Proietti 1994). 558 Meurers and Minnen Covariation Approach to HPSG Lexical Rules extended lexical entries call I .~ interaction predicates call unfolding c unfolding Figure 20 Schematic representation f the successive unfolding transformation. extended lexical entries call I ,, interaction predicates ca l l ,, lexical rule predicates &quot;~ unfolding / call .~ frame predicates / Figure 21 Schematic representation f the partial unfolding transformation. the clause. Whereas unfolding can be viewed as a symbolic way of going forward in computation, folding constitutes a symbolic step backwards in computation. Giv
t the beginning of processing does not have to be explored. 31 As it stands, our encoding of lexical rules and their application as covariation in lexical entries does not yet support the application of lexical rules on-the-fly. With respect o processing, the extended lexical entry of Figure 17 is problematic because before execution of the call to q_l, it is not known which information of the base lexical entry ends up in a derived lexical entry, i.e., tag ~ is completely uninstantiated. This means that there is no way of indexing the lexical entries according to what kind of 31 According to Pollard and Sag (1987) on-the-fly application of lexical rules is also well-suited to playing a role in a model of language use. 560 Meurers and Minnen Covariation Approach to HPSG Lexical Rules derived entry one is looking for. As a result, it is necessary to execute the call to q_l immediately when the lexical entry is used during processing. Otherwise, there would be no information available to restrict the search-space of a generation or parsing process. Flickinger, Pollard, and Wasow (1985) solve this problem using additional specifi- cations: &quot;By providing with each lexical rule a generic class frame which sp
 contains enough information to permit a postponed execution of the interaction predicate. When C is the common information, and D1, ..., Dk are the definitions of the interaction predicate called, we use distributivity to factor out C in (C A D1) V -.. V (C A Dk): We compute C A (D1 V ... V Dk), where the r) are assumed to contain no further common factors. Once we have computed c, we use it to make the extended lexical entry more specific. This technique closely resembles the off-line constraint propagation technique described by Marriott, Naish, and Lassez (1988). The reader is referred to Meurers and Minnen (1996) for a more detailed iscussion of our use of constraint propagation. 32 We illustrate the result of constraint propagation with our example grammar. Since the running example of this paper was kept small, for expository reasons, by only including features that do get changed by one of the lexical rules (which violates the empirical observation mentioned above), the full set of lexical rules would not provide a good example. Let us therefore assume that only the lexical rules 1 and 2 of Figure 11 are given. We then only obtain seven of the clauses of Figure 22: those calling lex_rule_l or lex_r
e. Let us therefore assume that only the lexical rules 1 and 2 of Figure 11 are given. We then only obtain seven of the clauses of Figure 22: those calling lex_rule_l or lex_rule_2, as well as the unit clauses for q_l, q_2, q3, and q_7. Applying constraint propagation to the extended lexical entry of Figure 17 yields the result shown in Figure 23. The information common to all solutions to the interaction call is lifted up into the lexical entry and becomes available upon lexical lookup. 32 In certain cases an extension ofthe constraint language with named isjunctions orcontexted constraints (Maxwell and Kaplan 1989; Eisele and D6rre 1990; Griffith 1996) can be used to circumvent constraint propagation. Encoding the disjunctive possibilities for lexical rule application i this way, instead of with definite clause attachments, makes all relevant lexical information available at lexical lookup. For analyses proposing infinite lexica, though, adefinite clause ncoding of disjunctive possibilities i still necessary and constraint propagation is indispensable forefficient processing. 561 Computational Linguistics Volume 23, Number 4 - 1\] Lct2\[zB\]j c x_ t2Lz \[\](a'b)JJ Figure 23 An entry suitable for on-the
 rules 1 and 2 of Figure 11 are given. We then only obtain seven of the clauses of Figure 22: those calling lex_rule_l or lex_rule_2, as well as the unit clauses for q_l, q_2, q3, and q_7. Applying constraint propagation to the extended lexical entry of Figure 17 yields the result shown in Figure 23. The information common to all solutions to the interaction call is lifted up into the lexical entry and becomes available upon lexical lookup. 32 In certain cases an extension ofthe constraint language with named isjunctions orcontexted constraints (Maxwell and Kaplan 1989; Eisele and D6rre 1990; Griffith 1996) can be used to circumvent constraint propagation. Encoding the disjunctive possibilities for lexical rule application i this way, instead of with definite clause attachments, makes all relevant lexical information available at lexical lookup. For analyses proposing infinite lexica, though, adefinite clause ncoding of disjunctive possibilities i still necessary and constraint propagation is indispensable forefficient processing. 561 Computational Linguistics Volume 23, Number 4 - 1\] Lct2\[zB\]j c x_ t2Lz \[\](a'b)JJ Figure 23 An entry suitable for on-the-fly application (lexical rules 1 and 2
pplication is not always profitable. For example, in the case of generation, un- derspecification f the head of a construction can lead to massive nondeterminism or even nontermination when not enough restricting information is available to generate its complements (Martinovi4 and Strzalkowski 1992; Minnen, Gerdemann, and G6tz 1995). Criteria to determine when it is most profitable to execute calls to an interaction predicate are required. One possibility is to annotate the lexical rule encoding with such criteria by means of delay statements, as, for example, suggested by van Noord and Bouma (1994). While we consider this kind of control facility (Naish \[1986\] and references therein) to be, in general, indispensable for efficient processing, it also has disadvantages that make it desirable to search for alternative or additional mechanisms: Delay statements presup- pose the procedural annotation of an otherwise declarative specification. Substantial computational expertise is required to provide restrictions on the instantiation status of a goal, which must be fulfilled before the goal can be executed. Furthermore, the computational bookkeeping necessary for the delaying mechanism is 
herefore, is to automatically determine certain control prob- lems and deal with them in an off-line fashion along the lines of Minnen, Gerdemann, and G6tz (1995) and Minnen, Gerdemann, and Hinrichs (1996). They describe the use of a dataflow analysis for an off-line improvement of grammars that determines automatically when a particular goal in a clause can best be executed. 6. Efficiency Evaluation The computational treatment of lexical rules as covariation in lexical entries was im- plemented in Prolog by the authors in cooperation with Dieter Martini for the ConTroll system (Gerdemann and King 1994; G6tz and Meurers 1997a). We tested the covaria- tion approach with a complex grammar implementing an HPSG analysis covering the so-called aux-flip phenomenon, and partial-VP topicalization i the three clause types of German (Hinrichs, Meurers, and Nakazawa 1994). This test grammar includes eight lexical rules; some serve syntactic purposes, like the Partial-VP Topicalization Lexical Rule, others are of morphological nature as, for example, an inflectional lexical rule that relates nonfinite verbs to their finite form. Our compiler distinguished seven word classes. Some nouns and most verbal 
s belonging to the same word class. 33 The lexicon of the test grammar can be expanded out off-line since the recursive Complement Extraction Lexical Rule applies only to full verbs, i.e, lexical entries with a complement list of finite length. As a result, the grammar does not have an infinite lexicon. 563 Computational Linguistics Volume 23, Number 4 This means that the more lexical entries in a word class, the greater the saving in space. The covariation approach therefore is particularly attractive for grammars with a large lexicon. 7. Related Work The powerful mechanism of lexical rules (Carpenter 1991) has been used in many natural language processing systems. In this section we briefly discuss some of the more prominent approaches and compare them with the treatment proposed in this paper. 7.1 Off-line Expansion of Lexical Rules A common computational treatment of lexical rules adopted, for example, in the ALE system (Carpenter and Penn 1994) consists of computing the transitive closure of the base lexical entries under lexical rule application at compile-time. While this provides a front-end to include lexical rules in the grammars, it has the disadvantage that the generalizations capture
me 23, Number 4 This means that the more lexical entries in a word class, the greater the saving in space. The covariation approach therefore is particularly attractive for grammars with a large lexicon. 7. Related Work The powerful mechanism of lexical rules (Carpenter 1991) has been used in many natural language processing systems. In this section we briefly discuss some of the more prominent approaches and compare them with the treatment proposed in this paper. 7.1 Off-line Expansion of Lexical Rules A common computational treatment of lexical rules adopted, for example, in the ALE system (Carpenter and Penn 1994) consists of computing the transitive closure of the base lexical entries under lexical rule application at compile-time. While this provides a front-end to include lexical rules in the grammars, it has the disadvantage that the generalizations captured by lexical rules are not used for computation. We mentioned in Section 2.2 that eliminating lexical rules in a precompilation step makes it impossible to process lexical rules or lexical entries that impose constraints that can only be properly executed once information from syntactic processing is available. A related problem is that for analy
lting in infinite lexica, the number of lexical rule applications needs to be limited. In the ALE system, for example, a depth bound can be specified for this purpose. Finally, as shown in Section 6, using an expanded out lexicon can be less time and space efficient han using a lexicon encoding that makes computational use of generalizations over lexical information, as, for example, the covariation encoding. 7.2 Lexical Rules as Unary Phrase Structure Rules Another common approach to lexical rules is to encode them as unary phrase structure rules. This approach is taken, for example, in LKB (Copestake 1992) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules (Copestake 1993, 31). A similar method is included in PATR-II (Shieber et al 1983) and can be used to encode lexical rules as binary relations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or the TFS system (Emele and Zajac 1990; Emele 1994). The covariation approach described in this paper can be viewed as a domain-specific refinement of such a treatment of lexical rules. The encoding of lexical rules used in the covariation appro
pose. Finally, as shown in Section 6, using an expanded out lexicon can be less time and space efficient han using a lexicon encoding that makes computational use of generalizations over lexical information, as, for example, the covariation encoding. 7.2 Lexical Rules as Unary Phrase Structure Rules Another common approach to lexical rules is to encode them as unary phrase structure rules. This approach is taken, for example, in LKB (Copestake 1992) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules (Copestake 1993, 31). A similar method is included in PATR-II (Shieber et al 1983) and can be used to encode lexical rules as binary relations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or the TFS system (Emele and Zajac 1990; Emele 1994). The covariation approach described in this paper can be viewed as a domain-specific refinement of such a treatment of lexical rules. The encoding of lexical rules used in the covariation approach is related to the work of van Noord and Bouma (1994), who describe the hand-encoding of a single lexical rule as definite relations and show how these relati
xicon can be less time and space efficient han using a lexicon encoding that makes computational use of generalizations over lexical information, as, for example, the covariation encoding. 7.2 Lexical Rules as Unary Phrase Structure Rules Another common approach to lexical rules is to encode them as unary phrase structure rules. This approach is taken, for example, in LKB (Copestake 1992) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules (Copestake 1993, 31). A similar method is included in PATR-II (Shieber et al 1983) and can be used to encode lexical rules as binary relations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or the TFS system (Emele and Zajac 1990; Emele 1994). The covariation approach described in this paper can be viewed as a domain-specific refinement of such a treatment of lexical rules. The encoding of lexical rules used in the covariation approach is related to the work of van Noord and Bouma (1994), who describe the hand-encoding of a single lexical rule as definite relations and show how these relations can be used to constrain a lexical entry. The covariation appro
he covariation encoding. 7.2 Lexical Rules as Unary Phrase Structure Rules Another common approach to lexical rules is to encode them as unary phrase structure rules. This approach is taken, for example, in LKB (Copestake 1992) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules (Copestake 1993, 31). A similar method is included in PATR-II (Shieber et al 1983) and can be used to encode lexical rules as binary relations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or the TFS system (Emele and Zajac 1990; Emele 1994). The covariation approach described in this paper can be viewed as a domain-specific refinement of such a treatment of lexical rules. The encoding of lexical rules used in the covariation approach is related to the work of van Noord and Bouma (1994), who describe the hand-encoding of a single lexical rule as definite relations and show how these relations can be used to constrain a lexical entry. The covariation approach builds on this proposal and extends it in three ways: First, the approach shows how to detect and encode the interaction of a set of lexical rules. Second, it pr
g. 7.2 Lexical Rules as Unary Phrase Structure Rules Another common approach to lexical rules is to encode them as unary phrase structure rules. This approach is taken, for example, in LKB (Copestake 1992) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules (Copestake 1993, 31). A similar method is included in PATR-II (Shieber et al 1983) and can be used to encode lexical rules as binary relations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or the TFS system (Emele and Zajac 1990; Emele 1994). The covariation approach described in this paper can be viewed as a domain-specific refinement of such a treatment of lexical rules. The encoding of lexical rules used in the covariation approach is related to the work of van Noord and Bouma (1994), who describe the hand-encoding of a single lexical rule as definite relations and show how these relations can be used to constrain a lexical entry. The covariation approach builds on this proposal and extends it in three ways: First, the approach shows how to detect and encode the interaction of a set of lexical rules. Second, it provides a way 
phrase structure rules and the parser makes no distinction between lexical and nonlexical rules (Copestake 1993, 31). A similar method is included in PATR-II (Shieber et al 1983) and can be used to encode lexical rules as binary relations in the CUF system (Dbrre and Eisele 1991; D6rre and Dorna 1993b) or the TFS system (Emele and Zajac 1990; Emele 1994). The covariation approach described in this paper can be viewed as a domain-specific refinement of such a treatment of lexical rules. The encoding of lexical rules used in the covariation approach is related to the work of van Noord and Bouma (1994), who describe the hand-encoding of a single lexical rule as definite relations and show how these relations can be used to constrain a lexical entry. The covariation approach builds on this proposal and extends it in three ways: First, the approach shows how to detect and encode the interaction of a set of lexical rules. Second, it provides a way to automatically obtain a definite clause encoding of lexical rules and their interaction. Finally, it automatically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexi
 a set of lexical rules. Second, it provides a way to automatically obtain a definite clause encoding of lexical rules and their interaction. Finally, it automatically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexical rule needs to be specified. 7.3 Alternative Ways to Express Lexical Generalizations Lexical rules have not gone unchallenged as a mechanism for expressing eneraliza- tions over lexical information. In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; 564 Meurers and Minnen Covariation Approach to HPSG Lexical Rules Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995). The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy. These approaches seem to propose a completely different way to capture lexical generalizations. It is therefore interesting that the covariation lexical rule compiler produces a lexicon encoding that, basically, uses an underspecification representation: The resulting 
ical rules. Second, it provides a way to automatically obtain a definite clause encoding of lexical rules and their interaction. Finally, it automatically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexical rule needs to be specified. 7.3 Alternative Ways to Express Lexical Generalizations Lexical rules have not gone unchallenged as a mechanism for expressing eneraliza- tions over lexical information. In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; 564 Meurers and Minnen Covariation Approach to HPSG Lexical Rules Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995). The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy. These approaches seem to propose a completely different way to capture lexical generalizations. It is therefore interesting that the covariation lexical rule compiler produces a lexicon encoding that, basically, uses an underspecification representation: The resulting definite clause representat
exical rules and their interaction. Finally, it automatically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexical rule needs to be specified. 7.3 Alternative Ways to Express Lexical Generalizations Lexical rules have not gone unchallenged as a mechanism for expressing eneraliza- tions over lexical information. In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; 564 Meurers and Minnen Covariation Approach to HPSG Lexical Rules Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995). The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy. These approaches seem to propose a completely different way to capture lexical generalizations. It is therefore interesting that the covariation lexical rule compiler produces a lexicon encoding that, basically, uses an underspecification representation: The resulting definite clause representation after constraint propagation represents the common information in the base lex
 their interaction. Finally, it automatically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexical rule needs to be specified. 7.3 Alternative Ways to Express Lexical Generalizations Lexical rules have not gone unchallenged as a mechanism for expressing eneraliza- tions over lexical information. In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; 564 Meurers and Minnen Covariation Approach to HPSG Lexical Rules Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995). The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy. These approaches seem to propose a completely different way to capture lexical generalizations. It is therefore interesting that the covariation lexical rule compiler produces a lexicon encoding that, basically, uses an underspecification representation: The resulting definite clause representation after constraint propagation represents the common information in the base lexical entry, 
action. Finally, it automatically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexical rule needs to be specified. 7.3 Alternative Ways to Express Lexical Generalizations Lexical rules have not gone unchallenged as a mechanism for expressing eneraliza- tions over lexical information. In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; 564 Meurers and Minnen Covariation Approach to HPSG Lexical Rules Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995). The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy. These approaches seem to propose a completely different way to capture lexical generalizations. It is therefore interesting that the covariation lexical rule compiler produces a lexicon encoding that, basically, uses an underspecification representation: The resulting definite clause representation after constraint propagation represents the common information in the base lexical entry, and uses a d
lly, it automatically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexical rule needs to be specified. 7.3 Alternative Ways to Express Lexical Generalizations Lexical rules have not gone unchallenged as a mechanism for expressing eneraliza- tions over lexical information. In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; 564 Meurers and Minnen Covariation Approach to HPSG Lexical Rules Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995). The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy. These approaches seem to propose a completely different way to capture lexical generalizations. It is therefore interesting that the covariation lexical rule compiler produces a lexicon encoding that, basically, uses an underspecification representation: The resulting definite clause representation after constraint propagation represents the common information in the base lexical entry, and uses a definite claus
atically derives the frame specification for lexical rules such that, following standard HPSG practice, only the information changed in a lexical rule needs to be specified. 7.3 Alternative Ways to Express Lexical Generalizations Lexical rules have not gone unchallenged as a mechanism for expressing eneraliza- tions over lexical information. In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; 564 Meurers and Minnen Covariation Approach to HPSG Lexical Rules Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995). The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy. These approaches seem to propose a completely different way to capture lexical generalizations. It is therefore interesting that the covariation lexical rule compiler produces a lexicon encoding that, basically, uses an underspecification representation: The resulting definite clause representation after constraint propagation represents the common information in the base lexical entry, and uses a definite clause attachment to en
