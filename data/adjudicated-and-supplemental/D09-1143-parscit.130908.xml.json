{"algorithms":{"#text":"\n","@version":"110505","algorithm":{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"date":{"#tail":"\n","#text":"2005"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"nt tree or of the path linking two entities of the dependency tree. For the design of automatic relation classifiers, we have investigated the impact of dependency structures to the RE task. Our novel composite kernels, which account for the two syntactic structures, are experimented with the appropriate convolution kernels and show significant improvement with respect to the state-ofthe-art in RE. Regarding future work, there are many research line that may be followed: i) Capturing more features by employing external knowledge such as ontological, lexical resource or WordNet-based features (Basili et al., 2005a; Basili et al., 2005b; Bloehdorn et al., 2006; Bloehdorn and Moschitti, 2007) or shallow semantic trees, (Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti and Bejan, 2004; Moschitti et al., 2007; Moschitti, 2008; Moschitti et al., 2008). ii) Design a new tree-based structures, which combines the information of both constituent and dependency parses. From dependency trees we can extract more precise but also more sparse relationships (which may cause overfit). From constituent trees, we can extract subtrees constituted by non-terminal symbols (grammar symbols), which provid","@endWordPosition":"4835","@position":"29400","annotationId":"T1","@startWordPosition":"4832","@citStr":"Basili et al., 2005"}},"title":{"#tail":"\n","#text":"Effective use of WordNet semantics via kernel-based learning."},"#tail":"\n","institution":{"#tail":"\n","#text":"for Computational Linguistics."},"rawString":{"#tail":"\n","#text":"Roberto Basili, Marco Cammisa, and Alessandro Moschitti. 2005a. Effective use of WordNet semantics via kernel-based learning. In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005), pages 1\u20138, Ann Arbor, Michigan, June. Association for Computational Linguistics."},"#text":"\n","pages":{"#tail":"\n","#text":"1--8"},"marker":{"#tail":"\n","#text":"Basili, Cammisa, Moschitti, 2005"},"publisher":{"#tail":"\n","#text":"Association"},"location":{"#tail":"\n","#text":"Ann Arbor, Michigan,"},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Roberto Basili"},{"#tail":"\n","#text":"Marco Cammisa"},{"#tail":"\n","#text":"Alessandro Moschitti"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Ana-Maria Giuglea and Alessandro Moschitti. 2006. Semantic Role Labeling via Framenet, Verbnet and Propbank. In Proceedings of ACL 2006, Sydney, Australia."},"#text":"\n","marker":{"#tail":"\n","#text":"Giuglea, Moschitti, 2006"},"location":{"#tail":"\n","#text":"Sydney, Australia."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"endency structures to the RE task. Our novel composite kernels, which account for the two syntactic structures, are experimented with the appropriate convolution kernels and show significant improvement with respect to the state-ofthe-art in RE. Regarding future work, there are many research line that may be followed: i) Capturing more features by employing external knowledge such as ontological, lexical resource or WordNet-based features (Basili et al., 2005a; Basili et al., 2005b; Bloehdorn et al., 2006; Bloehdorn and Moschitti, 2007) or shallow semantic trees, (Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti and Bejan, 2004; Moschitti et al., 2007; Moschitti, 2008; Moschitti et al., 2008). ii) Design a new tree-based structures, which combines the information of both constituent and dependency parses. From dependency trees we can extract more precise but also more sparse relationships (which may cause overfit). From constituent trees, we can extract subtrees constituted by non-terminal symbols (grammar symbols), which provide a better generalization (with a risk of underfitting). iii) Design a new kernel which can integrate the advantages of the constituent and dependency tree. The new","@endWordPosition":"4861","@position":"29564","annotationId":"T2","@startWordPosition":"4857","@citStr":"Giuglea and Moschitti, 2006"}},"title":{"#tail":"\n","#text":"Semantic Role Labeling via Framenet, Verbnet and Propbank."},"booktitle":{"#tail":"\n","#text":"In Proceedings of ACL 2006,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Ana-Maria Giuglea"},{"#tail":"\n","#text":"Alessandro Moschitti"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2004"},"rawString":{"#tail":"\n","#text":"Alessandro Moschitti and Cosmin Bejan. 2004. A semantic kernel for predicate argument classification. In CoNLL-2004, Boston, MA, USA."},"#text":"\n","marker":{"#tail":"\n","#text":"Moschitti, Bejan, 2004"},"location":{"#tail":"\n","#text":"Boston, MA, USA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"task. Our novel composite kernels, which account for the two syntactic structures, are experimented with the appropriate convolution kernels and show significant improvement with respect to the state-ofthe-art in RE. Regarding future work, there are many research line that may be followed: i) Capturing more features by employing external knowledge such as ontological, lexical resource or WordNet-based features (Basili et al., 2005a; Basili et al., 2005b; Bloehdorn et al., 2006; Bloehdorn and Moschitti, 2007) or shallow semantic trees, (Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti and Bejan, 2004; Moschitti et al., 2007; Moschitti, 2008; Moschitti et al., 2008). ii) Design a new tree-based structures, which combines the information of both constituent and dependency parses. From dependency trees we can extract more precise but also more sparse relationships (which may cause overfit). From constituent trees, we can extract subtrees constituted by non-terminal symbols (grammar symbols), which provide a better generalization (with a risk of underfitting). iii) Design a new kernel which can integrate the advantages of the constituent and dependency tree. The new tree kernel should inherit","@endWordPosition":"4865","@position":"29591","annotationId":"T3","@startWordPosition":"4862","@citStr":"Moschitti and Bejan, 2004"}},"title":{"#tail":"\n","#text":"A semantic kernel for predicate argument classification."},"booktitle":{"#tail":"\n","#text":"In CoNLL-2004,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Alessandro Moschitti"},{"#tail":"\n","#text":"Cosmin Bejan"}]}},{"volume":{"#tail":"\n","#text":"34"},"#tail":"\n","date":{"#tail":"\n","#text":"2008"},"rawString":{"#tail":"\n","#text":"Alessandro Moschitti, Daniele Pighin, and Roberto Basili. 2008. Tree kernels for semantic role labeling. Computational Linguistics, 34(2):193\u2013224."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"2"},"marker":{"#tail":"\n","#text":"Moschitti, Pighin, Basili, 2008"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ic structures, are experimented with the appropriate convolution kernels and show significant improvement with respect to the state-ofthe-art in RE. Regarding future work, there are many research line that may be followed: i) Capturing more features by employing external knowledge such as ontological, lexical resource or WordNet-based features (Basili et al., 2005a; Basili et al., 2005b; Bloehdorn et al., 2006; Bloehdorn and Moschitti, 2007) or shallow semantic trees, (Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti and Bejan, 2004; Moschitti et al., 2007; Moschitti, 2008; Moschitti et al., 2008). ii) Design a new tree-based structures, which combines the information of both constituent and dependency parses. From dependency trees we can extract more precise but also more sparse relationships (which may cause overfit). From constituent trees, we can extract subtrees constituted by non-terminal symbols (grammar symbols), which provide a better generalization (with a risk of underfitting). iii) Design a new kernel which can integrate the advantages of the constituent and dependency tree. The new tree kernel should inherit the benefits of the three available tree kernels: ST, SST or PT. ","@endWordPosition":"4875","@position":"29657","annotationId":"T4","@startWordPosition":"4872","@citStr":"Moschitti et al., 2008"}},"title":{"#tail":"\n","#text":"Tree kernels for semantic role labeling."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Alessandro Moschitti"},{"#tail":"\n","#text":"Daniele Pighin"},{"#tail":"\n","#text":"Roberto Basili"}]}}]}}}}
