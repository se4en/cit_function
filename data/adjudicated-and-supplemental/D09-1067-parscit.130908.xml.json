{"algorithms":{"#text":"\n","@version":"110505","algorithm":{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"2008"},"rawString":{"#tail":"\n","#text":"Shane Bergsma, Dekang Lin, and Randy Goebel. Discriminative learning of selectional preference from unlabeled text. In Proc. of EMNLP, 2008."},"#text":"\n","marker":{"#tail":"\n","#text":"Bergsma, Lin, Goebel, 2008"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" in better performance. However, additional information about semantic SPs of verbs has not yielded considerable improvement on verb classification although SPs can be strong indicators of diathesis alternations (McCarthy, 2001) and although fairly precise semantic descriptions, including information about verb se1See section 6 for discussion on previous work. lectional restrictions, can be assigned to the majority of Levin classes, as demonstrated by VerbNet (Kipper-Schuler, 2005). SP acquisition from undisambiguated corpus data is arguably challenging (Brockmann and Lapata, 2003; Erk, 2007; Bergsma et al., 2008). It is especially challenging in the context of verb classification where SP models are needed for specific syntactic slots for which the data may be sparse, and the resulting feature vectors integrating both syntactic and semantic features may be high dimensional. However, we wanted to investigate whether better results could be obtained if the features were optimised for richness, the feature extraction for accuracy, and a clustering method capable of dealing with the resulting high dimensional feature space was employed. 2.1 Feature extraction We adopted a recent SCF acquisition system whi","@endWordPosition":"979","@position":"6526","annotationId":"T1","@startWordPosition":"976","@citStr":"Bergsma et al., 2008"},{"#tail":"\n","#text":"t also on semantic features (Levin, 1993). In addition to the ideas mentioned earlier, our future plans include looking into optimal ways of acquiring SPs for verb classification. Considerable research has been done on SP acquisition most of which has involved collecting argument headwords from data and generalizing to WordNet classes. Brockmann and Lapata (2003) have showed that WordNet-based approaches do not always outperform simple frequency-based models, and a number of techniques have been recently proposed which may offer ideas for refining our current unsupervised approach (Erk, 2007; Bergsma et al., 2008). The number and type (and combination) of GRs for which SPs can be reliably acquired, especially when the data is sparse, requires also further investigation. In addition, we plan to investigate other potentially useful features for verb classification (e.g. named entities and preposition classes) and explore semi-automatic ML technology and active learning for guiding the classification. Finally, we plan to conduct a bigger experiment with a larger number of verbs, and conduct evaluation in the context of practical application tasks. Acknowledgments Our work was funded by the Dorothy Hodgkin","@endWordPosition":"6040","@position":"36444","annotationId":"T2","@startWordPosition":"6037","@citStr":"Bergsma et al., 2008"}]},"title":{"#tail":"\n","#text":"Discriminative learning of selectional preference from unlabeled text."},"booktitle":{"#tail":"\n","#text":"In Proc. of EMNLP,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Shane Bergsma"},{"#tail":"\n","#text":"Dekang Lin"},{"#tail":"\n","#text":"Randy Goebel"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Carsten Brockmann and Mirella Lapata. Evaluating and combining approaches to selectional preference acquisition. In Proc. of EACL, 2003."},"#text":"\n","marker":{"#tail":"\n","#text":"Brockmann, Lapata, 2003"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" and/or voice of the verb have resulted in better performance. However, additional information about semantic SPs of verbs has not yielded considerable improvement on verb classification although SPs can be strong indicators of diathesis alternations (McCarthy, 2001) and although fairly precise semantic descriptions, including information about verb se1See section 6 for discussion on previous work. lectional restrictions, can be assigned to the majority of Levin classes, as demonstrated by VerbNet (Kipper-Schuler, 2005). SP acquisition from undisambiguated corpus data is arguably challenging (Brockmann and Lapata, 2003; Erk, 2007; Bergsma et al., 2008). It is especially challenging in the context of verb classification where SP models are needed for specific syntactic slots for which the data may be sparse, and the resulting feature vectors integrating both syntactic and semantic features may be high dimensional. However, we wanted to investigate whether better results could be obtained if the features were optimised for richness, the feature extraction for accuracy, and a clustering method capable of dealing with the resulting high dimensional feature space was employed. 2.1 Feature extraction We adopted a","@endWordPosition":"973","@position":"6492","annotationId":"T3","@startWordPosition":"969","@citStr":"Brockmann and Lapata, 2003"},{"#tail":"\n","#text":"estrictions for T2, we found that each predominant SP was plausible. Also, the SPs frequent in our data were also frequent among the 17 classes according to VN. For example, the many SP clusters labeled as arrangements, issues, ideas and other abstract concepts were also frequent in T2, e.g. among COMMUNICATION (37), CHARACTERISE (29.2), AMALGAMATE (22.2) and other classes. This analysis showed that the SP models which performed well in verb clustering were semantically meaningful for our task. An independent evaluation using one of the standard datasets available for SP acquisition research (Brockmann and Lapata, 2003) is of course needed to determine how well the acquisition method performs in comparison with other existing methods. Finally, we evaluated the quality of the verb clusters created using the SP-based features. We found that some of the errors were similar to those seen on T2 when using syntactic features: errors due to polysemy and syntactic idiosyncracy. However, a new error type clearly due to the SP-based feature was detected. A small number of classes got confused because of strong similar SPs in the subject (agent) position. For example, some PEER (30.3) verbs (e.g. look, peer) were found","@endWordPosition":"4969","@position":"29725","annotationId":"T4","@startWordPosition":"4966","@citStr":"Brockmann and Lapata, 2003"},{"#tail":"\n","#text":"we showed on two well-established test sets that automatically acquired SPs can be highly useful for verb clustering. This result contrasts with most previous works but is in line with theoretical work on verb classification which relies not only on syntactic but also on semantic features (Levin, 1993). In addition to the ideas mentioned earlier, our future plans include looking into optimal ways of acquiring SPs for verb classification. Considerable research has been done on SP acquisition most of which has involved collecting argument headwords from data and generalizing to WordNet classes. Brockmann and Lapata (2003) have showed that WordNet-based approaches do not always outperform simple frequency-based models, and a number of techniques have been recently proposed which may offer ideas for refining our current unsupervised approach (Erk, 2007; Bergsma et al., 2008). The number and type (and combination) of GRs for which SPs can be reliably acquired, especially when the data is sparse, requires also further investigation. In addition, we plan to investigate other potentially useful features for verb classification (e.g. named entities and preposition classes) and explore semi-automatic ML technology and","@endWordPosition":"6000","@position":"36188","annotationId":"T5","@startWordPosition":"5997","@citStr":"Brockmann and Lapata (2003)"}]},"title":{"#tail":"\n","#text":"Evaluating and combining approaches to selectional preference acquisition."},"booktitle":{"#tail":"\n","#text":"In Proc. of EACL,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Carsten Brockmann"},{"#tail":"\n","#text":"Mirella Lapata"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Katrin Erk. A simple, similarity-based model for selectional preferences. In Proc. of ACL, 2007."},"#text":"\n","marker":{"#tail":"\n","#text":"Erk, 2007"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ve resulted in better performance. However, additional information about semantic SPs of verbs has not yielded considerable improvement on verb classification although SPs can be strong indicators of diathesis alternations (McCarthy, 2001) and although fairly precise semantic descriptions, including information about verb se1See section 6 for discussion on previous work. lectional restrictions, can be assigned to the majority of Levin classes, as demonstrated by VerbNet (Kipper-Schuler, 2005). SP acquisition from undisambiguated corpus data is arguably challenging (Brockmann and Lapata, 2003; Erk, 2007; Bergsma et al., 2008). It is especially challenging in the context of verb classification where SP models are needed for specific syntactic slots for which the data may be sparse, and the resulting feature vectors integrating both syntactic and semantic features may be high dimensional. However, we wanted to investigate whether better results could be obtained if the features were optimised for richness, the feature extraction for accuracy, and a clustering method capable of dealing with the resulting high dimensional feature space was employed. 2.1 Feature extraction We adopted a recent SCF","@endWordPosition":"975","@position":"6503","annotationId":"T6","@startWordPosition":"974","@citStr":"Erk, 2007"},{"#tail":"\n","#text":"yntactic but also on semantic features (Levin, 1993). In addition to the ideas mentioned earlier, our future plans include looking into optimal ways of acquiring SPs for verb classification. Considerable research has been done on SP acquisition most of which has involved collecting argument headwords from data and generalizing to WordNet classes. Brockmann and Lapata (2003) have showed that WordNet-based approaches do not always outperform simple frequency-based models, and a number of techniques have been recently proposed which may offer ideas for refining our current unsupervised approach (Erk, 2007; Bergsma et al., 2008). The number and type (and combination) of GRs for which SPs can be reliably acquired, especially when the data is sparse, requires also further investigation. In addition, we plan to investigate other potentially useful features for verb classification (e.g. named entities and preposition classes) and explore semi-automatic ML technology and active learning for guiding the classification. Finally, we plan to conduct a bigger experiment with a larger number of verbs, and conduct evaluation in the context of practical application tasks. Acknowledgments Our work was funded","@endWordPosition":"6036","@position":"36421","annotationId":"T7","@startWordPosition":"6035","@citStr":"Erk, 2007"}]},"title":{"#tail":"\n","#text":"A simple, similarity-based model for selectional preferences."},"booktitle":{"#tail":"\n","#text":"In Proc. of ACL,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Katrin Erk"}}}]}}}}
