{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","listItem":{"#tail":"\n","@confidence":"0.928640428571429","#text":"\n(2) John believes that the Earth is round.\n(3) *John forces that the Earth is round.\nSecondly, if a verb takes a direct object and a\nsentential complement, it will be an Equi verb, as\nexamples in (4) and (5) illustrate.\n(4) John persuaded Mary that the Earth is round.\n(5) *John believed Mary that the Earth is round.\n"},"figure":[{"#tail":"\n","@confidence":"0.402678625","#text":"\n(Record-type homograph\n(Seq-number E-code I-code))\n(Record-type headword (Serial-no Main-entry))\n(Record-type pronunciation (Phonetic))\n(Record-type variant (Spelling Pronunciation))\n(Record-type part-of-speech (Category Inflection))\n(Record-type grammar-code (G-code Label))\n(Record-type def-code\n(Seq-number G-code Subj-code Box-codes))\n(Record-type ntry-text\n(Phrase Label Definition Examples X-ref))\n(Record-type def-word (Basic-word Morphology\nHomograph Word-sense))\n(Record-type cross-reference (Type Pointers))\n(Record-type word-sense (Def-code Def-text))\n(Record-type Usage (Text X-ref))\n"},{"#tail":"\n","@confidence":"0.883703615384615","#text":"\n2828980t<R0154300<rivet\n28289902<02< <\n28290005<v<\n28290107<0100<TI;Xg<NAZV< H XS\n28290208<to cause to fasten with\n28290318<{*CA}RIVET{*CB){'46}s{*44}{*8A}:\n((rivet)\n(1 R0154300 ! < rivet)\n(22T< !<)\n(5v !<)\n(7 100 I< T1 !; X9 !< NAZV f< .... H---XS)\n(8 tO cause to fasten wi th\n*CA RIVET *CB *46 s *44 *8A : ........ ))\n"},{"#tail":"\n","@confidence":"0.837152625","#text":"\n206 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987\nBran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing\n((pair)\n(1 P0008800 < pair)\n(21 <<)\n(3 peER)\n(7 200 < C9 I, esp !. *46 of < CD-- < .... J---Y)\n(8 *45 a *44 2 things that are alike or of the same\n"},{"#tail":"\n","@confidence":"0.988732023809524","#text":"\n(Word-sense (Number 2)\n((Su b-deft nition\n(Item a) (Label NIL}\n(Deft nition 2 things that are alike or of the\nsame kind t, and are usually used together)\n((Example NIL (a pair of shoes))\n(Example NIL (a beautifu/ pair of legs)))\n(Cross-reference\ncompare-with\n(Ldoce-entry (Lexical COUPLE)\n(Morphology NIL )\n(Homograph-number 2)\n(Word-sense-number NIL)))\n(Sub-definition\n(Item b) (Label NIL)\n(Definition 2 playing cards of the same value\nbut of different\n(Ldoce-entry (SUIT)\n(Morphology s)\n(Homograph-number 1)\n(Word-sense-number 3))\n((Exam pie NIL (a pair of kings))))))\n(Word-sense (Number 3)\n((Sub-definition\n(Item a) (Label NIL)\n(Definition 2 people closely connected)\n((Example NIL (a pair of dancers))))\n(Sub-definition\n(Item b) (Label NIL)\n(Definition\n(Ldoce-entry (Lexical COUPLE )\n(Morphology NIL)\n(Homograph-number 2)\n(Word-sense-number 2))\n(Gloss:\nespecially in the phrase the happy pair )))\n(Sub-definition\n(Item c) (Label slang)\n(Definition 2 people closely connected who\ncause annoyance or displeasure)\n((Example NIL\n( You / 're a fine pair coming as late as this/))))))\n"},{"#tail":"\n","@confidence":"0.930088615384615","#text":"\nillustrate.\nhappen(S)\nwarn( l )\nass,l ine(I)\ndecline(S)\n\\[WvS;/t+15\\]\n(Type 1 SRaising)\n\\[Wv4;IO;Tl:( of, against) ifa;D5a;V3\\]\n(Type 30Equi)\n\\[Wv4;T1,Sa,b;X(to be)l,7\\]\n(Type 20Raising)\n\\[T1,3;I0\\]\n(Type 2 SEqui)\n"},{"#tail":"\n","@confidence":"0.8394701","#text":"\na Hch man\n(marry\n((Sense 1)\n((Takes NP NP) (Type 2))\n((Takes NP) (Type i)))\n((Sense 2)\n((Takes NP NP) (Type 2)))\n((Sense 3)\n((Takes NP NP PP) (Type 3) ) ) )\nword marry:\n"},{"#tail":"\n","@confidence":"0.722917285714286","#text":"\nPublished Derived %\nlists from\nLDOCE\nSEqui 31\nOEqui 58\nSRaising 7\nORaising 42\n"},{"#tail":"\n","@confidence":"0.953484714285714","#text":"\n56\n5\n28\n1oo%\n97%\n71%\n67%\n"}],"address":[{"#tail":"\n","@confidence":"0.880965","#text":"\nCambridge, CB2 3QG, England\n"},{"#tail":"\n","@confidence":"0.734689","#text":"\nBailrigg, Lancaster LA1 4YT, England\n"}],"author":[{"#tail":"\n","@confidence":"0.895576","#text":"\nBran Boguraev\n"},{"#tail":"\n","@confidence":"0.972034","#text":"\nTed Briscoe\n"}],"equation":[{"#tail":"\n","@confidence":"0.654297666666667","#text":"\n\\ [ trans: <DC16>\\]\\]\nres t : \\ [ f i r s t : lambda\\]\\] \\ ] \\ ]\nFigure 11\n"},{"#tail":"\n","@confidence":"0.838585461538462","#text":"\nw_sense =~\n<head trane sense-no> = l\nV TakesNP Dyadic\nw_sense\n<head trans sense-no> = i\nV Takes IntraneNP Monadic\nw_sense\n<head trans sense-no> = 2\nV TakesNP Dyadic\nw_sense =~\n<head trane sense-no> = 3\nV TakesNPPP Tr iadic\nFigure 12\n"},{"#tail":"\n","@confidence":"0.478695666666667","#text":"\nnominate (2,4) notify (1) obligate (1) oblige (1) order (1)\norganize (1) overhear (I) persuade (2) pester (1) petition (1)\nphone (1) pick (1) pick on (1) plead with (1) pledge (2)\n"}],"footnote":{"#tail":"\n","@confidence":"0.797321","#text":"\ncase, Object Raising verbs take a sentential complement\nand Object Equi verbs do not, as examples (2) and (3)\n"},"construct":[{"#tail":"\n","@confidence":"0.389359333333333","#text":"\nkind !, and are usu !. used together : *46 a pair of\nshoes T Ia beautiful pair of legs *44 *63 compare\n*CA COUPLE *CB *8B *45 b *44 2 playing cards of\nthe same value but of different *CA SUIT *CB *46\ns *8A *44 (3) : *46 a pair of kings)\n(7 300 < GC < .... < --S-U---Y)\n"},{"#tail":"\n","@confidence":"0.765523111111111","#text":"\nhead: \\[aux: fa l se\nt rans: \\[pred: storm\nsense-no: 1\narg l : <DGIS> - \\[\\]\narg2: <DG16> = \\ [ \\ ] \\ ] \\ ]\nsyncat : \\ [ f i r s t : \\ [cat: NP\nhead: \\ [ trans: <DG15>\\]\\]\nres t : \\ [ f i r s t : \\ [cat: NP\nhead:\n"}],"@confidence":"0.000000","#tail":"\n","reference":[{"#tail":"\n","@confidence":"0.983025975","#text":"\nAkkerman, Erik; Masereeuw, Pieter; and Meijs, Willem. 1985 De-\nsigning a Computerised Lexicon for Linguistic Purposes. ASCOT\nReport No. l, CIP-Gegevens Koninklijke Bibliotheek, Den Haag,\nNetherlands.\nAkkerman, Erik. 1986 A Critical Assessment of the LDOCE Coding\nSystem. To appear in: Akkerman, E.; Masereew, P.; and Meijs,\nW., Eds., ASCOT Report No 2, CIP-Gegevens Koninklijke Biblio-\ntheek, The Hague, Netherlands.\nAlshawi, Hiyan; Boguraev, Branimir; and Briscoe, Ted. 1985\nTowards aLexicon Support Environment for Real Time Parsing.\nIn Proceedings ofthe Second Conference ofthe European Chap-\nter of the Association for Computational Linguistics, Geneva,\nSwitzerland: 171-178.\nAlshawi, Hiyan. 1987 Processing Dictionary Definitions with Phrasal\nPattern Hierarchies. In this issue.\nBoguraev, Branimir. 1986 (and forthcoming) Machine Readable Dic-\ntionaries and Research inComputational Linguistics. InProceed-\nings of a Workshop on Automating the Lexicon, Grosseto, Italy (to\nComputational Linguistics, Volume 13, Numbers 3-4, July-December 1987 215\nBran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing\nbe published as Walker,D. and Zampolli,A., Eds., Automating the\nLexicon in a Multilingual Environment, Cambridge University\nPress, Cambridge, UK).\nBoguraev, Branimir. 1987 A Natural Language Toolkit: Reconciling\nTheory with Practice. In Proceedings of a Workshop on Word\nOrder and Parsing in Unification Grammars, Friedenweiler, Ger-\nmany (to be published as Reyle,U. and Rohrer,C., Eds., &quot;Word\nOrders, Parsing, and Unification Grammars&quot; D. Reidel, Dor-\ndrecht, Holland).\nBoguraev, Branimir; Carter, David and Briscoe, Ted. 1987 A Multi-\nPurpose Interface to an On-line Dictionary. In Proceedings of the\nThird Conference of the European Chapter of the Association for\nComputational Linguistics, Copenhagen, Denmark: 63-69.\nByrd, Roy. 1983 Word Formation in Natural Language Processing\nSystems. In Proceedings of the Eighth International Joint Confer-\nence on Artificial Intelligence, Karlsrnhe, Germany: 704-706.\nCalzolari, Nicoletta. 1984 Machine-Readable Dictionaries, Lexical\nData Bases and the Lexical System. In Proceedings of the lOth\nInternational Congress on Computational Linguistics, Stanford,\nCalifornia: 460-461.\nCarter, David. 1987 An Information Theoretic Analysis of Phonetic\nDictionary Access, Computer Speech and Language, 2:1-11.\nGazdar, Gerald; Klein, Ewan; Pullum, Geoffrey; and Sag, Ivan. 1985\nGeneralized Phrase Structure Grammar. Blackwell, Oxford, UK.\nHeidorn, George et al 1982 The EPISTLE Text-Critiquing System.\nIBM Systems Journal, 21(3): 305-326.\nHuttenlocher, Daniel and Zue, Victor. 1983 Phonotactic and Lexical\nConstraints in Speech Recognition, In Proceedings of the National\nConference on Artificial Intelligence, Washington, D.C.: 172-176.\nIngria, Robert. 1984 Complement Types in English. Report No. 5684,\nBolt Beranek and Newman Inc., Cambridge, Mass.\nJackendoff, Ray and Jane Grimshaw. 1985 A Key to the Brandeis\nVerb Catalog. Unpublished mimeo, under NSF Grant IST-84-\n20073, &quot;Information Structure of a Natural Language Lexicon&quot;,\nProgram in Linguistics and Cognitive Science, Brandeis Univer-\nsity, Waltham, Mass.\nKaplan, Ronald and Bresnan, Joan. 1982 Lexical-Functional Gram-\nmar: A Formal System for Grammatical Representation. In:\nJ.Bresnan, Ed., The Mental Representation of Grammatical Re-\nlations. The MIT Press, Cambridge, Mass: 173-281.\nKay, Martin. 1984a Functional Unification Grammar: A Formalism for\nMachine Translation. In Proceedings of the lOth International Con-\ngress on Computational Linguistics, Stanford, California: 75-79.\nKay, Martin. 1984b The Dictionary Server. In Proceedings of the lOth\nInternational Congress on Computational Linguistics, Stanford,\nCalifornia, 461-462.\nLeech, Geoffrey; Garside, Roger; and Atwell, Erik. 1983 The Auto-\nmatic Grammatical Tagging of the LOB Corpus. Bulletin of the\n1. Subject Raising verbs (total number 5)\nInternational Computer Archive of Modern English, Norwegian\nComputing Centre for the Humanities, Bergen, Norway.\nMichiels, Archibal. 1982 Exploiting a Large Dictionary Data Base.\nPhD Thesis, Universit6 de Liege, Liege, Belgium.\nMichiels, Archibal. 1983 Automatic Analysis of Texts. In Informatics\n7, Proceedings of a Conference of the ASLIB Informatics Group\nand the Information Retrieval Group of the British Computer\nSociety, Cambridge, UK: 103-120.\nMoulin, A.; Jansen, J; and Michiels, A. 1985 Computer Exploitation\nof LDOCE's Grammatical Codes, paper presented at a Confer-\nence on Survey of English Language, Lund.\nPerlmutter, D.M. and Soames, S. 1979 Syntactic Argumentation and\nthe Structure of English. University of California Press, Berkeley,\nCalifornia.\nPhillips, John and Thompson, Henry. 1986 A Parser for Generalised\nPhrase Structure Grammars. To apper in Klein, E. and Haddock,\nN., Eds., Edinburgh Working Papers in Cognitive Science, Uni-\nversity of Edinburgh, Edinburgh, Scotland.\nProcter, Paul. 1978 Longman Dictionary of Contemporary English.\nLongman Group Limited, Harlow and London, England.\nQuirk, Randolph; Greenbaum, Sidney; Leech, Geoffrey; and Svart-\nvik, Jan. 1972 A Grammar of Contemporary English, Longman\nGroup Limited, Harlow and London, England.\nQuirk, Randolph; Greenbaum, Sidney; Leech, Geoffrey; and Svart-\nvik, Jan. 1985 A Comprehensive Grammar of English, Longman\nGroup Limited, Harlow and London, England.\nRobinson, Jane. 1982 DIAGRAM: A Grammar for Dialogues. Com-\nmunications of the ACM, 25(1): 27-47.\nRosenbaum, P.S. 1967 The Grammar of English Predicate Comple-\nment Constructions. MIT Press, Cambridge, Mass.\nRussell, Graham; Pulman, Steve; Ritchie, Graeme; and Black, Alan.\n1986 A Dictionary and Morphological Analyser for English. In\nProceedings of the Eleventh International Congress on Computa-\ntional Linguistics, Bonn, Germany: 277-279.\nSager, N. 1981 Natural Language Information Processing, Addison-\nWesley, Reading, Mass.\nShieber, S. 1984 The Design of a Computer Language for Linguistic\nInformation, In Proceedings of the lOth International Congress on\nComputational Linguistics, Stanford, California: 362-366.\nStockwell, R.P.; Schachter, P.; and Partee, B.H. 1973 The Major\nSyntactic Structures of English. Holt, Rinehart and Winston, New\nYork, New York.\nTompa, Frank. 1986 Database Design for a Dictionary of the Future.\nPreliminary Report, Centre for the New Oxford English Dictio-\nnary, University of Waterloo, Waterloo, Ontario.\nWalker, D. and Amsler, A. 1986 The Use of Machine-Readable\nDictionaries in Sublanguage Analysis. In: R. Grishman and R.\nKittredge, Eds., Analysing Language in Restricted Domains,\nLawrence Erlbaum Associates, Hillsdale, New Jersey.\nWilliams, E.S., 1980 Predication. Linguistic Inquiry, 11(2): 203-238.\nAPPENDIX\nappear (3) chance (1) happen (3) seem (2) transpire (2)\n2. Object Raising verbs (total number 53)\nadjudge (1) admit (3) allow (5) argue (3) assert (1)\nassume (1) avow (1) believe (3) betray (3) certify (2)\ndeclare (2) deem (1) deny (1) determine (1) discover (2)\nengage (4) feel (5) find (8) foreordain (1) guess (1)\nhold (9) judge (3) maintain (5) make out (5) mean (2)\nmind (2) notice (1) observe (1) order (6) perceive (1)\npredicate (1) prefer (1) preordain (1) presume (1) presume (2)\nproclaim (1) pronounce (2) pronounce (3) prove (1) recognize (3)\nremember (1) report (1) reveal (2) see (2) smell (2)\nsmell (3) suppose (1) suppose (2) tell (6) think (2)\nunderstand (3) understand (4) warrant (2)\n216 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987\nBran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing\n3. Subject Equi verbs ( to ta l number 335)\nabide (1) account for (2) ache (2) acknowledge (1) adore (3)\nadvocate (1) affect (1) afford (2) agree (2) aim (2)\naim at (1) allude to (1) anticipate (1) appear (2) arrange (2)\naspire (1) assent (1) attach to (3) attempt (1) avoid (1)\nawake (1) bear (5) bear (9) begin (1) beg (3)\nbegrudge (1) bid fair (1) blanch (2) blink at (1) blush (2)\nbother (3) break off (1) burn (6) burst (3) burst out (1)\nbust out (3) care (1) cease (1) chance (1) choose (2)\nclaim (4) clamour (2) clog (1) close (3) cloud (3)\ncome (1) come (7) come before (1) come down to (1) come out against (1)\ncome into (1) come on (1) come to (1) commence (1) compare with (1)\ncompete (1) conceal (1) conceive of (1) concur (2) condescend (1)\nconduce to (1) confess (1) confess (2) confide (1) connive (1)\nconsent (1) consider (1) consist in (1) conspire (1) conspire (2)\ncontemplate (2) continue (1) continue (3) contract (1) contrive (1)\ncontrive (3) could (1) covenant (1) cut out (4) cry out against (1)\ndare (1) dare (2) decide (2) decide on (1) declare against (1)\ndeclare for (1) decline (3) defend (3) defy (3) deign (1)\ndelay (1) delight (2) delight in (1) demand (1) depose (2)\nderide (1) descend to (1) deserve (1) detest (1) disclaim (1)\ndiscontinue (1) discourage (2) disdain (2) dislike (1) do with (1,2)\ndread (1) duck out of (1) elect (2) endeavour (1) endure (1)\nenjoy (1) envisage (1) escape (3) essay (1) evade (2)\nexcuse (1) expect (1) exult (1) exult over (2) fail (1,3)\n"},{"#tail":"\n","@confidence":"0.820518","#text":"\ntend (2) think of (1) think of (5) threaten (2) train (3)\ntremble (3) trouble (3) try (1) try (2) try (3)\nundertake (2) unite (2) use (1) venture (2) venture (4)\nvolunteer (1) volunteer (2) vote (1) vouchsafe (1) vow (1)\nwait (1) want (3) want (4) warrant (1) watch (3)\nwitness to (1) wriggle out of (1) write (4) write back (1) yearn (1)\nComputational Linguistics, Volume 13, Numbers 3-4, July-December 1987 217\nBran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing\n4. Object Equi verbs (total number 284)\nacknowledge (2) adjure (1) advise (1) aid (1) allow (2)\nallure (1) appoint (1) arrange for (1) ask (4) assign (4)\nassist (1) attribute to (1) authorize (1) badger (1) bargain for (1)\nbeckon (1) behove (1) beseech (1) bestir (1) bid (2)\nbill (2) bludgeon into (1) bluff into (1) bribe (I) bring (2)\nbring (5) bring in (3) bully (1) buzz (3) cable (1)\ncall on (2) catch (3) cause (1) caution (1) challenge (1)\nchallenge (4) challenge (5) charge (5) charge with (1) charge with (2)\ncome down on (1) command (1) commission (1) compel (1) condemn (3)\ncondemn (4) condition (3) confess (3) conjure (1) connive at (1)\nconsider (2) constrain (1) cop (1) counsel (1) couple with (1)\ncozen into (1) credit with (1) dare (5) debar from (1) decide (4)\ndedicate to (1) defy (2) delegate (2) depend on (1) depute (1)\ndeputize (2) design (2) designate (2) detail (1) direct (3)\ndoom (1) dragoon into (1) draw on (3) drive (8) egg on (1)\nembolden (1) employ (1) employ (2) employ in (1) empower (1)\nenable (1) enable (2) encourage (1) end in (1) engage (1)\nenggae in (1) entice (1) entitle (2) entreat (1) equip (2)\nesteem (2) excite (2) exhort (1) expect (5) fancy (1)\nfancy (3) figure on (1) find (1) find (6) fit (5)\nforbid (1) force (I) frighten into (1) frighten out of (2) get (4)\nget (8) give (17) give over to (1) goad into (1) groom (4)\nhabituate to (1) hail as (1) harden to (1) hark at (1) hear (1)\nhelp (1) help (2) hunger (1) impel (1) implore (I)\nimportune (1) impute to (l) incite (1) incline (3) induce (1)\ninfluence (1) inhibit from (1) inspire (1) instigate (2) instruct (2)\ninstruct (3) intend (2) introduce to (1) inure to (1) inveigle into (1)\ninvite (2) invite (3) itch for (1) join with in (1) keep (10)\nkeep from (1) know (4) lead (2) lead on (1) legislate against (1)\nlegislate for (1) let (1) let (2) let (3) let (4)\nlet off (1) long for (I) look at (1) look to (2) lower (3)\nmake (3) make (5) make (6) make (7) mean (4)\nmotion (2) motion to (1) motivate (1) move (11) name (3)\n"},{"#tail":"\n","@confidence":"0.844372866666667","#text":"\ntimetable (1) time (1) tip (1) tip off (2) train (2)\ntrouble (2) unfit for (1) urge (2) want (2) warn (1)\nwatch (1) watch (5) watch for (1) wean from (1) worry at (1)\nyearn for (1)\n5. Equi verbs (total number 42)\nallow (1) allow for (1) approve of (1) ask (2) bank on (1)\nbeg (2) calculate on (1) chance (2) choose (1) compensate for (1)\ncountenance (1) count on (1) culminate in (1) desire (1) enjoin (1)\nhate (1) hate (2) hear about (1) hear of (1) help (4)\nimagine (1) intend (1) like (1) like (3) love (2)\nnag (1) need (1) pay (1) permit (1) prepare (4)\nqualify (1) race (3) recommend (2) rely on (1) save (4)\nsee (6) sign (3) sign up (1) start (3) ' visualize (1)\nwant (1) wish (5)\n218 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987\n"}],"bodyText":[{"#tail":"\n","@confidence":"0.986635875","#text":"\nThis article focusses on the derivation of large lexicons for natural language processing. We describe the\ndevelopment of a dictionary support environment linking a restructured version of the Longman\nDictionary of Contemporary English to natural language processing systems. The process of restruc-\nturing the information in the machine readable version of the dictionary is discussed. The Longman\ngrammar code system is used to construct 'theory neutral' lexical entries. We demonstrate how such\nlexical entries can be put to practical use by linking up the system described here with the experimental\nPATR-II grammar development environment. Finally, we offer an evaluation of the utility of the\ngrammar coding system for use by automatic natural language parsing systems.\n"},{"#tail":"\n","@confidence":"0.993608107438017","#text":"\nThe grammar coding system employed by the Longman\nDictionary of Contemporary English (henceforth\nLDOCE) is the most comprehensive description of\ngrammatical properties of words to be found in any\npublished dictionary available in machine readable\nform. This paper describes the extraction of this, and\nother, information from LDOCE and discusses the\nutility of the coding system for automated natural\nlanguage processing.\nRecent developments in linguistics, and especially on\ngrammatical theory - - for example, Generalised Phrase\nStructure Grammar (GPSG) (Gazdar et al, 1985), Lex-\nical Functional Grammar (LFG) (Kaplan and Bresnan,\n1982) - - and on natural language parsing frameworks\nfor example, Functional Unification Grammar (FUG)\n(Kay, 1984a), PATR-II (Shieber, 1984) - - make it\nfeasible to consider the implementation of efficient\nsystems for the syntactic analysis of substantial frag-\nments of natural anguage. These developments also\nemphasise that if natural anguage processing systems\nare to be able to handle the grammatical nd semantic\nidiosyncracies of individual lexical items elegantly and\nefficiently, then the lexicon must be a central compo-\nnent of the parsing system. Real-time parsing imposes\nstringent requirements on a dictionary support environ-\nment; at the very least it must allow frequent and rapid\naccess to the information in the dictionary via the\ndictionary head words. The research described below is\ntaking place in the context of three collaborative\nprojects (Boguraev, 1987; Russell et al, 1986; Phillips\nand Thompson, 1986) to develop a general-purpose,\nwide coverage morphological nd syntactic analyser for\nEnglish. One motivation for our interest in machine\nreadable dictionaries i to attempt to provide a substan-\ntial lexicon with lexical entries containing rammatical\ninformation compatible with the grammatical frame-\nwork employed by the analyser.\nThe idea of using the machine readable source of a\npublished ictionary has occurred to a wide range of\nresearchers, for spelling correction, lexical analysis,\nthesaurus construction, and machine translation, to\nname but a few applications. Most of the work on\nautomated dictionaries has concentrated on extracting\nlexical or other information, essentially by batch pro-\ncessing (eg. Amsler, 1981 ;Walker and Amsler, 1986), or\nCopyright 1987 by the Association for Computational Linguistics. Permission tocopy without fee all or part of this material is granted provided\nthat he copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page. To\ncopy otherwise, orto republish, requires afee and/or specific permission.\n0362-613X/87/030203-218503.00\nComputational Linguistics, Volume 13, Numbers 3-4, July-December 1987 203\nBran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing\non developing dictionary servers for office automation\nsystems (Kay, 1984b). Few established parsing systems\nhave substantial lexicons and even those which employ\nvery comprehensive grammars (eg. Robinson, 1982;\nBobrow, 1978) consult relatively small lexicons, typi-\ncally generated by hand. Two exceptions to this gener-\nalisation are the Linguistic String Project (Sager, 1981)\nand the IBM CRITIQUE (formerly EPISTLE) Project\n(Heidorn et al, 1982; Byrd, 1983); the former employs\na dictionary of approximately 10,000 words, most of\nwhich are specialist medical terms, the latter has well\nover 100,000 entries, gathered from machine readable\nsources. In addition, there are a number of projects\nunder way to develop substantial lexicons from machine\nreadable sources (see Boguraev, 1986 for details). How-\never, as yet few results have been published concerning\nthe utility of electronic versions of published ictionar-\nies as sources for such lexicons. In this paper we\nprovide an evaluation of the LDOCE grammar code\nsystem from this perspective.\nWe chose to employ LDOCE as the machine read-\nable source to aid the development of a substantial\nlexicon because this dictionary has several properties\nwhich make it uniquely appropriate for use as the core\nknowledge base of a natural anguage processing sys-\ntem. Most prominent among these are the rich gram-\nmatical subcategorisations of the 60,000 entries, the\nlarge amount of information concerning phrasal verbs,\nnoun compounds and idioms, the individual subject,\ncollocational nd semantic odes for the entries and the\nconsistent use of a controlled 'core' vocabulary in\ndefining the words throughout the dictionary. (Michiels\n(1982) contains further description and discussion of\nLDOCE.) In this paper we focus on the exploitation of\nthe LDOCE grammar coding system; Alshawi et al\n(1985) and Alshawi (1987) describe further esearch in\nCambridge utilising different types of information avail-\nable in LDOCE.\nThe information available in the dictionary is both\nvery rich and diverse, but also typically only semi-\nformalised, as it is intended for human, rather than\nmachine, interpetation. As a consequence the programs\nwe are developing, both to restructure and to exploit\nthis information, need to undergo constant revision as\nthey are being used. The system we describe is not\nintended for off-line use, where one might attempt to\nderive, completely automatically, a lexicon for natural\nlanguage analysis. Rather than trying to batch process\nthe electronic source, lexicon development from the\nLDOCE tape is more incremental nd interactive. Our\nsystem is designed as an integral part of a larger\ngrammar (and lexicon) development environment,\nwhere new lexical entries are automatically generated\nfrom the on-line version of the dictionary, checked for\ncorrectness and consistency and only then added to the\n'final' lexicon.\nThe problem of utilising LDOCE in natural language\nprocessing falls into two areas. Firstly, we must provide\nan environment in which the machine readable source is\nlinked to the development environment in an appropri-\nate fashion and secondly, we must restructure the\ninformation in the dictionary, using the development\nenvironment, in such a way that natural language pro-\ncessing systems are able to utilise it effectively. As an\nexample, we demonstrate how the LDOCE grammar\ncodes can be put to practical use by linking up the\nsystem with the experimental PATR-II parsing system.\nFinally, we offer an evaluation of the utility of the\nLDOCE grammar coding system from the perspective\nof natural language processing.\n"},{"#tail":"\n","@confidence":"0.984951884615385","#text":"\nThere is a well recognised problem with providing\ncomputational support for machine readable dictionar-\nies, in particular where issues of access are concerned.\nOn the one hand, dictionaries exhibit far too much\nstructure for conventional techniques for managing\n'flat' text to apply to them. On the other hand, the\nequally large amounts of free text in dictionary entries,\nas well as the implicitly marked relationships commonly\nused to encode linguistic information, makes a dictio-\nnary difficult o represent as a structured atabase of a\nstandard, eg. relational, type. In addition, in order to\nlink the machine readable version of LDOCE to our\ndevelopment environment, and eventually to our natu-\nral language processing systems, we need to provide\nfast access from Lisp to data held in secondary storage.\nLisp is not particularly well suited for interfacing to\ncomplex, structured objects, and it was not our inten-\ntion to embark on a major effort involving the develop-\nment of a formal model of a dictionary (of the style\ndescribed in, eg., Tompa 1986); on the other hand a\nmethod of access was clearly required, which was\nflexible enough to support a range of applications in-\ntending to make use of the LDOCE tape.\nThe requirement for having the dictionary entries in a\nform convenient for symbolic manipulation from within\nLisp was furthermore augmented by the constraint that\nall the information present in the typesetting tape should\nbe carried over to the on-line version of LDOCE, since\nit is impossible to say in advance which records and\nfields of an entry would, or would not, be of potential\nuse to a natural anguage processing program. Finally,\nthe complexity of the data structures tored on disc\nshould not be constrained in any way by the method of\naccess, as we do not have a very clear idea what form\nthe restructured dictionary may eventually take.\nGiven that we were targeting all envisaged access\nroutes from LDOCE to systems implemented in Lisp,\nand since the natural data structure for Lisp is the\ns-expression, we adopted the approach of converting\nthe tape source into a set of list structures, one per\nentry. Our task was made possible by the fact that while\nfar from being a database in the accepted sense of the\nword, the LDOCE typesetting tape is the only truly\ncomputerised dictionary of English (Michiels, 1983).\n204 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987\nBran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing\nThe logical structure of a dictionary entry is reflected on\nthe tape as a sequence of typed records (see Figure 1),\neach with additional internal segmentation, where rec-\nords and fields correspond to separate units in an entry,\nsuch as headword, pronunciation, grammar code, word\nsenses, and so forth.\n"},{"#tail":"\n","@confidence":"0.990415620689655","#text":"\nThe &quot;lispification&quot; of the typesetting tape was car-\nfled out in a series of batch jobs, via a program written\nin a general text editing facility. The need to carry out\nthe conversion without any loss of information meant\nthat special attention had to be paid to the large number\nof non-printing characters which appear on the tape.\nMost of these signal changes in the typographic appear-\nance of the printed dictionary, where crucial informa-\ntion about the structure of an entry is represented by\nchanges of typeface and font size. All control characters\nwere translated into atoms of the form *AB, where A\nand B correspond to the hexadecimal digits of the\nASCII character code. Information was thus preserved,\nand readily available to any program which needed to\nparse the implicit structure of a dictionary entry or field,\nand the lispified source was made suitable for transport-\ning between different software configurations and oper-\nating systems. Figure 2 illustrates part of an entry as it\nappears in the published ictionary, on the typesetting\ntape and after lispification.\nNote that as a result of the lispification, brackets\nhave been inserted at suitable points, both to delimit\nentries and indicate their internal structure; in addition\ncharacters pecial to Lisp have been appropriately\nescaped. Thus an individual dictionary entry can now\nbe made available to a client program by a single call to\na generic read function, once the Lisp reader has been\nproperly positioned and 'aligned' with the beginning of\nrivet 2 u 1 \\[TI;X9\\] to cause to fasten with RIVETst:...\n"},{"#tail":"\n","@confidence":"0.998542424","#text":"\nthe s-expression encoding the required entry. In the\nlispified entry in Figure 2 the numbers at the head of\neach sublist indicate the type of information stored in\neach field within the overall entry. For example, &quot;5&quot; is\nthe part of speech field, and &quot;8&quot; is the word sense\ndefinition.\nThe 60,000 or so complete ntries of the processed\ndictionary require of the order of 20 MBytes to store.\nThe problem of access, from Lisp, to the dictionary\nentry s-expressions held on secondary storage cannot\nbe resolved by ad hoc solutions, such as sequential\nscanning of files on disc or extracting subsets of such\nfiles which will fit in main memory, as these are not\nadequate as an efficient interface to a parser. (Exactly\nthe same problem would occur if our natural anguage\nsystems were implemented in Prolog, since the Prolog\n'database facility' refers to the knowledge base that\nProlog maintains in main memory.) In principle, given\nthat the dictionary is now in a Lisp-readable format, a\npowerful virtual memory system might be able to man-\nage access to the internal Lisp structures resulting from\nreading the entire dictionary; we have, however,\nadopted an alternative solution as outlined below.\nWe have mounted LDOCE on-line under two dif-\nferent hardware configurations. In both cases the same\nlispified form of the dictionary has been converted into\na random access file, paired together with an indexing\nfile from which the disc addresses of dictionary entries\nfor words and compounds can be computed.\nA series of systems in Cambridge are implemented in\nLisp running under Unix TM. They all make use of an\nefficient dictionary access system which services re-\nquests for s-expression entries made by client pro-\ngrams. A dictionary access process is fired off, which\ndynamically constructs a search tree and navigates\nthrough it from a given homograph directly to the offset\nin the lispified file from where all the associated infor-\nmation can be retrieved. As Alshawi (1987) points out,\ngiven that no situations were envisaged where the\ninformation from the tape would be altered once in-\nstalled in secondary storage, this simple and conven-\nComputational Linguistics, Volume 13, Numbers 3-4, July-December 1987 205\nBran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing\ntional access trategy is perfectly adequate. The use of\nsuch standard atabase indexing techniques makes it\npossible for an active dictionary process to be very\nundemanding with respect o main memory utilisation.\nFor reasons of efficiency and flexibility of customisa-\ntion, namely the use of LDOCE by different client\nprograms and from different Lisp and/or Prolog sys-\ntems, the dictionary access system is implemented in\nthe programming language C and makes use of the\ninter-process communication facilities provided by the\nUnix operating system. To the Lisp programmer, the\ncreation of a dictionary process and subsequent re-\nquests for information from the dictionary appear sim-\nply as Lisp function calls.\nMost of the recent work with the dictionary, and in\nparticular the decompacting and analysis of the gram-\nmar codes has been carried out in Interlisp-D on Xerox\n1100 series workstations. The same lispified form of the\ndictionary was used. Originally it was installed on a\nsingle workstation and only available locally. Instead of\na separate process building a search tree, the access\nmethod relies on a precompiled, multilevel indexing\nstructure which allows direct hashing into the on-line\nsource. In addition, the powerful Interlisp-D virtual\nmemory allows the access system to be significantly\nenhanced by caching most of the working subset of the\ndictionary at any given turn in main memory. It turns\nout that for a single user workstation, specially tuned\nfor Lisp and operations optimised at the microcode\nlevel for random file access and s-expression I/O, this\nstrategy offers remarkably good results.\nMore recently, a dictionary server, of the kind de-\nscribed by Kay (1984b), was implemented and installed\nas a background process on a Xerox workstation et-\nworked together with the rest of the equipment dedi-\ncated to natural anguage processing applications (Bo-\nguraev et al, 1987). Again, the same lispified form of the\nmachine readable source of LDOCE was used. From\nthe point of view of providing a centralised service to\nmore than one client, efficiently over a packet switching\nnetwork, disc space on the server processor was not an\nissue. This made it possible to construct a larger, but\nmore comprehensive, index for the dictionary, which\nnow allows the recovery of a word in guaranteed time\n(typically less than a second).\nThe main access route into LDOCE for most of our\ncurrent applications is via the homograph fields (see\nFigure 1). Options exist in the access software to\nspecify which particular homograph (or homographs)\nfor a lexical item is required. The early process of\nlispification was designed to bring together in a single\ngroup all dictionary entries corresponding not only to\ndifferent homographs, but also to lexicalised com-\npounds for which the argument word appears as the\nhead of the compound. Thus, the primary index for\nblow allows access to two different verb homographs\n(eg. b low 3) , two different noun homographs (eg. blow2),\n10 compounds (eg. blow offand blow-by-blow), or all 14\nof the dictionary entries (not necessarily to be found in\nsubsequent positions in the dictionary) related to blow.\nWhile no application currently makes use of this facil-\nity, the motivation for such an approach to dictionary\naccess comes from envisaging a parser which will\noperate on the basis of the on-line LDOCE; and any\nserious parser must be able to recognise compounds\nbefore it segments its input into separate words.\nFrom the master LDOCE file, we have computed\nalternative indexing information, which allows access\ninto the dictionary via different routes. In addition to\nheadwords, dictionary search through the pronuncia-\ntion field is available; Carter (1987) has merged infor-\nmation from the pronunciation and hyphenation fields,\ncreating an enhanced phonological representation\nwhich allows access to entries by broad phonetic lass\nand syllable structure (Huttenlocher and Zue, 1983). In\naddition, a fully flexible access system allows the re-\ntrieval of dictionary entries on the basis of constraints\nspecifying any combination ofphonetic, lexical, syntac-\ntic, and semantic information (Boguraev et al, 1987).\nIndependently, random selection of dictionary entries is\nalso provided to allow the testing of software on an\nunbiased sample.\n"},{"#tail":"\n","@confidence":"0.999593612903226","#text":"\nThe lispified LDOCE file retains the broad structure of\nthe typesetting tape and divides each entry into a\nnumber of fields - - head word, pronunciation, grammar\ncodes, definitions, examples, and so forth. However,\neach of these fields requires further decoding and re-\nstructuring to provide client programs with easy access\nto the information they require (see Calzolari (1984) for\nfurther discussion). For this purpose the formatting\ncodes on the typesetting tape are crucial since they\nprovide clues to the correct structure of this informa-\ntion. For example, word senses are largely defined in\nterms of the 2000 word core vocabulary, however, in\nsome cases other words (themselves defined elsewhere\nin terms of this vocabulary) are used. These words\nalways appear in small capitals and can therefore be\nrecognised because they will be preceded by a font\nchange control character. In Figure 1 above the defini-\ntion of rivet as verb includes the noun definition of\n&quot;RIVET 1'', as signalled by the font change and the\nnumerical superscript which indicates that it is the first\n(i.e. noun entry) homograph; additional notation exists\nfor word senses within homographs. On the typesetting\ntape, font control characters are indicated by hexadeci-\nmal numbers within curly brackets. In addition, there is\na further complication because this sense is used in the\nplural and the plural morpheme must be removed before\nRIVET can be associated with a dictionary entry.\nHowever, the restructuring program can achieve this\nbecause such morphology is always italicised, so the\nprogram knows that, in the context of non-core vocab-\nulary items, the italic font control character signals the\n"},{"#tail":"\n","@confidence":"0.921080166666667","#text":"\n(8 *45 a *44 2 people closely connected : *46 a pair\nof dancers *45 b *CA COUPLE *CB *8B *44 (2)\n(esp \\[. in the phr !. *45 the happy pair *44) *45 c\n*46 sl *44 2 people closely connected who cause\nannoyance or displeasure : *46 You!'re a fine pair\ncoming as late as this \\[\\[ ........ )\n"},{"#tail":"\n","@confidence":"0.969162073529412","#text":"\noccurrence of a morphological variant of a LDOCE\nhead entry.\nA suite of programs to unscramble and restructure all\nthe fields in LDOCE entries has been written which is\ncapable of decoding all the fields except hose providing\ncross-reference and usage information for complete\nhomographs. Figure 3 illustrates a simple lexical entry\nbefore and after the application of these programs. The\ndevelopment of the restructuring programs was a non-\ntrivial task because the organisation of information on\nthe typesetting tape presupposes its visual presentation,\nand the ability of human users to apply common sense,\nutilise basic morphological knowledge, ignore minor\nnotational inconsistencies, and so forth. To provide a\ntest-bed for these programs we have implemented an\ninteractive dictionary browser capable of displaying the\nrestructured information in a variety of ways and rep-\nresenting it in perspicuous and expanded form.\nIn what follows we will discuss the format of the\ngrammar codes in some detail as they are the focus of\nthe current paper, however, the reader should bear in\nmind that they represent only one comparatively con-\nstrained field of an LDOCE entry and therefore, a small\nproportion of the overall restructuring task. Figure 4\nillustrates the grammar code field for the third word\nsense of the verb believe as it appears in the published\ndictionary, on the typesetting tape and after re-\nstructuring.\nbe l ieve v ... B \\[TSa,b;V3;X(to be)l, (to be)7\\]\n(7 300 !< TSa l , b !; V3 !; X (*46 to be\n*44) 1 !, (*46 to be *44) 7 !< )\nsense-no 3 head: TSa\nhead: T5b\nhead: V3\nhead: X1 r ight opt iona l ( to be)\nhead: X7 r ight opt iona l ( to be)\nFigure 4\nLDOCE provides considerably more syntactic infor-\nmation than a traditional dictionary. The Longman\nlexicographers have developed a grammar coding sys-\ntem capable of representing in compact form a non-\ntrivial amount of information, usually to be found only\nin large descriptive grammars of English (such as Quirk\net al, 1985). A grammar code describes a particular\npattern of behaviour of a word. Patterns are descriptive,\nand are used to convey a range of information: eg.\ndistinctions between count and mass nouns (dog vs.\ndesire), predicative, postpositive and attributive adjec-\ntives (asleep vs. elect vs. jokular), noun complementa-\ntion (fondness, fact) and, most importantly, verb com-\nplementation a d valency.\nGrammar codes typically contain a capital letter,\nfollowed by a number and, occasionally, a small letter,\nfor example \\[T5a\\] or \\[V3\\]. The capital etters encode\ninformation &quot;about he way a word works in a sentence\nComputational Linguistics, Volume 13, Numbers 3-4, July-December 1987 207\nBran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing\nor about the position it can fill&quot; (Procter, 1978: xxviii);\nthe numbers &quot;give information about he way the rest of\na phrase or clause is made up in relation to the word\ndescribed&quot; (ibid.). For example, &quot;T&quot; denotes a transi-\ntive verb with one object, while &quot;5&quot; specifies that what\nfollows the verb must be a sentential complement\nintroduced by that. (The small letters, eg. &quot;a&quot; in the\ncase above, provide further information typically re-\nlated to the status of various complementisers, adverbs\nand prepositions in compound verb constructions: eg.\n&quot;a&quot; indicates that the word that can be left out between\na verb and the following clause.) As another example,\n&quot;V3&quot; introduces a verb followed by one NP object and\na verb form (V) which must be an infinitive with to (3).\nIn addition, codes can be qualified with words or\nphrases which provide further information concerning\nthe linguistic context in which the described item is\nlikely, and able, to occur; for example \\[Dl(to)\\] or \\[L(to\nbe)l\\]. Sets of codes, separated by semicolons, are\nassociated with individual word senses in the lexical\nentry for a particular item, as Figure 5 illustrates. These\nsets are elided and abbreviated in the code field associ-\nated with the word sense to save space. Partial codes\nsharing an initial letter can be separated by commas, for\nexample \\[T1,5a\\]. Word qualifiers relating to a complete\nsequence of codes can occur at the end of a code field,\ndelimited by a colon, for example \\[T1 ;I0: (DOWN)\\].\nCodes which are relevant o all the word senses in an\nentry often occur in a separate field after the head word\nand occasionally codes are elided from this field down\ninto code fields associated with each word sense as, for\nexample, in Figure 6. Decompacting and restructuring\ngrammar code entries into a format more suitable for\nfurther automated analysis can be done with knowledge\nof the syntax of the grammar code system and the\nsignificance of punctuation and font changes. However,\ndiscovering the syntax of the system is difficult since no\nexplicit description is available from Longman and the\ncode is geared more towards visual presentation than\nformal precision; for example, words which qualify\ncodes, such as &quot;to be&quot; in Figure 4, appear in italics and\ntherefore, will be preceded by the font control character\n*45. But sometimes the thin space control character *64\nalso appears; the insertion of this code is based solely\non visual criteria, rather than the informational struc-\nture of the dictionary. Similarly, choice of font can be\nvaried for reasons of appearance and occasionally in-\nfeel I ~ 1 \\[T1,6\\] to get the knowledge of by touching with the\nfingers: ... 2 \\[Wv6;T1\\] to experience (the touch or move-\nment of something): ... $ \\[LT\\] to experience (a condition\nof the mind or body); be consciously: ... 4 \\[L1\\] to seem to\noneself to be: ... 5 \\[T1,5;V3\\] to believe, esp. for the moment\n6 \\[LT\\] to give (a sensation): ... 7 \\[Wv6;I0\\] to (be able to)\nexperience sensations: ... 8 \\[Wv6;T1\\] to suffer because of\n(a state or event): ... 9 \\[L9 (after, \\]or)\\] to search with the\nfingers rather than with the eyes: ...\nFigure 5.\nsee off v oA. IT1\\] 1 \\[(at)\\] to go to the airport, station, etc.,\nwith (someone who is beginning a trip): saw h/s )'r/end oH\nat the bus #tat/on 2 to remain unharmed until (something or\nsomeone dangerous) has ceased to be active; WITHSTAND:\nThey maw off $ enemy attacks within $ daye\nFigure 6\nformation ormally associated with one field of an entry\nis shifted into another to create a more compact or\nelegant printed entry.\nIn addition to the 'noise' generated by the fact that\nwe are working with a typesetting tape geared to visual\npresentation, rather than a database, there are errors\nand inconsistencies in the use of the grammar code\nsystem. Examples of errors, illustrated in Figure 7,\ninclude the code for the noun promise which contains a\nmisplaced comma, that for the verb scream, in which a\ncolon delimiter occurs before the end of the field, and\nthat for the verb like where a grammatical label occurs\ninside a code field.\np,o , - i .e , ... X \\[C(of),C3.S;\nscream v ... 3 \\[T1,5; (OUT); I0\\]\nl i ke v ... 2 \\ [T3,4; ne9.\\]\n"},{"#tail":"\n","@confidence":"0.976646085714286","#text":"\nIn addition, inconsistencies occur in the application\nof the code system by different lexicographers. For\nexample, when codes containing &quot;to be&quot; are elided\nthey mostly occur as illustrated in Figure 4 above.\nHowever, sometimes this is represented as \\[L(to\nbe)l,9\\]. Presumably this kind of inconsistency arose\nbecause one member of the team of lexicographers\nrealised that this form of elision saved more space.\nThis type of error and inconsistency arises because\ngrammatical codes are constructed by hand and no\nautomatic hecking procedure is attempted (see Mi-\nchiels, 1982, for further comment). One approach to this\nproblem is that taken by the ASCOT project (Akkerman\net al, 1985; Akkerman, 1986). In this project, a new\nlexicon is being manually derived from LDOCE. The\ncoding system for the new lexicon is a slightly modified\nand simplified version of the LDOCE scheme, without\nany loss of generalisation a d expressive power. More\nimportantly, the assignment of codes for problematic or\nerroneously labelled words is being corrected in an\nattempt to make the resulting lexicon more appropriate\nfor automated analysis. In the medium term this ap-\nproach, though time consuming, will be of some utility\nfor producing more reliable lexicons for natural lan-\nguage processing.\n208 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987\nBran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing\nHowever, in the short term, the necessity to cope\nwith such errors provides much of the motivation for\nour interactive approach to lexicon development, since\nthis allows the restructuring programs to be progres-\nsively refined as these problems emerge. Any attempt at\nbatch processing without extensive initial testing of this\nkind would inevitably result in an incomplete and pos-\nsibly inaccurate l xicon.\n"},{"#tail":"\n","@confidence":"0.993450359375","#text":"\nOnce the grammar codes have been restructured, it still\nremains to be shown that the information they encode is\ngoing to be of some utility for natural language process-\ning. The grammar code system used in LDOCE is based\nquite closely on the descriptive grammatical framework\nof Quirk et al (1972, 1985). The codes are doubly\narticulated; capital letters represent he grammatical\nrelations which hold between a verb and its arguments\nand numbers represent subcategorisation frames which\na verb can appear in. Most of the subcategorisation\nframes are specified by syntactic ategory, but some are\nvery ill-specified; for instance, 9 is defined as &quot;needs a\ndescriptive word or phrase&quot;. In practice many adver-\nbial and predicative complements will satisfy this code,\nwhen attached to a verb; for example, put \\[xg\\] where\nthe code marks a locative adverbial prepositional phrase\nvs. make under sense 14 (hereafter written make(14)) is\ncoded IX9\\] where it marks a predicative noun phrase or\nprepositional phrase.\nThe criteria for assignment of capital etters to verbs\nis not made explicit, but is influenced by the syntactic\nand semantic relations which hold between the verb and\nits arguments; for example, I5, L5 and T5 can all be\nassigned to verbs which take a NP subject and a\nsentential complement, but L5 will only be assigned if\nthere is a fairly close semantic link between the two\narguments and T5 will be used in preference to I5 if the\nverb is felt to be semantically two place rather than one\nplace, such as know versus appear. On the other hand,\nboth believe and promise are assigned V3 which means\nthey take a NP object and infinitival complement, yet\nthere is a similar semantic distinction to be made\nbetween the two verbs; so the criteria for the assign-\nment of the V code seem to be purely syntactic.\nMichiels (1982) and Akkerman et al (1985) provide a\nmore detailed analysis of the information encoded by\nthe LDOCE grammar codes and discuss their efficacy as\na system of linguistic description. Ingria (1984) compre-\nhensively compares different approaches to comple-\nmentation within grammatical theory providing atouch-\nstone against which the LDOCE scheme can be\nevaluated.\nMost automated parsing systems employ grammars\nwhich carefully distinguish syntactic and semantic in-\nformation, therefore, if the information provided by the\nLongman grammar code system is to be of use, we need\nto be able to separate out this information and map it\ninto a representation scheme compatible with the type\nof lexicon used by such parsing systems.\nThe program which transforms the LDOCE grammar\ncodes into lexical entries utilisable by a parser takes as\ninput the decompacted codes and produces a relatively\ntheory neutral representation f the lexical entry for a\nparticular word, in the sense that this representation\ncould be further transformed into a format suitable for\nmost current parsing systems. For example, if the input\nwere the third sense of believe, as in Figure 4, the\nprogram would generate the (partial) entry shown in\nFigure 8 below. The four parts correspond to different\nsyntactic realisations of the third sense of the verb\nbelieve. Takes indicates the syntactic ategory of the\nsubject and complements required for a particular rea-\nlisation. Type indicates aspects of logical semantics\ndiscussed below.\n"},{"#tail":"\n","@confidence":"0.973685716049383","#text":"\nAt the time of writing, rules for producing adequate\nentries to drive a parsing system have only been devel-\noped for verb codes. In what follows we will describe\nthe overall transformation strategy and the particular\nrules we have developed for the verb codes. Extending\nthe system to handle nouns, adjectives and adverbs\nwould present no problems of principle. However, the\nLDOCE coding of verbs is more comprehensive than\nelsewhere, so verbs are the obvious place to start in an\nevaluation of the usefulness of the coding system. No\nattempt has been made to map any closed class entries\nfrom LDOCE, as a 3,000 word lexicon containing most\nclosed class items has been developed independently b\none of the groups collaborating with us to develop the\ngeneral purpose morphological nd syntactic analyser\n(see the Introduction and Russell et al, 1986).\nInitially the transformation f the LDOCE codes was\nperformed on a code-by-code basis, within a code field\nassociated with each individual word sense. This ap-\nproach is adequate if all that is required is an indication\nof the subcategorisation frames relevant o any partic-\nular sense. In the main, the code numbers determine a\nunique subcategorisation. Thus the entries can be used\nto select the appropriate VP rules from the grammar\n(assuming a GPSG-style approach to subcategorisation)\nComputational Linguistics, Volume 13, Numbers 3-4, July-December 1987 209\nBran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing\nand the relevant word senses of a verb in a particular\ngrammatical context can be determined. However, if\nthe parsing system is intended to produce a representa-\ntion of the predicate-argument structure for input sen-\ntences, then this simple approach is inadequate because\nthe individual codes only give partial indications of the\nsemantic nature of the relevant sense of the verb.\nThe solution we have adopted is to derive a semantic\nclassification of the particular sense of the verb under\nconsideration on the basis of the complete set of codes\nassigned to that sense. In any subcategorisation frame\nwhich involves a predicate complement there will be a\nnon-transparent relationship between the superficial\nsyntactic form and the underlying logical relations in the\nsentence. In these situations the parser can use the\nsemantic type of the verb to compute this relationship.\nExpanding on a suggestion of Michiels (1982), we\nclassify verbs as Subject Equi, Object Equi, Subject\nRaising or Object Raising for each sense which has a\npredicate complement code associated with it. These\nterms, which derive from Transformational Grammar,\nare used as convenient labels for what we regard as a\nsemantic distinction; the actual output of the program is\na specification of the mapping from superficial syntactic\nform to an underlying logical representation. For exam-\nple, labelling believe(3) (Type 20Raising) indicates that\nthis is a two place predicate and that, if believe(3)\noccurs with a syntactic direct object, as in\n(1) John believes the Earth to be round\nit will function as the logical subject of the predicate\ncomplement. Michiels proposed rules for doing this for\ninfinitive complement codes; however there seems to be\nno principled reason not to extend this approach to\ncomputing the underlying relations in other types of VP\nas well as in cases of NP, AP and PP predication (see\nWilliams (1980), for further discussion).\nThe five rules which are applied to the grammar\ncodes associated with a verb sense are ordered in a way\nwhich reflects the filtering of the verb sense through a\nseries of syntactic tests. Verb senses with an \\[it + 15\\]\ncode are classified as Subject Raising. Next, verb senses\nwhich contain a \\[V\\] or \\[X\\] code and one of \\[D5\\], \\[D5a\\],\n\\[D6\\] or \\[D6a\\] codes are classified as Object Equi. Then,\nverb senses which contain a \\[V\\] or \\[X\\] code and a IT5\\]\nor \\[T5a\\] code in the associated grammar code field, (but\nnone of the D codes mentioned above), are classified as\nObject Raising. Verb senses with a \\[V\\] or IX(to be)\\]\ncode, (but no IT5\\] or \\[T5a\\] codes), are classified as\nObject Equi. Finally, verb senses containing a \\[T2\\], \\[T3\\]\nor IT4\\] code, or an \\[I2\\], \\[13\\] or \\[14\\] code are classified as\nSubject Equi. Figure 9 gives examples of each type.\nThe Object Raising and Object Equi rules attempt o\nexploit the variation in transformational potential be-\ntween Raising and Equi verbs; thus, in the paradigm\n"},{"#tail":"\n","@confidence":"0.9851876","#text":"\nClearly, there are other syntactic and semantic tests\nfor this distinction, (see eg. Perlmutter and Soames,\n1979:472), but these are the only ones which are explicit\nin the LDOCE coding system.\nOnce the semantic type for a verb sense has been\ndetermined, the sequence of codes in the associated\ncode field is translated, as before, on a code-by-code\nbasis. However, when a predicate complement code is\nencountered, the semantic type is used to determine the\ntype assignment, asillustrated in Figures 4 and 8 above.\nWhere no predicate complement is involved, the letter\ncode is usually sufficient to determine the logical prop-\nerties of the verb involved. For example, T codes nearly\nalways translate into two-place predicates as Figure 10\nillustrates.\nIn some cases important syntactic information is\nconveyed by the word qualifiers associated with partic-\nular grammar codes and the translation system is there-\nfore sensitive to these correlations. For example, the\nSubject Raising rule above makes reference to the left\n"},{"#tail":"\n","@confidence":"0.980159222222222","#text":"\ncontext qualifier &quot; it&quot;. Another example where word\nqualifiers can be utilised straightforwardly is with di-\ntransitive verbs such as give and donate. Give is coded\nas \\[Dl(to)\\] which allows us to recover the information\nthat this verb permits dative movement and requires a\nprepositional phrase headed by &quot;to&quot;:\n(Takes NP NP ToPP) and (Takes NP NP NP).\nOn the other hand, donate is coded \\[T1 (to)\\], which\ntells us that it does not undergo dative movement but\ndoes require a prepositional phrase headed by &quot;to&quot;:\n(Takes NP NP ToPP).\nThere are many more distinctions which are con-\nveyed by the conjunction of grammar codes and word\nqualifiers (see Michiels, 1982, for further details). How-\never, exploiting this information to the full would be a\nnon-trivial task, because it would require accessing the\nrelevant knowledge about the words contained in the\nqualifier fields from their LDOCE entries.\n"},{"#tail":"\n","@confidence":"0.992351","#text":"\nThe output of the transformation program can be used\nto derive entries which are appropriate for particular\ngrammatical formalisms. To demonstrate hat this is\npossible we have implemented a system which con-\nstructs dictionary entries for the PATR-II system\n(Shieber, 1984 and references therein). PATR-II was\nchosen because it has been reimplemented in Cam-\nbridge and was therefore, available; however, the task\nwould be nearly identical if we were constructing en-\ntries for a system based on GPSG, FUG or LFG. We\n"},{"#tail":"\n","@confidence":"0.998874734693877","#text":"\nintend to use the LDOCE source in the same way to\nderive most of the lexicon for the general purpose,\nmorphological nd syntactic parser we are developing.\nThe latter employs a grammatical formalism based on\nGPSG; the comparatively theory neutral lexical entries\nthat we construct from LDOCE should translate\nstraightforwardly into this framework as well.\nThe PATR-II parsing system operates by unifying\ndirected graphs (DGs); the completed parse for a sen-\ntence will be the result of successively unifying the DGs\nassociated with the words and constituents of the sen-\ntence according to the rules of the grammar. The DG for\na lexical item is constructed from its lexical entry\nwhichcontains a set of templates for each syntactically\ndistinct variant. Templates are themselves abbrevia-\ntions for unifications which define the DG. For example,\nthe basic entry and associated DG for the verb storm are\nillustrated in Figure 11.\nThe template Dyadic defines the way in which the\nsyntactic arguments othe verb contribute to the logical\nstructure of the sentence, while the template TakesNP\ndefines what syntactic arguments storm requires; thus,\nthe information that storm is transitive and that it is\nlogically a two-place predicate is kept distinct. Conse-\nquently, the system can represent the fact that some\nverbs which take two syntactic arguments are neverthe-\nless one-place predicates.\nThe modified version of PATR-II that we have im-\nplemented contains only a small dictionary and con-\nstructs entries automatically from restructured LDOCE\nentries for most verbs that it encounters. As well as\ncarrying over the grammar codes, the PATR-II lexicon\nsystem has been modified to include word senses num-\nbers, which are derived from LDOCE. Thus, the anal-\nysis of a sentence by the PATR-II system now repre-\nsents its syntactic and logical structure and the\nparticular senses of the words (as defined in LDOCE)\nwhich are relevant in the grammatical context. Figures\n12 and 13 illustrate the dictionary entries for marry and\npersuade constructed by the system from LDOCE.\nIn Figure 14 we show one of the two analyses\nproduced by PATR-II for a sentence containing these\ntwo verbs. The other analysis is syntactically and\nlogically identical but incorporates sense two of marry.\nThus, the output from this version of PATR-II repre-\nsents the information that further semantic analysis\nneed only consider sense two of persuade and sense one\nand two of marry; this rules out one further sense of\neach, as defined in LDOCE.\n"},{"#tail":"\n","@confidence":"0.98901875","#text":"\nThe utility of the work reported above rests ultimately\non the accuracy of the lexical entries which can be\nderived from the LDOCE tape. We have not attempted\na systematic analysis of the entries which would result\nif the decompacting and grammar code transformation\nprograms were applied to the entire dictionary. In\nSection 3 we outlined some of the errors in the grammar\nComputational Linguistics, Volume 13, Numbers 3-4, July-December 1987 211\nBran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing\nmarry v 1 \\[T1; I0\\] to take (a person) in\nmarriage: He married late in lifs / never marrleK\nt (fig.) She marr/ed money (= a rich man) 2\nTI\\] (of a priest or official) to perform the\nceremony of marriage for (2 people): An o/d\nIt/end marr/ed them 3 IT1 (to)\\] to cause to take\nin marriage: She want8 to marry her dAzw~er to\n"},{"#tail":"\n","@confidence":"0.998609163265306","#text":"\ncodes which are problematic for the decompacting\nstage. However, mistakes or omissions in the assign-\nment of grammar codes represent a more serious prob-\nlem. While inconsistencies or errors in the application\nof the grammar coding system in some cases can be\nrectified by the gradual refinement of the decompacting\nprogram, it is not possible to correct errors of omission\nor assignment automatically. On the basis of unsyste-\nmatic evaluation, using the programs to dynamically\nproduce entries for the PATR-II parsing system, a\nnumber of errors of this type have emerged.\nFor example, the LDOCE definitions and associated\ncode fields in Figure 15, demonstrate hat upset(3) needs\nit + D5 which would correspond to its use with a noun\nphrase and a sentential complement; suppose(2) is miss-\ning optional &quot;to be&quot; for the X1 and X7 codes listed;\nhelp(l) needs a T3 code since it does not always require\na direct object as well as an infinitive complement; and\ndetest needs a V4 code because it can take a direct\nobject as well as a gerund complement.\nIt is difficult o quantify the extent of this problem on\nthe the basis of enumeration of examples of this type.\nTherefore, we have undertaken a limited test of both the\naccuracy of the assignment of the LDOCE codes in the\nsource dictionary and the reliability of the more ambi-\ntious (and potentially controversial) aspects of the\ngrammar code transformation rules. It is not clear, in\nparticular, that the rules for computing semantic types\nfor verbs are well enough motivated linguistically or\nthat the LDOCE lexicographers were sensitive nough\nto the different transformational potential of the various\nclasses of verbs to make a rule such as our one for\nObject Raising viable.\nWe tested the classification of verbs into semantic\ntypes using a verb list of 139 pre-classified items drawn\nfrom the lists published in Rosenbaum (1967) and Stock-\nwell et al (1973). Figure 16 gives the number of verbs\nclassified under each category by these authors and the\nnumber successfully classified into the same categories\nby the system.\nThe overall error rate of the system was 14%; how-\never, as the table illustrates, the rules discussed above\nclassify verbs into Subject Raising, Subject Equi and\npersuade v I \\[TI (of); D5\\] to cause to feel\ncertain; CONVINCE: She waa not persuaded\no,f the truth o.f hi~ ~ement = \\[Tl(into, out o~;\nV3\\] to cause to do something by reasoning,\narguing, begging, etc.: try to persuade him to\nlet .a go with him. l No~.~ wo.ld pers,zo~s him.\n"},{"#tail":"\n","@confidence":"0.910559114285714","#text":"\nparse> uther might persuade gwen to marry cornwall\n\\[cat: SENTENCE\nhead: \\[form: finite\nagr: \\[per: p3 num: sg\\]\naux: true\ntrana: \\[pred: possible\nsense-no: I\nargl: \\[pred: persuade\nsense-no: 2\nargl: \\[ref: uther sense-no: I\\]\narg2: \\[ref: gwen sense-no: I\\]\narg3: \\[pred: marry\nsense-no: 2\nargl: \\[ref: gwen sense-no: i\\]\narg2: \\[ref: cornwall\nsense-no : 1\\]\\]\\]\\]\\]\\]\nFigure 14\nObject Equi very successfully. The two Subject Raising\nverbs which were not so classified by the system were\ncome about and turn out. Come about is coded 15 in\nLDOCE, but is not given any word qualifier; turn out is\nnot given any 15 code. These are clear examples of\nomissions on the part of the Longman lexicographers,\nrather than of failure of the rule. Similarly, trust is not\nrecognised as an Object Equi verb, because its dictio-\nnary entry does not contain a V3 code; this must be an\nomission, given the grammaticality of\n(6) I trust h im to do the job .\nP re fer is misclassified as Object Raising, rather than\nas Object Equi, because the relevant code field contains\na T5 code, as well as a V3 code. The T5 code is marked\nas 'rare', and the occurrence of prefer with a tensed\nsentential complement, asopposed to with an infinitive,\nis certainly marginal:\nupset ... $ \\[T1\\] to cause to worry, not to be calm,\netc.: ........\nsuppose ... 2 \\[TSa,b; V3 often pasta.; X1,7,9\\] to be-\nlieve: I suppose that's true. \\] I supposed him to be a work-\nman, but he was in/act a thief. \\[ He was ~ommonly supposed\n(to be) looti, h ........\nhelp ... I \\[T1; I0; V3, (eep arn~ 2\\] to do part of the\nwork (for someone); be of use to (someone in doing\nsomething); AID, ASSIST: Could ~lou help me up (the\na~,o)~ I T~ a,'~ he~ps h~,. (to) ,~k, I Yo,,, o~u\nhelps a lot. I Can I help ( ,~ yo,,, wo~k)~ ........\ndetest ... \\[T1,4\\] to hate with very strong feeling: I\ndeter people who decelse and tell lies. I dn, . ~i\nshootir~ and k~lin? .........\n(7) I prefer that he come on Monday .\n(8) ?I pre fer that he marr ies Jul ie.\nThis example also highlights a deficiency in the\nLDOCE coding system since pre fer occurs much more\nnaturally with a sentential complement if it collocates\nwith a modal such as &quot;would&quot;. This deficiency is\nrectified in the verb classification system employed by\nJackendoff and Grimshaw (1985) in the Brandeis verb\ncatalogue.\nThe main source of error comes from the misclassi-\nfication of Object Raising into Object Equi verbs. Ar-\nguably, these errors also derive mostly from errors in\nthe dictionary, rather than a defect of the rule. 66% of\nthe Object Raising verbs were misclassified as Object\nEqui verbs, because the cooccurrence of the T5 and V\n(2, 3, or 4) codes in the same code fields, as predicted by\nthe Object Raising rule above, was not confirmed by\nLDOCE. All the 14 verbs misclassified contain V codes\nand 10 of these also contain T5 codes. However, the\nLongman lexicographers typically define two different\nword senses, one of which is marked (perhaps among\nother codes) T5 and the other with a V code. Analysis of\n"},{"#tail":"\n","@confidence":"0.922469316831684","#text":"\nComputational Linguistics, Volume 13, Numbers 3-4, July-December 1987 213\nBran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing\nacknowledge ... I \\[T1,4,5 (to) to agree\nto the t ruth of; recognise the fact or ex-\nistence (of): I o ,?~ie~e the h '~ of uoar\ntheU wer~ de/rated I They ~zowlcdCcd ha~/~?\nbeen d~y~t0d 2 \\[T1 (o); X (to be) 1,7\\] to\nreco~ise, accept, or admit (as): He w~\nacknowlod~d to be th~ b~ Ida~r. J He was\naeknowlod~d am their hinter. \\[ ~ admowl-\n~d th~rn~d~ (to be) d~y~atat ........\nhear ...e I \\[We6; T I ; V2,4; I0\\] to r~\nceive and understand (sounds) by using\nthe ears: I mn~ hear very wall. J I heard him\naa/t 8o. \\[ I can hear aomeone knock/nf 2 \\[Wv6;\nTl,Sa\\] to be told or informed: I heard\nthat he w~, dl ~ compare HEAR ABOUT,\nHEAR FROM, HEAR OF ........\nFigure 17\nthese word senses uggests that this approach is justi-\nfied in three cases, but unmotivated in five; for example,\nhear (1),(2) (justified) vs. acknowledge (1),(2) (unjus-\ntified) (see Figure 17). The other four cases we inter-\npreted as unmotivated were show, suspect , know, con-\nfess and in the case of consider(2), (Figure 18) there is a\nclear omission of a T5 code, as demonstrated by the\ngrammaticality of\n(9) I consider that it is a great honour to be here.\nSimilarly, expect is not given a V3 code under sense\n1 (Figure 19), however the grammaticality of\n(10) I expect him to pass the exam\nwith the relevant interpretation suggests that it should\nbe assigned a V3 code. Alternatively, sense 5, which is\nassigned a V3 code, seems uspiciously similar to sense\n1.\nThe four verbs which are misclassified as Object\nEqui and which do not have T5 codes anywhere in their\nentries are elect, love, represent and require. None of\nthese verbs take sentential complements and therefore\nthey appear to be counterexamples to our Object Rais-\ning rule. In addition, Moulin et al (1985) note that our\nObject Raising rule would assign mean to this category\nincorrectly. Mean is assigned both a V3 and a T5\ncategory in the code field associated with sense 2 (i.e.\n&quot;intend&quot;), however, when it is used in this sense it must\nbe treated as an Object Equi verb.\nThis small experiment demonstrates a number of\npoints. Firstly, it seems reasonable to conclude that the\nassignment of individual codes to verbs is on the whole\nrelatively accurate in LDOCE. Of the 139 verbs tested,\nwe only found code omissions in 10 cases. Secondly\nthough, when we consider the interaction between the\nassignments of codes and word sense classification,\nLDOCE appears less reliable. This is the primary\nsource of error in the case of the Object Raising rule.\nThirdly, it seems clear that the Object Raising rule is\nstraining the limits of what can be reliably extracted\nfrom the LDOCE coding system. Ideally, to distinguish\nbetween raising and equi verbs, a number of syntactic\ncriteria should be employed (Perlmutter and Soames,\n1979:460ff.). However, only two of these criteria are\nexplicit in the coding system.\nOn the basis of the results obtained, we explored the\npossibility of modifying the Object Raising rule to take\naccount of the cooccurrence ofT5 and T5a codes and V\nor X codes within a homograph, rather than within a\nword sense. An exhaustive search of the dictionary\nproduced 24 verbs coded in this fashion. Ten of these\nwere listed as Object Raising verbs in the published lists\nused in the above experiment. Five more verbs were\nclassified as Equi in the published lists. Of the remaining\nnine verbs which did not appear in the published lists,\nthree were clearly Object Raising, one was clearly Equi,\na further two were probably Object Raising, and the last\nthree were very difficult o classify. This demonstrates\nthat modifying the Object Raising rule in this fashion\nwould result in the misclassification f some Equi verbs.\nIn fact, the list is sufficiently small that this set of verbs\nis probably best coded by hand.\nAs a final test, we ran the rules for determining the\nsemantic type of verbs over all the 7,965 verb entries in\nLDOCE. There are 719 verb senses which are coded in\nthe dictionary as having the potential for predicate\ncomplementation. Of these 5 were classified as Subject\nRaising, 53 as Object Raising, 377 as Subject Equi, and\n326 as Object Equi by our rules. 42 of the Equi verbs are\nambiguous between Subject and Object Equi under the\nsame sense; in the transformation program this ambigu-\nity is resolved by selecting the type appropriate for each\nindividual code. For example, a code which translates\nconsider ... 2 \\[WvS, X (to be) 1,7; V3\\] to regard as; think\nof in a stated way: I ?on~der ~ a 1o0/(= I regard you as a\nfool). \\[ Icou'dor/t a~honour tobe~ ~UoutodoU. \\[He\ne.id ~ c o ~ me (to beJ ~o ~ to bB a ~ wor~. \\[ T~\n5~t l~ Ida~ are ~ l tV oo~dc~d a part o! Bootb~ .........\nexpect ... l \\ [T3,5a,b\\] to think (that something will hap-\npen): 1 ~ (t~t) heql p~s the ezra/nut/on. I He ~ to/d\nthe ~rdnat io~ \\[ &quot;Wdl she oome wonf&quot; &quot; /~p~ *o. ? ........ S\n\\[V3\\] to believe, hope and think (that someone will do some-\nthing): The o~?er ezl~cfcd h~ ram to do thdr duty in the ?om/ng\nba~/s .......\n"},{"#tail":"\n","@confidence":"0.998154210526316","#text":"\nof verbs together with the relevant LDOCE sense\nnumber are listed in the appendix. An exhaustive anal-\nysis of the 54 verbs classified as Object Raising revealed\ntwo further errors of inclusion in this set; order(6)\nshould be Object Equi and promise(l) should be Subject\nEqui. The 42 verbs which the transformation program\ntreats as ambiguous Equi verbs appear to be somewhat\nheterogeneous; some, such as want(1) and ask(2), are\ncases of 'Super-Equi' control verbs where the control\nrelations are determined contextually, whilst others,\nparticularly the phrasal verbs, appear to be better\nclassified as Object Raising. Allow(l) and permit(l)\nappear here incorrectly because they are coded \\[T4\\] to\ncapture xamples uch as\n(11) They do not al low/permit smoking in their house.\nIn this example the subject of the progressive comple-\nment is not controlled by the matrix subject. Again,\nsince the list is small, this set of verbs should probably\nbe coded by hand.\n"},{"#tail":"\n","@confidence":"0.999679080645161","#text":"\nMost applications for natural anguage processing sys-\ntems will require vocabularies substantially arger than\nthose typically developed for theoretical or demonstra-\ntion purposes and it is often not practical, and certainly\nnever desirable, to generate these by hand. The evalu-\nation of the LDOCE grammar coding system suggests\nthat it is sufficiently detailed and accurate (for verbs) to\nmake the on-line production of the syntactic omponent\nof lexical entries both viable and labour saving. How-\never, the success rate of the programs described above\nin producing useful exical entries for a parsing system\ndepends directly on the accuracy of the code assign-\nments in the source dictionary. Correcting the mistakes\nand omissions in these assignments would be a non-\ntrivial exercise. This is part of the motivation for\nadopting the interactive, rather than batch mode, ap-\nproach to using the tape for lexicon development. We\nenvisage ventually using the system to generate l xical\nentries in a semi-automatic fashion, allowing the user to\nintervene and correct errors during the actual process of\nconstructing lexical entries, so that gradually a reliable\nand relatively error-free large lexicon for automated\nnatural language processing systems containing detailed\ngrammatical information can be constructed from\nLDOCE.\nClearly, there is much more work to be done with\nLDOCE in the extension of the use of grammar codes\nand the improvement of the word sense classification\nsystem. Similarly, there is a considerable amount of\ninformation in LDOCE which we have not exploited\nsystematically as yet; for example, the box codes,\nwhich contain selection restrictions for verbs or the\nsubject codes, which classify word senses according to\nthe Merriam-Webster codes for subject matter (see\nWalker and Amsler (1983) for a suggested use for these).\nThe large amount of semi-formalised information con-\ncerning the interpretation of noun compounds and idi-\noms also represents a rich and potentially very useful\nsource of information for natural anguage processing\nsystems. In particular, we intend to investigate the\nautomatic generation of phrasal analysis rules from the\ninformation on idiomatic word usage.\nIn the longer term, it is clear that neither the contents\nnor form of any existing published ictionary meet al\nthe requirements of a natural anguage processing sys-\ntem. A substantial component of the research reported\nabove has been devoted to restructuring LDOCE to\nmake it more suitable for automatic analysis. However,\neven after this process much of the information in\nLDOCE remains difficult to access, essentially because\nit is aimed at a human reader, as opposed to a computer\nsystem. This suggests that the automatic construction of\ndictionaries from published sources intended for other\npurposes will have a limited life unless lexicography is\nheavily influenced by the requirements of automated\nnatural language analysis. In the longer term, therefore,\nthe automatic onstruction of dictionaries for natural\nlanguage processing systems may need to be based on\ntechniques for the automatic analysis of large corpora\n(eg. Leech et al, 1983). However, in the short term, the\napproach outlined in this paper will allow us to produce\na relatively sophisticated and useful dictionary rapidly.\n"},{"#tail":"\n","@confidence":"0.960172416666667","#text":"\nWe would like to thank the Longman Group Limited for\nkindly allowing us access to the LDOCE typesetting\ntape for research purposes. We also thank Steve Pul-\nman, Graham Russell and Karen Sparck Jones for their\ncomments on the first draft, which substantially im-\nproved this paper. Part of the research reported here\nwas funded by the UK Science and Engineering Re-\nsearch Council (Grant No. GR/D/05554) under the Al-\nvey Programme. This paper is a substantially revised\nand updated version of an earlier presentation at the\nSecond Conference of the European Chapter of the\nACL.\n"},{"#tail":"\n","@confidence":"0.846270472222222","#text":"\nfall to (1) finish (1) fix (2) fix on (1) flick (2)\nforbear (1) forbid (2) forget (1) forget about (1) forswear (I)\nfrown on (1) funk (1) get (3,11) get around to (1) get away with (1)\nget down to (1) get out of (1) get round to (1) give up (1) go (5)\ngo about (2) go in for (2) go on (5) go with (3) go without (1)\ngrow (5) grow out of (2) grow out of (3) grudge (1) guarantee (2)\nguard against (1) happen (2) hasten (2) hate (3) hesitate (1)\nhinge on (1) hit on (1) hope (1) incline (4) include (1)\nindulge in (1) inveigh against (1) involve (2) itch (3) jib at (1)\njustify (1) keep (11) keep from (2) keep on at (1) kick against (1)\nknock off (2) know about (1) lament (1) lead to (1) learn (1)\nleave (7) like (2) live by (1) loathe (1) long (1)\nlook forward to (1) make (18) make up for (1) manage (2) mean (5)\nmerit (1) militate magainst (1) miss (1,2,5) necessitate (1) need (1)\nneglect (1) neglect (2) negotiate (1) offer (3) omit (2)\noperate (2) own to (1) pant (4) pay for (1) pertain to (1)\npetition (2) pine (3) plan (1) play (3) play at (1)\nplay at (2) pledge (1) plot (5) plump for (1) pooh-pooh (1)\npostpone (1) practise (4) practise (5) prate about (1) pray (1)\npreclude (1) prepare (3) prepare for (1) presume (4) pretend (1)\npretend (2) pretend (4) proceed (1) profess (2) profit by (1)\nprohibit (1) promise (3) propose (1) propose (2) provide for (2)\nprovide for (3) purport (1) purpose (1) put off (1) quit (1)\nrecall (1) reckon on (2) recollect (1) refuse (1) regret (1)\nrejoice (1) relish (1) remember (2) repent (1) require (1)\nresent (1) resist (1) resist (2) resolve (1) resolve (2)\nresort to (1) result from (1) resume (1) revel in (1) revert to (1)\nrise above (1) risk (2) rue (1) say (5) scheme (1)\nscorn (1) scramble (2) scream (4) scruple (1) seek (3)\nseem (1) see (7) see about (1) see to (1) send (4)\nsend away (2) send off (3) serve (5) set about (1) set out (2)\nshirk (1) should (1) shrink from (1) shudder (1) shun (1)\nsicken of (1) smile (2) stand (8) stand (12) stand for (2)\nstart (1) stem from (1) stick (8) stoop (3) stoop to (1)\nstop (1) strive (1) subscribe to (1) suggest (2) swear (1)\nswear by (1) swear off (1) swear to (1) take to (2) take up (1)\n"},{"#tail":"\n","@confidence":"0.921008058823529","#text":"\nplume upon (1) pray (3) preclude from (1) predestinate (1) predestine (1)\npredetermine (1,3) predispose (1) preen on (1) prepare (1) prepare (5)\nprepare for (3) press (9) pressure (I) pressurize (1) prevail upon (1)\nprevent (1) prevent from (1) pride on (1) profess (3) program (1)\nprogramme (1) promise (1) prompt (i) prove (3) provoke (2)\nprovoke into (1) push (3) push on (2) put down as (1) put down to (1)\nput off (1) put up to (1) reckon (1) reckon on (1) reduce to (4)\nreeducate (1) regard as (1) rely on (2) remember as (1) remind (1)\nrepresent (1.2) represent as (1) request (1) require (2) result in (1)\nschedule (1) school (1) seduce (2) select (1) send (1)\nsend (2) send (3) set (4) set (8) shape (1)\nshow (1) show (9) signal (2) sign (2) slate (2)\nspur (2) spy (3) steel (I) stop (2) suffer (4)\nsummons (1) summon (I) supplicate (I) suppose (3) suspect (2)\ntake (18) talk into (1) talk out of (1) tax with (1) teach (1)\ntelegraph (1) telephone (1) telex (I) tell (2) tell (3)\ntell (5) tell off (2) tempt (1) tempt (2) thank (2)\n"}],"#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.719113","#text":"\nUniversity of Cambridge Computer Laboratory\nCorn Exchange Street\n"},{"#tail":"\n","@confidence":"0.997715","#text":"\nDepartment of Linguistics, University of Lancaster\n"}],"sectionHeader":[{"#tail":"\n","@confidence":"0.9965575","@genericHeader":"abstract","#text":"\nLARGE LEXICONS FOR NATURAL LANGUAGE PROCESSING:\nUTILISING THE GRAMMAR CODING SYSTEM OF LDOCE\n"},{"#tail":"\n","@confidence":"0.999412","@genericHeader":"introduction","#text":"\n1 INTRODUCTION\n"},{"#tail":"\n","@confidence":"0.985379","@genericHeader":"method","#text":"\n2 TIlE ACCESS ENVIRONMENT\n"},{"#tail":"\n","@confidence":"0.99963","@genericHeader":"method","#text":"\n3 THE FORMAT OF THE GRAMMAR CODES\n"},{"#tail":"\n","@confidence":"0.999416","@genericHeader":"method","#text":"\n4 THE CONTENT OF THE GRAMMAR CODES\n"},{"#tail":"\n","@confidence":"0.996868","@genericHeader":"method","#text":"\n5 LEXICAL ENTRIES FOR PATR-II\n"},{"#tail":"\n","@confidence":"0.99863","@genericHeader":"evaluation","#text":"\n6 EVALUATION\n"},{"#tail":"\n","@confidence":"0.999437","@genericHeader":"conclusions","#text":"\n7 CONCLUSION\n"},{"#tail":"\n","@confidence":"0.999766","@genericHeader":"acknowledgments","#text":"\n8 ACKNOWLEDGEMENTS\n"},{"#tail":"\n","@confidence":"0.992461","@genericHeader":"references","#text":"\nREFERENCES\n"}],"page":{"#tail":"\n","@confidence":"0.916851","#text":"\n31\n"},"figureCaption":[{"#tail":"\n","@confidence":"0.471714","#text":"\nFigure 1\n"},{"#tail":"\n","@confidence":"0.64345","#text":"\nFigure 2\n"},{"#tail":"\n","@confidence":"0.727791","#text":"\nFigure 3\n"},{"#tail":"\n","@confidence":"0.966049","#text":"\nFigure 7\n"},{"#tail":"\n","@confidence":"0.878996","#text":"\nFigure 9\n"},{"#tail":"\n","@confidence":"0.943265","#text":"\nFigure 15 Figure 16\n"}],"table":[{"#tail":"\n","@confidence":"0.951986142857143","#text":"\n((Takes NP SBar) (Type 2))\n((Takes NP NP Inf) (Type 2 Ogaisin8))\n(or ((Takes NP NP NP) (Type 2 Ogaisin8))\n((Takes NP NP AuxInf) (Type 2 ORaising)))\n(or ((Takes NP NP AP) (Type 20Raising))\n((Takes NP NP AuxInf) (Type 20Raislng)))\nFigure 8\n"},{"#tail":"\n","@confidence":"0.876042090909091","#text":"\nhate 2 e ... 1 \\[T1,3,4; V3,4\\] to have a great dislike of\n(hate\n((Sense 1)\n((Takes NP NP) (Type 2))\n((Takes NP Inf) (Type 2 SEqui))\n((Takes NP Ing) (Type 2 SEqui))\n((Takes NP NP Inf) (Type 30Equi))\n((Takes NP NP Ing) (Type 30Equi))\nFigure 10\n210 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987\nBran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing\n"},{"#tail":"\n","@confidence":"0.9029364","#text":"\nword storm:\nw Jense ~ <head t rans sense-no> = 1\nV TakesNP Dyadic\nworddag storm:\n\\ [cat: v\n"},{"#tail":"\n","@confidence":"0.739241481481481","#text":"\n. . . . . . . .\n(persuade\n( (Sense 1)\n((Takes NP NP) (Type 2))\n((Takes NP NP SBar)\n(Type 3)))\n( (Sense 2)\n((Takes NP NP) (Type 2))\n((Takes NP NP Inf)\n(Type 3 0bjectEqui))))\nword persuade:\nw_sense =~\n<head t rans sense-no> = I\nV TakesNP Dyadic\nw_sense =~\n<head t rans sense-no> = I\nV TakeeNPSBar Tr iadic\nw_sense =~\n<head t rane sense-no> = 2\nV TakesNP Dyadic\nw_sense\n<head trans sense-no> = 2\nV TakesNPInf\nObjectControl Triadic\nFigure 13\n212 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987\nBran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing\n"},{"#tail":"\n","@confidence":"0.9218684","#text":"\nFigure 18 Figure 19\n214 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987\nBran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing\nas (Takes NP Inf) would select Subject Equi, while\n(Takes NP NP Inf) would select Object Equi. These sets\n"}],"email":{"#tail":"\n","@confidence":"0.405339","#text":"\nand\n"}}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.138874","#tail":"\n","@no":"0","address":[{"#tail":"\n","@confidence":"0.999837","#text":"Cambridge, CB2 3QG, England"},{"#tail":"\n","@confidence":"0.99934","#text":"Bailrigg, Lancaster LA1 4YT, England"}],"#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.8273065","#text":"University of Cambridge Computer Laboratory Corn Exchange Street"},{"#tail":"\n","@confidence":"0.999988","#text":"Department of Linguistics, University of Lancaster"}],"author":[{"#tail":"\n","@confidence":"0.999868","#text":"Bran Boguraev"},{"#tail":"\n","@confidence":"0.7167235","#text":"Ted Briscoe"}],"abstract":{"#tail":"\n","@confidence":"0.890726625","#text":"This article focusses on the derivation of large lexicons for natural language processing. We describe the development of a dictionary support environment linking a restructured version of the Longman Dictionary of Contemporary English to natural language processing systems. The process of restructuring the information in the machine readable version of the dictionary is discussed. The Longman grammar code system is used to construct 'theory neutral' lexical entries. We demonstrate how such lexical entries can be put to practical use by linking up the system described here with the experimental PATR-II grammar development environment. Finally, we offer an evaluation of the utility of the grammar coding system for use by automatic natural language parsing systems."},"title":{"#tail":"\n","@confidence":"0.9986905","#text":"LARGE LEXICONS FOR NATURAL LANGUAGE PROCESSING: UTILISING THE GRAMMAR CODING SYSTEM OF LDOCE"}}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"1985"},"rawString":{"#tail":"\n","#text":"Akkerman, Erik; Masereeuw, Pieter; and Meijs, Willem. 1985 Designing a Computerised Lexicon for Linguistic Purposes. ASCOT Report No. l, CIP-Gegevens Koninklijke Bibliotheek, Den Haag, Netherlands."},"#text":"\n","marker":{"#tail":"\n","#text":"Akkerman, Masereeuw, Meijs, 1985"},"location":{"#tail":"\n","#text":"Den Haag, Netherlands."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" system by different lexicographers. For example, when codes containing &quot;to be&quot; are elided they mostly occur as illustrated in Figure 4 above. However, sometimes this is represented as \\[L(to be)l,9\\]. Presumably this kind of inconsistency arose because one member of the team of lexicographers realised that this form of elision saved more space. This type of error and inconsistency arises because grammatical codes are constructed by hand and no automatic hecking procedure is attempted (see Mi- chiels, 1982, for further comment). One approach to this problem is that taken by the ASCOT project (Akkerman et al, 1985; Akkerman, 1986). In this project, a new lexicon is being manually derived from LDOCE. The coding system for the new lexicon is a slightly modified and simplified version of the LDOCE scheme, without any loss of generalisation a d expressive power. More importantly, the assignment of codes for problematic or erroneously labelled words is being corrected in an attempt to make the resulting lexicon more appropriate for automated analysis. In the medium term this ap- proach, though time consuming, will be of some utility for producing more reliable lexicons for natural lan- guage processing. 208","@endWordPosition":"4910","@position":"30804","annotationId":"T1","@startWordPosition":"4907","@citStr":"Akkerman et al, 1985"},{"#tail":"\n","#text":"d to verbs which take a NP subject and a sentential complement, but L5 will only be assigned if there is a fairly close semantic link between the two arguments and T5 will be used in preference to I5 if the verb is felt to be semantically two place rather than one place, such as know versus appear. On the other hand, both believe and promise are assigned V3 which means they take a NP object and infinitival complement, yet there is a similar semantic distinction to be made between the two verbs; so the criteria for the assign- ment of the V code seem to be purely syntactic. Michiels (1982) and Akkerman et al (1985) provide a more detailed analysis of the information encoded by the LDOCE grammar codes and discuss their efficacy as a system of linguistic description. Ingria (1984) compre- hensively compares different approaches to comple- mentation within grammatical theory providing atouch- stone against which the LDOCE scheme can be evaluated. Most automated parsing systems employ grammars which carefully distinguish syntactic and semantic in- formation, therefore, if the information provided by the Longman grammar code system is to be of use, we need to be able to separate out this information and map ","@endWordPosition":"5409","@position":"33854","annotationId":"T2","@startWordPosition":"5406","@citStr":"Akkerman et al (1985)"}]},"title":{"#tail":"\n","#text":"Designing a Computerised Lexicon for Linguistic Purposes. ASCOT Report No. l, CIP-Gegevens Koninklijke Bibliotheek,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Erik Akkerman"},{"#tail":"\n","#text":"Pieter Masereeuw"},{"#tail":"\n","#text":"Willem Meijs"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1986"},"rawString":{"#tail":"\n","#text":"Akkerman, Erik. 1986 A Critical Assessment of the LDOCE Coding System. To appear in: Akkerman, E.; Masereew, P.; and Meijs, W., Eds., ASCOT Report No 2, CIP-Gegevens Koninklijke Bibliotheek, The Hague, Netherlands."},"#text":"\n","marker":{"#tail":"\n","#text":"Akkerman, 1986"},"location":{"#tail":"\n","#text":"Netherlands."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"exicographers. For example, when codes containing &quot;to be&quot; are elided they mostly occur as illustrated in Figure 4 above. However, sometimes this is represented as \\[L(to be)l,9\\]. Presumably this kind of inconsistency arose because one member of the team of lexicographers realised that this form of elision saved more space. This type of error and inconsistency arises because grammatical codes are constructed by hand and no automatic hecking procedure is attempted (see Mi- chiels, 1982, for further comment). One approach to this problem is that taken by the ASCOT project (Akkerman et al, 1985; Akkerman, 1986). In this project, a new lexicon is being manually derived from LDOCE. The coding system for the new lexicon is a slightly modified and simplified version of the LDOCE scheme, without any loss of generalisation a d expressive power. More importantly, the assignment of codes for problematic or erroneously labelled words is being corrected in an attempt to make the resulting lexicon more appropriate for automated analysis. In the medium term this ap- proach, though time consuming, will be of some utility for producing more reliable lexicons for natural lan- guage processing. 208 Computational Li","@endWordPosition":"4912","@position":"30821","annotationId":"T3","@startWordPosition":"4911","@citStr":"Akkerman, 1986"}},"title":{"#tail":"\n","#text":"A Critical Assessment of the LDOCE Coding System. To appear in:"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Erik Akkerman"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1985"},"rawString":{"#tail":"\n","#text":"Alshawi, Hiyan; Boguraev, Branimir; and Briscoe, Ted. 1985 Towards aLexicon Support Environment for Real Time Parsing. In Proceedings ofthe Second Conference ofthe European Chapter of the Association for Computational Linguistics, Geneva, Switzerland: 171-178."},"#text":"\n","pages":{"#tail":"\n","#text":"171--178"},"marker":{"#tail":"\n","#text":"Alshawi, Boguraev, Briscoe, 1985"},"location":{"#tail":"\n","#text":"Geneva, Switzerland:"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"y appropriate for use as the core knowledge base of a natural anguage processing sys- tem. Most prominent among these are the rich gram- matical subcategorisations of the 60,000 entries, the large amount of information concerning phrasal verbs, noun compounds and idioms, the individual subject, collocational nd semantic odes for the entries and the consistent use of a controlled 'core' vocabulary in defining the words throughout the dictionary. (Michiels (1982) contains further description and discussion of LDOCE.) In this paper we focus on the exploitation of the LDOCE grammar coding system; Alshawi et al (1985) and Alshawi (1987) describe further esearch in Cambridge utilising different types of information avail- able in LDOCE. The information available in the dictionary is both very rich and diverse, but also typically only semi- formalised, as it is intended for human, rather than machine, interpetation. As a consequence the programs we are developing, both to restructure and to exploit this information, need to undergo constant revision as they are being used. The system we describe is not intended for off-line use, where one might attempt to derive, completely automatically, a lexicon for natur","@endWordPosition":"854","@position":"5802","annotationId":"T4","@startWordPosition":"851","@citStr":"Alshawi et al (1985)"}},"title":{"#tail":"\n","#text":"Towards aLexicon Support Environment for Real Time Parsing."},"booktitle":{"#tail":"\n","#text":"In Proceedings ofthe Second Conference ofthe European Chapter of the Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Hiyan Alshawi"},{"#tail":"\n","#text":"Branimir Boguraev"},{"#tail":"\n","#text":"Ted Briscoe"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1987"},"rawString":{"#tail":"\n","#text":"Alshawi, Hiyan. 1987 Processing Dictionary Definitions with Phrasal Pattern Hierarchies. In this issue."},"#text":"\n","marker":{"#tail":"\n","#text":"Alshawi, 1987"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"the core knowledge base of a natural anguage processing sys- tem. Most prominent among these are the rich gram- matical subcategorisations of the 60,000 entries, the large amount of information concerning phrasal verbs, noun compounds and idioms, the individual subject, collocational nd semantic odes for the entries and the consistent use of a controlled 'core' vocabulary in defining the words throughout the dictionary. (Michiels (1982) contains further description and discussion of LDOCE.) In this paper we focus on the exploitation of the LDOCE grammar coding system; Alshawi et al (1985) and Alshawi (1987) describe further esearch in Cambridge utilising different types of information avail- able in LDOCE. The information available in the dictionary is both very rich and diverse, but also typically only semi- formalised, as it is intended for human, rather than machine, interpetation. As a consequence the programs we are developing, both to restructure and to exploit this information, need to undergo constant revision as they are being used. The system we describe is not intended for off-line use, where one might attempt to derive, completely automatically, a lexicon for natural language analysi","@endWordPosition":"857","@position":"5821","annotationId":"T5","@startWordPosition":"856","@citStr":"Alshawi (1987)"},{"#tail":"\n","#text":"ss file, paired together with an indexing file from which the disc addresses of dictionary entries for words and compounds can be computed. A series of systems in Cambridge are implemented in Lisp running under Unix TM. They all make use of an efficient dictionary access system which services re- quests for s-expression entries made by client pro- grams. A dictionary access process is fired off, which dynamically constructs a search tree and navigates through it from a given homograph directly to the offset in the lispified file from where all the associated infor- mation can be retrieved. As Alshawi (1987) points out, given that no situations were envisaged where the information from the tape would be altered once in- stalled in secondary storage, this simple and conven- Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 205 Bran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing tional access trategy is perfectly adequate. The use of such standard atabase indexing techniques makes it possible for an active dictionary process to be very undemanding with respect o main memory utilisation. For reasons of efficiency and flexibility of customisa- tion, namely","@endWordPosition":"2288","@position":"14886","annotationId":"T6","@startWordPosition":"2287","@citStr":"Alshawi (1987)"}]},"title":{"#tail":"\n","#text":"Processing Dictionary Definitions with Phrasal Pattern Hierarchies. In this issue."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Hiyan Alshawi"}}},{"date":{"#tail":"\n","#text":"1986"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ehensive grammars (eg. Robinson, 1982; Bobrow, 1978) consult relatively small lexicons, typi- cally generated by hand. Two exceptions to this gener- alisation are the Linguistic String Project (Sager, 1981) and the IBM CRITIQUE (formerly EPISTLE) Project (Heidorn et al, 1982; Byrd, 1983); the former employs a dictionary of approximately 10,000 words, most of which are specialist medical terms, the latter has well over 100,000 entries, gathered from machine readable sources. In addition, there are a number of projects under way to develop substantial lexicons from machine readable sources (see Boguraev, 1986 for details). How- ever, as yet few results have been published concerning the utility of electronic versions of published ictionar- ies as sources for such lexicons. In this paper we provide an evaluation of the LDOCE grammar code system from this perspective. We chose to employ LDOCE as the machine read- able source to aid the development of a substantial lexicon because this dictionary has several properties which make it uniquely appropriate for use as the core knowledge base of a natural anguage processing sys- tem. Most prominent among these are the rich gram- matical subcategorisations","@endWordPosition":"689","@position":"4745","annotationId":"T7","@startWordPosition":"688","@citStr":"Boguraev, 1986"}},"title":{"#tail":"\n","#text":"(and forthcoming) Machine Readable Dictionaries and Research inComputational Linguistics. InProceedings of a Workshop on Automating the Lexicon, Grosseto, Italy (to Computational Linguistics, Volume 13, Numbers 3-4,"},"#tail":"\n","institution":{"#tail":"\n","#text":"Bran Boguraev and Ted Briscoe"},"rawString":{"#tail":"\n","#text":"Boguraev, Branimir. 1986 (and forthcoming) Machine Readable Dictionaries and Research inComputational Linguistics. InProceedings of a Workshop on Automating the Lexicon, Grosseto, Italy (to Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 215 Bran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing be published as Walker,D. and Zampolli,A., Eds., Automating the Lexicon in a Multilingual Environment, Cambridge University Press, Cambridge, UK)."},"#text":"\n","pages":{"#tail":"\n","#text":"215"},"marker":{"#tail":"\n","#text":"Boguraev, 1986"},"publisher":{"#tail":"\n","#text":"Cambridge University Press,"},"location":{"#tail":"\n","#text":"Cambridge, UK)."},"@valid":"false","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Branimir Boguraev"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1987"},"note":{"#tail":"\n","#text":"to be published as"},"rawString":{"#tail":"\n","#text":"Boguraev, Branimir. 1987 A Natural Language Toolkit: Reconciling Theory with Practice. In Proceedings of a Workshop on Word Order and Parsing in Unification Grammars, Friedenweiler, Germany (to be published as Reyle,U. and Rohrer,C., Eds., &quot;Word Orders, Parsing, and Unification Grammars&quot; D. Reidel, Dordrecht, Holland)."},"#text":"\n","marker":{"#tail":"\n","#text":"Boguraev, 1987"},"location":{"#tail":"\n","#text":"Friedenweiler, Germany"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ts of natural anguage. These developments also emphasise that if natural anguage processing systems are to be able to handle the grammatical nd semantic idiosyncracies of individual lexical items elegantly and efficiently, then the lexicon must be a central compo- nent of the parsing system. Real-time parsing imposes stringent requirements on a dictionary support environ- ment; at the very least it must allow frequent and rapid access to the information in the dictionary via the dictionary head words. The research described below is taking place in the context of three collaborative projects (Boguraev, 1987; Russell et al, 1986; Phillips and Thompson, 1986) to develop a general-purpose, wide coverage morphological nd syntactic analyser for English. One motivation for our interest in machine readable dictionaries i to attempt to provide a substan- tial lexicon with lexical entries containing rammatical information compatible with the grammatical frame- work employed by the analyser. The idea of using the machine readable source of a published ictionary has occurred to a wide range of researchers, for spelling correction, lexical analysis, thesaurus construction, and machine translation, to name b","@endWordPosition":"381","@position":"2608","annotationId":"T8","@startWordPosition":"380","@citStr":"Boguraev, 1987"}},"title":{"#tail":"\n","#text":"A Natural Language Toolkit: Reconciling Theory with Practice."},"booktitle":{"#tail":"\n","#text":"In Proceedings of a Workshop on Word Order and Parsing in Unification Grammars,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Branimir Boguraev"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1987"},"rawString":{"#tail":"\n","#text":"Boguraev, Branimir; Carter, David and Briscoe, Ted. 1987 A MultiPurpose Interface to an On-line Dictionary. In Proceedings of the Third Conference of the European Chapter of the Association for Computational Linguistics, Copenhagen, Denmark: 63-69."},"#text":"\n","pages":{"#tail":"\n","#text":"63--69"},"marker":{"#tail":"\n","#text":"Boguraev, Carter, Briscoe, 1987"},"location":{"#tail":"\n","#text":"Copenhagen, Denmark:"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"which allows access into the dictionary via different routes. In addition to headwords, dictionary search through the pronuncia- tion field is available; Carter (1987) has merged infor- mation from the pronunciation and hyphenation fields, creating an enhanced phonological representation which allows access to entries by broad phonetic lass and syllable structure (Huttenlocher and Zue, 1983). In addition, a fully flexible access system allows the re- trieval of dictionary entries on the basis of constraints specifying any combination ofphonetic, lexical, syntac- tic, and semantic information (Boguraev et al, 1987). Independently, random selection of dictionary entries is also provided to allow the testing of software on an unbiased sample. 3 THE FORMAT OF THE GRAMMAR CODES The lispified LDOCE file retains the broad structure of the typesetting tape and divides each entry into a number of fields - - head word, pronunciation, grammar codes, definitions, examples, and so forth. However, each of these fields requires further decoding and re- structuring to provide client programs with easy access to the information they require (see Calzolari (1984) for further discussion). For this purpose the formatting ","@endWordPosition":"2992","@position":"19374","annotationId":"T9","@startWordPosition":"2989","@citStr":"Boguraev et al, 1987"}},"title":{"#tail":"\n","#text":"A MultiPurpose Interface to an On-line Dictionary."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Third Conference of the European Chapter of the Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Branimir Boguraev"},{"#tail":"\n","#text":"David Carter"},{"#tail":"\n","#text":"Ted Briscoe"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1983"},"rawString":{"#tail":"\n","#text":"Byrd, Roy. 1983 Word Formation in Natural Language Processing Systems. In Proceedings of the Eighth International Joint Conference on Artificial Intelligence, Karlsrnhe, Germany: 704-706."},"#text":"\n","pages":{"#tail":"\n","#text":"704--706"},"marker":{"#tail":"\n","#text":"Byrd, 1983"},"location":{"#tail":"\n","#text":"Karlsrnhe, Germany:"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"omputational Linguistics, Volume 13, Numbers 3-4, July-December 1987 203 Bran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing on developing dictionary servers for office automation systems (Kay, 1984b). Few established parsing systems have substantial lexicons and even those which employ very comprehensive grammars (eg. Robinson, 1982; Bobrow, 1978) consult relatively small lexicons, typi- cally generated by hand. Two exceptions to this gener- alisation are the Linguistic String Project (Sager, 1981) and the IBM CRITIQUE (formerly EPISTLE) Project (Heidorn et al, 1982; Byrd, 1983); the former employs a dictionary of approximately 10,000 words, most of which are specialist medical terms, the latter has well over 100,000 entries, gathered from machine readable sources. In addition, there are a number of projects under way to develop substantial lexicons from machine readable sources (see Boguraev, 1986 for details). How- ever, as yet few results have been published concerning the utility of electronic versions of published ictionar- ies as sources for such lexicons. In this paper we provide an evaluation of the LDOCE grammar code system from this perspective. We chose to","@endWordPosition":"640","@position":"4419","annotationId":"T10","@startWordPosition":"639","@citStr":"Byrd, 1983"}},"title":{"#tail":"\n","#text":"Word Formation in Natural Language Processing Systems."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Eighth International Joint Conference on Artificial Intelligence,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Roy Byrd"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1984"},"rawString":{"#tail":"\n","#text":"Calzolari, Nicoletta. 1984 Machine-Readable Dictionaries, Lexical Data Bases and the Lexical System. In Proceedings of the lOth International Congress on Computational Linguistics, Stanford, California: 460-461."},"#text":"\n","pages":{"#tail":"\n","#text":"460--461"},"marker":{"#tail":"\n","#text":"Calzolari, 1984"},"location":{"#tail":"\n","#text":"Stanford, California:"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"tic, lexical, syntac- tic, and semantic information (Boguraev et al, 1987). Independently, random selection of dictionary entries is also provided to allow the testing of software on an unbiased sample. 3 THE FORMAT OF THE GRAMMAR CODES The lispified LDOCE file retains the broad structure of the typesetting tape and divides each entry into a number of fields - - head word, pronunciation, grammar codes, definitions, examples, and so forth. However, each of these fields requires further decoding and re- structuring to provide client programs with easy access to the information they require (see Calzolari (1984) for further discussion). For this purpose the formatting codes on the typesetting tape are crucial since they provide clues to the correct structure of this informa- tion. For example, word senses are largely defined in terms of the 2000 word core vocabulary, however, in some cases other words (themselves defined elsewhere in terms of this vocabulary) are used. These words always appear in small capitals and can therefore be recognised because they will be preceded by a font change control character. In Figure 1 above the defini- tion of rivet as verb includes the noun definition of &quot;RIVET 1'","@endWordPosition":"3077","@position":"19916","annotationId":"T11","@startWordPosition":"3076","@citStr":"Calzolari (1984)"}},"title":{"#tail":"\n","#text":"Machine-Readable Dictionaries, Lexical Data Bases and the Lexical System."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the lOth International Congress on Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Nicoletta Calzolari"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1987"},"rawString":{"#tail":"\n","#text":"Carter, David. 1987 An Information Theoretic Analysis of Phonetic Dictionary Access, Computer Speech and Language, 2:1-11."},"#text":"\n","pages":{"#tail":"\n","#text":"2--1"},"marker":{"#tail":"\n","#text":"Carter, 1987"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"bsequent positions in the dictionary) related to blow. While no application currently makes use of this facil- ity, the motivation for such an approach to dictionary access comes from envisaging a parser which will operate on the basis of the on-line LDOCE; and any serious parser must be able to recognise compounds before it segments its input into separate words. From the master LDOCE file, we have computed alternative indexing information, which allows access into the dictionary via different routes. In addition to headwords, dictionary search through the pronuncia- tion field is available; Carter (1987) has merged infor- mation from the pronunciation and hyphenation fields, creating an enhanced phonological representation which allows access to entries by broad phonetic lass and syllable structure (Huttenlocher and Zue, 1983). In addition, a fully flexible access system allows the re- trieval of dictionary entries on the basis of constraints specifying any combination ofphonetic, lexical, syntac- tic, and semantic information (Boguraev et al, 1987). Independently, random selection of dictionary entries is also provided to allow the testing of software on an unbiased sample. 3 THE FORMAT OF T","@endWordPosition":"2928","@position":"18920","annotationId":"T12","@startWordPosition":"2927","@citStr":"Carter (1987)"}},"title":{"#tail":"\n","#text":"An Information Theoretic Analysis of Phonetic Dictionary Access, Computer Speech and Language,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"David Carter"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1985"},"rawString":{"#tail":"\n","#text":"Gazdar, Gerald; Klein, Ewan; Pullum, Geoffrey; and Sag, Ivan. 1985 Generalized Phrase Structure Grammar. Blackwell, Oxford, UK."},"#text":"\n","marker":{"#tail":"\n","#text":"Gazdar, Klein, Pullum, Sag, 1985"},"location":{"#tail":"\n","#text":"Blackwell, Oxford, UK."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"l language parsing systems. 1 INTRODUCTION The grammar coding system employed by the Longman Dictionary of Contemporary English (henceforth LDOCE) is the most comprehensive description of grammatical properties of words to be found in any published dictionary available in machine readable form. This paper describes the extraction of this, and other, information from LDOCE and discusses the utility of the coding system for automated natural language processing. Recent developments in linguistics, and especially on grammatical theory - - for example, Generalised Phrase Structure Grammar (GPSG) (Gazdar et al, 1985), Lex- ical Functional Grammar (LFG) (Kaplan and Bresnan, 1982) - - and on natural language parsing frameworks for example, Functional Unification Grammar (FUG) (Kay, 1984a), PATR-II (Shieber, 1984) - - make it feasible to consider the implementation of efficient systems for the syntactic analysis of substantial frag- ments of natural anguage. These developments also emphasise that if natural anguage processing systems are to be able to handle the grammatical nd semantic idiosyncracies of individual lexical items elegantly and efficiently, then the lexicon must be a central compo- nent of the ","@endWordPosition":"240","@position":"1671","annotationId":"T13","@startWordPosition":"237","@citStr":"Gazdar et al, 1985"}},"booktitle":{"#tail":"\n","#text":"Generalized Phrase Structure Grammar."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Gerald Gazdar"},{"#tail":"\n","#text":"Ewan Klein"},{"#tail":"\n","#text":"Geoffrey Pullum"},{"#tail":"\n","#text":"Ivan Sag"}]}},{"volume":{"#tail":"\n","#text":"21"},"#tail":"\n","date":{"#tail":"\n","#text":"1982"},"rawString":{"#tail":"\n","#text":"Heidorn, George et al 1982 The EPISTLE Text-Critiquing System. IBM Systems Journal, 21(3): 305-326."},"journal":{"#tail":"\n","#text":"IBM Systems Journal,"},"#text":"\n","pages":{"#tail":"\n","#text":"305--326"},"issue":{"#tail":"\n","#text":"3"},"marker":{"#tail":"\n","#text":"Heidorn, 1982"},"title":{"#tail":"\n","#text":"The EPISTLE Text-Critiquing System."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"George Heidorn"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1983"},"rawString":{"#tail":"\n","#text":"Huttenlocher, Daniel and Zue, Victor. 1983 Phonotactic and Lexical Constraints in Speech Recognition, In Proceedings of the National Conference on Artificial Intelligence, Washington, D.C.: 172-176."},"#text":"\n","pages":{"#tail":"\n","#text":"172--176"},"marker":{"#tail":"\n","#text":"Huttenlocher, Zue, 1983"},"location":{"#tail":"\n","#text":"Washington, D.C.:"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"l operate on the basis of the on-line LDOCE; and any serious parser must be able to recognise compounds before it segments its input into separate words. From the master LDOCE file, we have computed alternative indexing information, which allows access into the dictionary via different routes. In addition to headwords, dictionary search through the pronuncia- tion field is available; Carter (1987) has merged infor- mation from the pronunciation and hyphenation fields, creating an enhanced phonological representation which allows access to entries by broad phonetic lass and syllable structure (Huttenlocher and Zue, 1983). In addition, a fully flexible access system allows the re- trieval of dictionary entries on the basis of constraints specifying any combination ofphonetic, lexical, syntac- tic, and semantic information (Boguraev et al, 1987). Independently, random selection of dictionary entries is also provided to allow the testing of software on an unbiased sample. 3 THE FORMAT OF THE GRAMMAR CODES The lispified LDOCE file retains the broad structure of the typesetting tape and divides each entry into a number of fields - - head word, pronunciation, grammar codes, definitions, examples, and so forth. Howe","@endWordPosition":"2959","@position":"19147","annotationId":"T14","@startWordPosition":"2956","@citStr":"Huttenlocher and Zue, 1983"}},"title":{"#tail":"\n","#text":"Phonotactic and Lexical Constraints in Speech Recognition,"},"booktitle":{"#tail":"\n","#text":"In Proceedings of the National Conference on Artificial Intelligence,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Daniel Huttenlocher"},{"#tail":"\n","#text":"Victor Zue"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Report No. 5684,"},"date":{"#tail":"\n","#text":"1984"},"institution":{"#tail":"\n","#text":"Bolt Beranek and Newman Inc.,"},"rawString":{"#tail":"\n","#text":"Ingria, Robert. 1984 Complement Types in English. Report No. 5684, Bolt Beranek and Newman Inc., Cambridge, Mass."},"#text":"\n","marker":{"#tail":"\n","#text":"Ingria, 1984"},"location":{"#tail":"\n","#text":"Cambridge, Mass."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"used in preference to I5 if the verb is felt to be semantically two place rather than one place, such as know versus appear. On the other hand, both believe and promise are assigned V3 which means they take a NP object and infinitival complement, yet there is a similar semantic distinction to be made between the two verbs; so the criteria for the assign- ment of the V code seem to be purely syntactic. Michiels (1982) and Akkerman et al (1985) provide a more detailed analysis of the information encoded by the LDOCE grammar codes and discuss their efficacy as a system of linguistic description. Ingria (1984) compre- hensively compares different approaches to comple- mentation within grammatical theory providing atouch- stone against which the LDOCE scheme can be evaluated. Most automated parsing systems employ grammars which carefully distinguish syntactic and semantic in- formation, therefore, if the information provided by the Longman grammar code system is to be of use, we need to be able to separate out this information and map it into a representation scheme compatible with the type of lexicon used by such parsing systems. The program which transforms the LDOCE grammar codes into lexical ent","@endWordPosition":"5435","@position":"34021","annotationId":"T15","@startWordPosition":"5434","@citStr":"Ingria (1984)"}},"title":{"#tail":"\n","#text":"Complement Types in English."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Robert Ingria"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1985"},"institution":{"#tail":"\n","#text":"Brandeis University,"},"rawString":{"#tail":"\n","#text":"Jackendoff, Ray and Jane Grimshaw. 1985 A Key to the Brandeis Verb Catalog. Unpublished mimeo, under NSF Grant IST-84-20073, &quot;Information Structure of a Natural Language Lexicon&quot;, Program in Linguistics and Cognitive Science, Brandeis University, Waltham, Mass."},"#text":"\n","marker":{"#tail":"\n","#text":"Jackendoff, Grimshaw, 1985"},"location":{"#tail":"\n","#text":"Waltham, Mass."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"~lou help me up (the a~,o)~ I T~ a,'~ he~ps h~,. (to) ,~k, I Yo,,, o~u helps a lot. I Can I help ( ,~ yo,,, wo~k)~ ........ detest ... \\[T1,4\\] to hate with very strong feeling: I deter people who decelse and tell lies. I dn, . ~i shootir~ and k~lin? ......... (7) I prefer that he come on Monday . (8) ?I pre fer that he marr ies Jul ie. This example also highlights a deficiency in the LDOCE coding system since pre fer occurs much more naturally with a sentential complement if it collocates with a modal such as &quot;would&quot;. This deficiency is rectified in the verb classification system employed by Jackendoff and Grimshaw (1985) in the Brandeis verb catalogue. The main source of error comes from the misclassi- fication of Object Raising into Object Equi verbs. Ar- guably, these errors also derive mostly from errors in the dictionary, rather than a defect of the rule. 66% of the Object Raising verbs were misclassified as Object Equi verbs, because the cooccurrence of the T5 and V (2, 3, or 4) codes in the same code fields, as predicted by the Object Raising rule above, was not confirmed by LDOCE. All the 14 verbs misclassified contain V codes and 10 of these also contain T5 codes. However, the Longman lexicographers t","@endWordPosition":"8653","@position":"53094","annotationId":"T16","@startWordPosition":"8650","@citStr":"Jackendoff and Grimshaw (1985)"}},"title":{"#tail":"\n","#text":"A Key to the Brandeis Verb Catalog. Unpublished mimeo, under NSF Grant IST-84-20073, &quot;Information Structure of a Natural Language Lexicon&quot;,"},"booktitle":{"#tail":"\n","#text":"Program in Linguistics and Cognitive Science,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Ray Jackendoff"},{"#tail":"\n","#text":"Jane Grimshaw"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1982"},"rawString":{"#tail":"\n","#text":"Kaplan, Ronald and Bresnan, Joan. 1982 Lexical-Functional Grammar: A Formal System for Grammatical Representation. In: J.Bresnan, Ed., The Mental Representation of Grammatical Relations. The MIT Press, Cambridge, Mass: 173-281."},"#text":"\n","pages":{"#tail":"\n","#text":"173--281"},"marker":{"#tail":"\n","#text":"Kaplan, Bresnan, 1982"},"publisher":{"#tail":"\n","#text":"The MIT Press,"},"location":{"#tail":"\n","#text":"Cambridge, Mass:"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ding system employed by the Longman Dictionary of Contemporary English (henceforth LDOCE) is the most comprehensive description of grammatical properties of words to be found in any published dictionary available in machine readable form. This paper describes the extraction of this, and other, information from LDOCE and discusses the utility of the coding system for automated natural language processing. Recent developments in linguistics, and especially on grammatical theory - - for example, Generalised Phrase Structure Grammar (GPSG) (Gazdar et al, 1985), Lex- ical Functional Grammar (LFG) (Kaplan and Bresnan, 1982) - - and on natural language parsing frameworks for example, Functional Unification Grammar (FUG) (Kay, 1984a), PATR-II (Shieber, 1984) - - make it feasible to consider the implementation of efficient systems for the syntactic analysis of substantial frag- ments of natural anguage. These developments also emphasise that if natural anguage processing systems are to be able to handle the grammatical nd semantic idiosyncracies of individual lexical items elegantly and efficiently, then the lexicon must be a central compo- nent of the parsing system. Real-time parsing imposes stringent requirement","@endWordPosition":"249","@position":"1734","annotationId":"T17","@startWordPosition":"246","@citStr":"Kaplan and Bresnan, 1982"}},"title":{"#tail":"\n","#text":"Lexical-Functional Grammar: A Formal System for Grammatical Representation. In: J.Bresnan, Ed., The Mental Representation of Grammatical Relations."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Ronald Kaplan"},{"#tail":"\n","#text":"Joan Bresnan"}]}},{"#tail":"\n","rawString":{"#tail":"\n","#text":"Kay, Martin. 1984a Functional Unification Grammar: A Formalism for Machine Translation. In Proceedings of the lOth International Congress on Computational Linguistics, Stanford, California: 75-79."},"#text":"\n","pages":{"#tail":"\n","#text":"75--79"},"marker":{"#tail":"\n","#text":"Kay, "},"location":{"#tail":"\n","#text":"Stanford, California:"},"title":{"#tail":"\n","#text":"1984a Functional Unification Grammar: A Formalism for Machine Translation."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the lOth International Congress on Computational Linguistics,"},"@valid":"false","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Martin Kay"}}},{"#tail":"\n","rawString":{"#tail":"\n","#text":"Kay, Martin. 1984b The Dictionary Server. In Proceedings of the lOth International Congress on Computational Linguistics, Stanford, California, 461-462."},"#text":"\n","pages":{"#tail":"\n","#text":"461--462"},"marker":{"#tail":"\n","#text":"Kay, "},"location":{"#tail":"\n","#text":"Stanford, California,"},"title":{"#tail":"\n","#text":"1984b The Dictionary Server."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the lOth International Congress on Computational Linguistics,"},"@valid":"false","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Martin Kay"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1983"},"rawString":{"#tail":"\n","#text":"Leech, Geoffrey; Garside, Roger; and Atwell, Erik. 1983 The Automatic Grammatical Tagging of the LOB Corpus. Bulletin of the 1. Subject Raising verbs (total number 5) International Computer Archive of Modern English, Norwegian Computing Centre for the Humanities, Bergen, Norway."},"#text":"\n","marker":{"#tail":"\n","#text":"Leech, Garside, Atwell, 1983"},"location":{"#tail":"\n","#text":"Bergen, Norway."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ter this process much of the information in LDOCE remains difficult to access, essentially because it is aimed at a human reader, as opposed to a computer system. This suggests that the automatic construction of dictionaries from published sources intended for other purposes will have a limited life unless lexicography is heavily influenced by the requirements of automated natural language analysis. In the longer term, therefore, the automatic onstruction of dictionaries for natural language processing systems may need to be based on techniques for the automatic analysis of large corpora (eg. Leech et al, 1983). However, in the short term, the approach outlined in this paper will allow us to produce a relatively sophisticated and useful dictionary rapidly. 8 ACKNOWLEDGEMENTS We would like to thank the Longman Group Limited for kindly allowing us access to the LDOCE typesetting tape for research purposes. We also thank Steve Pul- man, Graham Russell and Karen Sparck Jones for their comments on the first draft, which substantially im- proved this paper. Part of the research reported here was funded by the UK Science and Engineering Re- search Council (Grant No. GR/D/05554) under the Al- vey Programme.","@endWordPosition":"10409","@position":"63494","annotationId":"T18","@startWordPosition":"10406","@citStr":"Leech et al, 1983"}},"title":{"#tail":"\n","#text":"The Automatic Grammatical Tagging of the LOB Corpus. Bulletin of the 1. Subject Raising verbs (total number 5) International Computer Archive of Modern English, Norwegian Computing Centre for the Humanities,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Geoffrey Leech"},{"#tail":"\n","#text":"Roger Garside"},{"#tail":"\n","#text":"Erik Atwell"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"PhD Thesis, Universit6 de Liege,"},"date":{"#tail":"\n","#text":"1982"},"rawString":{"#tail":"\n","#text":"Michiels, Archibal. 1982 Exploiting a Large Dictionary Data Base. PhD Thesis, Universit6 de Liege, Liege, Belgium."},"#text":"\n","marker":{"#tail":"\n","#text":"Michiels, 1982"},"location":{"#tail":"\n","#text":"Liege, Belgium."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" as the machine read- able source to aid the development of a substantial lexicon because this dictionary has several properties which make it uniquely appropriate for use as the core knowledge base of a natural anguage processing sys- tem. Most prominent among these are the rich gram- matical subcategorisations of the 60,000 entries, the large amount of information concerning phrasal verbs, noun compounds and idioms, the individual subject, collocational nd semantic odes for the entries and the consistent use of a controlled 'core' vocabulary in defining the words throughout the dictionary. (Michiels (1982) contains further description and discussion of LDOCE.) In this paper we focus on the exploitation of the LDOCE grammar coding system; Alshawi et al (1985) and Alshawi (1987) describe further esearch in Cambridge utilising different types of information avail- able in LDOCE. The information available in the dictionary is both very rich and diverse, but also typically only semi- formalised, as it is intended for human, rather than machine, interpetation. As a consequence the programs we are developing, both to restructure and to exploit this information, need to undergo constant revision as the","@endWordPosition":"829","@position":"5647","annotationId":"T19","@startWordPosition":"828","@citStr":"Michiels (1982)"},{"#tail":"\n","#text":"5 can all be assigned to verbs which take a NP subject and a sentential complement, but L5 will only be assigned if there is a fairly close semantic link between the two arguments and T5 will be used in preference to I5 if the verb is felt to be semantically two place rather than one place, such as know versus appear. On the other hand, both believe and promise are assigned V3 which means they take a NP object and infinitival complement, yet there is a similar semantic distinction to be made between the two verbs; so the criteria for the assign- ment of the V code seem to be purely syntactic. Michiels (1982) and Akkerman et al (1985) provide a more detailed analysis of the information encoded by the LDOCE grammar codes and discuss their efficacy as a system of linguistic description. Ingria (1984) compre- hensively compares different approaches to comple- mentation within grammatical theory providing atouch- stone against which the LDOCE scheme can be evaluated. Most automated parsing systems employ grammars which carefully distinguish syntactic and semantic in- formation, therefore, if the information provided by the Longman grammar code system is to be of use, we need to be able to separate out","@endWordPosition":"5404","@position":"33828","annotationId":"T20","@startWordPosition":"5403","@citStr":"Michiels (1982)"},{"#tail":"\n","#text":"tial indications of the semantic nature of the relevant sense of the verb. The solution we have adopted is to derive a semantic classification of the particular sense of the verb under consideration on the basis of the complete set of codes assigned to that sense. In any subcategorisation frame which involves a predicate complement there will be a non-transparent relationship between the superficial syntactic form and the underlying logical relations in the sentence. In these situations the parser can use the semantic type of the verb to compute this relationship. Expanding on a suggestion of Michiels (1982), we classify verbs as Subject Equi, Object Equi, Subject Raising or Object Raising for each sense which has a predicate complement code associated with it. These terms, which derive from Transformational Grammar, are used as convenient labels for what we regard as a semantic distinction; the actual output of the program is a specification of the mapping from superficial syntactic form to an underlying logical representation. For exam- ple, labelling believe(3) (Type 20Raising) indicates that this is a two place predicate and that, if believe(3) occurs with a syntactic direct object, as in (1)","@endWordPosition":"6062","@position":"37981","annotationId":"T21","@startWordPosition":"6061","@citStr":"Michiels (1982)"},{"#tail":"\n","#text":"rd qualifiers can be utilised straightforwardly is with di- transitive verbs such as give and donate. Give is coded as \\[Dl(to)\\] which allows us to recover the information that this verb permits dative movement and requires a prepositional phrase headed by &quot;to&quot;: (Takes NP NP ToPP) and (Takes NP NP NP). On the other hand, donate is coded \\[T1 (to)\\], which tells us that it does not undergo dative movement but does require a prepositional phrase headed by &quot;to&quot;: (Takes NP NP ToPP). There are many more distinctions which are con- veyed by the conjunction of grammar codes and word qualifiers (see Michiels, 1982, for further details). How- ever, exploiting this information to the full would be a non-trivial task, because it would require accessing the relevant knowledge about the words contained in the qualifier fields from their LDOCE entries. 5 LEXICAL ENTRIES FOR PATR-II The output of the transformation program can be used to derive entries which are appropriate for particular grammatical formalisms. To demonstrate hat this is possible we have implemented a system which con- structs dictionary entries for the PATR-II system (Shieber, 1984 and references therein). PATR-II was chosen because it has ","@endWordPosition":"6849","@position":"42754","annotationId":"T22","@startWordPosition":"6848","@citStr":"Michiels, 1982"}]},"title":{"#tail":"\n","#text":"Exploiting a Large Dictionary Data Base."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Archibal Michiels"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1983"},"rawString":{"#tail":"\n","#text":"Michiels, Archibal. 1983 Automatic Analysis of Texts. In Informatics 7, Proceedings of a Conference of the ASLIB Informatics Group and the Information Retrieval Group of the British Computer Society, Cambridge, UK: 103-120."},"#text":"\n","pages":{"#tail":"\n","#text":"103--120"},"marker":{"#tail":"\n","#text":"Michiels, 1983"},"location":{"#tail":"\n","#text":"Cambridge, UK:"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"nstrained in any way by the method of access, as we do not have a very clear idea what form the restructured dictionary may eventually take. Given that we were targeting all envisaged access routes from LDOCE to systems implemented in Lisp, and since the natural data structure for Lisp is the s-expression, we adopted the approach of converting the tape source into a set of list structures, one per entry. Our task was made possible by the fact that while far from being a database in the accepted sense of the word, the LDOCE typesetting tape is the only truly computerised dictionary of English (Michiels, 1983). 204 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 Bran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing The logical structure of a dictionary entry is reflected on the tape as a sequence of typed records (see Figure 1), each with additional internal segmentation, where rec- ords and fields correspond to separate units in an entry, such as headword, pronunciation, grammar code, word senses, and so forth. (Record-type homograph (Seq-number E-code I-code)) (Record-type headword (Serial-no Main-entry)) (Record-type pronunciation (Phonetic)) (Record-","@endWordPosition":"1522","@position":"9936","annotationId":"T23","@startWordPosition":"1521","@citStr":"Michiels, 1983"}},"title":{"#tail":"\n","#text":"Automatic Analysis of Texts. In Informatics 7,"},"booktitle":{"#tail":"\n","#text":"Proceedings of a Conference of the ASLIB Informatics Group and the Information Retrieval Group of the British Computer Society,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Archibal Michiels"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1985"},"rawString":{"#tail":"\n","#text":"Moulin, A.; Jansen, J; and Michiels, A. 1985 Computer Exploitation of LDOCE's Grammatical Codes, paper presented at a Conference on Survey of English Language, Lund."},"#text":"\n","marker":{"#tail":"\n","#text":"Moulin, Jansen, Michiels, 1985"},"location":{"#tail":"\n","#text":"Lund."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"here. Similarly, expect is not given a V3 code under sense 1 (Figure 19), however the grammaticality of (10) I expect him to pass the exam with the relevant interpretation suggests that it should be assigned a V3 code. Alternatively, sense 5, which is assigned a V3 code, seems uspiciously similar to sense 1. The four verbs which are misclassified as Object Equi and which do not have T5 codes anywhere in their entries are elect, love, represent and require. None of these verbs take sentential complements and therefore they appear to be counterexamples to our Object Rais- ing rule. In addition, Moulin et al (1985) note that our Object Raising rule would assign mean to this category incorrectly. Mean is assigned both a V3 and a T5 category in the code field associated with sense 2 (i.e. &quot;intend&quot;), however, when it is used in this sense it must be treated as an Object Equi verb. This small experiment demonstrates a number of points. Firstly, it seems reasonable to conclude that the assignment of individual codes to verbs is on the whole relatively accurate in LDOCE. Of the 139 verbs tested, we only found code omissions in 10 cases. Secondly though, when we consider the interaction between the assignments","@endWordPosition":"9148","@position":"55853","annotationId":"T24","@startWordPosition":"9145","@citStr":"Moulin et al (1985)"}},"title":{"#tail":"\n","#text":"Computer Exploitation of LDOCE's Grammatical Codes, paper presented at a Conference on Survey of English Language,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A Moulin"},{"#tail":"\n","#text":"J Jansen"},{"#tail":"\n","#text":"A Michiels"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1979"},"rawString":{"#tail":"\n","#text":"Perlmutter, D.M. and Soames, S. 1979 Syntactic Argumentation and the Structure of English. University of California Press, Berkeley, California."},"#text":"\n","marker":{"#tail":"\n","#text":"Perlmutter, Soames, 1979"},"publisher":{"#tail":"\n","#text":"University of California Press,"},"location":{"#tail":"\n","#text":"Berkeley, California."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"( l ) ass,l ine(I) decline(S) \\[WvS;/t+15\\] (Type 1 SRaising) \\[Wv4;IO;Tl:( of, against) ifa;D5a;V3\\] (Type 30Equi) \\[Wv4;T1,Sa,b;X(to be)l,7\\] (Type 20Raising) \\[T1,3;I0\\] (Type 2 SEqui) Figure 9 (2) John believes that the Earth is round. (3) *John forces that the Earth is round. Secondly, if a verb takes a direct object and a sentential complement, it will be an Equi verb, as examples in (4) and (5) illustrate. (4) John persuaded Mary that the Earth is round. (5) *John believed Mary that the Earth is round. Clearly, there are other syntactic and semantic tests for this distinction, (see eg. Perlmutter and Soames, 1979:472), but these are the only ones which are explicit in the LDOCE coding system. Once the semantic type for a verb sense has been determined, the sequence of codes in the associated code field is translated, as before, on a code-by-code basis. However, when a predicate complement code is encountered, the semantic type is used to determine the type assignment, asillustrated in Figures 4 and 8 above. Where no predicate complement is involved, the letter code is usually sufficient to determine the logical prop- erties of the verb involved. For example, T codes nearly always translate into two-pl","@endWordPosition":"6527","@position":"40785","annotationId":"T25","@startWordPosition":"6524","@citStr":"Perlmutter and Soames, 1979"},{"#tail":"\n","#text":"dual codes to verbs is on the whole relatively accurate in LDOCE. Of the 139 verbs tested, we only found code omissions in 10 cases. Secondly though, when we consider the interaction between the assignments of codes and word sense classification, LDOCE appears less reliable. This is the primary source of error in the case of the Object Raising rule. Thirdly, it seems clear that the Object Raising rule is straining the limits of what can be reliably extracted from the LDOCE coding system. Ideally, to distinguish between raising and equi verbs, a number of syntactic criteria should be employed (Perlmutter and Soames, 1979:460ff.). However, only two of these criteria are explicit in the coding system. On the basis of the results obtained, we explored the possibility of modifying the Object Raising rule to take account of the cooccurrence ofT5 and T5a codes and V or X codes within a homograph, rather than within a word sense. An exhaustive search of the dictionary produced 24 verbs coded in this fashion. Ten of these were listed as Object Raising verbs in the published lists used in the above experiment. Five more verbs were classified as Equi in the published lists. Of the remaining nine verbs which did not app","@endWordPosition":"9320","@position":"56874","annotationId":"T26","@startWordPosition":"9317","@citStr":"Perlmutter and Soames, 1979"}]},"title":{"#tail":"\n","#text":"Syntactic Argumentation and the Structure of English."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"D M Perlmutter"},{"#tail":"\n","#text":"S Soames"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1986"},"note":{"#tail":"\n","#text":"To apper in"},"institution":{"#tail":"\n","#text":"University of Edinburgh,"},"rawString":{"#tail":"\n","#text":"Phillips, John and Thompson, Henry. 1986 A Parser for Generalised Phrase Structure Grammars. To apper in Klein, E. and Haddock, N., Eds., Edinburgh Working Papers in Cognitive Science, University of Edinburgh, Edinburgh, Scotland."},"#text":"\n","marker":{"#tail":"\n","#text":"Phillips, Thompson, 1986"},"location":{"#tail":"\n","#text":"Edinburgh, Scotland."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ents also emphasise that if natural anguage processing systems are to be able to handle the grammatical nd semantic idiosyncracies of individual lexical items elegantly and efficiently, then the lexicon must be a central compo- nent of the parsing system. Real-time parsing imposes stringent requirements on a dictionary support environ- ment; at the very least it must allow frequent and rapid access to the information in the dictionary via the dictionary head words. The research described below is taking place in the context of three collaborative projects (Boguraev, 1987; Russell et al, 1986; Phillips and Thompson, 1986) to develop a general-purpose, wide coverage morphological nd syntactic analyser for English. One motivation for our interest in machine readable dictionaries i to attempt to provide a substan- tial lexicon with lexical entries containing rammatical information compatible with the grammatical frame- work employed by the analyser. The idea of using the machine readable source of a published ictionary has occurred to a wide range of researchers, for spelling correction, lexical analysis, thesaurus construction, and machine translation, to name but a few applications. Most of the work on automate","@endWordPosition":"389","@position":"2659","annotationId":"T27","@startWordPosition":"386","@citStr":"Phillips and Thompson, 1986"}},"title":{"#tail":"\n","#text":"A Parser for Generalised Phrase Structure Grammars."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"John Phillips"},{"#tail":"\n","#text":"Henry Thompson"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1978"},"rawString":{"#tail":"\n","#text":"Procter, Paul. 1978 Longman Dictionary of Contemporary English. Longman Group Limited, Harlow and London, England."},"#text":"\n","marker":{"#tail":"\n","#text":"Procter, 1978"},"publisher":{"#tail":"\n","#text":"Longman Group Limited,"},"location":{"#tail":"\n","#text":"Harlow and London, England."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":". desire), predicative, postpositive and attributive adjec- tives (asleep vs. elect vs. jokular), noun complementa- tion (fondness, fact) and, most importantly, verb com- plementation a d valency. Grammar codes typically contain a capital letter, followed by a number and, occasionally, a small letter, for example \\[T5a\\] or \\[V3\\]. The capital etters encode information &quot;about he way a word works in a sentence Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 207 Bran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing or about the position it can fill&quot; (Procter, 1978: xxviii); the numbers &quot;give information about he way the rest of a phrase or clause is made up in relation to the word described&quot; (ibid.). For example, &quot;T&quot; denotes a transi- tive verb with one object, while &quot;5&quot; specifies that what follows the verb must be a sentential complement introduced by that. (The small letters, eg. &quot;a&quot; in the case above, provide further information typically re- lated to the status of various complementisers, adverbs and prepositions in compound verb constructions: eg. &quot;a&quot; indicates that the word that can be left out between a verb and the following clause.) As another","@endWordPosition":"4084","@position":"25976","annotationId":"T28","@startWordPosition":"4083","@citStr":"Procter, 1978"}},"title":{"#tail":"\n","#text":"Longman Dictionary of Contemporary English."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Paul Procter"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1972"},"rawString":{"#tail":"\n","#text":"Quirk, Randolph; Greenbaum, Sidney; Leech, Geoffrey; and Svartvik, Jan. 1972 A Grammar of Contemporary English, Longman Group Limited, Harlow and London, England."},"#text":"\n","marker":{"#tail":"\n","#text":"Quirk, Greenbaum, Leech, Svartvik, 1972"},"location":{"#tail":"\n","#text":"Harlow and London, England."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"oach to lexicon development, since this allows the restructuring programs to be progres- sively refined as these problems emerge. Any attempt at batch processing without extensive initial testing of this kind would inevitably result in an incomplete and pos- sibly inaccurate l xicon. 4 THE CONTENT OF THE GRAMMAR CODES Once the grammar codes have been restructured, it still remains to be shown that the information they encode is going to be of some utility for natural language process- ing. The grammar code system used in LDOCE is based quite closely on the descriptive grammatical framework of Quirk et al (1972, 1985). The codes are doubly articulated; capital letters represent he grammatical relations which hold between a verb and its arguments and numbers represent subcategorisation frames which a verb can appear in. Most of the subcategorisation frames are specified by syntactic ategory, but some are very ill-specified; for instance, 9 is defined as &quot;needs a descriptive word or phrase&quot;. In practice many adver- bial and predicative complements will satisfy this code, when attached to a verb; for example, put \\[xg\\] where the code marks a locative adverbial prepositional phrase vs. make under sense","@endWordPosition":"5145","@position":"32292","annotationId":"T29","@startWordPosition":"5142","@citStr":"Quirk et al (1972"}},"title":{"#tail":"\n","#text":"A Grammar of Contemporary English, Longman Group Limited,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Randolph Quirk"},{"#tail":"\n","#text":"Sidney Greenbaum"},{"#tail":"\n","#text":"Geoffrey Leech"},{"#tail":"\n","#text":"Jan Svartvik"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1985"},"rawString":{"#tail":"\n","#text":"Quirk, Randolph; Greenbaum, Sidney; Leech, Geoffrey; and Svartvik, Jan. 1985 A Comprehensive Grammar of English, Longman Group Limited, Harlow and London, England."},"#text":"\n","marker":{"#tail":"\n","#text":"Quirk, Greenbaum, Leech, Svartvik, 1985"},"location":{"#tail":"\n","#text":"Harlow and London, England."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"typesetting tape and after re- structuring. be l ieve v ... B \\[TSa,b;V3;X(to be)l, (to be)7\\] (7 300 !< TSa l , b !; V3 !; X (*46 to be *44) 1 !, (*46 to be *44) 7 !< ) sense-no 3 head: TSa head: T5b head: V3 head: X1 r ight opt iona l ( to be) head: X7 r ight opt iona l ( to be) Figure 4 LDOCE provides considerably more syntactic infor- mation than a traditional dictionary. The Longman lexicographers have developed a grammar coding sys- tem capable of representing in compact form a non- trivial amount of information, usually to be found only in large descriptive grammars of English (such as Quirk et al, 1985). A grammar code describes a particular pattern of behaviour of a word. Patterns are descriptive, and are used to convey a range of information: eg. distinctions between count and mass nouns (dog vs. desire), predicative, postpositive and attributive adjec- tives (asleep vs. elect vs. jokular), noun complementa- tion (fondness, fact) and, most importantly, verb com- plementation a d valency. Grammar codes typically contain a capital letter, followed by a number and, occasionally, a small letter, for example \\[T5a\\] or \\[V3\\]. The capital etters encode information &quot;about he way a word works in ","@endWordPosition":"3961","@position":"25165","annotationId":"T30","@startWordPosition":"3958","@citStr":"Quirk et al, 1985"}},"title":{"#tail":"\n","#text":"A Comprehensive Grammar of English, Longman Group Limited,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Randolph Quirk"},{"#tail":"\n","#text":"Sidney Greenbaum"},{"#tail":"\n","#text":"Geoffrey Leech"},{"#tail":"\n","#text":"Jan Svartvik"}]}},{"date":{"#tail":"\n","#text":"1982"},"issue":{"#tail":"\n","#text":"1"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ovided that he copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page. To copy otherwise, orto republish, requires afee and/or specific permission. 0362-613X/87/030203-218503.00 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 203 Bran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing on developing dictionary servers for office automation systems (Kay, 1984b). Few established parsing systems have substantial lexicons and even those which employ very comprehensive grammars (eg. Robinson, 1982; Bobrow, 1978) consult relatively small lexicons, typi- cally generated by hand. Two exceptions to this gener- alisation are the Linguistic String Project (Sager, 1981) and the IBM CRITIQUE (formerly EPISTLE) Project (Heidorn et al, 1982; Byrd, 1983); the former employs a dictionary of approximately 10,000 words, most of which are specialist medical terms, the latter has well over 100,000 entries, gathered from machine readable sources. In addition, there are a number of projects under way to develop substantial lexicons from machine readable sources (see Boguraev, 1986 for details). How- eve","@endWordPosition":"603","@position":"4168","annotationId":"T31","@startWordPosition":"602","@citStr":"Robinson, 1982"}},"title":{"#tail":"\n","#text":"DIAGRAM: A Grammar for Dialogues."},"volume":{"#tail":"\n","#text":"25"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Robinson, Jane. 1982 DIAGRAM: A Grammar for Dialogues. Communications of the ACM, 25(1): 27-47."},"journal":{"#tail":"\n","#text":"Communications of the ACM,"},"#text":"\n","pages":{"#tail":"\n","#text":"27--47"},"marker":{"#tail":"\n","#text":"Robinson, 1982"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Jane Robinson"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1967"},"rawString":{"#tail":"\n","#text":"Rosenbaum, P.S. 1967 The Grammar of English Predicate Complement Constructions. MIT Press, Cambridge, Mass."},"#text":"\n","marker":{"#tail":"\n","#text":"Rosenbaum, 1967"},"publisher":{"#tail":"\n","#text":"MIT Press,"},"location":{"#tail":"\n","#text":"Cambridge, Mass."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"he source dictionary and the reliability of the more ambi- tious (and potentially controversial) aspects of the grammar code transformation rules. It is not clear, in particular, that the rules for computing semantic types for verbs are well enough motivated linguistically or that the LDOCE lexicographers were sensitive nough to the different transformational potential of the various classes of verbs to make a rule such as our one for Object Raising viable. We tested the classification of verbs into semantic types using a verb list of 139 pre-classified items drawn from the lists published in Rosenbaum (1967) and Stock- well et al (1973). Figure 16 gives the number of verbs classified under each category by these authors and the number successfully classified into the same categories by the system. The overall error rate of the system was 14%; how- ever, as the table illustrates, the rules discussed above classify verbs into Subject Raising, Subject Equi and persuade v I \\[TI (of); D5\\] to cause to feel certain; CONVINCE: She waa not persuaded o,f the truth o.f hi~ ~ement = \\[Tl(into, out o~; V3\\] to cause to do something by reasoning, arguing, begging, etc.: try to persuade him to let .a go with ","@endWordPosition":"8020","@position":"49586","annotationId":"T32","@startWordPosition":"8019","@citStr":"Rosenbaum (1967)"}},"title":{"#tail":"\n","#text":"The Grammar of English Predicate Complement Constructions."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"P S Rosenbaum"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1986"},"rawString":{"#tail":"\n","#text":"Russell, Graham; Pulman, Steve; Ritchie, Graeme; and Black, Alan. 1986 A Dictionary and Morphological Analyser for English. In Proceedings of the Eleventh International Congress on Computational Linguistics, Bonn, Germany: 277-279."},"#text":"\n","pages":{"#tail":"\n","#text":"277--279"},"marker":{"#tail":"\n","#text":"Russell, Pulman, Ritchie, Black, 1986"},"location":{"#tail":"\n","#text":"Bonn, Germany:"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"guage. These developments also emphasise that if natural anguage processing systems are to be able to handle the grammatical nd semantic idiosyncracies of individual lexical items elegantly and efficiently, then the lexicon must be a central compo- nent of the parsing system. Real-time parsing imposes stringent requirements on a dictionary support environ- ment; at the very least it must allow frequent and rapid access to the information in the dictionary via the dictionary head words. The research described below is taking place in the context of three collaborative projects (Boguraev, 1987; Russell et al, 1986; Phillips and Thompson, 1986) to develop a general-purpose, wide coverage morphological nd syntactic analyser for English. One motivation for our interest in machine readable dictionaries i to attempt to provide a substan- tial lexicon with lexical entries containing rammatical information compatible with the grammatical frame- work employed by the analyser. The idea of using the machine readable source of a published ictionary has occurred to a wide range of researchers, for spelling correction, lexical analysis, thesaurus construction, and machine translation, to name but a few applications","@endWordPosition":"385","@position":"2629","annotationId":"T33","@startWordPosition":"382","@citStr":"Russell et al, 1986"},{"#tail":"\n","#text":"ve developed for the verb codes. Extending the system to handle nouns, adjectives and adverbs would present no problems of principle. However, the LDOCE coding of verbs is more comprehensive than elsewhere, so verbs are the obvious place to start in an evaluation of the usefulness of the coding system. No attempt has been made to map any closed class entries from LDOCE, as a 3,000 word lexicon containing most closed class items has been developed independently b one of the groups collaborating with us to develop the general purpose morphological nd syntactic analyser (see the Introduction and Russell et al, 1986). Initially the transformation f the LDOCE codes was performed on a code-by-code basis, within a code field associated with each individual word sense. This ap- proach is adequate if all that is required is an indication of the subcategorisation frames relevant o any partic- ular sense. In the main, the code numbers determine a unique subcategorisation. Thus the entries can be used to select the appropriate VP rules from the grammar (assuming a GPSG-style approach to subcategorisation) Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 209 Bran Boguraev and Ted Briscoe Large","@endWordPosition":"5819","@position":"36416","annotationId":"T34","@startWordPosition":"5816","@citStr":"Russell et al, 1986"}]},"title":{"#tail":"\n","#text":"A Dictionary and Morphological Analyser for English."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Eleventh International Congress on Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Graham Russell"},{"#tail":"\n","#text":"Steve Pulman"},{"#tail":"\n","#text":"Graeme Ritchie"},{"#tail":"\n","#text":"Alan Black"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1981"},"rawString":{"#tail":"\n","#text":"Sager, N. 1981 Natural Language Information Processing, AddisonWesley, Reading, Mass."},"#text":"\n","marker":{"#tail":"\n","#text":"Sager, 1981"},"publisher":{"#tail":"\n","#text":"AddisonWesley,"},"location":{"#tail":"\n","#text":"Reading, Mass."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"epublish, requires afee and/or specific permission. 0362-613X/87/030203-218503.00 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 203 Bran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing on developing dictionary servers for office automation systems (Kay, 1984b). Few established parsing systems have substantial lexicons and even those which employ very comprehensive grammars (eg. Robinson, 1982; Bobrow, 1978) consult relatively small lexicons, typi- cally generated by hand. Two exceptions to this gener- alisation are the Linguistic String Project (Sager, 1981) and the IBM CRITIQUE (formerly EPISTLE) Project (Heidorn et al, 1982; Byrd, 1983); the former employs a dictionary of approximately 10,000 words, most of which are specialist medical terms, the latter has well over 100,000 entries, gathered from machine readable sources. In addition, there are a number of projects under way to develop substantial lexicons from machine readable sources (see Boguraev, 1986 for details). How- ever, as yet few results have been published concerning the utility of electronic versions of published ictionar- ies as sources for such lexicons. In this paper we provide","@endWordPosition":"627","@position":"4337","annotationId":"T35","@startWordPosition":"626","@citStr":"Sager, 1981"}},"title":{"#tail":"\n","#text":"Natural Language Information Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"N Sager"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1984"},"rawString":{"#tail":"\n","#text":"Shieber, S. 1984 The Design of a Computer Language for Linguistic Information, In Proceedings of the lOth International Congress on Computational Linguistics, Stanford, California: 362-366."},"#text":"\n","pages":{"#tail":"\n","#text":"362--366"},"marker":{"#tail":"\n","#text":"Shieber, 1984"},"location":{"#tail":"\n","#text":"Stanford, California:"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"perties of words to be found in any published dictionary available in machine readable form. This paper describes the extraction of this, and other, information from LDOCE and discusses the utility of the coding system for automated natural language processing. Recent developments in linguistics, and especially on grammatical theory - - for example, Generalised Phrase Structure Grammar (GPSG) (Gazdar et al, 1985), Lex- ical Functional Grammar (LFG) (Kaplan and Bresnan, 1982) - - and on natural language parsing frameworks for example, Functional Unification Grammar (FUG) (Kay, 1984a), PATR-II (Shieber, 1984) - - make it feasible to consider the implementation of efficient systems for the syntactic analysis of substantial frag- ments of natural anguage. These developments also emphasise that if natural anguage processing systems are to be able to handle the grammatical nd semantic idiosyncracies of individual lexical items elegantly and efficiently, then the lexicon must be a central compo- nent of the parsing system. Real-time parsing imposes stringent requirements on a dictionary support environ- ment; at the very least it must allow frequent and rapid access to the information in the dictionary","@endWordPosition":"268","@position":"1869","annotationId":"T36","@startWordPosition":"267","@citStr":"Shieber, 1984"},{"#tail":"\n","#text":" the conjunction of grammar codes and word qualifiers (see Michiels, 1982, for further details). How- ever, exploiting this information to the full would be a non-trivial task, because it would require accessing the relevant knowledge about the words contained in the qualifier fields from their LDOCE entries. 5 LEXICAL ENTRIES FOR PATR-II The output of the transformation program can be used to derive entries which are appropriate for particular grammatical formalisms. To demonstrate hat this is possible we have implemented a system which con- structs dictionary entries for the PATR-II system (Shieber, 1984 and references therein). PATR-II was chosen because it has been reimplemented in Cam- bridge and was therefore, available; however, the task would be nearly identical if we were constructing en- tries for a system based on GPSG, FUG or LFG. We word storm: w Jense ~ <head t rans sense-no> = 1 V TakesNP Dyadic worddag storm: \\ [cat: v head: \\[aux: fa l se t rans: \\[pred: storm sense-no: 1 arg l : <DGIS> - \\[\\] arg2: <DG16> = \\ [ \\ ] \\ ] \\ ] syncat : \\ [ f i r s t : \\ [cat: NP head: \\ [ trans: <DG15>\\]\\] res t : \\ [ f i r s t : \\ [cat: NP head: \\ [ trans: <DC16>\\]\\] res t : \\ [ f i r s t : lambd","@endWordPosition":"6931","@position":"43294","annotationId":"T37","@startWordPosition":"6930","@citStr":"Shieber, 1984"}]},"title":{"#tail":"\n","#text":"The Design of a Computer Language for Linguistic Information,"},"booktitle":{"#tail":"\n","#text":"In Proceedings of the lOth International Congress on Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"S Shieber"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1973"},"rawString":{"#tail":"\n","#text":"Stockwell, R.P.; Schachter, P.; and Partee, B.H. 1973 The Major Syntactic Structures of English. Holt, Rinehart and Winston, New York, New York."},"#text":"\n","marker":{"#tail":"\n","#text":"Stockwell, Schachter, Partee, 1973"},"location":{"#tail":"\n","#text":"Holt, Rinehart and Winston, New York, New York."},"title":{"#tail":"\n","#text":"The Major Syntactic Structures of English."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"R P Stockwell"},{"#tail":"\n","#text":"P Schachter"},{"#tail":"\n","#text":"B H Partee"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Preliminary Report,"},"date":{"#tail":"\n","#text":"1986"},"institution":{"#tail":"\n","#text":"Centre for the New Oxford English Dictionary, University of Waterloo,"},"rawString":{"#tail":"\n","#text":"Tompa, Frank. 1986 Database Design for a Dictionary of the Future. Preliminary Report, Centre for the New Oxford English Dictionary, University of Waterloo, Waterloo, Ontario."},"#text":"\n","marker":{"#tail":"\n","#text":"Tompa, 1986"},"location":{"#tail":"\n","#text":"Waterloo, Ontario."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"uistic information, makes a dictio- nary difficult o represent as a structured atabase of a standard, eg. relational, type. In addition, in order to link the machine readable version of LDOCE to our development environment, and eventually to our natu- ral language processing systems, we need to provide fast access from Lisp to data held in secondary storage. Lisp is not particularly well suited for interfacing to complex, structured objects, and it was not our inten- tion to embark on a major effort involving the develop- ment of a formal model of a dictionary (of the style described in, eg., Tompa 1986); on the other hand a method of access was clearly required, which was flexible enough to support a range of applications in- tending to make use of the LDOCE tape. The requirement for having the dictionary entries in a form convenient for symbolic manipulation from within Lisp was furthermore augmented by the constraint that all the information present in the typesetting tape should be carried over to the on-line version of LDOCE, since it is impossible to say in advance which records and fields of an entry would, or would not, be of potential use to a natural anguage processing program. Fina","@endWordPosition":"1301","@position":"8648","annotationId":"T38","@startWordPosition":"1300","@citStr":"Tompa 1986"}},"title":{"#tail":"\n","#text":"Database Design for a Dictionary of the Future."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Frank Tompa"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1986"},"rawString":{"#tail":"\n","#text":"Walker, D. and Amsler, A. 1986 The Use of Machine-Readable Dictionaries in Sublanguage Analysis. In: R. Grishman and R. Kittredge, Eds., Analysing Language in Restricted Domains, Lawrence Erlbaum Associates, Hillsdale, New Jersey."},"#text":"\n","marker":{"#tail":"\n","#text":"Walker, Amsler, 1986"},"location":{"#tail":"\n","#text":"Hillsdale, New Jersey."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"machine readable dictionaries i to attempt to provide a substan- tial lexicon with lexical entries containing rammatical information compatible with the grammatical frame- work employed by the analyser. The idea of using the machine readable source of a published ictionary has occurred to a wide range of researchers, for spelling correction, lexical analysis, thesaurus construction, and machine translation, to name but a few applications. Most of the work on automated dictionaries has concentrated on extracting lexical or other information, essentially by batch pro- cessing (eg. Amsler, 1981 ;Walker and Amsler, 1986), or Copyright 1987 by the Association for Computational Linguistics. Permission tocopy without fee all or part of this material is granted provided that he copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page. To copy otherwise, orto republish, requires afee and/or specific permission. 0362-613X/87/030203-218503.00 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 203 Bran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing on developing dictionary servers for office automation","@endWordPosition":"498","@position":"3412","annotationId":"T39","@startWordPosition":"495","@citStr":"Walker and Amsler, 1986"}},"title":{"#tail":"\n","#text":"The Use of Machine-Readable Dictionaries in Sublanguage Analysis. In:"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"D Walker"},{"#tail":"\n","#text":"A Amsler"}]}},{"date":{"#tail":"\n","#text":"1980"},"issue":{"#tail":"\n","#text":"2"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"rficial syntactic form to an underlying logical representation. For exam- ple, labelling believe(3) (Type 20Raising) indicates that this is a two place predicate and that, if believe(3) occurs with a syntactic direct object, as in (1) John believes the Earth to be round it will function as the logical subject of the predicate complement. Michiels proposed rules for doing this for infinitive complement codes; however there seems to be no principled reason not to extend this approach to computing the underlying relations in other types of VP as well as in cases of NP, AP and PP predication (see Williams (1980), for further discussion). The five rules which are applied to the grammar codes associated with a verb sense are ordered in a way which reflects the filtering of the verb sense through a series of syntactic tests. Verb senses with an \\[it + 15\\] code are classified as Subject Raising. Next, verb senses which contain a \\[V\\] or \\[X\\] code and one of \\[D5\\], \\[D5a\\], \\[D6\\] or \\[D6a\\] codes are classified as Object Equi. Then, verb senses which contain a \\[V\\] or \\[X\\] code and a IT5\\] or \\[T5a\\] code in the associated grammar code field, (but none of the D codes mentioned above), are classifie","@endWordPosition":"6221","@position":"38962","annotationId":"T40","@startWordPosition":"6220","@citStr":"Williams (1980)"}},"title":{"#tail":"\n","#text":"Predication."},"volume":{"#tail":"\n","#text":"11"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Williams, E.S., 1980 Predication. Linguistic Inquiry, 11(2): 203-238."},"journal":{"#tail":"\n","#text":"Linguistic Inquiry,"},"#text":"\n","pages":{"#tail":"\n","#text":"203--238"},"marker":{"#tail":"\n","#text":"Williams, 1980"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"E S Williams"}}},{"volume":{"#tail":"\n","#text":"5"},"#tail":"\n","date":{"#tail":"\n","#text":"1987"},"rawString":{"#tail":"\n","#text":"APPENDIX appear (3) chance (1) happen (3) seem (2) transpire (2) 2. Object Raising verbs (total number 53) adjudge (1) admit (3) allow (5) argue (3) assert (1) assume (1) avow (1) believe (3) betray (3) certify (2) declare (2) deem (1) deny (1) determine (1) discover (2) engage (4) feel (5) find (8) foreordain (1) guess (1) hold (9) judge (3) maintain (5) make out (5) mean (2) mind (2) notice (1) observe (1) order (6) perceive (1) predicate (1) prefer (1) preordain (1) presume (1) presume (2) proclaim (1) pronounce (2) pronounce (3) prove (1) recognize (3) remember (1) report (1) reveal (2) see (2) smell (2) smell (3) suppose (1) suppose (2) tell (6) think (2) understand (3) understand (4) warrant (2) 216 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 Bran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing 3. Subject Equi verbs ( to ta l  number  335) abide (1) account for (2) ache (2) acknowledge (1) adore (3) advocate (1) affect (1) afford (2) agree (2) aim (2) aim at (1) allude to (1) anticipate (1) appear (2) arrange (2) aspire (1) assent (1) attach to (3) attempt (1) avoid (1) awake (1) bear (5) bear (9) begin (1) beg (3) begrudge (1) bid fair (1) blanch (2) blink at (1) blush (2) bother (3) break off (1) burn (6) burst (3) burst out (1) bust out (3) care (1) cease (1) chance (1) choose (2) claim (4) clamour (2) clog (1) close (3) cloud (3) come (1) come (7) come before (1) come down to (1) come out against (1) come into (1) come on (1) come to (1) commence (1) compare with (1) compete (1) conceal (1) conceive of (1) concur (2) condescend (1) conduce to (1) confess (1) confess (2) confide (1) connive (1) consent (1) consider (1) consist in (1) conspire (1) conspire (2) contemplate (2) continue (1) continue (3) contract (1) contrive (1) contrive (3) could (1) covenant (1) cut out (4) cry out against (1) dare (1) dare (2) decide (2) decide on (1) declare against (1) declare for (1) decline (3) defend (3) defy (3) deign (1) delay (1) delight (2) delight in (1) demand (1) depose (2) deride (1) descend to (1) deserve (1) detest (1) disclaim (1) discontinue (1) discourage (2) disdain (2) dislike (1) do with (1,2) dread (1) duck out of (1) elect (2) endeavour (1) endure (1) enjoy (1) envisage (1) escape (3) essay (1) evade (2) excuse (1) expect (1) exult (1) exult over (2) fail (1,3) fall to (1) finish (1) fix (2) fix on (1) flick (2) forbear (1) forbid (2) forget (1) forget about (1) forswear (I) frown on (1) funk (1) get (3,11) get around to (1) get away with (1) get down to (1) get out of (1) get round to (1) give up (1) go (5) go about (2) go in for (2) go on (5) go with (3) go without (1) grow (5) grow out of (2) grow out of (3) grudge (1) guarantee (2) guard against (1) happen (2) hasten (2) hate (3) hesitate (1) hinge on (1) hit on (1) hope (1) incline (4) include (1) indulge in (1) inveigh against (1) involve (2) itch (3) jib at (1) justify (1) keep (11) keep from (2) keep on at (1) kick against (1) knock off (2) know about (1) lament (1) lead to (1) learn (1) leave (7) like (2) live by (1) loathe (1) long (1) look forward to (1) make (18) make up for (1) manage (2) mean (5) merit (1) militate magainst (1) miss (1,2,5) necessitate (1) need (1) neglect (1) neglect (2) negotiate (1) offer (3) omit (2) operate (2) own to (1) pant (4) pay for (1) pertain to (1) petition (2) pine (3) plan (1) play (3) play at (1) play at (2) pledge (1) plot (5) plump for (1) pooh-pooh (1) postpone (1) practise (4) practise (5) prate about (1) pray (1) preclude (1) prepare (3) prepare for (1) presume (4) pretend (1) pretend (2) pretend (4) proceed (1) profess (2) profit by (1) prohibit (1) promise (3) propose (1) propose (2) provide for (2) provide for (3) purport (1) purpose (1) put off (1) quit (1) recall (1) reckon on (2) recollect (1) refuse (1) regret (1) rejoice (1) relish (1) remember (2) repent (1) require (1) resent (1) resist (1) resist (2) resolve (1) resolve (2) resort to (1) result from (1) resume (1) revel in (1) revert to (1) rise above (1) risk (2) rue (1) say (5) scheme (1) scorn (1) scramble (2) scream (4) scruple (1) seek (3) seem (1) see (7) see about (1) see to (1) send (4) send away (2) send off (3) serve (5) set about (1) set out (2) shirk (1) should (1) shrink from (1) shudder (1) shun (1) sicken of (1) smile (2) stand (8) stand (12) stand for (2) start (1) stem from (1) stick (8) stoop (3) stoop to (1) stop (1) strive (1) subscribe to (1) suggest (2) swear (1) swear by (1) swear off (1) swear to (1) take to (2) take up (1) tend (2) think of (1) think of (5) threaten (2) train (3) tremble (3) trouble (3) try (1) try (2) try (3) undertake (2) unite (2) use (1) venture (2) venture (4) volunteer (1) volunteer (2) vote (1) vouchsafe (1) vow (1) wait (1) want (3) want (4) warrant (1) watch (3) witness to (1) wriggle out of (1) write (4) write back (1) yearn (1) Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 217 Bran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing 4. Object Equi verbs (total number 284) acknowledge (2) adjure (1) advise (1) aid (1) allow (2) allure (1) appoint (1) arrange for (1) ask (4) assign (4) assist (1) attribute to (1) authorize (1) badger (1) bargain for (1) beckon (1) behove (1) beseech (1) bestir (1) bid (2) bill (2) bludgeon into (1) bluff into (1) bribe (I) bring (2) bring (5) bring in (3) bully (1) buzz (3) cable (1) call on (2) catch (3) cause (1) caution (1) challenge (1) challenge (4) challenge (5) charge (5) charge with (1) charge with (2) come down on (1) command (1) commission (1) compel (1) condemn (3) condemn (4) condition (3) confess (3) conjure (1) connive at (1) consider (2) constrain (1) cop (1) counsel (1) couple with (1) cozen into (1) credit with (1) dare (5) debar from (1) decide (4) dedicate to (1) defy (2) delegate (2) depend on (1) depute (1) deputize (2) design (2) designate (2) detail (1) direct (3) doom (1) dragoon into (1) draw on (3) drive (8) egg on (1) embolden (1) employ (1) employ (2) employ in (1) empower (1) enable (1) enable (2) encourage (1) end in (1) engage (1) enggae in (1) entice (1) entitle (2) entreat (1) equip (2) esteem (2) excite (2) exhort (1) expect (5) fancy (1) fancy (3) figure on (1) find (1) find (6) fit (5) forbid (1) force (I) frighten into (1) frighten out of (2) get (4) get (8) give (17) give over to (1) goad into (1) groom (4) habituate to (1) hail as (1) harden to (1) hark at (1) hear (1) help (1) help (2) hunger (1) impel (1) implore (I) importune (1) impute to (l) incite (1) incline (3) induce (1) influence (1) inhibit from (1) inspire (1) instigate (2) instruct (2) instruct (3) intend (2) introduce to (1) inure to (1) inveigle into (1) invite (2) invite (3) itch for (1) join with in (1) keep (10) keep from (1) know (4) lead (2) lead on (1) legislate against (1) legislate for (1) let (1) let (2) let (3) let (4) let off (1) long for (I) look at (1) look to (2) lower (3) make (3) make (5) make (6) make (7) mean (4) motion (2) motion to (1) motivate (1) move (11) name (3) nominate (2,4) notify (1) obligate (1) oblige (1) order (1) organize (1) overhear (I) persuade (2) pester (1) petition (1) phone (1) pick (1) pick on (1) plead with (1) pledge (2) plume upon (1) pray (3) preclude from (1) predestinate (1) predestine (1) predetermine (1,3) predispose (1) preen on (1) prepare (1) prepare (5) prepare for (3) press (9) pressure (I) pressurize (1) prevail upon (1) prevent (1) prevent from (1) pride on (1) profess (3) program (1) programme (1) promise (1) prompt (i) prove (3) provoke (2) provoke into (1) push (3) push on (2) put down as (1) put down to (1) put off (1) put up to (1) reckon (1) reckon on (1) reduce to (4) reeducate (1) regard as (1) rely on (2) remember as (1) remind (1) represent (1.2) represent as (1) request (1) require (2) result in (1) schedule (1) school (1) seduce (2) select (1) send (1) send (2) send (3) set (4) set (8) shape (1) show (1) show (9) signal (2) sign (2) slate (2) spur (2) spy (3) steel (I) stop (2) suffer (4) summons (1) summon (I) supplicate (I) suppose (3) suspect (2) take (18) talk into (1) talk out of (1) tax with (1) teach (1) telegraph (1) telephone (1) telex (I) tell (2) tell (3) tell (5) tell off (2) tempt (1) tempt (2) thank (2) timetable (1) time (1) tip (1) tip off (2) train (2) trouble (2) unfit for (1) urge (2) want (2) warn (1) watch (1) watch (5) watch for (1) wean from (1) worry at (1) yearn for (1) 5. Equi verbs (total number 42) allow (1) allow for (1) approve of (1) ask (2) bank on (1) beg (2) calculate on (1) chance (2) choose (1) compensate for (1) countenance (1) count on (1) culminate in (1) desire (1) enjoin (1) hate (1) hate (2) hear about (1) hear of (1) help (4) imagine (1) intend (1) like (1) like (3) love (2) nag (1) need (1) pay (1) permit (1) prepare (4) qualify (1) race (3) recommend (2) rely on (1) save (4) see (6) sign (3) sign up (1) start (3) ' visualize (1) want (1) wish (5) 218 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987"},"journal":{"#tail":"\n","#text":"of"},"#text":"\n","marker":{"#tail":"\n","#text":"appear, 1987"},"title":{"#tail":"\n","#text":"(3) chance (1) happen (3) seem (2) transpire (2) 2. Object Raising verbs (total number 53) adjudge (1) admit (3) allow (5) argue (3) assert (1) assume (1) avow (1) believe (3) betray (3) certify (2) declare (2) deem (1) deny (1) determine (1) discover (2) engage (4) feel (5) find (8) foreordain (1) guess (1) hold (9) judge (3) maintain (5) make out (5) mean (2) mind (2) notice (1) observe (1) order (6) perceive (1) predicate (1) prefer (1) preordain (1) presume (1) presume (2) proclaim (1) pronounce (2) pronounce (3) prove (1) recognize (3) remember (1) report (1) reveal (2) see (2) smell (2) smell (3) suppose (1) suppose (2) tell (6) think (2) understand (3) understand (4) warrant (2) 216 Computational Linguistics, Volume 13, Numbers 3-4,"},"booktitle":{"#tail":"\n","#text":"Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 217 Bran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing 4. Object Equi verbs (total number"},"@valid":"false","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"APPENDIX appear"}}}]}}]}}
