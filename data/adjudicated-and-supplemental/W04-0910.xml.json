{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@confidence":"0.000003","#tail":"\n","reference":{"#tail":"\n","@confidence":"0.99972782278481","#text":"\nA. Abeille?. 2002. Une Grammaire Electronique du\nFranais. CNRS Editions.\nR. Barzilay and L. Lee. 2003. Learning to\nparaphrase: an unsupervised approahc using\nmutliple-sequence alignment. In Proceedings of\nNAACL-HLT.\nA. Black, S. Abney, D. Flickinger, C. Gdaniec,\nR. Grishman, P. Harrison, D. Hindel, R. INgria,\nF. Jelinek, F. Klaavans, M. Liberman, M. Mar-\ncus, S. Roukos, B. Santorini, and T. Strzalkowski.\n1991. A procedure for quantitatively comparing\nthe syntactic coverage of english grammars. In\nProceedings of teh 4th DARPA Speech and Natu-\nral Language Workshop.\nJ. Bos. 1995. Predicate logic unplugged. In Paul\nDekker and Martin Stokhof, editors, Proceedings\nof the 10th Amsterdam Colloquium, pages 133?\n142.\nM.H Candito. 1999. Un outil multilingue de gener-\nation de ltag : application au francais et a l?italien.\nTAL, 40(1).\nC.Johnson, C. Fillmore, M. Petruckand C. Baker,\nM. Ellsworth, and J. Ruppenhofer. 2002.\nFramenet: Theory and practice. Technical report,\nBerkeley.\nAnn Copestake and Dan Flickinger. 2000. An open\nsource grammar development environment and\nbroad-coverage English grammar using HPSG.\nIn Proceedings of the 2nd International Con-\nference on Language Resources and Evaluation,\nAthens, Greece.\nA. Copestake, D. Flickinger, I. Sag, and C. Pollard.\n1999. Minimal Recursion Semantics. An Intro-\nduction. Manuscript, Stanford University.\nA. Copestake, A. Lascarides, and D. Flickinger.\n2001. An algebra for semantic construction in\nconstraint-based grammars. In Proceedings of\nthe 39th Annual Meeting of the Association for\nComputational Linguistics, Toulouse, France.\nM. Dalrymple. 1999. Semantics and syntax in lexi-\ncal functional grammar. MIT Press.\nD. Flickinger, J. Nerbonne, I. Sag, and T. Wasow.\n1987. Towards evaluation of nlp systems. Tech-\nnical report, Hewlett-Packard Laboratories.\nC. Gardent and L. Kallmeyer. 2003. Semantic con-\nstruction in ftag. In Proceedings of EACL, Bu-\ndapest, Hungary.\nO. Glickman and I. Dagan. 2003. Identifying lexi-\ncal paraphrases from a single corpus: a case study\nfor verbs. In Proceedings of Recent Advances in\nNatural Language Processing.\nM. Gross. 1975. Me?thodes en syntase. Masson,\nParis.\nG. Gross. 1989. Les constructions converses du\nfrancais. CNRS Editions.\nDekang Lin and Patrick Pantel. 2001. Discovery of\ninference rules for question answering. Natural\nLanguage Engineering.\nD. Lin. 1998. Automatic retrieval and clustering of\nsimilar words. In Proceedings of ACL/COLING,\npages 768?774.\nI. Mel?c?uk. 1988. Paraphrase et lexique dans la\nthorie linguistique sens-texte. Lexique, 6:13?54.\nS. Oepen and D. Flickinger. 1998. Towards sys-\ntematic grammar profiling. test suite technology\n10 years after. Computer Speech and Language,\n12:411?435.\nF. Pereira, N. Tishby, and L. Lee. 1993. Distribu-\ntional clustering of english words. In Proceed-\nings of the ACL, pages 183?190.\nS. Ploux. 1997. Modlisation et traitement infor-\nmatique de la synonymi. Linguisticae Investiga-\ntiones, XXI(1).\nP. Saint-Dizier, 1999. Alternations and Verb Se-\nmantic Classes for French: analysis and class\nformation, chapter 5. Kluwer.\nY. Shinyanma, S. Sekine, K. Sudo, and R. Grish-\nman. 2002. Automatic paraphrase acquisition\nfrom news articles. In Proceedings of HLT.\n"},"@no":"0","listItem":[{"#tail":"\n","@confidence":"0.785662","#text":"\n(1) WordNet Verb Family; (2) Aspect; (3) Arite?\n"},{"#tail":"\n","@confidence":"0.633662","#text":"\n(9) a. the(x, person(x) ? the(y, car(y) ?\n"}],"figure":[{"#tail":"\n","@confidence":"0.966796785714286","#text":"\nParaphrastic Grammars\nClaire Gardent\nCNRS-LORIA, Nancy\nFrance\nClaire.Gardent@loria.fr\nMarilisa Amoia\nComputational Linguistics\nUniversity of Saarbruecken\nGermany\namoia@coli.uni-sb.de\nEvelyne Jacquey\nCNRS-ATILF, Nancy\nFrance\nEvelyne.Jacquey@atilf.fr\n"},{"#tail":"\n","@confidence":"0.8523184","#text":"\nfollowing:5\ncandidater candidature +pred-N\nposer sa +pred-vsupV\ncandidature\nbriguer +pred-V\n"},{"#tail":"\n","@confidence":"0.97893175","#text":"\nNPj\nJohn\nname(j,john)\nS\nNP?x1 VP\nV NP?x2 NPm\nloves Mary\nlove(x1,x2) name(m,mary)\n"},{"#tail":"\n","@confidence":"0.992969888888889","#text":"\nS\nGNG ? V GAdvM ?\ncoute\nGNX S:Commerce GAdvY\nD NX ? (S,G):goods cher\nla (S,M):money Y:High\nNX\ncroisiere\nX:Cruise\n"},{"#tail":"\n","@confidence":"0.992736545454545","#text":"\nS\nGNG ? VSup? GN\na D? NGMGNX\ncout\nD NX ? D S:Commerce\nla un (S,M):money\nNX (S,G):goods\ncroisiere N\nX:Cruise ? NY Adj\neleve\nY:High\n"},{"#tail":"\n","@confidence":"0.98980925","#text":"\nSGNY ? Cop GAdjY ?\nGNY est eleve\nD NY ? Y:High\nle\nNM\nN GP\ncout P? GNG ?\nS:Commerce\n(S,M):money P GNX\n(S,G):goods de D NX\nla croisiere\nX:Cruise\n"}],"bodyText":[{"#tail":"\n","@confidence":"0.996724857142857","#text":"\nArguably, grammars which associate natural lan-\nguage expressions not only with a syntactic but\nalso with a semantic representation, should do so in\na way that capture paraphrasing relations between\nsentences whose core semantics are equivalent. Yet\nexisting semantic grammars fail to do so. In this pa-\nper, we describe an ongoing project whose aim is\nthe production of a ?paraphrastic grammar? that is,\na grammar which associates paraphrases with iden-\ntical semantic representations. We begin by propos-\ning a typology of paraphrases. We then show how\nthis typology can be used to simultaneously guide\nthe development of a grammar and of a testsuite de-\nsigned to support the evaluation of this grammar.\n"},{"#tail":"\n","@confidence":"0.992556261363636","#text":"\nA salient feature of natural language is that it allows\nparaphrases that is, it allows different verbalisations\nof the same content. Thus although the various ver-\nbalisations in (1) may have different pragmatic or\ncommunicative values (with respect for instance to\ntopicalisation, presuppositions or focus/ground par-\ntitioning), they all share a core semantic content, the\ncontent approximated by a traditional montagovian\ncompositional semantics.\n(1) a. La croisie`re cou?te cher.\nLit. the cruse is expensive\nb. Le cou?t de la croisie`re est e?leve?.\nLit. the cost of the cruse is high\nc. La croisie`re a un cou?t e?leve?\nLit. the cruse has a high cost\nLinguists have long noticed the pervasiveness of\nparaphrases in natural language and attempted to\ncaracterise it. Thus for instance Chomsky?s ?trans-\nformations? capture the relation between one core\nmeaning (a deep structure in Chomsky?s terms) and\nseveral surface realisations (for instance, between\nthe passive and the active form of the same sen-\ntence) while (Mel?c?uk, 1988) presents sixty para-\nphrastic rules designed to account for paraphrastic\nrelations between sentences.\nMore recently, work in information extraction\n(IE) and question answering (QA) has triggered a\nrenewed research interest in paraphrases as IE and\nQA systems typically need to be able to recognise\nvarious verbalisations of the content. Because of the\nlarge, open domain corpora these systems deal with,\ncoverage and robustness are key issues and much on\nthe work on paraphrases in that domain is based on\nautomatic learning techniques. For instance, (Lin\nand Pantel, 2001) acquire two-argument templates\n(inference rules) from corpora using an extended\nversion of the distributional analysis in which paths\nin dependency trees that have similar arguments are\ntaken to be close in meaning. Similarly, (Barzi-\nlay and Lee, 2003) and (Shinyanma et al, 2002)\nlearn sentence level paraphrase templates from a\ncorpus of news articles stemming from different\nnews source. And (Glickman and Dagan, 2003) use\nclustering and similarity measures to identify sim-\nilar contexts in a single corpus and extract verbal\nparaphrases from these contexts.\nSuch machine learning approaches have known\npros and cons. On the one hand, they produce large\nscale resources at little man labour cost. On the\nother hand, the degree of descriptive abstraction of-\nfered by the list of inference or paraphrase rules they\noutput is low.\nWe chose to investigate an alternative research di-\nrection by aiming to develop a ?paraphrastic gram-\nmar? that is, a grammar which captures the para-\nphrastic relations between linguistic structures1 .\nBased on a computational grammar that associates\nnatural language expressions with both a syntactic\nand a semantic representation, a paraphrastic gram-\n1As we shall briefly discuss in section 4, the grammar is de-\nveloped with the help of a meta-grammar (Candito, 1999) thus\nensuring an additional level of abstraction. The metagrammar\nis an abstract specification of the linguistic properties (phrase\nstructure, valency, realisation of grammatical functions etc.)\nencoded in the grammar basic units. This specification is then\ncompiled to automatically produce a specific grammar.\nmar is a grammar that moreover associates para-\nphrases with the same semantic representation. That\nis, contrary to machine learning based approaches\nwhich relate paraphrases via sentence patterns, the\nparaphrastic grammar approach relates paraphrases\nvia a common semantic representation. In this way,\nthe paraphrastic approach provides an interesting al-\nternative basis for generation from conceptual rep-\nresentations and for the inference-based, deep se-\nmantic processing of the kind that is ultimately\nneeded for high quality question answering.\nSpecifically, we aim at developing a paraphras-\ntic grammar for French, based on the Tree Adjoin-\ning Grammar (TAG) developed for this language by\nAnne Abeille? (Abeille?, 2002).\nThe paper is structured as follows. We start\nby proposing a typology of the paraphrastic means\nmade available by natural language. We then show\nhow this typology can be used to develop a testsuite\nfor developing and evaluating a paraphrastic gram-\nmar. Finally, we highlight some of the issues arising\nwhen developing a paraphrastic grammar.\n"},{"#tail":"\n","@confidence":"0.969727464285715","#text":"\nA paraphrastic grammar should capture the vari-\nous means made available by natural language to\nsupport paraphrasing. But what are those means?\nWe distinguish here between three main classes\nnamely, parallel, shuffling and definitional para-\nphrastic means.\nParallel paraphrastic means. A parallel para-\nphrase can hold either between two non predica-\ntive lexical units (words or multi word expressions)\nmodulo negation or between two predicative units\nof identical arity. If it holds between predicative\nunits, the mapping linking grammatical functions\n(subject, objects, etc.) and thematic roles (agent,\ntheme, etc.) must be the same. Depending on\nwhether or not negation is involved, semantic equiv-\nalence will futhermore obtain either through syn-\nonymy or through antonymy.\nAs illustrated in Figure 1, synonymy can be fur-\nther divided in a number of cases depending on var-\nious morphological and syntactic criteria. The clas-\nsification criteria used involve :\n? Syntactic category: Do the synonyms have the\nsame syntactic category?\n? Morphological relatedness: Do the synonyms\ncontain words that are morphologically re-\nlated?\n? Form: Are the synonyms simple lexical units\nor multi word expressions?\nAs for antonymy, we distinguish between trans\nand intracategorial antonymy:\n(2) Jean est lent/Jean n?est pas rapide.\nJean is slow/Jean is not fast.\nlent/rapide, intracategorial\nJean a cesser de fumer/Jean ne fume plus.\nJean has stopped smoking/Jean smokes no\nmore.\ncesse de/ne . . . plus, transcategorial\nShuffling paraphrastic means. When a seman-\ntic equivalence holds between predicative units with\ndistinct grammatical functions/thematic role link-\ning, we speak of shuffling paraphrases. Such para-\nphrases can be realised either by means of argument\npreserving alternations (in the sense of Beth Levin,\ncf. (4)) or using a converse construction (cf. 3)2.\n(3) a Jean donne un livre a` Marie.\nJean gives a book to Marie.\nMarie rec?oit un livre de Jean\nJean receives a book from Marie.\nb Jean est le parent de Marie.\nJean is the parent of Marie.\nMarie est l?enfant de Jean.\nMarie is the child of Jean.\n(4) a. Cette cle? ouvre le coffre fort\nThis key opens the safe.\nLe coffre fort s?ouvre avec cette cle?\nThe safe opens with this key.\nb. Jean mange une pomme\nJean eats an apple.\nune pomme est mange?e par Jean\nAn apple is eaten by Jean.\nIl a e?te? mange? une pomme par Jean.\nThere has been an apple eaten by Jean.\nc. L?eau remplit la cruche\nThe water fills the jug .\nLa cruche se remplit d?eau\nThe jug fills with water.\nOn remplit la cruche d?eau\nOne fills the jug with water.\nd. Le laboratoire fusionne avec l?entreprise\nThe laboratory merges with the firm.\nle laboratoire et l?entreprise fusionnent\nThe laboratory and the firm merge.\ne. Jean frappe le mur avec un baton\nJean hit the wall with a stick.\n2Obviously, the english translations do not reflect the ac-\nceptability of the french equivalent.\nSame synt. Same morph. Form Example\ncategories family\nyes no word/word policier, flic\nyes yes word/mwe conseiller, donner conseil\nyes no word/mwe s?exprimer sur, donner son avis sur\nyes no mwe/mwe donner carte blanche a`, laisser tout pouvoir\nno yes word/word construire, construction\nno no word/word candidature a`, briguer\n"},{"#tail":"\n","@confidence":"0.98869864","#text":"\nJean frappe le baton sur le mur.\nJean hit the stick on the wall.\nf. Je fournis des livres a` Jean\nI provide books to Jean.\nJe fournis Jean en livre\nI provide Jean with books.\nDefinitional paraphrastic means. Third, we call\n?definitional paraphrases? semantic equivalences\nthat hold between a lexical unit and a phrase con-\nsisting of more than one lexical unit. The phrase\nin this case, defines the meaning of the lexical unit.\nSince definitions are notoriously difficult to decide\nupon, we restrict ourselves here to such definitions\nas can be given by derivational morphology that is,\ndefinitions based on a word that is morphologically\nlinked to the definiendum (cf. 5).\n(5) a. Le conducteur de la BMW est chauve\nThe driver of the BMW is bald.\nLa personne qui conduit la BMW est\nchauve\nThe person who drives the BMW is bald.\nb. Cet outil est parame?trable\nThis tool is parameterisable.\nCet outil peut e?tre parame?tre?\nThis tool can be parameterised.\n"},{"#tail":"\n","@confidence":"0.942202310344828","#text":"\nBased on the above typology, we can systematically\nconstruct a testsuite for developing and evaluating\na paraphrastic grammar. Indeed, when developing\na grammar, it is necessary to have some means of\nassessing both the coverage of the grammar (does\nit generate all the sentences of the described lan-\nguage?) and its degree of overgeneration (does it\ngenerate only the sentences of the described lan-\nguage?) While corpus driven efforts along the PAR-\nSEVAL lines (Black et al, 1991) are good at giving\nsome measure of a grammar coverage, they are not\nsuitable for finer grained analysis and in particular,\nfor progress evaluation, regression testing and com-\nparative report generation. Another known method\nconsists in developing and using a test suite that is,\na set of negative and positive items against which\nthe grammar can be systematically tested. For en-\nglish, there is for instance the 15 year old Hewlett-\nPackard test suite, a simple text file listing test sen-\ntences and grouping them according to linguistics\nphenomena (Flickinger et al, 1987); and more re-\ncently, the much more sophisticated TSNLP (Test\nSuite for Natural Language Processing) which in-\ncludes some 9500 test items for English, French and\nGerman, each of them being annotated with syntac-\ntic and application related information (Oepen and\nFlickinger, 1998).\nYet because they do not take into account the se-\nmantic dimension, none of these tools are adequate\nfor evaluating the paraphrastic power of a gram-\nmar. To remedy this, we propose to develop a para-\nphrase test suite based on the paraphrase typology\ndescribed in the previous section. In such a testsuite,\ntest items pair a semantic representation with a set\nof paraphrases verbalising this semantics. The con-\nstruction and annotation of the paraphrases reflects\nthe paraphrase typology. In a first phase, we concen-\ntrate on simple, non-recursive predicate/argument\nstructure. Given such a structure, the construction\nand annotation of a test item proceeds as follows.\nFirst, a ?canonical verbalisation? is produced in\nwhich the predicate is realised by the ?canonical\nverb? for the given concept3 and the arguments by\nthe canonical nouns.\nNext variants are produced by systematically try-\ning to create parallel, shuffling and definitional para-\nphrases. Each of the variant is furthermore anno-\ntated with labels caracterising the type of paraphras-\ning involved. Here is an example. Suppose the input\nsemantics is:\napply(e), agent(e,jean), theme(e,job), failure(e)\nfor which the canonical verbalisation is:\n(6) Jean a candidate? sans succe`s sur le poste\nJean has applied in vain for the job.\n3Like in a thesaurus, we assume that amongst a set of syn-\nonyms, one lexical unit is ?canonical? and the others not. The\ncanonical unit is sometimes called a descriptor.\nThe parallel synonyms4 that can be used are the\n"},{"#tail":"\n","@confidence":"0.955542485714286","#text":"\nsans succe`s e?chouer +mod-V\ne?tre sans succe`s +mod-beAdv\nne pas e?tre retenu +mod-Vanton\nFor shuffling synonymy, two alternations are\navailable: the active/passive alternation for ?poser?\nand the active/locative one for ?e?chouer?. There is\nno converse construction. Neither is there any defi-\nnition given by derivational morphology for any of\nthe terms occurring in the canonical verbalisation.\nBased on these facts, the following variants and an-\nnotations can be constructed.\n(7) a. Jean a brigue? le poste sans succe`s\nJean has asked for the job in vain.\n+pred-Vsyn\nb. Jean a pose? sa candidature sur le poste sans\nsucce`s\nJean has submitted his application for the\njob in vain.\n+pred-vsupN\nc. La candidature pose?e par Jean sur le poste\na e?te? sans succe`s\nThe application submitted by Jean for the\njob was in vain.\n+pred-partAdj, +mod-beAdv\nd. La candidature pose?e par Jean sur le poste\na e?choue?\nThe application submitted by Jean for the\njob failed.\n+pred-partAdj, +mod-V\ne. La candidature de Jean sur le poste a e?te?\nsans succe`s\nJean?s application for the job was in vain.\n+pred-N, +mod-beAdv\nf. La candidature de Jean sur le poste n?a pas\ne?te? retenue\n4As has been abundantly argued by linguists, real synonyms\nare extremely rare. By synonyms, we in fact refer here to the\nnotion of quasi-synonyms used for instance in WordNet that is,\nwords that are interchangeable in a restricted set of contexts.\n5The labels are the ones used for annotation. They carac-\nterise variations with respect to the canonical realisation. For\ninstance, +pref-N indicates that the main predicate (realised by\na verb in the canonical verbalisation) is realised as a noun.\nJean?s application for the job was not suc-\ncessful.\n+pred-N, +mod-Vanton\ng. La candidature de Jean sur le poste a\ne?choue?\nJean?s application for the job failed.\n+pred-N, +mod-V\nh. Jean a e?choue? dans sa candidature sur le\nposte.\nJean failed in his application for the job.\n+pred-N, +mod-V-altLoc\nThus the typology of paraphrastic means help\nguide the construction of the various paraphrases\ncontained in a single item. There remains the ques-\ntion of how to choose the particular items of the\ntestsuite. In other words: which semantic repre-\nsentations should we use to populate the test suite\nand on the basis of which criteria? The basic aim\nhere is to cover the various types of possible seman-\ntic combinations and the constraints they are sub-\nject to at the syntactic (realisation) level. If, as Beth\nLevin argues, syntax is a reflex of semantic proper-\nties, then different semantic contents should be sub-\nject to varying syntactic constraints and the test suite\nought to cover these various types of interactions.\nAccordingly test items are constructed whose main\npredicate vary along the following dimensions :\n"},{"#tail":"\n","@confidence":"0.973902666666667","#text":"\nThat is, items are constructed for each word-\nNet family (the french WordNet counts roughly 170\nsuch families). Within a given family, we attempt\nto find examples with distinct aspectual categories\n(state, accomplishment and process). Finally, given\na WN family and an aspectual category, items will\nvary with respect to the arity of the main predicate\nand the types of their arguments e.g., predicates of\narity one (run, cost, sleep), of arity two with non\npropositional arguments (eat, hit, dug), of arity two\nwith a propositional argument (say, promise etc.),\netc.\n"},{"#tail":"\n","@confidence":"0.950108575757576","#text":"\n?Semantic grammars? already exist which describe\nnot only the syntax but also the semantics of nat-\nural language. Thus for instance, (Copestake and\nFlickinger, 2000; Copestake et al, 2001) describes\na Head Driven Phrase Structure Grammar (HPSG)\nwhich supports the parallel construction of a phrase\nstructure (or derived) tree and of a semantic repre-\nsentation and (Dalrymple, 1999) show how to equip\nLexical Functional grammar (LFG) with a glue se-\nmantics.\nThese grammars are both efficient and large scale\nin that they cover an important fragment of the nat-\nural language they describe and can be processed by\nparsers and generators in almost real time. For in-\nstance, the LFG grammar parses sentences from the\nWall Street Journal and the ERG HPSG grammar\nwill produce semantic representations for about 83\nper cent of the utterances in a corpus of some 10\n000 utterances varying in length between one and\nthirty words. Parsing times vary between a few ms\nfor short sentences and several tens of seconds for\nlonger ones.\nNonetheless, from a semantics viewpoint, these\ngrammars fail to yield a clear account of the para-\nphrastic relation. Here is a simple example illustrat-\ning this shortcoming. Suppose we parse the follow-\ning paraphrases where a lexical definition (driver ?\nperson who drives) is involved:\n(8) a. The person who drives the car is mad.\nb. The driver of the car is mad.\nWhen given these sentences, the LKB system\nbased on the ERG HPSG grammar returns semantic\nrepresentations which can be sketched as follows6:\n"},{"#tail":"\n","@confidence":"0.938491277777778","#text":"\nIn other words, the grammar associates with\nthese paraphrases semantic representations which\nare very different. It could be argued of course\nthat although these representations are syntactically\ndistinct, they can be inferred, given the appropri-\nate knowledge, to be semantically equivalent. But\na solution that avoids placing such extra burden on\nthe inferencing component is obviously better. In\nshort, one important shortcoming of existing large\nscale semantic grammars is that they do not assign\nsemantically equivalent sentences, the same seman-\ntic representation.\nBy contrast, we propose to develop a grammar\nwhich whereever possible assigns identical seman-\ntic representations to paraphrases and whose devel-\n6These semantic representations have been simplified for\nbetter readibility. The real representations output by the LKB\nare the following:\n"},{"#tail":"\n","@confidence":"0.6840255","#text":"\nopment is based both on semantic and syntactic con-\nsiderations.\n"},{"#tail":"\n","@confidence":"0.99854454","#text":"\nOur grammar is couched within the Feature-Based\nTree Adjoining grammar (FTAG) formalism. An\nFTAG consists of a set of (auxiliary or initial) ele-\nmentary trees and two tree composition operations:\nsubstitution and adjunction. Substitution is the stan-\ndard tree operation used in phrase structure gram-\nmars while adjunction is an operation which inserts\nan auxiliary tree into a derived tree. To account for\nthe effect of these insertions, two feature structures\n(called top and bottom) are associated with each\ntree node in FTAG. The top feature structure en-\ncodes information that needs to be percolated up the\ntree should an adjunction take place. In contrast, the\nbottom feature structure encodes information that\nremains local to the node at which adjunction takes\nplace.\nThe language chosen for semantic representa-\ntion is a flat semantics along the line of (Bos,\n1995; Copestake et al, 1999; Copestake et al,\n2001). However because we are here focusing on\nparaphrases rather than fine grained semantic dis-\ntinctions, the underspecification and the descrip-\ntion of the scope relations permitted by these se-\nmantics will here be largely ignored and flat se-\nmantics will be principally used as a convenient\nway of describing predicate/arguments and modi-\nfiers/modified relationships. Thus the semantic rep-\nresentations we assume are simply set of literals of\nthe form P n(x1, . . . , xn) where P n is a predicate\nof arity n and xi is either a constant or a unifica-\ntion variable whose value will be instantiated during\nprocessing.\nSemantic construction proceeds from the derived\ntree (Gardent and Kallmeyer, 2003) rather than ?\nas is more common in TAG ? from the derivation\ntree. This is done by associating each elementary\ntree with a semantic representation and by deco-\nrating relevant tree nodes with unification variables\nand constants occuring in associated semantic rep-\nresentation. The association between tree nodes and\nunification variables encodes the syntax/semantics\ninterface ? it specifies which node in the tree pro-\nvides the value for which variable in the final se-\nmantic representation.\nAs trees combine during derivation, (i) variables\nare unified ? both in the tree and in the associated\nsemantic representation ? and (ii) the semantics of\nthe derived tree is constructed from the conjunction\nof the semantics of the combined trees. A simple\nexample will illustrate this.\n"},{"#tail":"\n","@confidence":"0.997886461538461","#text":"\nSuppose the elementary trees for ?John?, ?loves?\nand ?Mary? are as given in Fig. 2 where a downar-\nrow (?) indicates a substitution node and Cx/Cx ab-\nbreviate a node with category C and a top/bottom\nfeature structure including the feature-value pair {\nindex : x}. On substitution, the root node of the tree\nbeing substituted in is unified with the node at which\nsubstitution takes place. Further, when derivation\nends, the top and bottom feature structures of each\nnode in the derived tree are unified. Thus in this\ncase, x1 is unified with j and x2 with m. Hence, the\nresulting semantics is:\nlove(j, m), name(j, john), name(m, mary)\n"},{"#tail":"\n","@confidence":"0.996481083333333","#text":"\nrepresentation language\nLet us now come back to the paraphrases given in\nexample 1. To produce an identical semantic rep-\nresentation of these three sentences, we first need to\nensure that synonyms be assigned the same concept.\nThat is, we need to fix a concept inventory and to\nuse this inventory in a consistent way in particular,\nby assigning synonyms the same concept.\nFor non predicative units, we use WordNet synset\nnumbers or when working within a restricted do-\nmain with a well defined thesaurus, the descriptors\nof that thesaurus.\nTo represent the semantics of predicative units,\nwe use FrameNet inventory of frames and frame el-\nements (C.Johnson et al, 2002). FrameNet is an on-\nline lexical resource for English based on the prin-\nciples of Frame Semantics. In this approach, a word\nevokes a frame i.e., a simple or a complex event, and\neach frame is associated with a number of frame el-\nements that is, a number of participants fulfilling a\ngiven role in the frame. Finally each frame is as-\nsociated with a set of target words, the words that\nevoke that frame.\nThus FrameNet associates synonyms with an\nidentical concept namely, the frame evoked by those\nsynonyms. We make use of this feature and instead\nof choosing our own semantic predicates and re-\nlations, draw on FrameNet frames and frame ele-\nments. For instance, the paraphrases in example 1\nare taken to evoke the FrameNet COMMERCE frame\nand to instantiate two of its frame elements namely,\nGOODS and MONEY. The semantic representation\nthey will be assigned will therefore be the follow-\ning:\ncommerce(e,g,m), cruise(g), goods(e,g), high(m),\nmoney(e,m)\n"},{"#tail":"\n","@confidence":"0.999435802197802","#text":"\nGiven the basic signature provided by FrameNet\n(and any extension of it that will prove necessary\nto account for the data), the grammar must then\nspecify a compositional semantics which will de-\nrive identical representations for the types of para-\nphrases captured by our typology. In essence, this\nimplies assigning the same semantic representations\nto synonyms, converses and alternations. Con-\ncretely, this involves two different subtasks : first,\na modeling of the synonymic relation between syn-\ntactically divergent constructs (e.g., between a pred-\nicative noun, a support verb construction and a verb)\nand second, the identification of the synonymic sets\n(which are the words and multi word expressions\nthat stand in a parallel, shuffling or definitional para-\nphrastic relation?).\nModeling intercategorial synonymic links. A\nfirst investigation of Anne Abeille??s TAG for French\nsuggests that modeling the synonymic relations\nacross syntactic constructs is reasonably straightfor-\nward. For instance, as Figures 3, 4 and 5 show, the\nFTAG trees assigned on syntactic grounds by Anne\nAbeille? FTAG to predicative nouns, support verb\nconstructions and transitive verbs can be equiped\nwith a flat semantics in such a way as to assign\nthe three sentences in 1 a unique semantic rep-\nresentation namely the one given above. Gener-\nally, the problem is not so much to state the cor-\nrespondances between synonymic but syntactically\ndifferent constructs as to do this in a general way\nwhile not overgeneralising. To address this prob-\nlem, we are currently working on developing a\nmetagrammar in the sense of (Candito, 1999). This\nmetagrammar allows us to factorise both syntac-\ntic and semantic information. Syntactic informa-\ntion is factorised in the usual way. For instance,\nthere will be a class NOVN1 which groups together\nall the initial trees representing the possible syntac-\ntic configurations in which a transitive verb with\ntwo nominal arguments can occur. But addition-\nnally there will be semantic classes such as, ?bi-\nnary predicate of semantic type X? which will be\nassociated with the relevant syntactic classes for in-\nstance, NOVN1 (the class of transitive verbs with\nnominal arguments), BINARY NPRED (the class of\nbinary predicative nouns), NOVSUPNN1 , the class\nof support verb constructions taking two nominal\narguments. By further associating semantic units\n(e.g., ?cost?) with the appropriate semantic classes\n(e.g., ?binary predicate of semantic type X?), we\ncan in this way capture both intra and intercategorial\nparaphrasing links in a general way.\nConstructing paraphrastic sets. Depending on\nthe type of paraphrastic means involved, construct-\ning a paraphrastic set (the set of all lexical items re-\nlated by a paraphrastic link be it parallel, shuffling\nor definitional) is more or less easy as resources for\nthat specific means may or may not be readily avail-\nable.\nCases of intracategorial synonymy are relatively\nstraigthtforward as several electronic synonym dic-\ntionnaries for french are available (Ploux, 1997).\nMulti word expressions however remain a problem\nas they are often not or only partially included in\nsuch dictionnaries. For these or for a specific do-\nmain, basic synonymic dictionaries can be comple-\nmented using learning methods based on distribu-\ntional similarity (Pereira et al, 1993; Lin, 1998).\ntechniques.\nFor intercategorial synonymy involving a deriva-\ntional morphology link, some resources are avail-\nable which however are only partial in that they only\nstore morphological families that is, sets of items\nthat are morphologically related. Lexical semantics\ninformation still need to be included.\nIntercategorial synonymy not involving a deriva-\ntional morphology link has been little studied and\nresources are lacking. However as for other types\nof synonymy, distributional analysis and clustering\ntechniques can be used to develop such resources.\nFor shuffling paraphrases, french alternations are\npartially described in (Saint-Dizier, 1999) and a re-\nsource is available which describes alternation and\nthe mapping verbs/alternations for roughly 1 700\nverbs. For complementing this database and for\nconverse constructions, the LADL tables (Gross,\n1975) can furthermore be resorted to, which list\ndetailed syntactico-semantic descriptions for 5 000\nverbs and 25 000 verbal expressions. In particu-\nlar, (Gross, 1989) lists the converses of some 3 500\npredicative nouns.\n"},{"#tail":"\n","@confidence":"0.983700222222222","#text":"\nBesides the development and evaluation of a core\nparaphrastic testsuite and grammar for French, we\nplan to investigate two main issues. First, how pre-\ncisely should a metagrammar be structured to best\ndescribe a paraphrastic grammar? And second: is\nit possible to extract from the kind of inference\nrules automatically derived in machine learning ap-\nproach, information that can be used to specify this\nmetagrammar?\n"},{"#tail":"\n","@confidence":"0.988006333333333","#text":"\nThis paper is based upon work suppported in part by\nthe project ?Des connaissances a` leurs re?alisation en\nlangue? within the CNRS funded TCAN program.\n"}],"#text":"\n","sectionHeader":[{"#tail":"\n","@confidence":"0.892897","@genericHeader":"abstract","#text":"\nAbstract\n"},{"#tail":"\n","@confidence":"0.998247","@genericHeader":"introduction","#text":"\n1 Introduction\n"},{"#tail":"\n","@confidence":"0.965971","@genericHeader":"method","#text":"\n2 Classifying paraphrases\n"},{"#tail":"\n","@confidence":"0.552568","@genericHeader":"method","#text":"\n3 Developing a paraphrase testsuite\n"},{"#tail":"\n","@confidence":"0.908548","@genericHeader":"method","#text":"\n4 A paraphrastic grammar\n"},{"#tail":"\n","@confidence":"0.99644","@genericHeader":"evaluation","#text":"\n5 Conclusion\n"},{"#tail":"\n","@confidence":"0.9631","@genericHeader":"conclusions","#text":"\n6 Acknowledgments.\n"},{"#tail":"\n","@confidence":"0.945299","@genericHeader":"references","#text":"\nReferences\n"}],"equation":[{"#tail":"\n","@confidence":"0.992527","#text":"\ndrive(e,x,y) ? mad(x)))\na. the(y, car(y) ? the(x, driver(x,y) ? of(x,y))\n? mad(x))\n"},{"#tail":"\n","@confidence":"0.915841833333333","#text":"\nprpstn(def(x,person(x)?prpstn(def(y,car(y),\ndrive(e1,v1,x,y,v2),v3)), mad(e2,x,v4),v5)\nprpstn(def(x,person(x)?prpstn(def(y,car(y),\ndrive(e1,v1,x,y,v2),v3)), mad(e2,x,v4),v5)\nprpstn(def(y,car(y)?prpstn(def(x, driver(x,y) ? of(e1,x,y,v1),\nmad(e2,x,v2,v3)))))\n"}],"subsectionHeader":[{"#tail":"\n","@confidence":"0.993968","#text":"\n4.1 Linguistic framework\n"},{"#tail":"\n","@confidence":"0.9489","#text":"\n4.2 The signature of the semantic\n"},{"#tail":"\n","@confidence":"0.989928","#text":"\n4.3 Capturing paraphrastic relations\n"}],"figureCaption":[{"#tail":"\n","@confidence":"0.896179","#text":"\nFigure 1: Synonymy\n"},{"#tail":"\n","@confidence":"0.997505","#text":"\nFigure 2: ?John loves Mary?\n"},{"#tail":"\n","@confidence":"0.968515","#text":"\nFigure 3: La croisie`re cou?te cher\n"},{"#tail":"\n","@confidence":"0.999768","#text":"\nFigure 4: La croisie`re a un cou?t e?leve?\n"},{"#tail":"\n","@confidence":"0.999254","#text":"\nFigure 5: Le cou?t de la croisie`re est e?leve?\n"}]}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.097324","#tail":"\n","@no":"0","address":[{"#tail":"\n","@confidence":"0.510823","#text":"France"},{"#tail":"\n","@confidence":"0.994244","#text":"Germany"},{"#tail":"\n","@confidence":"0.868181","#text":"France"}],"#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.895332","#text":"CNRS-LORIA, Nancy"},{"#tail":"\n","@confidence":"0.9977805","#text":"Computational Linguistics University of Saarbruecken"},{"#tail":"\n","@confidence":"0.840689","#text":"CNRS-ATILF, Nancy"}],"author":[{"#tail":"\n","@confidence":"0.996921","#text":"Claire Gardent"},{"#tail":"\n","@confidence":"0.977878","#text":"Marilisa Amoia"},{"#tail":"\n","@confidence":"0.649499","#text":"Evelyne Jacquey"}],"abstract":{"#tail":"\n","@confidence":"0.974567066666667","#text":"Arguably, grammars which associate natural language expressions not only with a syntactic but also with a semantic representation, should do so in a way that capture paraphrasing relations between sentences whose core semantics are equivalent. Yet existing semantic grammars fail to do so. In this paper, we describe an ongoing project whose aim is the production of a ?paraphrastic grammar? that is, a grammar which associates paraphrases with identical semantic representations. We begin by proposing a typology of paraphrases. We then show how this typology can be used to simultaneously guide the development of a grammar and of a testsuite designed to support the evaluation of this grammar."},"title":{"#tail":"\n","@confidence":"0.999913","#text":"Paraphrastic Grammars"},"email":[{"#tail":"\n","@confidence":"0.394043","#text":"Claire.Gardent@loria.fr"},{"#tail":"\n","@confidence":"0.99903","#text":"amoia@coli.uni-sb.de"},{"#tail":"\n","@confidence":"0.980954","#text":"Evelyne.Jacquey@atilf.fr"}]}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"A. Abeille?. 2002. Une Grammaire Electronique du Franais. CNRS Editions."},"#text":"\n","marker":{"#tail":"\n","#text":"Abeille, 2002"},"publisher":{"#tail":"\n","#text":"CNRS Editions."},"title":{"#tail":"\n","#text":"Une Grammaire Electronique du Franais."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"A Abeille"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"R. Barzilay and L. Lee. 2003. Learning to paraphrase: an unsupervised approahc using mutliple-sequence alignment. In Proceedings of NAACL-HLT."},"#text":"\n","marker":{"#tail":"\n","#text":"Barzilay, Lee, 2003"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ed research interest in paraphrases as IE and QA systems typically need to be able to recognise various verbalisations of the content. Because of the large, open domain corpora these systems deal with, coverage and robustness are key issues and much on the work on paraphrases in that domain is based on automatic learning techniques. For instance, (Lin and Pantel, 2001) acquire two-argument templates (inference rules) from corpora using an extended version of the distributional analysis in which paths in dependency trees that have similar arguments are taken to be close in meaning. Similarly, (Barzilay and Lee, 2003) and (Shinyanma et al, 2002) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source. And (Glickman and Dagan, 2003) use clustering and similarity measures to identify similar contexts in a single corpus and extract verbal paraphrases from these contexts. Such machine learning approaches have known pros and cons. On the one hand, they produce large scale resources at little man labour cost. On the other hand, the degree of descriptive abstraction offered by the list of inference or paraphrase rules they output is low. We chose to investigate","@endWordPosition":"424","@position":"2822","annotationId":"T1","@startWordPosition":"420","@citStr":"Barzilay and Lee, 2003"}},"title":{"#tail":"\n","#text":"Learning to paraphrase: an unsupervised approahc using mutliple-sequence alignment."},"booktitle":{"#tail":"\n","#text":"In Proceedings of NAACL-HLT."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"R Barzilay"},{"#tail":"\n","#text":"L Lee"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1991"},"rawString":{"#tail":"\n","#text":"A. Black, S. Abney, D. Flickinger, C. Gdaniec, R. Grishman, P. Harrison, D. Hindel, R. INgria, F. Jelinek, F. Klaavans, M. Liberman, M. Marcus, S. Roukos, B. Santorini, and T. Strzalkowski. 1991. A procedure for quantitatively comparing the syntactic coverage of english grammars. In Proceedings of teh 4th DARPA Speech and Natural Language Workshop."},"#text":"\n","marker":{"#tail":"\n","#text":"Black, Abney, Flickinger, Gdaniec, Grishman, Harrison, Hindel, INgria, Jelinek, Klaavans, Liberman, Marcus, Roukos, Santorini, Strzalkowski, 1991"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"me?trable This tool is parameterisable. Cet outil peut e?tre parame?tre? This tool can be parameterised. 3 Developing a paraphrase testsuite Based on the above typology, we can systematically construct a testsuite for developing and evaluating a paraphrastic grammar. Indeed, when developing a grammar, it is necessary to have some means of assessing both the coverage of the grammar (does it generate all the sentences of the described language?) and its degree of overgeneration (does it generate only the sentences of the described language?) While corpus driven efforts along the PARSEVAL lines (Black et al, 1991) are good at giving some measure of a grammar coverage, they are not suitable for finer grained analysis and in particular, for progress evaluation, regression testing and comparative report generation. Another known method consists in developing and using a test suite that is, a set of negative and positive items against which the grammar can be systematically tested. For english, there is for instance the 15 year old HewlettPackard test suite, a simple text file listing test sentences and grouping them according to linguistics phenomena (Flickinger et al, 1987); and more recently, the much m","@endWordPosition":"1571","@position":"9957","annotationId":"T2","@startWordPosition":"1568","@citStr":"Black et al, 1991"}},"title":{"#tail":"\n","#text":"A procedure for quantitatively comparing the syntactic coverage of english grammars."},"booktitle":{"#tail":"\n","#text":"In Proceedings of teh 4th DARPA Speech and Natural Language Workshop."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A Black"},{"#tail":"\n","#text":"S Abney"},{"#tail":"\n","#text":"D Flickinger"},{"#tail":"\n","#text":"C Gdaniec"},{"#tail":"\n","#text":"R Grishman"},{"#tail":"\n","#text":"P Harrison"},{"#tail":"\n","#text":"D Hindel"},{"#tail":"\n","#text":"R INgria"},{"#tail":"\n","#text":"F Jelinek"},{"#tail":"\n","#text":"F Klaavans"},{"#tail":"\n","#text":"M Liberman"},{"#tail":"\n","#text":"M Marcus"},{"#tail":"\n","#text":"S Roukos"},{"#tail":"\n","#text":"B Santorini"},{"#tail":"\n","#text":"T Strzalkowski"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1995"},"rawString":{"#tail":"\n","#text":"J. Bos. 1995. Predicate logic unplugged. In Paul Dekker and Martin Stokhof, editors, Proceedings of the 10th Amsterdam Colloquium, pages 133? 142."},"#text":"\n","pages":{"#tail":"\n","#text":"133--142"},"marker":{"#tail":"\n","#text":"Bos, 1995"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"operation used in phrase structure grammars while adjunction is an operation which inserts an auxiliary tree into a derived tree. To account for the effect of these insertions, two feature structures (called top and bottom) are associated with each tree node in FTAG. The top feature structure encodes information that needs to be percolated up the tree should an adjunction take place. In contrast, the bottom feature structure encodes information that remains local to the node at which adjunction takes place. The language chosen for semantic representation is a flat semantics along the line of (Bos, 1995; Copestake et al, 1999; Copestake et al, 2001). However because we are here focusing on paraphrases rather than fine grained semantic distinctions, the underspecification and the description of the scope relations permitted by these semantics will here be largely ignored and flat semantics will be principally used as a convenient way of describing predicate/arguments and modifiers/modified relationships. Thus the semantic representations we assume are simply set of literals of the form P n(x1, . . . , xn) where P n is a predicate of arity n and xi is either a constant or a unification variabl","@endWordPosition":"3076","@position":"19514","annotationId":"T3","@startWordPosition":"3075","@citStr":"Bos, 1995"}},"title":{"#tail":"\n","#text":"Predicate logic unplugged."},"booktitle":{"#tail":"\n","#text":"In Paul Dekker and Martin Stokhof, editors, Proceedings of the 10th Amsterdam Colloquium,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"J Bos"}}},{"volume":{"#tail":"\n","#text":"40"},"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"M.H Candito. 1999. Un outil multilingue de generation de ltag : application au francais et a l?italien. TAL, 40(1)."},"journal":{"#tail":"\n","#text":"TAL,"},"#text":"\n","issue":{"#tail":"\n","#text":"1"},"marker":{"#tail":"\n","#text":"Candito, 1999"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"tle man labour cost. On the other hand, the degree of descriptive abstraction offered by the list of inference or paraphrase rules they output is low. We chose to investigate an alternative research direction by aiming to develop a ?paraphrastic grammar? that is, a grammar which captures the paraphrastic relations between linguistic structures1 . Based on a computational grammar that associates natural language expressions with both a syntactic and a semantic representation, a paraphrastic gram1As we shall briefly discuss in section 4, the grammar is developed with the help of a meta-grammar (Candito, 1999) thus ensuring an additional level of abstraction. The metagrammar is an abstract specification of the linguistic properties (phrase structure, valency, realisation of grammatical functions etc.) encoded in the grammar basic units. This specification is then compiled to automatically produce a specific grammar. mar is a grammar that moreover associates paraphrases with the same semantic representation. That is, contrary to machine learning based approaches which relate paraphrases via sentence patterns, the paraphrastic grammar approach relates paraphrases via a common semantic representation.","@endWordPosition":"590","@position":"3862","annotationId":"T4","@startWordPosition":"589","@citStr":"Candito, 1999"},{"#tail":"\n","#text":"tance, as Figures 3, 4 and 5 show, the FTAG trees assigned on syntactic grounds by Anne Abeille? FTAG to predicative nouns, support verb constructions and transitive verbs can be equiped with a flat semantics in such a way as to assign the three sentences in 1 a unique semantic representation namely the one given above. Generally, the problem is not so much to state the correspondances between synonymic but syntactically different constructs as to do this in a general way while not overgeneralising. To address this problem, we are currently working on developing a metagrammar in the sense of (Candito, 1999). This metagrammar allows us to factorise both syntactic and semantic information. Syntactic information is factorised in the usual way. For instance, there will be a class NOVN1 which groups together all the initial trees representing the possible syntactic configurations in which a transitive verb with two nominal arguments can occur. But additionnally there will be semantic classes such as, ?binary predicate of semantic type X? which will be associated with the relevant syntactic classes for instance, NOVN1 (the class of transitive verbs with nominal arguments), BINARY NPRED (the class of b","@endWordPosition":"3983","@position":"25051","annotationId":"T5","@startWordPosition":"3982","@citStr":"Candito, 1999"}]},"title":{"#tail":"\n","#text":"Un outil multilingue de generation de ltag : application au francais et a l?italien."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"M H Candito"}}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Technical report, Berkeley."},"date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"C.Johnson, C. Fillmore, M. Petruckand C. Baker, M. Ellsworth, and J. Ruppenhofer. 2002. Framenet: Theory and practice. Technical report, Berkeley."},"#text":"\n","marker":{"#tail":"\n","#text":"Johnson, Baker, Ellsworth, Ruppenhofer, 2002"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" to the paraphrases given in example 1. To produce an identical semantic representation of these three sentences, we first need to ensure that synonyms be assigned the same concept. That is, we need to fix a concept inventory and to use this inventory in a consistent way in particular, by assigning synonyms the same concept. For non predicative units, we use WordNet synset numbers or when working within a restricted domain with a well defined thesaurus, the descriptors of that thesaurus. To represent the semantics of predicative units, we use FrameNet inventory of frames and frame elements (C.Johnson et al, 2002). FrameNet is an online lexical resource for English based on the principles of Frame Semantics. In this approach, a word evokes a frame i.e., a simple or a complex event, and each frame is associated with a number of frame elements that is, a number of participants fulfilling a given role in the frame. Finally each frame is associated with a set of target words, the words that evoke that frame. Thus FrameNet associates synonyms with an identical concept namely, the frame evoked by those synonyms. We make use of this feature and instead of choosing our own semantic predicates and relations, dr","@endWordPosition":"3567","@position":"22464","annotationId":"T6","@startWordPosition":"3564","@citStr":"Johnson et al, 2002"}},"title":{"#tail":"\n","#text":"Framenet: Theory and practice."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"C Fillmore C Johnson"},{"#tail":"\n","#text":"M Petruckand C Baker"},{"#tail":"\n","#text":"M Ellsworth"},{"#tail":"\n","#text":"J Ruppenhofer"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Ann Copestake and Dan Flickinger. 2000. An open source grammar development environment and broad-coverage English grammar using HPSG. In Proceedings of the 2nd International Conference on Language Resources and Evaluation, Athens, Greece."},"#text":"\n","marker":{"#tail":"\n","#text":"Copestake, Flickinger, 2000"},"location":{"#tail":"\n","#text":"Athens, Greece."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" family, we attempt to find examples with distinct aspectual categories (state, accomplishment and process). Finally, given a WN family and an aspectual category, items will vary with respect to the arity of the main predicate and the types of their arguments e.g., predicates of arity one (run, cost, sleep), of arity two with non propositional arguments (eat, hit, dug), of arity two with a propositional argument (say, promise etc.), etc. 4 A paraphrastic grammar ?Semantic grammars? already exist which describe not only the syntax but also the semantics of natural language. Thus for instance, (Copestake and Flickinger, 2000; Copestake et al, 2001) describes a Head Driven Phrase Structure Grammar (HPSG) which supports the parallel construction of a phrase structure (or derived) tree and of a semantic representation and (Dalrymple, 1999) show how to equip Lexical Functional grammar (LFG) with a glue semantics. These grammars are both efficient and large scale in that they cover an important fragment of the natural language they describe and can be processed by parsers and generators in almost real time. For instance, the LFG grammar parses sentences from the Wall Street Journal and the ERG HPSG grammar will produc","@endWordPosition":"2541","@position":"15969","annotationId":"T7","@startWordPosition":"2538","@citStr":"Copestake and Flickinger, 2000"}},"title":{"#tail":"\n","#text":"An open source grammar development environment and broad-coverage English grammar using HPSG."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 2nd International Conference on Language Resources and Evaluation,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Ann Copestake"},{"#tail":"\n","#text":"Dan Flickinger"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Manuscript,"},"date":{"#tail":"\n","#text":"1999"},"institution":{"#tail":"\n","#text":"Stanford University."},"rawString":{"#tail":"\n","#text":"A. Copestake, D. Flickinger, I. Sag, and C. Pollard. 1999. Minimal Recursion Semantics. An Introduction. Manuscript, Stanford University."},"#text":"\n","marker":{"#tail":"\n","#text":"Copestake, Flickinger, Sag, Pollard, 1999"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"sed in phrase structure grammars while adjunction is an operation which inserts an auxiliary tree into a derived tree. To account for the effect of these insertions, two feature structures (called top and bottom) are associated with each tree node in FTAG. The top feature structure encodes information that needs to be percolated up the tree should an adjunction take place. In contrast, the bottom feature structure encodes information that remains local to the node at which adjunction takes place. The language chosen for semantic representation is a flat semantics along the line of (Bos, 1995; Copestake et al, 1999; Copestake et al, 2001). However because we are here focusing on paraphrases rather than fine grained semantic distinctions, the underspecification and the description of the scope relations permitted by these semantics will here be largely ignored and flat semantics will be principally used as a convenient way of describing predicate/arguments and modifiers/modified relationships. Thus the semantic representations we assume are simply set of literals of the form P n(x1, . . . , xn) where P n is a predicate of arity n and xi is either a constant or a unification variable whose value will be i","@endWordPosition":"3080","@position":"19537","annotationId":"T8","@startWordPosition":"3077","@citStr":"Copestake et al, 1999"}},"title":{"#tail":"\n","#text":"Minimal Recursion Semantics. An Introduction."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A Copestake"},{"#tail":"\n","#text":"D Flickinger"},{"#tail":"\n","#text":"I Sag"},{"#tail":"\n","#text":"C Pollard"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"A. Copestake, A. Lascarides, and D. Flickinger. 2001. An algebra for semantic construction in constraint-based grammars. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics, Toulouse, France."},"#text":"\n","marker":{"#tail":"\n","#text":"Copestake, Lascarides, Flickinger, 2001"},"location":{"#tail":"\n","#text":"Toulouse, France."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ples with distinct aspectual categories (state, accomplishment and process). Finally, given a WN family and an aspectual category, items will vary with respect to the arity of the main predicate and the types of their arguments e.g., predicates of arity one (run, cost, sleep), of arity two with non propositional arguments (eat, hit, dug), of arity two with a propositional argument (say, promise etc.), etc. 4 A paraphrastic grammar ?Semantic grammars? already exist which describe not only the syntax but also the semantics of natural language. Thus for instance, (Copestake and Flickinger, 2000; Copestake et al, 2001) describes a Head Driven Phrase Structure Grammar (HPSG) which supports the parallel construction of a phrase structure (or derived) tree and of a semantic representation and (Dalrymple, 1999) show how to equip Lexical Functional grammar (LFG) with a glue semantics. These grammars are both efficient and large scale in that they cover an important fragment of the natural language they describe and can be processed by parsers and generators in almost real time. For instance, the LFG grammar parses sentences from the Wall Street Journal and the ERG HPSG grammar will produce semantic representatio","@endWordPosition":"2545","@position":"15993","annotationId":"T9","@startWordPosition":"2542","@citStr":"Copestake et al, 2001"},{"#tail":"\n","#text":" grammars while adjunction is an operation which inserts an auxiliary tree into a derived tree. To account for the effect of these insertions, two feature structures (called top and bottom) are associated with each tree node in FTAG. The top feature structure encodes information that needs to be percolated up the tree should an adjunction take place. In contrast, the bottom feature structure encodes information that remains local to the node at which adjunction takes place. The language chosen for semantic representation is a flat semantics along the line of (Bos, 1995; Copestake et al, 1999; Copestake et al, 2001). However because we are here focusing on paraphrases rather than fine grained semantic distinctions, the underspecification and the description of the scope relations permitted by these semantics will here be largely ignored and flat semantics will be principally used as a convenient way of describing predicate/arguments and modifiers/modified relationships. Thus the semantic representations we assume are simply set of literals of the form P n(x1, . . . , xn) where P n is a predicate of arity n and xi is either a constant or a unification variable whose value will be instantiated during proce","@endWordPosition":"3084","@position":"19561","annotationId":"T10","@startWordPosition":"3081","@citStr":"Copestake et al, 2001"}]},"title":{"#tail":"\n","#text":"An algebra for semantic construction in constraint-based grammars."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A Copestake"},{"#tail":"\n","#text":"A Lascarides"},{"#tail":"\n","#text":"D Flickinger"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"M. Dalrymple. 1999. Semantics and syntax in lexical functional grammar. MIT Press."},"#text":"\n","marker":{"#tail":"\n","#text":"Dalrymple, 1999"},"publisher":{"#tail":"\n","#text":"MIT Press."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" the types of their arguments e.g., predicates of arity one (run, cost, sleep), of arity two with non propositional arguments (eat, hit, dug), of arity two with a propositional argument (say, promise etc.), etc. 4 A paraphrastic grammar ?Semantic grammars? already exist which describe not only the syntax but also the semantics of natural language. Thus for instance, (Copestake and Flickinger, 2000; Copestake et al, 2001) describes a Head Driven Phrase Structure Grammar (HPSG) which supports the parallel construction of a phrase structure (or derived) tree and of a semantic representation and (Dalrymple, 1999) show how to equip Lexical Functional grammar (LFG) with a glue semantics. These grammars are both efficient and large scale in that they cover an important fragment of the natural language they describe and can be processed by parsers and generators in almost real time. For instance, the LFG grammar parses sentences from the Wall Street Journal and the ERG HPSG grammar will produce semantic representations for about 83 per cent of the utterances in a corpus of some 10 000 utterances varying in length between one and thirty words. Parsing times vary between a few ms for short sentences and sev","@endWordPosition":"2574","@position":"16185","annotationId":"T11","@startWordPosition":"2573","@citStr":"Dalrymple, 1999"}},"title":{"#tail":"\n","#text":"Semantics and syntax in lexical functional grammar."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"M Dalrymple"}}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Technical report, Hewlett-Packard Laboratories."},"date":{"#tail":"\n","#text":"1987"},"rawString":{"#tail":"\n","#text":"D. Flickinger, J. Nerbonne, I. Sag, and T. Wasow. 1987. Towards evaluation of nlp systems. Technical report, Hewlett-Packard Laboratories."},"#text":"\n","marker":{"#tail":"\n","#text":"Flickinger, Nerbonne, Sag, Wasow, 1987"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"n efforts along the PARSEVAL lines (Black et al, 1991) are good at giving some measure of a grammar coverage, they are not suitable for finer grained analysis and in particular, for progress evaluation, regression testing and comparative report generation. Another known method consists in developing and using a test suite that is, a set of negative and positive items against which the grammar can be systematically tested. For english, there is for instance the 15 year old HewlettPackard test suite, a simple text file listing test sentences and grouping them according to linguistics phenomena (Flickinger et al, 1987); and more recently, the much more sophisticated TSNLP (Test Suite for Natural Language Processing) which includes some 9500 test items for English, French and German, each of them being annotated with syntactic and application related information (Oepen and Flickinger, 1998). Yet because they do not take into account the semantic dimension, none of these tools are adequate for evaluating the paraphrastic power of a grammar. To remedy this, we propose to develop a paraphrase test suite based on the paraphrase typology described in the previous section. In such a testsuite, test items pair a se","@endWordPosition":"1664","@position":"10526","annotationId":"T12","@startWordPosition":"1661","@citStr":"Flickinger et al, 1987"}},"title":{"#tail":"\n","#text":"Towards evaluation of nlp systems."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"D Flickinger"},{"#tail":"\n","#text":"J Nerbonne"},{"#tail":"\n","#text":"I Sag"},{"#tail":"\n","#text":"T Wasow"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"C. Gardent and L. Kallmeyer. 2003. Semantic construction in ftag. In Proceedings of EACL, Budapest, Hungary."},"#text":"\n","marker":{"#tail":"\n","#text":"Gardent, Kallmeyer, 2003"},"location":{"#tail":"\n","#text":"Budapest, Hungary."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"than fine grained semantic distinctions, the underspecification and the description of the scope relations permitted by these semantics will here be largely ignored and flat semantics will be principally used as a convenient way of describing predicate/arguments and modifiers/modified relationships. Thus the semantic representations we assume are simply set of literals of the form P n(x1, . . . , xn) where P n is a predicate of arity n and xi is either a constant or a unification variable whose value will be instantiated during processing. Semantic construction proceeds from the derived tree (Gardent and Kallmeyer, 2003) rather than ? as is more common in TAG ? from the derivation tree. This is done by associating each elementary tree with a semantic representation and by decorating relevant tree nodes with unification variables and constants occuring in associated semantic representation. The association between tree nodes and unification variables encodes the syntax/semantics interface ? it specifies which node in the tree provides the value for which variable in the final semantic representation. As trees combine during derivation, (i) variables are unified ? both in the tree and in the associated semantic","@endWordPosition":"3198","@position":"20250","annotationId":"T13","@startWordPosition":"3195","@citStr":"Gardent and Kallmeyer, 2003"}},"title":{"#tail":"\n","#text":"Semantic construction in ftag."},"booktitle":{"#tail":"\n","#text":"In Proceedings of EACL,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"C Gardent"},{"#tail":"\n","#text":"L Kallmeyer"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"O. Glickman and I. Dagan. 2003. Identifying lexical paraphrases from a single corpus: a case study for verbs. In Proceedings of Recent Advances in Natural Language Processing."},"#text":"\n","marker":{"#tail":"\n","#text":"Glickman, Dagan, 2003"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"n corpora these systems deal with, coverage and robustness are key issues and much on the work on paraphrases in that domain is based on automatic learning techniques. For instance, (Lin and Pantel, 2001) acquire two-argument templates (inference rules) from corpora using an extended version of the distributional analysis in which paths in dependency trees that have similar arguments are taken to be close in meaning. Similarly, (Barzilay and Lee, 2003) and (Shinyanma et al, 2002) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source. And (Glickman and Dagan, 2003) use clustering and similarity measures to identify similar contexts in a single corpus and extract verbal paraphrases from these contexts. Such machine learning approaches have known pros and cons. On the one hand, they produce large scale resources at little man labour cost. On the other hand, the degree of descriptive abstraction offered by the list of inference or paraphrase rules they output is low. We chose to investigate an alternative research direction by aiming to develop a ?paraphrastic grammar? that is, a grammar which captures the paraphrastic relations between linguistic structur","@endWordPosition":"450","@position":"2991","annotationId":"T14","@startWordPosition":"447","@citStr":"Glickman and Dagan, 2003"}},"title":{"#tail":"\n","#text":"Identifying lexical paraphrases from a single corpus: a case study for verbs."},"booktitle":{"#tail":"\n","#text":"In Proceedings of Recent Advances in Natural Language Processing."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"O Glickman"},{"#tail":"\n","#text":"I Dagan"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1975"},"rawString":{"#tail":"\n","#text":"M. Gross. 1975. Me?thodes en syntase. Masson, Paris."},"#text":"\n","marker":{"#tail":"\n","#text":"Gross, 1975"},"location":{"#tail":"\n","#text":"Masson, Paris."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" Lexical semantics information still need to be included. Intercategorial synonymy not involving a derivational morphology link has been little studied and resources are lacking. However as for other types of synonymy, distributional analysis and clustering techniques can be used to develop such resources. For shuffling paraphrases, french alternations are partially described in (Saint-Dizier, 1999) and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs. For complementing this database and for converse constructions, the LADL tables (Gross, 1975) can furthermore be resorted to, which list detailed syntactico-semantic descriptions for 5 000 verbs and 25 000 verbal expressions. In particular, (Gross, 1989) lists the converses of some 3 500 predicative nouns. S GNG ? V GAdvM ? coute GNX S:Commerce GAdvY D NX ? (S,G):goods cher la (S,M):money Y:High NX croisiere X:Cruise Figure 3: La croisie`re cou?te cher S GNG ? VSup? GN a D? NGMGNX cout D NX ? D S:Commerce la un (S,M):money NX (S,G):goods croisiere N X:Cruise ? NY Adj eleve Y:High Figure 4: La croisie`re a un cou?t e?leve? 5 Conclusion Besides the development and evaluation of a core p","@endWordPosition":"4371","@position":"27614","annotationId":"T15","@startWordPosition":"4370","@citStr":"Gross, 1975"}},"title":{"#tail":"\n","#text":"Me?thodes en syntase."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"M Gross"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1989"},"rawString":{"#tail":"\n","#text":"G. Gross. 1989. Les constructions converses du francais. CNRS Editions."},"#text":"\n","marker":{"#tail":"\n","#text":"Gross, 1989"},"publisher":{"#tail":"\n","#text":"CNRS Editions."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"rces are lacking. However as for other types of synonymy, distributional analysis and clustering techniques can be used to develop such resources. For shuffling paraphrases, french alternations are partially described in (Saint-Dizier, 1999) and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs. For complementing this database and for converse constructions, the LADL tables (Gross, 1975) can furthermore be resorted to, which list detailed syntactico-semantic descriptions for 5 000 verbs and 25 000 verbal expressions. In particular, (Gross, 1989) lists the converses of some 3 500 predicative nouns. S GNG ? V GAdvM ? coute GNX S:Commerce GAdvY D NX ? (S,G):goods cher la (S,M):money Y:High NX croisiere X:Cruise Figure 3: La croisie`re cou?te cher S GNG ? VSup? GN a D? NGMGNX cout D NX ? D S:Commerce la un (S,M):money NX (S,G):goods croisiere N X:Cruise ? NY Adj eleve Y:High Figure 4: La croisie`re a un cou?t e?leve? 5 Conclusion Besides the development and evaluation of a core paraphrastic testsuite and grammar for French, we plan to investigate two main issues. First, how precisely should a metagrammar be structured to best describe a ","@endWordPosition":"4395","@position":"27775","annotationId":"T16","@startWordPosition":"4394","@citStr":"Gross, 1989"}},"title":{"#tail":"\n","#text":"Les constructions converses du francais."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"G Gross"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Dekang Lin and Patrick Pantel. 2001. Discovery of inference rules for question answering. Natural Language Engineering."},"#text":"\n","marker":{"#tail":"\n","#text":"Lin, Pantel, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"form of the same sentence) while (Mel?c?uk, 1988) presents sixty paraphrastic rules designed to account for paraphrastic relations between sentences. More recently, work in information extraction (IE) and question answering (QA) has triggered a renewed research interest in paraphrases as IE and QA systems typically need to be able to recognise various verbalisations of the content. Because of the large, open domain corpora these systems deal with, coverage and robustness are key issues and much on the work on paraphrases in that domain is based on automatic learning techniques. For instance, (Lin and Pantel, 2001) acquire two-argument templates (inference rules) from corpora using an extended version of the distributional analysis in which paths in dependency trees that have similar arguments are taken to be close in meaning. Similarly, (Barzilay and Lee, 2003) and (Shinyanma et al, 2002) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source. And (Glickman and Dagan, 2003) use clustering and similarity measures to identify similar contexts in a single corpus and extract verbal paraphrases from these contexts. Such machine learning approaches have k","@endWordPosition":"386","@position":"2570","annotationId":"T17","@startWordPosition":"383","@citStr":"Lin and Pantel, 2001"}},"title":{"#tail":"\n","#text":"Discovery of inference rules for question answering. Natural Language Engineering."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Dekang Lin"},{"#tail":"\n","#text":"Patrick Pantel"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"D. Lin. 1998. Automatic retrieval and clustering of similar words. In Proceedings of ACL/COLING, pages 768?774."},"#text":"\n","pages":{"#tail":"\n","#text":"768--774"},"marker":{"#tail":"\n","#text":"Lin, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ted by a paraphrastic link be it parallel, shuffling or definitional) is more or less easy as resources for that specific means may or may not be readily available. Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available (Ploux, 1997). Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries. For these or for a specific domain, basic synonymic dictionaries can be complemented using learning methods based on distributional similarity (Pereira et al, 1993; Lin, 1998). techniques. For intercategorial synonymy involving a derivational morphology link, some resources are available which however are only partial in that they only store morphological families that is, sets of items that are morphologically related. Lexical semantics information still need to be included. Intercategorial synonymy not involving a derivational morphology link has been little studied and resources are lacking. However as for other types of synonymy, distributional analysis and clustering techniques can be used to develop such resources. For shuffling paraphrases, french alternatio","@endWordPosition":"4249","@position":"26754","annotationId":"T18","@startWordPosition":"4248","@citStr":"Lin, 1998"}},"title":{"#tail":"\n","#text":"Automatic retrieval and clustering of similar words."},"booktitle":{"#tail":"\n","#text":"In Proceedings of ACL/COLING,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"D Lin"}}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Lexique,"},"date":{"#tail":"\n","#text":"1988"},"rawString":{"#tail":"\n","#text":"I. Mel?c?uk. 1988. Paraphrase et lexique dans la thorie linguistique sens-texte. Lexique, 6:13?54."},"#text":"\n","pages":{"#tail":"\n","#text":"6--13"},"marker":{"#tail":"\n","#text":"Melcuk, 1988"},"title":{"#tail":"\n","#text":"Paraphrase et lexique dans la thorie linguistique sens-texte."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"I Melcuk"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"S. Oepen and D. Flickinger. 1998. Towards systematic grammar profiling. test suite technology 10 years after. Computer Speech and Language, 12:411?435."},"#text":"\n","pages":{"#tail":"\n","#text":"12--411"},"marker":{"#tail":"\n","#text":"Oepen, Flickinger, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ethod consists in developing and using a test suite that is, a set of negative and positive items against which the grammar can be systematically tested. For english, there is for instance the 15 year old HewlettPackard test suite, a simple text file listing test sentences and grouping them according to linguistics phenomena (Flickinger et al, 1987); and more recently, the much more sophisticated TSNLP (Test Suite for Natural Language Processing) which includes some 9500 test items for English, French and German, each of them being annotated with syntactic and application related information (Oepen and Flickinger, 1998). Yet because they do not take into account the semantic dimension, none of these tools are adequate for evaluating the paraphrastic power of a grammar. To remedy this, we propose to develop a paraphrase test suite based on the paraphrase typology described in the previous section. In such a testsuite, test items pair a semantic representation with a set of paraphrases verbalising this semantics. The construction and annotation of the paraphrases reflects the paraphrase typology. In a first phase, we concentrate on simple, non-recursive predicate/argument structure. Given such a structure, the","@endWordPosition":"1707","@position":"10802","annotationId":"T19","@startWordPosition":"1704","@citStr":"Oepen and Flickinger, 1998"}},"title":{"#tail":"\n","#text":"Towards systematic grammar profiling. test suite technology 10 years after. Computer Speech and Language,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"S Oepen"},{"#tail":"\n","#text":"D Flickinger"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"F. Pereira, N. Tishby, and L. Lee. 1993. Distributional clustering of english words. In Proceedings of the ACL, pages 183?190."},"#text":"\n","pages":{"#tail":"\n","#text":"183--190"},"marker":{"#tail":"\n","#text":"Pereira, Tishby, Lee, 1993"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ll lexical items related by a paraphrastic link be it parallel, shuffling or definitional) is more or less easy as resources for that specific means may or may not be readily available. Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available (Ploux, 1997). Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries. For these or for a specific domain, basic synonymic dictionaries can be complemented using learning methods based on distributional similarity (Pereira et al, 1993; Lin, 1998). techniques. For intercategorial synonymy involving a derivational morphology link, some resources are available which however are only partial in that they only store morphological families that is, sets of items that are morphologically related. Lexical semantics information still need to be included. Intercategorial synonymy not involving a derivational morphology link has been little studied and resources are lacking. However as for other types of synonymy, distributional analysis and clustering techniques can be used to develop such resources. For shuffling paraphrases, frenc","@endWordPosition":"4247","@position":"26742","annotationId":"T20","@startWordPosition":"4244","@citStr":"Pereira et al, 1993"}},"title":{"#tail":"\n","#text":"Distributional clustering of english words."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the ACL,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"F Pereira"},{"#tail":"\n","#text":"N Tishby"},{"#tail":"\n","#text":"L Lee"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"S. Ploux. 1997. Modlisation et traitement informatique de la synonymi. Linguisticae Investigationes, XXI(1)."},"#text":"\n","marker":{"#tail":"\n","#text":"Ploux, 1997"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"sses (e.g., ?binary predicate of semantic type X?), we can in this way capture both intra and intercategorial paraphrasing links in a general way. Constructing paraphrastic sets. Depending on the type of paraphrastic means involved, constructing a paraphrastic set (the set of all lexical items related by a paraphrastic link be it parallel, shuffling or definitional) is more or less easy as resources for that specific means may or may not be readily available. Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available (Ploux, 1997). Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries. For these or for a specific domain, basic synonymic dictionaries can be complemented using learning methods based on distributional similarity (Pereira et al, 1993; Lin, 1998). techniques. For intercategorial synonymy involving a derivational morphology link, some resources are available which however are only partial in that they only store morphological families that is, sets of items that are morphologically related. Lexical semantics information still need to be include","@endWordPosition":"4201","@position":"26457","annotationId":"T21","@startWordPosition":"4200","@citStr":"Ploux, 1997"}},"title":{"#tail":"\n","#text":"Modlisation et traitement informatique de la synonymi. Linguisticae Investigationes,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"S Ploux"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"P. Saint-Dizier, 1999. Alternations and Verb Semantic Classes for French: analysis and class formation, chapter 5. Kluwer."},"#text":"\n","marker":{"#tail":"\n","#text":"Saint-Dizier, 1999"},"publisher":{"#tail":"\n","#text":"Kluwer."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"al synonymy involving a derivational morphology link, some resources are available which however are only partial in that they only store morphological families that is, sets of items that are morphologically related. Lexical semantics information still need to be included. Intercategorial synonymy not involving a derivational morphology link has been little studied and resources are lacking. However as for other types of synonymy, distributional analysis and clustering techniques can be used to develop such resources. For shuffling paraphrases, french alternations are partially described in (Saint-Dizier, 1999) and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs. For complementing this database and for converse constructions, the LADL tables (Gross, 1975) can furthermore be resorted to, which list detailed syntactico-semantic descriptions for 5 000 verbs and 25 000 verbal expressions. In particular, (Gross, 1989) lists the converses of some 3 500 predicative nouns. S GNG ? V GAdvM ? coute GNX S:Commerce GAdvY D NX ? (S,G):goods cher la (S,M):money Y:High NX croisiere X:Cruise Figure 3: La croisie`re cou?te cher S GNG ? VSup? GN a D? NGMG","@endWordPosition":"4340","@position":"27404","annotationId":"T22","@startWordPosition":"4339","@citStr":"Saint-Dizier, 1999"}},"title":{"#tail":"\n","#text":"Alternations and Verb Semantic Classes for French: analysis and class formation, chapter 5."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"P Saint-Dizier"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"Y. Shinyanma, S. Sekine, K. Sudo, and R. Grishman. 2002. Automatic paraphrase acquisition from news articles. In Proceedings of HLT."},"#text":"\n","marker":{"#tail":"\n","#text":"Shinyanma, Sekine, Sudo, Grishman, 2002"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"hrases as IE and QA systems typically need to be able to recognise various verbalisations of the content. Because of the large, open domain corpora these systems deal with, coverage and robustness are key issues and much on the work on paraphrases in that domain is based on automatic learning techniques. For instance, (Lin and Pantel, 2001) acquire two-argument templates (inference rules) from corpora using an extended version of the distributional analysis in which paths in dependency trees that have similar arguments are taken to be close in meaning. Similarly, (Barzilay and Lee, 2003) and (Shinyanma et al, 2002) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source. And (Glickman and Dagan, 2003) use clustering and similarity measures to identify similar contexts in a single corpus and extract verbal paraphrases from these contexts. Such machine learning approaches have known pros and cons. On the one hand, they produce large scale resources at little man labour cost. On the other hand, the degree of descriptive abstraction offered by the list of inference or paraphrase rules they output is low. We chose to investigate an alternative research dir","@endWordPosition":"429","@position":"2850","annotationId":"T23","@startWordPosition":"426","@citStr":"Shinyanma et al, 2002"}},"title":{"#tail":"\n","#text":"Automatic paraphrase acquisition from news articles."},"booktitle":{"#tail":"\n","#text":"In Proceedings of HLT."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Y Shinyanma"},{"#tail":"\n","#text":"S Sekine"},{"#tail":"\n","#text":"K Sudo"},{"#tail":"\n","#text":"R Grishman"}]}}]}}]}}
