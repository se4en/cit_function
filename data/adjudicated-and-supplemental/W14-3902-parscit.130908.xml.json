{"algorithms":{"#text":"\n","@version":"110505","algorithm":{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"date":{"#tail":"\n","#text":"2013"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ing code mixing in speech (Solorio and Liu, 2008a; Weiner et al., 2012). Solorio and Liu (2008b) try to predict the points inside a set of spoken Spanish-English sentences where the speakers switch between the two languages. Other studies have looked at code mixing in different types of short texts, such as information retrieval queries (Gottron and Lipka, 2010) and SMS messages (Farrugia, 2004; Rosner and Farrugia, 2007). Yamaguchi and Tanaka-Ishii (2012) perform language identification using artificial multilingual data, created by randomly sampling text segments from monolingual documents. King and Abney (2013) used weakly semi-supervised methods to perform word-level language identification. A dataset of 30 languages has been used in their work. They explore several language identification approaches, including a Naive Bayes classifier for individual word-level classification and sequence labelling with Conditional Random Fields trained with Generalized Expectation criteria (Mann and McCallum, 2008; Mann and McCallum, 2010), which achieved the highest scores. Another very recent work on this topic is (Nguyen and Do˘gru¨oz, 2013). They report on language identification experiments performed on Turki","@endWordPosition":"1017","@position":"6623","annotationId":"T1","@startWordPosition":"1014","@citStr":"King and Abney (2013)"},{"#tail":"\n","#text":"suited best for our data. Hence, we consider this as our baseline language identification system. Dictionary Accuracy(%) BNC 80.09 SemevalTwitter 77.61 LexNormList 79.86 Training Data 90.21 LexNormList+TrainingData (Baseline) 93.12 Table 4: Average cross-validation accuracy of dictionary-based detection 5.2 Word-Level Classification without Contextual Clues The following feature types are employed: 1. Char-n-grams (G): We start with a character n-gram-based approach (Cavnar and Trenkle, 1994), which is most common and followed by many language identification researchers. Following the work of King and Abney (2013), we select character n-grams (n=1 to 5) and the word as the features in our experiments. 2. Presence in Dictionaries (D): We use presence in a dictionary as a features for all available dictionaries in previous experiments. 3. Length of words (L): Instead of using the raw length value as a feature, we follow our previous work (Rubino et al., 2013; Wagner et al., 2014) and create multiple features for length using a decision tree (J48). We use length as the only feature to train a decision tree for each fold and use the nodes obtained from the tree to create boolean features. 4. Capitalization","@endWordPosition":"4021","@position":"25275","annotationId":"T2","@startWordPosition":"4018","@citStr":"King and Abney (2013)"}]},"title":{"#tail":"\n","#text":"Labeling the languages of words in mixed-language documents using weakly supervised methods."},"#tail":"\n","institution":{"#tail":"\n","#text":"for Computational Linguistics."},"rawString":{"#tail":"\n","#text":"Ben King and Steven Abney. 2013. Labeling the languages of words in mixed-language documents using weakly supervised methods. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1110\u2013 1119, Atlanta, Georgia. Association for Computational Linguistics."},"#text":"\n","pages":{"#tail":"\n","#text":"1110--1119"},"marker":{"#tail":"\n","#text":"King, Abney, 2013"},"publisher":{"#tail":"\n","#text":"Association"},"location":{"#tail":"\n","#text":"Atlanta,"},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Ben King"},{"#tail":"\n","#text":"Steven Abney"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2013"},"institution":{"#tail":"\n","#text":"Sofia, Bulgaria. Association for Computational Linguistics."},"rawString":{"#tail":"\n","#text":"Raphael Rubino, Joachim Wagner, Jennifer Foster, Johann Roturier, Rasoul Samad Zadeh Kaljahi, and Fred Hollowood. 2013. DCU-Symantec at the WMT 2013 quality estimation shared task. In Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 392\u2013397, Sofia, Bulgaria. Association for Computational Linguistics."},"#text":"\n","pages":{"#tail":"\n","#text":"392--397"},"marker":{"#tail":"\n","#text":"Rubino, Wagner, Foster, Roturier, Kaljahi, Hollowood, 2013"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"al Clues The following feature types are employed: 1. Char-n-grams (G): We start with a character n-gram-based approach (Cavnar and Trenkle, 1994), which is most common and followed by many language identification researchers. Following the work of King and Abney (2013), we select character n-grams (n=1 to 5) and the word as the features in our experiments. 2. Presence in Dictionaries (D): We use presence in a dictionary as a features for all available dictionaries in previous experiments. 3. Length of words (L): Instead of using the raw length value as a feature, we follow our previous work (Rubino et al., 2013; Wagner et al., 2014) and create multiple features for length using a decision tree (J48). We use length as the only feature to train a decision tree for each fold and use the nodes obtained from the tree to create boolean features. 4. Capitalization (C): We use 3 boolean features to encode capitalization information: whether any letter in the word is capitalized, whether all letters in the word are capitalized and whether the first letter is capitalized. We perform experiments with an SVM classifier (linear kernel) for different combination of these features.3 Parameter optimizations (C rang","@endWordPosition":"4084","@position":"25624","annotationId":"T3","@startWordPosition":"4081","@citStr":"Rubino et al., 2013"}},"title":{"#tail":"\n","#text":"DCU-Symantec at the WMT 2013 quality estimation shared task."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the Eighth Workshop on Statistical Machine Translation,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Raphael Rubino"},{"#tail":"\n","#text":"Joachim Wagner"},{"#tail":"\n","#text":"Jennifer Foster"},{"#tail":"\n","#text":"Johann Roturier"},{"#tail":"\n","#text":"Rasoul Samad Zadeh Kaljahi"},{"#tail":"\n","#text":"Fred Hollowood"}]}},{"date":{"#tail":"\n","#text":"2014"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"g feature types are employed: 1. Char-n-grams (G): We start with a character n-gram-based approach (Cavnar and Trenkle, 1994), which is most common and followed by many language identification researchers. Following the work of King and Abney (2013), we select character n-grams (n=1 to 5) and the word as the features in our experiments. 2. Presence in Dictionaries (D): We use presence in a dictionary as a features for all available dictionaries in previous experiments. 3. Length of words (L): Instead of using the raw length value as a feature, we follow our previous work (Rubino et al., 2013; Wagner et al., 2014) and create multiple features for length using a decision tree (J48). We use length as the only feature to train a decision tree for each fold and use the nodes obtained from the tree to create boolean features. 4. Capitalization (C): We use 3 boolean features to encode capitalization information: whether any letter in the word is capitalized, whether all letters in the word are capitalized and whether the first letter is capitalized. We perform experiments with an SVM classifier (linear kernel) for different combination of these features.3 Parameter optimizations (C range 2-15 to 210) for SVM","@endWordPosition":"4088","@position":"25646","annotationId":"T4","@startWordPosition":"4085","@citStr":"Wagner et al., 2014"}},"title":{"#tail":"\n","#text":"DCU: Aspect-based polarity classification for SemEval task 4."},"#tail":"\n","institution":{"#tail":"\n","#text":"for Computational Linguistics."},"rawString":{"#tail":"\n","#text":"Joachim Wagner, Piyush Arora, Santiago Cortes, Utsab Barman, Dasha Bogdanova, Jennifer Foster, and Lamia Tounsi. 2014. DCU: Aspect-based polarity classification for SemEval task 4. In Proceedings of the International Workshop on Semantic Evaluation (SemEval-2014), pages 392\u2013397, Dublin, Ireland. Association for Computational Linguistics."},"#text":"\n","pages":{"#tail":"\n","#text":"392--397"},"marker":{"#tail":"\n","#text":"Wagner, Arora, Cortes, Barman, Bogdanova, Foster, Tounsi, 2014"},"publisher":{"#tail":"\n","#text":"Association"},"location":{"#tail":"\n","#text":"Dublin, Ireland."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the International Workshop on Semantic Evaluation (SemEval-2014),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Joachim Wagner"},{"#tail":"\n","#text":"Piyush Arora"},{"#tail":"\n","#text":"Santiago Cortes"},{"#tail":"\n","#text":"Utsab Barman"},{"#tail":"\n","#text":"Dasha Bogdanova"},{"#tail":"\n","#text":"Jennifer Foster"},{"#tail":"\n","#text":"Lamia Tounsi"}]}}]}}}}
