{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","figure":{"#tail":"\n","@confidence":"0.998526666666667","#text":"\nDialogue ManagerParserContextualInterpreter\nInterpretation\nCurriculumPlanner\nKnowledgeBase\nContent Planner & Generator\nTutorialPlanner\nTutoring\nGUI\nDiagnoser\n"},"address":{"#tail":"\n","@confidence":"0.988432","#text":"\nMount Carmel, Haifa, Israel\n"},"author":[{"#tail":"\n","@confidence":"0.830465","#text":"\nNatalie Steinhauser and Gwendolyn Campbell\n"},{"#tail":"\n","@confidence":"0.978645","#text":"\nElaine Farrow\n"},{"#tail":"\n","@confidence":"0.979441","#text":"\nCharles B. Callaway\n"}],"subsectionHeader":[{"#tail":"\n","@confidence":"0.994429","#text":"\n2.1 Interpretation Components\n"},{"#tail":"\n","@confidence":"0.999932","#text":"\n2.2 Domain Reasoning and Diagnosis\n"},{"#tail":"\n","@confidence":"0.999071","#text":"\n2.3 Tutorial Planner\n"},{"#tail":"\n","@confidence":"0.980207","#text":"\n2.4 Generation\n"},{"#tail":"\n","@confidence":"0.912956","#text":"\n2.5 Dialogue Management\n"}],"footnote":{"#tail":"\n","@confidence":"0.1507866","#text":"\nProceedings of the ACL 2010 System Demonstrations, pages 13?18,\nUppsala, Sweden, 13 July 2010. c?2010 Association for Computational Linguistics\nBEETLE II: a system for tutoring and computational linguistics\nexperimentation\nMyroslava O. Dzikovska and Johanna D. Moore\n"},"@confidence":"0.000932","#tail":"\n","reference":[{"#tail":"\n","@confidence":"0.671655833333333","#text":"\nConference on Artificial Intelligence in Education\n(AIED ?01)?.\nJames Allen, Myroslava Dzikovska, Mehdi Manshadi,\nand Mary Swift. 2007. Deep linguistic processing\nfor spoken dialogue systems. In Proceedings of the\nACL-07 Workshop on Deep Linguistic Processing.\n"},{"#tail":"\n","@confidence":"0.998361628318584","#text":"\nMark Buckley and Magdalena Wolska. 2007. To-\nwards modelling and using common ground in tu-\ntorial dialogue. In Proceedings of DECALOG, the\n2007 Workshop on the Semantics and Pragmatics of\nDialogue, pages 41?48.\nDonna K. Byron. 2002. Resolving Pronominal Refer-\nence to Abstract Entities. Ph.D. thesis, University of\nRochester.\nCharles B. Callaway, Myroslava Dzikovska, Elaine\nFarrow, Manuel Marques-Pita, Colin Matheson, and\nJohanna D. Moore. 2007. The Beetle and BeeD-\niff tutoring systems. In Proceedings of SLaTE?07\n(Speech and Language Technology in Education).\nMichelene T. H. Chi, Nicholas de Leeuw, Mei-Hung\nChiu, and Christian LaVancher. 1994. Eliciting\nself-explanations improves understanding. Cogni-\ntive Science, 18(3):439?477.\nPeter Clark and Bruce Porter, 1999. KM (1.4): Users\nManual. http://www.cs.utexas.edu/users/mfkb/km.\nMyroslava O. Dzikovska, Charles B. Callaway, and\nElaine Farrow. 2006. Interpretation and generation\nin a knowledge-based tutorial system. In Proceed-\nings of EACL-06 workshop on knowledge and rea-\nsoning for language processing, Trento, Italy, April.\nMyroslava O. Dzikovska, James F. Allen, and Mary D.\nSwift. 2008a. Linking semantic and knowledge\nrepresentations in a multi-domain dialogue system.\nJournal of Logic and Computation, 18(3):405?430.\nMyroslava O. Dzikovska, Gwendolyn E. Campbell,\nCharles B. Callaway, Natalie B. Steinhauser, Elaine\nFarrow, Johanna D. Moore, Leslie A. Butler, and\nColin Matheson. 2008b. Diagnosing natural lan-\nguage answers to support adaptive tutoring. In\nProceedings 21st International FLAIRS Conference,\nCoconut Grove, Florida, May.\nMyroslava O. Dzikovska, Charles B. Callaway, Elaine\nFarrow, Johanna D. Moore, Natalie B. Steinhauser,\nand Gwendolyn C. Campbell. 2009. Dealing with\ninterpretation errors in tutorial dialogue. In Pro-\nceedings of SIGDIAL-09, London, UK, Sep.\nMyroslava O. Dzikovska, Johanna D. Moore, Natalie\nSteinhauser, and Gwendolyn Campbell. 2010. The\nimpact of interpretation problems on tutorial dia-\nlogue. In Proceedings of the 48th Annual Meeting of\nthe Association for Computational Linguistics(ACL-\n2010).\nMichael Elhadad and Jacques Robin. 1992. Control-\nling content realization with functional unification\ngrammars. In R. Dale, E. Hovy, D. Ro?sner, and\nO. Stock, editors, Proceedings of the Sixth Interna-\ntional Workshop on Natural Language Generation,\npages 89?104, Berlin, April. Springer-Verlag.\nA. C. Graesser, P. Wiemer-Hastings, P. Wiemer-\nHastings, and R. Kreuz. 1999. Autotutor: A simula-\ntion of a human tutor. Cognitive Systems Research,\n1:35?51.\nBeth Ann Hockey, Oliver Lemon, Ellen Campana,\nLaura Hiatt, Gregory Aist, James Hieronymus,\nAlexander Gruenstein, and John Dowding. 2003.\nTargeted help for spoken dialogue systems: intelli-\ngent feedback improves naive users? performance.\nIn Proceedings of the tenth conference on European\nchapter of the Association for Computational Lin-\nguistics, pages 147?154, Morristown, NJ, USA.\nPamela Jordan, Maxim Makatchev, Umarani Pap-\npuswamy, Kurt VanLehn, and Patricia Albacete.\n2006. A natural language tutorial dialogue system\nfor physics. In Proceedings of the 19th International\nFLAIRS conference.\nStaffan Larsson and David Traum. 2000. Information\nstate and dialogue management in the TRINDI Dia-\nlogue Move Engine Toolkit. Natural Language En-\ngineering, 6(3-4):323?340.\nDiane Litman, Carolyn P. Rose?, Kate Forbes-Riley,\nKurt VanLehn, Dumisizwe Bhembe, and Scott Sil-\nliman. 2006. Spoken versus typed human and com-\nputer dialogue tutoring. International Journal of Ar-\ntificial Intelligence in Education, 16:145?170.\nDiane Litman, Johanna Moore, Myroslava Dzikovska,\nand Elaine Farrow. 2009. Generalizing tutorial dia-\nlogue results. In Proceedings of 14th International\nConference on Artificial Intelligence in Education\n(AIED), Brighton, UK, July.\nRodney D. Nielsen, Wayne Ward, and James H. Mar-\ntin. 2008. Learning to assess low-level conceptual\nunderstanding. In Proceedings 21st International\nFLAIRS Conference, Coconut Grove, Florida, May.\nAmruta Purandare and Diane Litman. 2008. Content-\nlearning correlations in spoken tutoring dialogs at\nword, turn and discourse levels. In Proceedings 21st\nInternational FLAIRS Conference, Coconut Grove,\nFlorida, May.\nC.P. Rose? and C. Torrey. 2005. Interactivity versus ex-\npectation: Eliciting learning oriented behavior with\ntutorial dialogue systems. In Proceedings of Inter-\nact?05.\nN. B. Steinhauser, L. A. Butler, and G. E. Campbell.\n2007. Simulated tutors in immersive learning envi-\nronments: Empirically-derived design principles. In\nProceedings of the 2007 Interservice/Industry Train-\ning, Simulation and Education Conference, Orlando,\nFL.\nKurt VanLehn, Pamela Jordan, and Diane Litman.\n2007. Developing pedagogically effective tutorial\ndialogue tactics: Experiments and a testbed. In Pro-\nceedings of SLaTE Workshop on Speech and Lan-\nguage Technology in Education, Farmington, PA,\nOctober.\nArthur Ward and Diane Litman. 2006. Cohesion and\nlearning in a tutorial spoken dialog system. In Pro-\nceedings of 19th International FLAIRS (Florida Ar-\ntificial Intelligence Research Society) Conference,\nMelbourne Beach, FL.\n"}],"bodyText":[{"#tail":"\n","@confidence":"0.9992705","#text":"\nWe present BEETLE II, a tutorial dia-\nlogue system designed to accept unre-\nstricted language input and support exper-\nimentation with different tutorial planning\nand dialogue strategies. Our first system\nevaluation used two different tutorial poli-\ncies and demonstrated that the system can\nbe successfully used to study the impact\nof different approaches to tutoring. In the\nfuture, the system can also be used to ex-\nperiment with a variety of natural language\ninterpretation and generation techniques.\n"},{"#tail":"\n","@confidence":"0.999700701754386","#text":"\nOver the last decade there has been a lot of inter-\nest in developing tutorial dialogue systems that un-\nderstand student explanations (Jordan et al, 2006;\nGraesser et al, 1999; Aleven et al, 2001; Buckley\nand Wolska, 2007; Nielsen et al, 2008; VanLehn\net al, 2007), because high percentages of self-\nexplanation and student contentful talk are known\nto be correlated with better learning in human-\nhuman tutoring (Chi et al, 1994; Litman et al,\n2009; Purandare and Litman, 2008; Steinhauser et\nal., 2007). However, most existing systems use\npre-authored tutor responses for addressing stu-\ndent errors. The advantage of this approach is that\ntutors can devise remediation dialogues that are\nhighly tailored to specific misconceptions many\nstudents share, providing step-by-step scaffolding\nand potentially suggesting additional problems.\nThe disadvantage is a lack of adaptivity and gen-\nerality: students often get the same remediation\nfor the same error regardless of their past perfor-\nmance or dialogue context, as it is infeasible to\nauthor a different remediation dialogue for every\npossible dialogue state. It also becomes more dif-\nficult to experiment with different tutorial policies\nwithin the system due to the inherent completixites\nin applying tutoring strategies consistently across\na large number of individual hand-authored reme-\ndiations.\nThe BEETLE II system architecture is designed\nto overcome these limitations (Callaway et al,\n2007). It uses a deep parser and generator, to-\ngether with a domain reasoner and a diagnoser,\nto produce detailed analyses of student utterances\nand generate feedback automatically. This allows\nthe system to consistently apply the same tutorial\npolicy across a range of questions. To some extent,\nthis comes at the expense of being able to address\nindividual student misconceptions. However, the\nsystem?s modular setup and extensibility make it\na suitable testbed for both computational linguis-\ntics algorithms and more general questions about\ntheories of learning.\nA distinguishing feature of the system is that it\nis based on an introductory electricity and elec-\ntronics course developed by experienced instruc-\ntional designers. The course was first created for\nuse in a human-human tutoring study, without tak-\ning into account possible limitations of computer\ntutoring. The exercises were then transferred into\na computer system with only minor adjustments\n(e.g., breaking down compound questions into in-\ndividual questions). This resulted in a realistic tu-\ntoring setup, which presents interesting challenges\nto language processing components, involving a\nwide variety of language phenomena.\nWe demonstrate a version of the system that\nhas undergone a successful user evaluation in\n"},{"#tail":"\n","@confidence":"0.999174636363636","#text":"\n2009. The evaluation results indicate that addi-\ntional improvements to remediation strategies, and\nespecially to strategies dealing with interpretation\nproblems, are necessary for effective tutoring. At\nthe same time, the successful large-scale evalua-\ntion shows that BEETLE II can be used as a plat-\nform for future experimentation.\nThe rest of this paper discusses the BEETLE II\nsystem architecture (Section 2), system evaluation\n(Section 3), and the range of computational lin-\nguistics problems that can be investigated using\n"},{"#tail":"\n","@confidence":"0.998897611111111","#text":"\nThe BEETLE II system delivers basic electricity\nand electronics tutoring to students with no prior\nknowledge of the subject. A screenshot of the sys-\ntem is shown in Figure 1. The student interface in-\ncludes an area to display reading material, a circuit\nsimulator, and a dialogue history window. All in-\nteractions with the system are typed. Students read\npre-authored curriculum slides and carry out exer-\ncises which involve experimenting with the circuit\nsimulator and explaining the observed behavior.\nThe system also asks some high-level questions,\nsuch as ?What is voltage??.\nThe system architecture is shown in Figure 2.\nThe system uses a standard interpretation pipeline,\nwith domain-independent parsing and generation\ncomponents supported by domain specific reason-\ners for decision making. The architecture is dis-\ncussed in detail in the rest of this section.\n"},{"#tail":"\n","@confidence":"0.9993116","#text":"\nWe use the TRIPS dialogue parser (Allen et al,\n2007) to parse the utterances. The parser provides\na domain-independent semantic representation in-\ncluding high-level word senses and semantic role\nlabels. The contextual interpreter then uses a refer-\nence resolution approach similar to Byron (2002),\nand an ontology mapping mechanism (Dzikovska\net al, 2008a) to produce a domain-specific seman-\ntic representation of the student?s output. Utter-\nance content is represented as a set of extracted\nobjects and relations between them. Negation is\nsupported, together with a heuristic scoping algo-\nrithm. The interpreter also performs basic ellipsis\nresolution. For example, it can determine that in\nthe answer to the question ?Which bulbs will be\non and which bulbs will be off in this diagram??,\n?off? can be taken to mean ?all bulbs in the di-\nagram will be off.? The resulting output is then\npassed on to the domain reasoning and diagnosis\ncomponents.\n"},{"#tail":"\n","@confidence":"0.99947440625","#text":"\nThe system uses a knowledge base implemented in\nthe KM representation language (Clark and Porter,\n1999; Dzikovska et al, 2006) to represent the state\nof the world. At present, the knowledge base rep-\nresents 14 object types and supports the curricu-\nlum containing over 200 questions and 40 differ-\nent circuits.\nStudent explanations are checked on two levels,\nverifying factual and explanation correctness. For\nexample, for a question ?Why is bulb A lit??, if\nthe student says ?it is in a closed path?, the system\nchecks two things: a) is the bulb indeed in a closed\npath? and b) is being in a closed path a reason-\nable explanation for the bulb being lit? Different\nremediation strategies need to be used depending\non whether the student made a factual error (i.e.,\nthey misread the diagram and the bulb is not in a\nclosed path) or produced an incorrect explanation\n(i.e., the bulb is indeed in a closed path, but they\nfailed to mention that a battery needs to be in the\nsame closed path for the bulb to light).\nThe knowledge base is used to check the fac-\ntual correctness of the answers first, and then a di-\nagnoser checks the explanation correctness. The\ndiagnoser, based on Dzikovska et al (2008b), out-\nputs a diagnosis which consists of lists of correct,\ncontradictory and non-mentioned objects and re-\nlations from the student?s answer. At present, the\nsystem uses a heuristic matching algorithm to clas-\nsify relations into the appropriate category, though\nin the future we may consider a classifier similar\nto Nielsen et al (2008).\n"},{"#tail":"\n","@confidence":"0.999924538461538","#text":"\nThe tutorial planner implements a set of generic\ntutoring strategies, as well as a policy to choose\nan appropriate strategy at each point of the inter-\naction. It is designed so that different policies can\nbe defined for the system. The currently imple-\nmented strategies are: acknowledging the correct\npart of the answer; suggesting a slide to read with\nbackground material; prompting for missing parts\nof the answer; hinting (low- and high- specificity);\nand giving away the answer. Two or more strate-\ngies can be used together if necessary.\nThe hint selection mechanism generates hints\nautomatically. For a low specificity hint it selects\n"},{"#tail":"\n","@confidence":"0.999519714285715","#text":"\nan as-yet unmentioned object and hints at it, for\nexample, ?Here?s a hint: Your answer should men-\ntion a battery.? For high-specificity, it attempts to\nhint at a two-place relation, for example, ?Here?s\na hint: the battery is connected to something.?\nThe tutorial policy makes a high-level decision\nas to which strategy to use (for example, ?ac-\nknowledge the correct part and give a high speci-\nficity hint?) based on the answer analysis and di-\nalogue context. At present, the system takes into\nconsideration the number of incorrect answers re-\nceived in response to the current question and the\nnumber of uninterpretable answers.1\nIn addition to a remediation policy, the tuto-\nrial planner implements an error recovery policy\n(Dzikovska et al, 2009). Since the system ac-\ncepts unrestricted input, interpretation errors are\nunavoidable. Our recovery policy is modeled on\nthe TargetedHelp (Hockey et al, 2003) policy used\nin task-oriented dialogue. If the system cannot\nfind an interpretation for an utterance, it attempts\nto produce a message that describes the problem\nbut without giving away the answer, for example,\n?I?m sorry, I?m having a problem understanding. I\ndon?t know the word power.? The help message is\naccompanied with a hint at the appropriate level,\nalso depending on the number of previous incor-\nrect and non-interpretable answers.\n"},{"#tail":"\n","@confidence":"0.999422818181818","#text":"\nThe strategy decision made by the tutorial plan-\nner, together with relevant semantic content from\nthe student?s answer (e.g., part of the answer to\nconfirm), is passed to content planning and gen-\neration. The system uses a domain-specific con-\ntent planner to produce input to the surface realizer\nbased on the strategy decision, and a FUF/SURGE\n(Elhadad and Robin, 1992) generation system to\nproduce the appropriate text. Templates are used\nto generate some stock phrases such as ?When you\nare ready, go on to the next slide.?\n"},{"#tail":"\n","@confidence":"0.996591769230769","#text":"\nInteraction between components is coordinated by\nthe dialogue manager which uses the information-\nstate approach (Larsson and Traum, 2000). The\ndialogue state is represented by a cumulative an-\nswer analysis which tracks, over multiple turns,\nthe correct, incorrect, and not-yet-mentioned parts\n1Other factors such as student confidence could be con-\nsidered as well (Callaway et al, 2007).\nof the answer. Once the complete answer has been\naccumulated, the system accepts it and moves on.\nTutor hints can contribute parts of the answer to\nthe cumulative state as well, allowing the system\nto jointly construct the solution with the student.\n"},{"#tail":"\n","@confidence":"0.998597636363636","#text":"\nThe first experimental evaluation involving 81 par-\nticipants (undergraduates recruited from a South-\neastern University in the USA) was completed in\n2009. Participants had little or no prior knowledge\nof the domain. Each participant took a pre-test,\nworked through a lesson with the system, took a\npost-test, and completed a user satisfaction survey.\nEach session lasted approximately 4 hours.\nWe implemented two different tutoring policies\nin the system for this evaluation. The baseline\npolicy used an ?accept and bottom out? strategy\nfor all student answers, regardless of their con-\ntent. The students were always given the correct\nanswer, but the system made no attempt at reme-\ndiation, and never indicated whether the student\nwas understood (or correct). In comparison, the\nfull adaptive policy attempted to select an appro-\npriate strategy based on student answer analysis\nand dialogue context, as described above. Stu-\ndents were randomly assigned to a condition. On\naverage, each student session contained 232 stu-\ndent language turns in the fully adaptive condition\n(SD = 25.6) and 156 turns in the baseline condi-\ntion (SD = 2.02). Additional time was taken by\nreading and interacting with the simulation envi-\nronment.\nOut of 81 students, 76 successfully completed\nthe evaluation (data from 5 participants had to be\ndiscarded due to system crashes). There was no\nsignificant difference in learning gain between the\ntwo conditions (baseline: M = 0.63, SD = 0.26,\nfull: M = 0.57, SD = 0.23, t-test p = 0.32),\nand students gave higher satisfaction scores to the\nbaseline condition (baseline: M = 3.32, SD =\n0.65, full: M = 2.56, SD = 0.65, t-test, p <\n0.01). We are currently analyzing the data to in-\nvestigate the reasons for this outcome. However,\nthe evaluation demonstrated that the system can be\nsuccessfully deployed in experiments with naive\nusers and therefore can be used to study the im-\npact of different natural language processing algo-\nrithms on learning gain and user satisfaction.\nAn example dialogue with the system, taken\nfrom the evaluation corpus, is shown in Figure 3.\n"},{"#tail":"\n","@confidence":"0.920929666666666","#text":"\nTutor: Why was bulb A on when switch Y\nwas open and switch Z was closed?\nStudent: because it had a closed path\nTutor: Right. There is a closed path. Keep\ngoing.\nStudent: there was a closed path not effected by\nthe switch\nTutor: I?m sorry, I?m having a problem un-\nderstanding. I don?t understand the\nword ?effect? here. Here?s a hint. Your\nanswer should mention a battery.\nStudent: it has a closed path with the battery\nTutor: You?re on the right track. Here?s the\nanswer. Bulb A is still contained in a\nclosed path with the battery.\n"},{"#tail":"\n","@confidence":"0.969734307692308","#text":"\nfrom our corpus\nIt shows three key system properties: after the stu-\ndent?s first turn, the system rephrases its under-\nstanding of the correct part of the student answer\nand prompts the student to supply the missing in-\nformation. In the second turn, the student utter-\nance could not be interpreted and the system re-\nsponds with a targeted help message and a hint\nabout the object that needs to be mentioned. Fi-\nnally, in the last turn the system combines the in-\nformation from the tutor?s hint and the student?s\nanswers and restates the complete answer since the\ncurrent answer was completed over multiple turns.\n"},{"#tail":"\n","@confidence":"0.9994768","#text":"\nThe BEETLE II system we present was built to\nserve as a platform for research in computational\nlinguistics and tutoring, and can be used for task-\nbased evaluation of algorithms developed for other\ndomains. We are currently developing an annota-\ntion scheme for the data we collected to identify\nstudent paraphrases of correct answers. The an-\nnotated data will be used to evaluate the accuracy\nof existing paraphrasing and textual entailment ap-\nproaches and to investigate how to combine such\nalgorithms with the current deep linguistic analy-\nsis to improve system robustness. We also plan\nto annotate the data we collected for evidence of\nmisunderstandings, i.e., situations where the sys-\ntem arrived at an incorrect interpretation of a stu-\ndent utterance and took action on it. Such annota-\ntion can provide useful input for statistical learn-\ning algorithms to detect and recover from misun-\nderstandings.\nIn dialogue management and generation, the\nkey issue we are planning to investigate is that of\nlinguistic alignment. The analysis of the data we\nhave collected indicates that student satisfaction\nmay be affected if the system rephrases student\nanswers using different words (for example, using\nbetter terminology) but doesn?t explicitly explain\nthe reason why different terminology is needed\n(Dzikovska et al, 2010). Results from other sys-\ntems show that measures of semantic coherence\nbetween a student and a system were positively as-\nsociated with higher learning gain (Ward and Lit-\nman, 2006). Using a deep generator to automati-\ncally generate system feedback gives us a level of\ncontrol over the output and will allow us to devise\nexperiments to study those issues in more detail.\nFrom the point of view of tutoring research,\nwe are planning to use the system to answer\nquestions about the effectiveness of different ap-\nproaches to tutoring, and the differences between\nhuman-human and human-computer tutoring. Pre-\nvious comparisons of human-human and human-\ncomputer dialogue were limited to systems that\nasked short-answer questions (Litman et al, 2006;\nRose? and Torrey, 2005). Having a system that al-\nlows more unrestricted language input will pro-\nvide a more balanced comparison. We are also\nplanning experiments that will allow us to eval-\nuate the effectiveness of individual strategies im-\nplemented in the system by comparing system ver-\nsions using different tutoring policies.\n"},{"#tail":"\n","@confidence":"0.9966784","#text":"\nThis work has been supported in part by US Office\nof Naval Research grants N000140810043 and\nN0001410WX20278. We thank Katherine Harri-\nson and Leanne Taylor for their help running the\nevaluation.\n"},{"#tail":"\n","@confidence":"0.748967","#text":"\nV. Aleven, O. Popescu, and K. R. Koedinger. 2001.\nTowards tutorial dialog to support self-explanation:\nAdding natural language understanding to a cogni-\ntive tutor. In Proceedings of the 10th International\n"}],"#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.96337","#text":"\nSchool of Informatics, University of Edinburgh, Edinburgh, United Kingdom\n"},{"#tail":"\n","@confidence":"0.819745","#text":"\nNaval Air Warfare Center Training Systems Division, Orlando, FL, USA\n"},{"#tail":"\n","@confidence":"0.8681855","#text":"\nHeriot-Watt University\nEdinburgh, United Kingdom\n"},{"#tail":"\n","@confidence":"0.999385","#text":"\nUniversity of Haifa\n"}],"sectionHeader":[{"#tail":"\n","@confidence":"0.990754","@genericHeader":"abstract","#text":"\nAbstract\n"},{"#tail":"\n","@confidence":"0.998266","@genericHeader":"introduction","#text":"\n1 Introduction\n"},{"#tail":"\n","@confidence":"0.9501835","@genericHeader":"method","#text":"\nBEETLE II (Section 4).\n2 System Architecture\n"},{"#tail":"\n","@confidence":"0.997799","@genericHeader":"evaluation","#text":"\n3 Evaluation\n"},{"#tail":"\n","@confidence":"0.993534","@genericHeader":"conclusions","#text":"\n4 Conclusions and Future Work\n"},{"#tail":"\n","@confidence":"0.917033","@genericHeader":"acknowledgments","#text":"\nAcknowledgments\n"},{"#tail":"\n","@confidence":"0.923971","@genericHeader":"references","#text":"\nReferences\n"}],"page":[{"#tail":"\n","@confidence":"0.999351","#text":"\n13\n"},{"#tail":"\n","@confidence":"0.999442","#text":"\n14\n"},{"#tail":"\n","@confidence":"0.984439","#text":"\n15\n"},{"#tail":"\n","@confidence":"0.994497","#text":"\n16\n"},{"#tail":"\n","@confidence":"0.990944","#text":"\n17\n"},{"#tail":"\n","@confidence":"0.998521","#text":"\n18\n"}],"figureCaption":[{"#tail":"\n","@confidence":"0.999731","#text":"\nFigure 1: Screenshot of the BEETLE II system\n"},{"#tail":"\n","@confidence":"0.992117","#text":"\nFigure 2: System architecture diagram\n"},{"#tail":"\n","@confidence":"0.992528","#text":"\nFigure 3: Example interaction with the system\n"}],"email":[{"#tail":"\n","@confidence":"0.986275","#text":"\n{m.dzikovska,j.moore}@ed.ac.uk\n"},{"#tail":"\n","@confidence":"0.985539","#text":"\n{gwendolyn.campbell,natalie.steihauser}@navy.mil\n"},{"#tail":"\n","@confidence":"0.992963","#text":"\ne.farrow@hw.ac.uk\n"},{"#tail":"\n","@confidence":"0.995043","#text":"\nccallawa@gmail.com\n"}]}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.247689","#tail":"\n","@no":"0","note":{"#tail":"\n","@confidence":"0.988074333333333","#text":"Proceedings of the ACL 2010 System Demonstrations, pages 13?18, Uppsala, Sweden, 13 July 2010. c?2010 Association for Computational Linguistics BEETLE II: a system for tutoring and computational linguistics"},"address":[{"#tail":"\n","@confidence":"0.537897","#text":"Naval Air Warfare Center Training Systems Division, Orlando, FL, USA"},{"#tail":"\n","@confidence":"0.977329","#text":"Edinburgh, United Kingdom"},{"#tail":"\n","@confidence":"0.968032","#text":"Mount Carmel, Haifa, Israel"}],"#text":"\n","affiliation":[{"#tail":"\n","@confidence":"0.9872","#text":"School of Informatics, University of Edinburgh, Edinburgh, United Kingdom"},{"#tail":"\n","@confidence":"0.53067","#text":"Natalie Steinhauser and Gwendolyn Campbell"},{"#tail":"\n","@confidence":"0.999993","#text":"Heriot-Watt University"},{"#tail":"\n","@confidence":"0.999926","#text":"University of Haifa"}],"author":[{"#tail":"\n","@confidence":"0.999758","#text":"Myroslava O Dzikovska"},{"#tail":"\n","@confidence":"0.999758","#text":"Johanna D Moore"},{"#tail":"\n","@confidence":"0.996549","#text":"Elaine Farrow"},{"#tail":"\n","@confidence":"0.997922","#text":"Charles B Callaway"}],"abstract":{"#tail":"\n","@confidence":"0.999198076923077","#text":"We present BEETLE II, a tutorial dialogue system designed to accept unrestricted language input and support experimentation with different tutorial planning and dialogue strategies. Our first system evaluation used two different tutorial policies and demonstrated that the system can be successfully used to study the impact of different approaches to tutoring. In the future, the system can also be used to experiment with a variety of natural language interpretation and generation techniques."},"title":{"#tail":"\n","@confidence":"0.759063","#text":"experimentation"},"email":[{"#tail":"\n","@confidence":"0.957806","#text":"m.dzikovska@ed.ac.uk"},{"#tail":"\n","@confidence":"0.957806","#text":"j.moore@ed.ac.uk"},{"#tail":"\n","@confidence":"0.99267","#text":"gwendolyn.campbell@navy.mil"},{"#tail":"\n","@confidence":"0.99267","#text":"natalie.steihauser@navy.mil"},{"#tail":"\n","@confidence":"0.998662","#text":"e.farrow@hw.ac.uk"},{"#tail":"\n","@confidence":"0.999907","#text":"ccallawa@gmail.com"}]}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"V. Aleven, O. Popescu, and K. R. Koedinger. 2001. Towards tutorial dialog to support self-explanation: Adding natural language understanding to a cognitive tutor. In Proceedings of the 10th International Conference on Artificial Intelligence in Education (AIED ?01)?."},"#text":"\n","marker":{"#tail":"\n","#text":"Aleven, Popescu, Koedinger, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"uage input and support experimentation with different tutorial planning and dialogue strategies. Our first system evaluation used two different tutorial policies and demonstrated that the system can be successfully used to study the impact of different approaches to tutoring. In the future, the system can also be used to experiment with a variety of natural language interpretation and generation techniques. 1 Introduction Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations (Jordan et al, 2006; Graesser et al, 1999; Aleven et al, 2001; Buckley and Wolska, 2007; Nielsen et al, 2008; VanLehn et al, 2007), because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring (Chi et al, 1994; Litman et al, 2009; Purandare and Litman, 2008; Steinhauser et al., 2007). However, most existing systems use pre-authored tutor responses for addressing student errors. The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potenti","@endWordPosition":"194","@position":"1413","annotationId":"T1","@startWordPosition":"191","@citStr":"Aleven et al, 2001"}},"title":{"#tail":"\n","#text":"Towards tutorial dialog to support self-explanation: Adding natural language understanding to a cognitive tutor."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 10th International Conference on Artificial Intelligence in Education (AIED ?01)?."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"V Aleven"},{"#tail":"\n","#text":"O Popescu"},{"#tail":"\n","#text":"K R Koedinger"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"James Allen, Myroslava Dzikovska, Mehdi Manshadi, and Mary Swift. 2007. Deep linguistic processing for spoken dialogue systems. In Proceedings of the ACL-07 Workshop on Deep Linguistic Processing."},"#text":"\n","marker":{"#tail":"\n","#text":"Allen, Dzikovska, Manshadi, Swift, 2007"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"m are typed. Students read pre-authored curriculum slides and carry out exercises which involve experimenting with the circuit simulator and explaining the observed behavior. The system also asks some high-level questions, such as ?What is voltage??. The system architecture is shown in Figure 2. The system uses a standard interpretation pipeline, with domain-independent parsing and generation components supported by domain specific reasoners for decision making. The architecture is discussed in detail in the rest of this section. 2.1 Interpretation Components We use the TRIPS dialogue parser (Allen et al, 2007) to parse the utterances. The parser provides a domain-independent semantic representation including high-level word senses and semantic role labels. The contextual interpreter then uses a reference resolution approach similar to Byron (2002), and an ontology mapping mechanism (Dzikovska et al, 2008a) to produce a domain-specific semantic representation of the student?s output. Utterance content is represented as a set of extracted objects and relations between them. Negation is supported, together with a heuristic scoping algorithm. The interpreter also performs basic ellipsis resolution. For","@endWordPosition":"805","@position":"5448","annotationId":"T2","@startWordPosition":"802","@citStr":"Allen et al, 2007"}},"title":{"#tail":"\n","#text":"Deep linguistic processing for spoken dialogue systems."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the ACL-07 Workshop on Deep Linguistic Processing."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"James Allen"},{"#tail":"\n","#text":"Myroslava Dzikovska"},{"#tail":"\n","#text":"Mehdi Manshadi"},{"#tail":"\n","#text":"Mary Swift"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Mark Buckley and Magdalena Wolska. 2007. Towards modelling and using common ground in tutorial dialogue. In Proceedings of DECALOG, the 2007 Workshop on the Semantics and Pragmatics of Dialogue, pages 41?48."},"#text":"\n","pages":{"#tail":"\n","#text":"41--48"},"marker":{"#tail":"\n","#text":"Buckley, Wolska, 2007"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"rt experimentation with different tutorial planning and dialogue strategies. Our first system evaluation used two different tutorial policies and demonstrated that the system can be successfully used to study the impact of different approaches to tutoring. In the future, the system can also be used to experiment with a variety of natural language interpretation and generation techniques. 1 Introduction Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations (Jordan et al, 2006; Graesser et al, 1999; Aleven et al, 2001; Buckley and Wolska, 2007; Nielsen et al, 2008; VanLehn et al, 2007), because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring (Chi et al, 1994; Litman et al, 2009; Purandare and Litman, 2008; Steinhauser et al., 2007). However, most existing systems use pre-authored tutor responses for addressing student errors. The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional","@endWordPosition":"198","@position":"1439","annotationId":"T3","@startWordPosition":"195","@citStr":"Buckley and Wolska, 2007"}},"title":{"#tail":"\n","#text":"Towards modelling and using common ground in tutorial dialogue."},"booktitle":{"#tail":"\n","#text":"In Proceedings of DECALOG, the 2007 Workshop on the Semantics and Pragmatics of Dialogue,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Mark Buckley"},{"#tail":"\n","#text":"Magdalena Wolska"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Ph.D. thesis,"},"date":{"#tail":"\n","#text":"2002"},"institution":{"#tail":"\n","#text":"University of Rochester."},"rawString":{"#tail":"\n","#text":"Donna K. Byron. 2002. Resolving Pronominal Reference to Abstract Entities. Ph.D. thesis, University of Rochester."},"#text":"\n","marker":{"#tail":"\n","#text":"Byron, 2002"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"?. The system architecture is shown in Figure 2. The system uses a standard interpretation pipeline, with domain-independent parsing and generation components supported by domain specific reasoners for decision making. The architecture is discussed in detail in the rest of this section. 2.1 Interpretation Components We use the TRIPS dialogue parser (Allen et al, 2007) to parse the utterances. The parser provides a domain-independent semantic representation including high-level word senses and semantic role labels. The contextual interpreter then uses a reference resolution approach similar to Byron (2002), and an ontology mapping mechanism (Dzikovska et al, 2008a) to produce a domain-specific semantic representation of the student?s output. Utterance content is represented as a set of extracted objects and relations between them. Negation is supported, together with a heuristic scoping algorithm. The interpreter also performs basic ellipsis resolution. For example, it can determine that in the answer to the question ?Which bulbs will be on and which bulbs will be off in this diagram??, ?off? can be taken to mean ?all bulbs in the diagram will be off.? The resulting output is then passed on to ","@endWordPosition":"839","@position":"5690","annotationId":"T4","@startWordPosition":"838","@citStr":"Byron (2002)"}},"title":{"#tail":"\n","#text":"Resolving Pronominal Reference to Abstract Entities."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Donna K Byron"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Charles B. Callaway, Myroslava Dzikovska, Elaine Farrow, Manuel Marques-Pita, Colin Matheson, and Johanna D. Moore. 2007. The Beetle and BeeDiff tutoring systems. In Proceedings of SLaTE?07 (Speech and Language Technology in Education)."},"#text":"\n","marker":{"#tail":"\n","#text":"Callaway, Dzikovska, Farrow, Marques-Pita, Matheson, Moore, 2007"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"l problems. The disadvantage is a lack of adaptivity and generality: students often get the same remediation for the same error regardless of their past performance or dialogue context, as it is infeasible to author a different remediation dialogue for every possible dialogue state. It also becomes more difficult to experiment with different tutorial policies within the system due to the inherent completixites in applying tutoring strategies consistently across a large number of individual hand-authored remediations. The BEETLE II system architecture is designed to overcome these limitations (Callaway et al, 2007). It uses a deep parser and generator, together with a domain reasoner and a diagnoser, to produce detailed analyses of student utterances and generate feedback automatically. This allows the system to consistently apply the same tutorial policy across a range of questions. To some extent, this comes at the expense of being able to address individual student misconceptions. However, the system?s modular setup and extensibility make it a suitable testbed for both computational linguistics algorithms and more general questions about theories of learning. A distinguishing feature of the system is","@endWordPosition":"380","@position":"2659","annotationId":"T5","@startWordPosition":"377","@citStr":"Callaway et al, 2007"},{"#tail":"\n","#text":"ategy decision, and a FUF/SURGE (Elhadad and Robin, 1992) generation system to produce the appropriate text. Templates are used to generate some stock phrases such as ?When you are ready, go on to the next slide.? 2.5 Dialogue Management Interaction between components is coordinated by the dialogue manager which uses the informationstate approach (Larsson and Traum, 2000). The dialogue state is represented by a cumulative answer analysis which tracks, over multiple turns, the correct, incorrect, and not-yet-mentioned parts 1Other factors such as student confidence could be considered as well (Callaway et al, 2007). of the answer. Once the complete answer has been accumulated, the system accepts it and moves on. Tutor hints can contribute parts of the answer to the cumulative state as well, allowing the system to jointly construct the solution with the student. 3 Evaluation The first experimental evaluation involving 81 participants (undergraduates recruited from a Southeastern University in the USA) was completed in 2009. Participants had little or no prior knowledge of the domain. Each participant took a pre-test, worked through a lesson with the system, took a post-test, and completed a user satisfac","@endWordPosition":"1713","@position":"11089","annotationId":"T6","@startWordPosition":"1710","@citStr":"Callaway et al, 2007"}]},"title":{"#tail":"\n","#text":"The Beetle and BeeDiff tutoring systems."},"booktitle":{"#tail":"\n","#text":"In Proceedings of SLaTE?07 (Speech and Language Technology in Education)."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Charles B Callaway"},{"#tail":"\n","#text":"Myroslava Dzikovska"},{"#tail":"\n","#text":"Elaine Farrow"},{"#tail":"\n","#text":"Manuel Marques-Pita"},{"#tail":"\n","#text":"Colin Matheson"},{"#tail":"\n","#text":"Johanna D Moore"}]}},{"volume":{"#tail":"\n","#text":"18"},"#tail":"\n","date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Michelene T. H. Chi, Nicholas de Leeuw, Mei-Hung Chiu, and Christian LaVancher. 1994. Eliciting self-explanations improves understanding. Cognitive Science, 18(3):439?477."},"journal":{"#tail":"\n","#text":"Cognitive Science,"},"#text":"\n","issue":{"#tail":"\n","#text":"3"},"marker":{"#tail":"\n","#text":"Chi, de Leeuw, Chiu, LaVancher, 1994"},"title":{"#tail":"\n","#text":"Eliciting self-explanations improves understanding."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Michelene T H Chi"},{"#tail":"\n","#text":"Nicholas de Leeuw"},{"#tail":"\n","#text":"Mei-Hung Chiu"},{"#tail":"\n","#text":"Christian LaVancher"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"note":{"#tail":"\n","#text":"KM (1.4): Users Manual. http://www.cs.utexas.edu/users/mfkb/km."},"rawString":{"#tail":"\n","#text":"Peter Clark and Bruce Porter, 1999. KM (1.4): Users Manual. http://www.cs.utexas.edu/users/mfkb/km."},"#text":"\n","marker":{"#tail":"\n","#text":"Clark, Porter, 1999"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"presented as a set of extracted objects and relations between them. Negation is supported, together with a heuristic scoping algorithm. The interpreter also performs basic ellipsis resolution. For example, it can determine that in the answer to the question ?Which bulbs will be on and which bulbs will be off in this diagram??, ?off? can be taken to mean ?all bulbs in the diagram will be off.? The resulting output is then passed on to the domain reasoning and diagnosis components. 2.2 Domain Reasoning and Diagnosis The system uses a knowledge base implemented in the KM representation language (Clark and Porter, 1999; Dzikovska et al, 2006) to represent the state of the world. At present, the knowledge base represents 14 object types and supports the curriculum containing over 200 questions and 40 different circuits. Student explanations are checked on two levels, verifying factual and explanation correctness. For example, for a question ?Why is bulb A lit??, if the student says ?it is in a closed path?, the system checks two things: a) is the bulb indeed in a closed path? and b) is being in a closed path a reasonable explanation for the bulb being lit? Different remediation strategies need to be used dep","@endWordPosition":"967","@position":"6474","annotationId":"T7","@startWordPosition":"964","@citStr":"Clark and Porter, 1999"}},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Peter Clark"},{"#tail":"\n","#text":"Bruce Porter"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Myroslava O. Dzikovska, Charles B. Callaway, and Elaine Farrow. 2006. Interpretation and generation in a knowledge-based tutorial system. In Proceedings of EACL-06 workshop on knowledge and reasoning for language processing, Trento, Italy, April. Myroslava O. Dzikovska, James F. Allen, and Mary D."},"journal":{"#tail":"\n","#text":"Myroslava"},"#text":"\n","marker":{"#tail":"\n","#text":"Dzikovska, Callaway, Farrow, 2006"},"location":{"#tail":"\n","#text":"Trento, Italy,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"tracted objects and relations between them. Negation is supported, together with a heuristic scoping algorithm. The interpreter also performs basic ellipsis resolution. For example, it can determine that in the answer to the question ?Which bulbs will be on and which bulbs will be off in this diagram??, ?off? can be taken to mean ?all bulbs in the diagram will be off.? The resulting output is then passed on to the domain reasoning and diagnosis components. 2.2 Domain Reasoning and Diagnosis The system uses a knowledge base implemented in the KM representation language (Clark and Porter, 1999; Dzikovska et al, 2006) to represent the state of the world. At present, the knowledge base represents 14 object types and supports the curriculum containing over 200 questions and 40 different circuits. Student explanations are checked on two levels, verifying factual and explanation correctness. For example, for a question ?Why is bulb A lit??, if the student says ?it is in a closed path?, the system checks two things: a) is the bulb indeed in a closed path? and b) is being in a closed path a reasonable explanation for the bulb being lit? Different remediation strategies need to be used depending on whether the st","@endWordPosition":"971","@position":"6498","annotationId":"T8","@startWordPosition":"968","@citStr":"Dzikovska et al, 2006"}},"title":{"#tail":"\n","#text":"Interpretation and generation in a knowledge-based tutorial system."},"booktitle":{"#tail":"\n","#text":"In Proceedings of EACL-06 workshop on"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Myroslava O Dzikovska"},{"#tail":"\n","#text":"Charles B Callaway"},{"#tail":"\n","#text":"Elaine Farrow"}]}},{"volume":{"#tail":"\n","#text":"18"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Swift. 2008a. Linking semantic and knowledge representations in a multi-domain dialogue system. Journal of Logic and Computation, 18(3):405?430."},"journal":{"#tail":"\n","#text":"Journal of Logic and Computation,"},"#text":"\n","issue":{"#tail":"\n","#text":"3"},"marker":{"#tail":"\n","#text":"2008a, "},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"d to mention that a battery needs to be in the same closed path for the bulb to light). The knowledge base is used to check the factual correctness of the answers first, and then a diagnoser checks the explanation correctness. The diagnoser, based on Dzikovska et al (2008b), outputs a diagnosis which consists of lists of correct, contradictory and non-mentioned objects and relations from the student?s answer. At present, the system uses a heuristic matching algorithm to classify relations into the appropriate category, though in the future we may consider a classifier similar to Nielsen et al (2008). 2.3 Tutorial Planner The tutorial planner implements a set of generic tutoring strategies, as well as a policy to choose an appropriate strategy at each point of the interaction. It is designed so that different policies can be defined for the system. The currently implemented strategies are: acknowledging the correct part of the answer; suggesting a slide to read with background material; prompting for missing parts of the answer; hinting (low- and high- specificity); and giving away the answer. Two or more strategies can be used together if necessary. The hint selection mechanism generates","@endWordPosition":"1215","@position":"7896","annotationId":"T9","@startWordPosition":"1215","@citStr":"(2008)"}},"title":{"#tail":"\n","#text":"Linking semantic and knowledge representations in a multi-domain dialogue system."},"@valid":"false","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"2008a"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2008"},"rawString":{"#tail":"\n","#text":"Myroslava O. Dzikovska, Gwendolyn E. Campbell, Charles B. Callaway, Natalie B. Steinhauser, Elaine Farrow, Johanna D. Moore, Leslie A. Butler, and Colin Matheson. 2008b. Diagnosing natural language answers to support adaptive tutoring. In Proceedings 21st International FLAIRS Conference, Coconut Grove, Florida, May."},"#text":"\n","marker":{"#tail":"\n","#text":"Dzikovska, Campbell, Callaway, Steinhauser, Farrow, Moore, Butler, Matheson, 2008"},"location":{"#tail":"\n","#text":"Grove, Florida,"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"The system uses a standard interpretation pipeline, with domain-independent parsing and generation components supported by domain specific reasoners for decision making. The architecture is discussed in detail in the rest of this section. 2.1 Interpretation Components We use the TRIPS dialogue parser (Allen et al, 2007) to parse the utterances. The parser provides a domain-independent semantic representation including high-level word senses and semantic role labels. The contextual interpreter then uses a reference resolution approach similar to Byron (2002), and an ontology mapping mechanism (Dzikovska et al, 2008a) to produce a domain-specific semantic representation of the student?s output. Utterance content is represented as a set of extracted objects and relations between them. Negation is supported, together with a heuristic scoping algorithm. The interpreter also performs basic ellipsis resolution. For example, it can determine that in the answer to the question ?Which bulbs will be on and which bulbs will be off in this diagram??, ?off? can be taken to mean ?all bulbs in the diagram will be off.? The resulting output is then passed on to the domain reasoning and diagnosis components. 2.2 Domain ","@endWordPosition":"848","@position":"5748","annotationId":"T10","@startWordPosition":"845","@citStr":"Dzikovska et al, 2008"},{"#tail":"\n","#text":"nd b) is being in a closed path a reasonable explanation for the bulb being lit? Different remediation strategies need to be used depending on whether the student made a factual error (i.e., they misread the diagram and the bulb is not in a closed path) or produced an incorrect explanation (i.e., the bulb is indeed in a closed path, but they failed to mention that a battery needs to be in the same closed path for the bulb to light). The knowledge base is used to check the factual correctness of the answers first, and then a diagnoser checks the explanation correctness. The diagnoser, based on Dzikovska et al (2008b), outputs a diagnosis which consists of lists of correct, contradictory and non-mentioned objects and relations from the student?s answer. At present, the system uses a heuristic matching algorithm to classify relations into the appropriate category, though in the future we may consider a classifier similar to Nielsen et al (2008). 2.3 Tutorial Planner The tutorial planner implements a set of generic tutoring strategies, as well as a policy to choose an appropriate strategy at each point of the interaction. It is designed so that different policies can be defined for the system. The currentl","@endWordPosition":"1162","@position":"7562","annotationId":"T11","@startWordPosition":"1159","@citStr":"Dzikovska et al (2008"}]},"title":{"#tail":"\n","#text":"Diagnosing natural language answers to support adaptive tutoring."},"booktitle":{"#tail":"\n","#text":"In Proceedings 21st International FLAIRS Conference, Coconut"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Myroslava O Dzikovska"},{"#tail":"\n","#text":"Gwendolyn E Campbell"},{"#tail":"\n","#text":"Charles B Callaway"},{"#tail":"\n","#text":"Natalie B Steinhauser"},{"#tail":"\n","#text":"Elaine Farrow"},{"#tail":"\n","#text":"Johanna D Moore"},{"#tail":"\n","#text":"Leslie A Butler"},{"#tail":"\n","#text":"Colin Matheson"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2009"},"rawString":{"#tail":"\n","#text":"Myroslava O. Dzikovska, Charles B. Callaway, Elaine Farrow, Johanna D. Moore, Natalie B. Steinhauser, and Gwendolyn C. Campbell. 2009. Dealing with interpretation errors in tutorial dialogue. In Proceedings of SIGDIAL-09, London, UK, Sep."},"#text":"\n","marker":{"#tail":"\n","#text":"Dzikovska, Callaway, Farrow, Moore, Steinhauser, Campbell, 2009"},"location":{"#tail":"\n","#text":"London, UK,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"gh-specificity, it attempts to hint at a two-place relation, for example, ?Here?s a hint: the battery is connected to something.? The tutorial policy makes a high-level decision as to which strategy to use (for example, ?acknowledge the correct part and give a high specificity hint?) based on the answer analysis and dialogue context. At present, the system takes into consideration the number of incorrect answers received in response to the current question and the number of uninterpretable answers.1 In addition to a remediation policy, the tutorial planner implements an error recovery policy (Dzikovska et al, 2009). Since the system accepts unrestricted input, interpretation errors are unavoidable. Our recovery policy is modeled on the TargetedHelp (Hockey et al, 2003) policy used in task-oriented dialogue. If the system cannot find an interpretation for an utterance, it attempts to produce a message that describes the problem but without giving away the answer, for example, ?I?m sorry, I?m having a problem understanding. I don?t know the word power.? The help message is accompanied with a hint at the appropriate level, also depending on the number of previous incorrect and non-interpretable answers. 2.","@endWordPosition":"1471","@position":"9545","annotationId":"T12","@startWordPosition":"1468","@citStr":"Dzikovska et al, 2009"}},"title":{"#tail":"\n","#text":"Dealing with interpretation errors in tutorial dialogue."},"booktitle":{"#tail":"\n","#text":"In Proceedings of SIGDIAL-09,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Myroslava O Dzikovska"},{"#tail":"\n","#text":"Charles B Callaway"},{"#tail":"\n","#text":"Elaine Farrow"},{"#tail":"\n","#text":"Johanna D Moore"},{"#tail":"\n","#text":"Natalie B Steinhauser"},{"#tail":"\n","#text":"Gwendolyn C Campbell"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2010"},"rawString":{"#tail":"\n","#text":"Myroslava O. Dzikovska, Johanna D. Moore, Natalie Steinhauser, and Gwendolyn Campbell. 2010. The impact of interpretation problems on tutorial dialogue. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics(ACL2010)."},"#text":"\n","marker":{"#tail":"\n","#text":"Dzikovska, Moore, Steinhauser, Campbell, 2010"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"rrived at an incorrect interpretation of a student utterance and took action on it. Such annotation can provide useful input for statistical learning algorithms to detect and recover from misunderstandings. In dialogue management and generation, the key issue we are planning to investigate is that of linguistic alignment. The analysis of the data we have collected indicates that student satisfaction may be affected if the system rephrases student answers using different words (for example, using better terminology) but doesn?t explicitly explain the reason why different terminology is needed (Dzikovska et al, 2010). Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain (Ward and Litman, 2006). Using a deep generator to automatically generate system feedback gives us a level of control over the output and will allow us to devise experiments to study those issues in more detail. From the point of view of tutoring research, we are planning to use the system to answer questions about the effectiveness of different approaches to tutoring, and the differences between human-human and human-computer tutoring. Previ","@endWordPosition":"2521","@position":"15957","annotationId":"T13","@startWordPosition":"2518","@citStr":"Dzikovska et al, 2010"}},"title":{"#tail":"\n","#text":"The impact of interpretation problems on tutorial dialogue."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics(ACL2010)."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Myroslava O Dzikovska"},{"#tail":"\n","#text":"Johanna D Moore"},{"#tail":"\n","#text":"Natalie Steinhauser"},{"#tail":"\n","#text":"Gwendolyn Campbell"}]}},{"date":{"#tail":"\n","#text":"1992"},"editor":{"#tail":"\n","#text":"R. Dale, E. Hovy, D. Ro?sner, and O. Stock, editors,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"or example, ?I?m sorry, I?m having a problem understanding. I don?t know the word power.? The help message is accompanied with a hint at the appropriate level, also depending on the number of previous incorrect and non-interpretable answers. 2.4 Generation The strategy decision made by the tutorial planner, together with relevant semantic content from the student?s answer (e.g., part of the answer to confirm), is passed to content planning and generation. The system uses a domain-specific content planner to produce input to the surface realizer based on the strategy decision, and a FUF/SURGE (Elhadad and Robin, 1992) generation system to produce the appropriate text. Templates are used to generate some stock phrases such as ?When you are ready, go on to the next slide.? 2.5 Dialogue Management Interaction between components is coordinated by the dialogue manager which uses the informationstate approach (Larsson and Traum, 2000). The dialogue state is represented by a cumulative answer analysis which tracks, over multiple turns, the correct, incorrect, and not-yet-mentioned parts 1Other factors such as student confidence could be considered as well (Callaway et al, 2007). of the answer. Once the complete a","@endWordPosition":"1626","@position":"10525","annotationId":"T14","@startWordPosition":"1623","@citStr":"Elhadad and Robin, 1992"}},"title":{"#tail":"\n","#text":"Controlling content realization with functional unification grammars. In"},"#tail":"\n","rawString":{"#tail":"\n","#text":"Michael Elhadad and Jacques Robin. 1992. Controlling content realization with functional unification grammars. In R. Dale, E. Hovy, D. Ro?sner, and O. Stock, editors, Proceedings of the Sixth International Workshop on Natural Language Generation, pages 89?104, Berlin, April. Springer-Verlag."},"#text":"\n","pages":{"#tail":"\n","#text":"89--104"},"marker":{"#tail":"\n","#text":"Elhadad, Robin, 1992"},"publisher":{"#tail":"\n","#text":"Springer-Verlag."},"location":{"#tail":"\n","#text":"Berlin,"},"booktitle":{"#tail":"\n","#text":"Proceedings of the Sixth International Workshop on Natural Language Generation,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Michael Elhadad"},{"#tail":"\n","#text":"Jacques Robin"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"A. C. Graesser, P. Wiemer-Hastings, P. WiemerHastings, and R. Kreuz. 1999. Autotutor: A simulation of a human tutor. Cognitive Systems Research, 1:35?51."},"#text":"\n","pages":{"#tail":"\n","#text":"1--35"},"marker":{"#tail":"\n","#text":"Graesser, Wiemer-Hastings, WiemerHastings, Kreuz, 1999"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"cept unrestricted language input and support experimentation with different tutorial planning and dialogue strategies. Our first system evaluation used two different tutorial policies and demonstrated that the system can be successfully used to study the impact of different approaches to tutoring. In the future, the system can also be used to experiment with a variety of natural language interpretation and generation techniques. 1 Introduction Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations (Jordan et al, 2006; Graesser et al, 1999; Aleven et al, 2001; Buckley and Wolska, 2007; Nielsen et al, 2008; VanLehn et al, 2007), because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring (Chi et al, 1994; Litman et al, 2009; Purandare and Litman, 2008; Steinhauser et al., 2007). However, most existing systems use pre-authored tutor responses for addressing student errors. The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step sca","@endWordPosition":"190","@position":"1393","annotationId":"T15","@startWordPosition":"187","@citStr":"Graesser et al, 1999"}},"title":{"#tail":"\n","#text":"Autotutor: A simulation of a human tutor. Cognitive Systems Research,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A C Graesser"},{"#tail":"\n","#text":"P Wiemer-Hastings"},{"#tail":"\n","#text":"P WiemerHastings"},{"#tail":"\n","#text":"R Kreuz"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2003"},"rawString":{"#tail":"\n","#text":"Beth Ann Hockey, Oliver Lemon, Ellen Campana, Laura Hiatt, Gregory Aist, James Hieronymus, Alexander Gruenstein, and John Dowding. 2003. Targeted help for spoken dialogue systems: intelligent feedback improves naive users? performance. In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics, pages 147?154, Morristown, NJ, USA."},"#text":"\n","pages":{"#tail":"\n","#text":"147--154"},"marker":{"#tail":"\n","#text":"Hockey, Lemon, Campana, Hiatt, Aist, Hieronymus, Gruenstein, Dowding, 2003"},"location":{"#tail":"\n","#text":"Morristown, NJ, USA."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"gh-level decision as to which strategy to use (for example, ?acknowledge the correct part and give a high specificity hint?) based on the answer analysis and dialogue context. At present, the system takes into consideration the number of incorrect answers received in response to the current question and the number of uninterpretable answers.1 In addition to a remediation policy, the tutorial planner implements an error recovery policy (Dzikovska et al, 2009). Since the system accepts unrestricted input, interpretation errors are unavoidable. Our recovery policy is modeled on the TargetedHelp (Hockey et al, 2003) policy used in task-oriented dialogue. If the system cannot find an interpretation for an utterance, it attempts to produce a message that describes the problem but without giving away the answer, for example, ?I?m sorry, I?m having a problem understanding. I don?t know the word power.? The help message is accompanied with a hint at the appropriate level, also depending on the number of previous incorrect and non-interpretable answers. 2.4 Generation The strategy decision made by the tutorial planner, together with relevant semantic content from the student?s answer (e.g., part of the answer ","@endWordPosition":"1494","@position":"9702","annotationId":"T16","@startWordPosition":"1491","@citStr":"Hockey et al, 2003"}},"title":{"#tail":"\n","#text":"Targeted help for spoken dialogue systems: intelligent feedback improves naive users? performance."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the tenth conference on European chapter of the Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Beth Ann Hockey"},{"#tail":"\n","#text":"Oliver Lemon"},{"#tail":"\n","#text":"Ellen Campana"},{"#tail":"\n","#text":"Laura Hiatt"},{"#tail":"\n","#text":"Gregory Aist"},{"#tail":"\n","#text":"James Hieronymus"},{"#tail":"\n","#text":"Alexander Gruenstein"},{"#tail":"\n","#text":"John Dowding"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Pamela Jordan, Maxim Makatchev, Umarani Pappuswamy, Kurt VanLehn, and Patricia Albacete. 2006. A natural language tutorial dialogue system for physics. In Proceedings of the 19th International FLAIRS conference."},"#text":"\n","marker":{"#tail":"\n","#text":"Jordan, Makatchev, Pappuswamy, VanLehn, Albacete, 2006"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ystem designed to accept unrestricted language input and support experimentation with different tutorial planning and dialogue strategies. Our first system evaluation used two different tutorial policies and demonstrated that the system can be successfully used to study the impact of different approaches to tutoring. In the future, the system can also be used to experiment with a variety of natural language interpretation and generation techniques. 1 Introduction Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations (Jordan et al, 2006; Graesser et al, 1999; Aleven et al, 2001; Buckley and Wolska, 2007; Nielsen et al, 2008; VanLehn et al, 2007), because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring (Chi et al, 1994; Litman et al, 2009; Purandare and Litman, 2008; Steinhauser et al., 2007). However, most existing systems use pre-authored tutor responses for addressing student errors. The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, prov","@endWordPosition":"186","@position":"1371","annotationId":"T17","@startWordPosition":"183","@citStr":"Jordan et al, 2006"}},"title":{"#tail":"\n","#text":"A natural language tutorial dialogue system for physics."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 19th International FLAIRS conference."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Pamela Jordan"},{"#tail":"\n","#text":"Maxim Makatchev"},{"#tail":"\n","#text":"Umarani Pappuswamy"},{"#tail":"\n","#text":"Kurt VanLehn"},{"#tail":"\n","#text":"Patricia Albacete"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Staffan Larsson and David Traum. 2000. Information state and dialogue management in the TRINDI Dialogue Move Engine Toolkit. Natural Language Engineering, 6(3-4):323?340."},"journal":{"#tail":"\n","#text":"Natural Language Engineering,"},"#text":"\n","pages":{"#tail":"\n","#text":"6--3"},"marker":{"#tail":"\n","#text":"Larsson, Traum, 2000"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" with relevant semantic content from the student?s answer (e.g., part of the answer to confirm), is passed to content planning and generation. The system uses a domain-specific content planner to produce input to the surface realizer based on the strategy decision, and a FUF/SURGE (Elhadad and Robin, 1992) generation system to produce the appropriate text. Templates are used to generate some stock phrases such as ?When you are ready, go on to the next slide.? 2.5 Dialogue Management Interaction between components is coordinated by the dialogue manager which uses the informationstate approach (Larsson and Traum, 2000). The dialogue state is represented by a cumulative answer analysis which tracks, over multiple turns, the correct, incorrect, and not-yet-mentioned parts 1Other factors such as student confidence could be considered as well (Callaway et al, 2007). of the answer. Once the complete answer has been accumulated, the system accepts it and moves on. Tutor hints can contribute parts of the answer to the cumulative state as well, allowing the system to jointly construct the solution with the student. 3 Evaluation The first experimental evaluation involving 81 participants (undergraduates recruited fr","@endWordPosition":"1675","@position":"10842","annotationId":"T18","@startWordPosition":"1672","@citStr":"Larsson and Traum, 2000"}},"title":{"#tail":"\n","#text":"Information state and dialogue management in the TRINDI Dialogue Move Engine Toolkit."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Staffan Larsson"},{"#tail":"\n","#text":"David Traum"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Diane Litman, Carolyn P. Rose?, Kate Forbes-Riley, Kurt VanLehn, Dumisizwe Bhembe, and Scott Silliman. 2006. Spoken versus typed human and computer dialogue tutoring. International Journal of Artificial Intelligence in Education, 16:145?170."},"journal":{"#tail":"\n","#text":"International Journal of Artificial Intelligence in Education,"},"#text":"\n","pages":{"#tail":"\n","#text":"16--145"},"marker":{"#tail":"\n","#text":"Litman, Rose, Forbes-Riley, VanLehn, Bhembe, Silliman, 2006"},"title":{"#tail":"\n","#text":"Spoken versus typed human and computer dialogue tutoring."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Diane Litman"},{"#tail":"\n","#text":"Carolyn P Rose"},{"#tail":"\n","#text":"Kate Forbes-Riley"},{"#tail":"\n","#text":"Kurt VanLehn"},{"#tail":"\n","#text":"Dumisizwe Bhembe"},{"#tail":"\n","#text":"Scott Silliman"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2009"},"rawString":{"#tail":"\n","#text":"Diane Litman, Johanna Moore, Myroslava Dzikovska, and Elaine Farrow. 2009. Generalizing tutorial dialogue results. In Proceedings of 14th International Conference on Artificial Intelligence in Education (AIED), Brighton, UK, July."},"#text":"\n","marker":{"#tail":"\n","#text":"Litman, Moore, Dzikovska, Farrow, 2009"},"location":{"#tail":"\n","#text":"Brighton, UK,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"nt approaches to tutoring. In the future, the system can also be used to experiment with a variety of natural language interpretation and generation techniques. 1 Introduction Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations (Jordan et al, 2006; Graesser et al, 1999; Aleven et al, 2001; Buckley and Wolska, 2007; Nielsen et al, 2008; VanLehn et al, 2007), because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring (Chi et al, 1994; Litman et al, 2009; Purandare and Litman, 2008; Steinhauser et al., 2007). However, most existing systems use pre-authored tutor responses for addressing student errors. The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems. The disadvantage is a lack of adaptivity and generality: students often get the same remediation for the same error regardless of their past performance or dialogue context, as it is infeasible to author a differe","@endWordPosition":"236","@position":"1663","annotationId":"T19","@startWordPosition":"233","@citStr":"Litman et al, 2009"}},"title":{"#tail":"\n","#text":"Generalizing tutorial dialogue results."},"booktitle":{"#tail":"\n","#text":"In Proceedings of 14th International Conference on Artificial Intelligence in Education (AIED),"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Diane Litman"},{"#tail":"\n","#text":"Johanna Moore"},{"#tail":"\n","#text":"Myroslava Dzikovska"},{"#tail":"\n","#text":"Elaine Farrow"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2008"},"rawString":{"#tail":"\n","#text":"Rodney D. Nielsen, Wayne Ward, and James H. Martin. 2008. Learning to assess low-level conceptual understanding. In Proceedings 21st International FLAIRS Conference, Coconut Grove, Florida, May."},"#text":"\n","marker":{"#tail":"\n","#text":"Nielsen, Ward, Martin, 2008"},"location":{"#tail":"\n","#text":"Grove, Florida,"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"fferent tutorial planning and dialogue strategies. Our first system evaluation used two different tutorial policies and demonstrated that the system can be successfully used to study the impact of different approaches to tutoring. In the future, the system can also be used to experiment with a variety of natural language interpretation and generation techniques. 1 Introduction Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations (Jordan et al, 2006; Graesser et al, 1999; Aleven et al, 2001; Buckley and Wolska, 2007; Nielsen et al, 2008; VanLehn et al, 2007), because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring (Chi et al, 1994; Litman et al, 2009; Purandare and Litman, 2008; Steinhauser et al., 2007). However, most existing systems use pre-authored tutor responses for addressing student errors. The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems. The disadv","@endWordPosition":"202","@position":"1460","annotationId":"T20","@startWordPosition":"199","@citStr":"Nielsen et al, 2008"},{"#tail":"\n","#text":"but they failed to mention that a battery needs to be in the same closed path for the bulb to light). The knowledge base is used to check the factual correctness of the answers first, and then a diagnoser checks the explanation correctness. The diagnoser, based on Dzikovska et al (2008b), outputs a diagnosis which consists of lists of correct, contradictory and non-mentioned objects and relations from the student?s answer. At present, the system uses a heuristic matching algorithm to classify relations into the appropriate category, though in the future we may consider a classifier similar to Nielsen et al (2008). 2.3 Tutorial Planner The tutorial planner implements a set of generic tutoring strategies, as well as a policy to choose an appropriate strategy at each point of the interaction. It is designed so that different policies can be defined for the system. The currently implemented strategies are: acknowledging the correct part of the answer; suggesting a slide to read with background material; prompting for missing parts of the answer; hinting (low- and high- specificity); and giving away the answer. Two or more strategies can be used together if necessary. The hint selection mechanism generates","@endWordPosition":"1215","@position":"7896","annotationId":"T21","@startWordPosition":"1212","@citStr":"Nielsen et al (2008)"}]},"title":{"#tail":"\n","#text":"Learning to assess low-level conceptual understanding."},"booktitle":{"#tail":"\n","#text":"In Proceedings 21st International FLAIRS Conference, Coconut"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Rodney D Nielsen"},{"#tail":"\n","#text":"Wayne Ward"},{"#tail":"\n","#text":"James H Martin"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2008"},"rawString":{"#tail":"\n","#text":"Amruta Purandare and Diane Litman. 2008. Contentlearning correlations in spoken tutoring dialogs at word, turn and discourse levels. In Proceedings 21st International FLAIRS Conference, Coconut Grove, Florida, May."},"#text":"\n","marker":{"#tail":"\n","#text":"Purandare, Litman, 2008"},"location":{"#tail":"\n","#text":"Grove, Florida,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"oring. In the future, the system can also be used to experiment with a variety of natural language interpretation and generation techniques. 1 Introduction Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations (Jordan et al, 2006; Graesser et al, 1999; Aleven et al, 2001; Buckley and Wolska, 2007; Nielsen et al, 2008; VanLehn et al, 2007), because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring (Chi et al, 1994; Litman et al, 2009; Purandare and Litman, 2008; Steinhauser et al., 2007). However, most existing systems use pre-authored tutor responses for addressing student errors. The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems. The disadvantage is a lack of adaptivity and generality: students often get the same remediation for the same error regardless of their past performance or dialogue context, as it is infeasible to author a different remediation dialogue for ","@endWordPosition":"240","@position":"1691","annotationId":"T22","@startWordPosition":"237","@citStr":"Purandare and Litman, 2008"}},"title":{"#tail":"\n","#text":"Contentlearning correlations in spoken tutoring dialogs at word, turn and discourse levels."},"booktitle":{"#tail":"\n","#text":"In Proceedings 21st International FLAIRS Conference, Coconut"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Amruta Purandare"},{"#tail":"\n","#text":"Diane Litman"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"C.P. Rose? and C. Torrey. 2005. Interactivity versus expectation: Eliciting learning oriented behavior with tutorial dialogue systems. In Proceedings of Interact?05."},"#text":"\n","marker":{"#tail":"\n","#text":"Rose, Torrey, 2005"},"title":{"#tail":"\n","#text":"Interactivity versus expectation: Eliciting learning oriented behavior with tutorial dialogue systems."},"booktitle":{"#tail":"\n","#text":"In Proceedings of Interact?05."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"C P Rose"},{"#tail":"\n","#text":"C Torrey"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"N. B. Steinhauser, L. A. Butler, and G. E. Campbell. 2007. Simulated tutors in immersive learning environments: Empirically-derived design principles. In Proceedings of the 2007 Interservice/Industry Training, Simulation and Education Conference, Orlando, FL."},"#text":"\n","marker":{"#tail":"\n","#text":"Steinhauser, Butler, Campbell, 2007"},"location":{"#tail":"\n","#text":"Orlando, FL."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"stem can also be used to experiment with a variety of natural language interpretation and generation techniques. 1 Introduction Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations (Jordan et al, 2006; Graesser et al, 1999; Aleven et al, 2001; Buckley and Wolska, 2007; Nielsen et al, 2008; VanLehn et al, 2007), because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring (Chi et al, 1994; Litman et al, 2009; Purandare and Litman, 2008; Steinhauser et al., 2007). However, most existing systems use pre-authored tutor responses for addressing student errors. The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems. The disadvantage is a lack of adaptivity and generality: students often get the same remediation for the same error regardless of their past performance or dialogue context, as it is infeasible to author a different remediation dialogue for every possible dialogue sta","@endWordPosition":"244","@position":"1718","annotationId":"T23","@startWordPosition":"241","@citStr":"Steinhauser et al., 2007"}},"title":{"#tail":"\n","#text":"Simulated tutors in immersive learning environments: Empirically-derived design principles."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 2007 Interservice/Industry Training, Simulation and Education Conference,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"N B Steinhauser"},{"#tail":"\n","#text":"L A Butler"},{"#tail":"\n","#text":"G E Campbell"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"Kurt VanLehn, Pamela Jordan, and Diane Litman. 2007. Developing pedagogically effective tutorial dialogue tactics: Experiments and a testbed. In Proceedings of SLaTE Workshop on Speech and Language Technology in Education, Farmington, PA, October."},"#text":"\n","marker":{"#tail":"\n","#text":"VanLehn, Jordan, Litman, 2007"},"location":{"#tail":"\n","#text":"Farmington, PA,"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ning and dialogue strategies. Our first system evaluation used two different tutorial policies and demonstrated that the system can be successfully used to study the impact of different approaches to tutoring. In the future, the system can also be used to experiment with a variety of natural language interpretation and generation techniques. 1 Introduction Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations (Jordan et al, 2006; Graesser et al, 1999; Aleven et al, 2001; Buckley and Wolska, 2007; Nielsen et al, 2008; VanLehn et al, 2007), because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring (Chi et al, 1994; Litman et al, 2009; Purandare and Litman, 2008; Steinhauser et al., 2007). However, most existing systems use pre-authored tutor responses for addressing student errors. The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems. The disadvantage is a lack of ad","@endWordPosition":"206","@position":"1482","annotationId":"T24","@startWordPosition":"203","@citStr":"VanLehn et al, 2007"}},"title":{"#tail":"\n","#text":"Developing pedagogically effective tutorial dialogue tactics: Experiments and a testbed."},"booktitle":{"#tail":"\n","#text":"In Proceedings of SLaTE Workshop on Speech and Language Technology in Education,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kurt VanLehn"},{"#tail":"\n","#text":"Pamela Jordan"},{"#tail":"\n","#text":"Diane Litman"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"Arthur Ward and Diane Litman. 2006. Cohesion and learning in a tutorial spoken dialog system. In Proceedings of 19th International FLAIRS (Florida Artificial Intelligence Research Society) Conference, Melbourne Beach, FL."},"#text":"\n","marker":{"#tail":"\n","#text":"Ward, Litman, 2006"},"location":{"#tail":"\n","#text":"Melbourne Beach, FL."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"cover from misunderstandings. In dialogue management and generation, the key issue we are planning to investigate is that of linguistic alignment. The analysis of the data we have collected indicates that student satisfaction may be affected if the system rephrases student answers using different words (for example, using better terminology) but doesn?t explicitly explain the reason why different terminology is needed (Dzikovska et al, 2010). Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain (Ward and Litman, 2006). Using a deep generator to automatically generate system feedback gives us a level of control over the output and will allow us to devise experiments to study those issues in more detail. From the point of view of tutoring research, we are planning to use the system to answer questions about the effectiveness of different approaches to tutoring, and the differences between human-human and human-computer tutoring. Previous comparisons of human-human and humancomputer dialogue were limited to systems that asked short-answer questions (Litman et al, 2006; Rose? and Torrey, 2005). Having a system","@endWordPosition":"2551","@position":"16134","annotationId":"T25","@startWordPosition":"2547","@citStr":"Ward and Litman, 2006"}},"title":{"#tail":"\n","#text":"Cohesion and learning in a tutorial spoken dialog system."},"booktitle":{"#tail":"\n","#text":"In Proceedings of 19th International FLAIRS (Florida Artificial Intelligence Research Society) Conference,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Arthur Ward"},{"#tail":"\n","#text":"Diane Litman"}]}}]}}]}}
