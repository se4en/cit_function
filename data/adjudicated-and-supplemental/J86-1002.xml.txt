Number 1, January-March 1986 Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input 3 A REPRESENTATION FOR USER BEHAVIORS Suppose a user inputs the following sequence: Sentence Label Display my mail summary for today. S 1 Show me this letter. (with touch input) $2 (the letter appears on the screen) Remove this letter. $3 Display the letter from JA. $4 (letter appears on the screen) Delete it. $5 Log off. $6 We denote the meaning of each sentence Si with the notation M(Si). The exact form of M(Si) need not be discussed at this point; it could be a conceptual depend- ence graph (Schank and Abelson 1977), a deep parse of Si, or some other representation. A user behavior is represented by a network, or directed graph, of such meanings. At the beginning of a task, the state of the interaction is represented by the start state of the graph. The immediate successors of this state are the typical opening meaning structures for this user, and succeeding states represent, historically, paths that have been followed by this user. It is important hat if two sentences, Si and Sj, have approximately the same meaning this should be clear in the representations M(Si) and M(Sj). Our algorithm, described be
ion, which was used to investigate the viability of this approach and the perform- ance it can achieve. Computational Linguistics, Volume 12, Number 1, January-March 1986 17 Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input 5 AN IMPLEMENTATION 5.1 THE EXPECTATION PARSER The usefulness of the methodology described above was tested in the implementation of a connected speech understanding system. An off-the-shelf speech recogni- tion device, a Nippon Electric Corporation DP-200, was added to an existing natural anguage processing system, the Natural Language Computer (NLC) (Ballard 1979, Biermann and Ballard 1980). The expectation system provided the intermediate processing between the error- ful output of the speech recognizer and the deep seman- tics of NLC. The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (VNLCE, Fink 1983). \[The current system should be distinguished from an earlier voice system (VNLC, Biermann et al 1985), which had no expectation and which handled discrete speech where a 300 millisec- ond pause must follow each word.\] It should be emphasized, of course, that the central issue here is the study o
 used to investigate the viability of this approach and the perform- ance it can achieve. Computational Linguistics, Volume 12, Number 1, January-March 1986 17 Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input 5 AN IMPLEMENTATION 5.1 THE EXPECTATION PARSER The usefulness of the methodology described above was tested in the implementation of a connected speech understanding system. An off-the-shelf speech recogni- tion device, a Nippon Electric Corporation DP-200, was added to an existing natural anguage processing system, the Natural Language Computer (NLC) (Ballard 1979, Biermann and Ballard 1980). The expectation system provided the intermediate processing between the error- ful output of the speech recognizer and the deep seman- tics of NLC. The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (VNLCE, Fink 1983). \[The current system should be distinguished from an earlier voice system (VNLC, Biermann et al 1985), which had no expectation and which handled discrete speech where a 300 millisec- ond pause must follow each word.\] It should be emphasized, of course, that the central issue here is the study of expectation mechanisms and
ess of the methodology described above was tested in the implementation of a connected speech understanding system. An off-the-shelf speech recogni- tion device, a Nippon Electric Corporation DP-200, was added to an existing natural anguage processing system, the Natural Language Computer (NLC) (Ballard 1979, Biermann and Ballard 1980). The expectation system provided the intermediate processing between the error- ful output of the speech recognizer and the deep seman- tics of NLC. The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (VNLCE, Fink 1983). \[The current system should be distinguished from an earlier voice system (VNLC, Biermann et al 1985), which had no expectation and which handled discrete speech where a 300 millisec- ond pause must follow each word.\] It should be emphasized, of course, that the central issue here is the study of expectation mechanisms and the details of the design decisions could have been made in rather different ways. Thus one could have implemented expectation error correction with a typed input system or with a speech input system that integrates voice signal processing with higher level functions in a
 understanding system. An off-the-shelf speech recogni- tion device, a Nippon Electric Corporation DP-200, was added to an existing natural anguage processing system, the Natural Language Computer (NLC) (Ballard 1979, Biermann and Ballard 1980). The expectation system provided the intermediate processing between the error- ful output of the speech recognizer and the deep seman- tics of NLC. The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (VNLCE, Fink 1983). \[The current system should be distinguished from an earlier voice system (VNLC, Biermann et al 1985), which had no expectation and which handled discrete speech where a 300 millisec- ond pause must follow each word.\] It should be emphasized, of course, that the central issue here is the study of expectation mechanisms and the details of the design decisions could have been made in rather different ways. Thus one could have implemented expectation error correction with a typed input system or with a speech input system that integrates voice signal processing with higher level functions in a way not possi- ble with a commercial recognizer. This implementation shows only one way in which the f
probabilities in the following discussion. However, in reality, the ratings are one thou- sand times the values of the logarithms of numbers between 0 and 1. Thus, the ratings span the values -999 to 0, where 0 is equivalent to a probability of one. These ratings are computed this way because they remain inte- gral and still fairly accurately represent the correct values. Also, they can simply be added and subtracted rather than multiplied and divided in the hundreds of calculations required for a single sentence parse. The expectation parser uses an ATN-like represen- tation for its grammar (Woods 1970). Its strategy is top-down. The types of sentences accepted are essential- ly those accepted by the original NLC grammar, imper- ative sentences with nested noun groups and conjunctions (Ballard 1979). An attempt has been made to build as deep a parse as possible so that sentences with the same meaning result in identical parses. Sentences have the same &quot;meaning&quot; if they &quot;result in identical tasks being performed. The various sentence structures that We have have the same meaning we call paraphrases. studied the following types of paraphrasing: 1) WORD<=>WORD 'entry' <=> 'number' 2) ADJ NOUN <
o 0, where 0 is equivalent to a probability of one. These ratings are computed this way because they remain inte- gral and still fairly accurately represent the correct values. Also, they can simply be added and subtracted rather than multiplied and divided in the hundreds of calculations required for a single sentence parse. The expectation parser uses an ATN-like represen- tation for its grammar (Woods 1970). Its strategy is top-down. The types of sentences accepted are essential- ly those accepted by the original NLC grammar, imper- ative sentences with nested noun groups and conjunctions (Ballard 1979). An attempt has been made to build as deep a parse as possible so that sentences with the same meaning result in identical parses. Sentences have the same &quot;meaning&quot; if they &quot;result in identical tasks being performed. The various sentence structures that We have have the same meaning we call paraphrases. studied the following types of paraphrasing: 1) WORD<=>WORD 'entry' <=> 'number' 2) ADJ NOUN <=> NOUN QUALIFIER 'positive ntries' < = > 'entries which are positive' 3) NOUN NUMBER <=> DET ORDINAL NOUN 'row 2' <=> 'the second row' 4) CLASSIFIER NOUN < = > NOUN of/in CLASSIFIER 'the row 1 entrie
 multiplication, simul- taneous linear equations, and Gaussian elimination. Non-linear algebra problems that require matrix-type representations can also be learned, such as gradebook maintenance and invoice manipulation. Though the implemented system is limited to matrix-oriented prob- lems, the theoretical system is capable of learning a wide range of problem types. The only requirement on the problem or situation is that it can be entered into the expectation system in the form of examples. Thus, for example, it can acquire a &quot;script&quot; such as the one for going to a restaurant as defined in Schank and Abelson (1977). The expectation module takes two inputs and produc- es two outputs. The inputs are ? the user behavior graph discussed earlier, called the expected ialogue D, and ? the meaning of the most recently input sentence, M(S). Its outputs are a new expected dialogue D modified according to the latest input sentence M(S) and an expected sentence set E. These outputs are produced based upon the inputs and the functions Predicts, Merge- able, and Merge. The role of the predicate Predicts can be best under- stood by recalling the function of the parser P. P uses the set of expected sentences E(current)
ng in the sentence, the expectation parser will error correct the sentence to the most probable value, or the first one in the set if the probabilities are equal, here the value one for row 1. Thus, both options are imperfect in terms of the error correction capabilities that they can provide. The comparison that must be made to deter- mine which option is better in a given situation is how often the first will error correct incorrectly as opposed to how much error correcting power we will lose by using the second. How it is done is beyond the scope of this paper but is explained in detail in Fink (1983). The Merge function takes two inputs, M1 and M2, which have been determined by the Mergeable function to be similar in some way by considering their respective environments and meanings. Based upon how similar the two meanings are, Merge creates a meaning M that is a generalization of M1 and M2, sometimes employing an argument. Thus, there are only two possible kinds of matches at this point between an input sentence and a member of the expected sentence set, an exact match or a similar match. In the case of an exact match M = M1 = M2 and M replaces Mi in the expected ialogue. In the case of 
es of the expectation system. Note that, in all eight graphs in Figures 11 through 14, the word and sentence error rates from the voice recognizer generally increased with the progress through the dialogue. This is due to the increased rate of speech. However, the actual failure rate of VNLCE did not increase by the same amount. These extra errors were corrected by the expectation system. Figure 16 gives a summary of the average error and correction rates for each test and over all. 7 RELATED LITERATURE A number of speech understanding systems have been developed uring the past fifteen years (Barnett et al 1980, Dixon and Martin 1979, Erman et al 1980, Haton and Pierrel 1976, Lea 1980, Lowerre and Reddy 1980, Medress 1980, Reddy 1976, Walker 1978, and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds
 all eight graphs in Figures 11 through 14, the word and sentence error rates from the voice recognizer generally increased with the progress through the dialogue. This is due to the increased rate of speech. However, the actual failure rate of VNLCE did not increase by the same amount. These extra errors were corrected by the expectation system. Figure 16 gives a summary of the average error and correction rates for each test and over all. 7 RELATED LITERATURE A number of speech understanding systems have been developed uring the past fifteen years (Barnett et al 1980, Dixon and Martin 1979, Erman et al 1980, Haton and Pierrel 1976, Lea 1980, Lowerre and Reddy 1980, Medress 1980, Reddy 1976, Walker 1978, and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in t
in Figures 11 through 14, the word and sentence error rates from the voice recognizer generally increased with the progress through the dialogue. This is due to the increased rate of speech. However, the actual failure rate of VNLCE did not increase by the same amount. These extra errors were corrected by the expectation system. Figure 16 gives a summary of the average error and correction rates for each test and over all. 7 RELATED LITERATURE A number of speech understanding systems have been developed uring the past fifteen years (Barnett et al 1980, Dixon and Martin 1979, Erman et al 1980, Haton and Pierrel 1976, Lea 1980, Lowerre and Reddy 1980, Medress 1980, Reddy 1976, Walker 1978, and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in 
 and sentence error rates from the voice recognizer generally increased with the progress through the dialogue. This is due to the increased rate of speech. However, the actual failure rate of VNLCE did not increase by the same amount. These extra errors were corrected by the expectation system. Figure 16 gives a summary of the average error and correction rates for each test and over all. 7 RELATED LITERATURE A number of speech understanding systems have been developed uring the past fifteen years (Barnett et al 1980, Dixon and Martin 1979, Erman et al 1980, Haton and Pierrel 1976, Lea 1980, Lowerre and Reddy 1980, Medress 1980, Reddy 1976, Walker 1978, and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handli
s from the voice recognizer generally increased with the progress through the dialogue. This is due to the increased rate of speech. However, the actual failure rate of VNLCE did not increase by the same amount. These extra errors were corrected by the expectation system. Figure 16 gives a summary of the average error and correction rates for each test and over all. 7 RELATED LITERATURE A number of speech understanding systems have been developed uring the past fifteen years (Barnett et al 1980, Dixon and Martin 1979, Erman et al 1980, Haton and Pierrel 1976, Lea 1980, Lowerre and Reddy 1980, Medress 1980, Reddy 1976, Walker 1978, and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed 
ce recognizer generally increased with the progress through the dialogue. This is due to the increased rate of speech. However, the actual failure rate of VNLCE did not increase by the same amount. These extra errors were corrected by the expectation system. Figure 16 gives a summary of the average error and correction rates for each test and over all. 7 RELATED LITERATURE A number of speech understanding systems have been developed uring the past fifteen years (Barnett et al 1980, Dixon and Martin 1979, Erman et al 1980, Haton and Pierrel 1976, Lea 1980, Lowerre and Reddy 1980, Medress 1980, Reddy 1976, Walker 1978, and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed input has be
ased with the progress through the dialogue. This is due to the increased rate of speech. However, the actual failure rate of VNLCE did not increase by the same amount. These extra errors were corrected by the expectation system. Figure 16 gives a summary of the average error and correction rates for each test and over all. 7 RELATED LITERATURE A number of speech understanding systems have been developed uring the past fifteen years (Barnett et al 1980, Dixon and Martin 1979, Erman et al 1980, Haton and Pierrel 1976, Lea 1980, Lowerre and Reddy 1980, Medress 1980, Reddy 1976, Walker 1978, and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed input has been studied by Carbonell and Hayes (1983
, Lea 1980, Lowerre and Reddy 1980, Medress 1980, Reddy 1976, Walker 1978, and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed input has been studied by Carbonell and Hayes (1983), Granger (1983), Jensen et al (1983), Kwasny and Sondheimer (1981), Riesbeek and Schank (1976), Thompson (1980), Weis- chedel and Black (1980), and Weischedel and Sondheim- er (1983). A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level. However, these methodologies have not used historical information at the dialogue level as described here. In most cases, the goal of these systems is to characterize the ill-formed input
 and Wolf and Woods 1980). Most of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed input has been studied by Carbonell and Hayes (1983), Granger (1983), Jensen et al (1983), Kwasny and Sondheimer (1981), Riesbeek and Schank (1976), Thompson (1980), Weis- chedel and Black (1980), and Weischedel and Sondheim- er (1983). A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level. However, these methodologies have not used historical information at the dialogue level as described here. In most cases, the goal of these systems is to characterize the ill-formed input into classes of errors and to correct on that basis. The work described here makes no at
ost of these efforts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed input has been studied by Carbonell and Hayes (1983), Granger (1983), Jensen et al (1983), Kwasny and Sondheimer (1981), Riesbeek and Schank (1976), Thompson (1980), Weis- chedel and Black (1980), and Weischedel and Sondheim- er (1983). A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level. However, these methodologies have not used historical information at the dialogue level as described here. In most cases, the goal of these systems is to characterize the ill-formed input into classes of errors and to correct on that basis. The work described here makes no attempt to classif
orts concentrated on the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed input has been studied by Carbonell and Hayes (1983), Granger (1983), Jensen et al (1983), Kwasny and Sondheimer (1981), Riesbeek and Schank (1976), Thompson (1980), Weis- chedel and Black (1980), and Weischedel and Sondheim- er (1983). A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level. However, these methodologies have not used historical information at the dialogue level as described here. In most cases, the goal of these systems is to characterize the ill-formed input into classes of errors and to correct on that basis. The work described here makes no attempt to classify the errors, but tre
the interaction between low level information sources from a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed input has been studied by Carbonell and Hayes (1983), Granger (1983), Jensen et al (1983), Kwasny and Sondheimer (1981), Riesbeek and Schank (1976), Thompson (1980), Weis- chedel and Black (1980), and Weischedel and Sondheim- er (1983). A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level. However, these methodologies have not used historical information at the dialogue level as described here. In most cases, the goal of these systems is to characterize the ill-formed input into classes of errors and to correct on that basis. The work described here makes no attempt to classify the errors, but treats them as random events that
 a speech recognizer and a natural language processor to discover the meaning of an input sentence. While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction. A detailed escription of the kinds of expectation mechanisms appearing in these systems appears in Fink (1983). The problem of handling ill-formed input has been studied by Carbonell and Hayes (1983), Granger (1983), Jensen et al (1983), Kwasny and Sondheimer (1981), Riesbeek and Schank (1976), Thompson (1980), Weis- chedel and Black (1980), and Weischedel and Sondheim- er (1983). A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level. However, these methodologies have not used historical information at the dialogue level as described here. In most cases, the goal of these systems is to characterize the ill-formed input into classes of errors and to correct on that basis. The work described here makes no attempt to classify the errors, but treats them as random events that occur at any point in a sentence. Thus, an e
r rected word-er ror - ra te sentence-er ror - ra te .59 1 .50 1 .50 4 .17 1 .94 61 .22 40 .83 52 .25 56.33 52.66 cor rected sentence-er ror - ra te 3.22 6 .00 5 .38 16 ,00 7 .65 average speak ing ra te 2 .27 2 .95 1 .85 1 .97 2 .26 Figure 16. Average word and sentence rror rate in percent, average speaking rate in words-spoken-per-minute. 34 Computational Linguistics, Volume 12, Number 1, January-March 1986 Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input The acquisition of dialogue as implemented in VNLCE is reminiscent of the program synthesis methodology developed by Biermann and Krishnaswamy (1976) where program flowcharts were constructed from traces of their behaviors. However, the &quot;flowcharts&quot; in the current project are probabilistic in nature and the prob- lems associated with matching incoming sentences to existing nodes has not been previously addressed. Another dialogue acquisition system has been developed by Ho (1984). However, that system has different goals: to enable the user to consciously design a dialogue to embody a particular human-machine interaction. The acquisition system described here is aimed at dealing with ill-formed input and is completely automatic and invisib
 Linguistics, Volume 12, Number 1, January-March 1986 Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input The acquisition of dialogue as implemented in VNLCE is reminiscent of the program synthesis methodology developed by Biermann and Krishnaswamy (1976) where program flowcharts were constructed from traces of their behaviors. However, the &quot;flowcharts&quot; in the current project are probabilistic in nature and the prob- lems associated with matching incoming sentences to existing nodes has not been previously addressed. Another dialogue acquisition system has been developed by Ho (1984). However, that system has different goals: to enable the user to consciously design a dialogue to embody a particular human-machine interaction. The acquisition system described here is aimed at dealing with ill-formed input and is completely automatic and invisible to the user. It self activates to bias recognition toward historically observed patterns but is not otherwise observable. The VNLCE processor may be considered to be a learning system of the tradition described, for example, in Michalski et al (1984). The current system learns finite state flowcharts whereas typical learning syste
s has not been previously addressed. Another dialogue acquisition system has been developed by Ho (1984). However, that system has different goals: to enable the user to consciously design a dialogue to embody a particular human-machine interaction. The acquisition system described here is aimed at dealing with ill-formed input and is completely automatic and invisible to the user. It self activates to bias recognition toward historically observed patterns but is not otherwise observable. The VNLCE processor may be considered to be a learning system of the tradition described, for example, in Michalski et al (1984). The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in Minsky and Papert (1969), assertional statements as in Michalski (1980), or semantic nets as in Winston (1975). That is, the current system learns procedures rather than data structures. There is some literature on procedure acquisition such as the LISP synthesis work described in Biermann et al (1984) and the PROLOG synthesis method of Shapiro (1982). However, the latter methodologies have not been applied to dialogue acquisition. 8 CONCLUSIONS AND AREAS FOR FUTURE RES
to enable the user to consciously design a dialogue to embody a particular human-machine interaction. The acquisition system described here is aimed at dealing with ill-formed input and is completely automatic and invisible to the user. It self activates to bias recognition toward historically observed patterns but is not otherwise observable. The VNLCE processor may be considered to be a learning system of the tradition described, for example, in Michalski et al (1984). The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in Minsky and Papert (1969), assertional statements as in Michalski (1980), or semantic nets as in Winston (1975). That is, the current system learns procedures rather than data structures. There is some literature on procedure acquisition such as the LISP synthesis work described in Biermann et al (1984) and the PROLOG synthesis method of Shapiro (1982). However, the latter methodologies have not been applied to dialogue acquisition. 8 CONCLUSIONS AND AREAS FOR FUTURE RESEARCH We have shown that the ability to use expectation i the form of knowledge about the dialogue being spoken, as with humans, is a tremendous aid t
embody a particular human-machine interaction. The acquisition system described here is aimed at dealing with ill-formed input and is completely automatic and invisible to the user. It self activates to bias recognition toward historically observed patterns but is not otherwise observable. The VNLCE processor may be considered to be a learning system of the tradition described, for example, in Michalski et al (1984). The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in Minsky and Papert (1969), assertional statements as in Michalski (1980), or semantic nets as in Winston (1975). That is, the current system learns procedures rather than data structures. There is some literature on procedure acquisition such as the LISP synthesis work described in Biermann et al (1984) and the PROLOG synthesis method of Shapiro (1982). However, the latter methodologies have not been applied to dialogue acquisition. 8 CONCLUSIONS AND AREAS FOR FUTURE RESEARCH We have shown that the ability to use expectation i the form of knowledge about the dialogue being spoken, as with humans, is a tremendous aid to speech recognition by computer. Since expecta
tion. The acquisition system described here is aimed at dealing with ill-formed input and is completely automatic and invisible to the user. It self activates to bias recognition toward historically observed patterns but is not otherwise observable. The VNLCE processor may be considered to be a learning system of the tradition described, for example, in Michalski et al (1984). The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in Minsky and Papert (1969), assertional statements as in Michalski (1980), or semantic nets as in Winston (1975). That is, the current system learns procedures rather than data structures. There is some literature on procedure acquisition such as the LISP synthesis work described in Biermann et al (1984) and the PROLOG synthesis method of Shapiro (1982). However, the latter methodologies have not been applied to dialogue acquisition. 8 CONCLUSIONS AND AREAS FOR FUTURE RESEARCH We have shown that the ability to use expectation i the form of knowledge about the dialogue being spoken, as with humans, is a tremendous aid to speech recognition by computer. Since expectation, in this research, has been based 
historically observed patterns but is not otherwise observable. The VNLCE processor may be considered to be a learning system of the tradition described, for example, in Michalski et al (1984). The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in Minsky and Papert (1969), assertional statements as in Michalski (1980), or semantic nets as in Winston (1975). That is, the current system learns procedures rather than data structures. There is some literature on procedure acquisition such as the LISP synthesis work described in Biermann et al (1984) and the PROLOG synthesis method of Shapiro (1982). However, the latter methodologies have not been applied to dialogue acquisition. 8 CONCLUSIONS AND AREAS FOR FUTURE RESEARCH We have shown that the ability to use expectation i the form of knowledge about the dialogue being spoken, as with humans, is a tremendous aid to speech recognition by computer. Since expectation, in this research, has been based on repetition of patterns, the expectation system's ability to correct varies, of course, with the repetitiveness of the dialogue itself. We have attempted, in sections 5 and 6, to justify this
vable. The VNLCE processor may be considered to be a learning system of the tradition described, for example, in Michalski et al (1984). The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in Minsky and Papert (1969), assertional statements as in Michalski (1980), or semantic nets as in Winston (1975). That is, the current system learns procedures rather than data structures. There is some literature on procedure acquisition such as the LISP synthesis work described in Biermann et al (1984) and the PROLOG synthesis method of Shapiro (1982). However, the latter methodologies have not been applied to dialogue acquisition. 8 CONCLUSIONS AND AREAS FOR FUTURE RESEARCH We have shown that the ability to use expectation i the form of knowledge about the dialogue being spoken, as with humans, is a tremendous aid to speech recognition by computer. Since expectation, in this research, has been based on repetition of patterns, the expectation system's ability to correct varies, of course, with the repetitiveness of the dialogue itself. We have attempted, in sections 5 and 6, to justify this decision by demon- strating how the expectation s
 implemented in the VNLCE system. This theory has been aimed at error correction of random errors using expectation based on historical information. However, there are many possible exten- sions that could be examined in the future and added to the implementation if the investigation indicates that it would create a yet more usable system. These include the following: ? use of low level knowledge from the speech recognition phase, ? use of high level knowledge about the domain in partic- ular and the dialogue task in general, ? a &quot;continue&quot; facility and an &quot;auto-loop&quot; facility as described by Biermann and Krishnaswamy (1976), ? a &quot;conditioning&quot; facility as described by Fink et al (1985), ? implementation f new types of paraphrasing, ? checking a larger environment in the expectation acquisition algorithm when deciding if an incoming sentence is the same or similar to one already seen, and ? examining inter-speaker dialogue patterns. All but two of these areas for expansion are aimed at moving the expectation system from one that finds patterns in a user's dialogues and acquires historical knowledge about them to one that can acquire true procedures. The first two areas for expansion have noth- ing to do with crea
on of random errors using expectation based on historical information. However, there are many possible exten- sions that could be examined in the future and added to the implementation if the investigation indicates that it would create a yet more usable system. These include the following: ? use of low level knowledge from the speech recognition phase, ? use of high level knowledge about the domain in partic- ular and the dialogue task in general, ? a &quot;continue&quot; facility and an &quot;auto-loop&quot; facility as described by Biermann and Krishnaswamy (1976), ? a &quot;conditioning&quot; facility as described by Fink et al (1985), ? implementation f new types of paraphrasing, ? checking a larger environment in the expectation acquisition algorithm when deciding if an incoming sentence is the same or similar to one already seen, and ? examining inter-speaker dialogue patterns. All but two of these areas for expansion are aimed at moving the expectation system from one that finds patterns in a user's dialogues and acquires historical knowledge about them to one that can acquire true procedures. The first two areas for expansion have noth- ing to do with creating a true procedure acquisition module but would be highly de
