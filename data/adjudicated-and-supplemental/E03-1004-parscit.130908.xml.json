{"algorithms":{"#text":"\n","@version":"110505","algorithm":{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"volume":{"#tail":"\n","#text":"76"},"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Alena Bohmova. 2001. Automatic procedures in tectogrammatical tagging. The Prague Bulletin of Mathematical Linguistics, 76."},"journal":{"#tail":"\n","#text":"The Prague Bulletin of Mathematical Linguistics,"},"#text":"\n","marker":{"#tail":"\n","#text":"Bohmova, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ependency parser, which creates the structure of a dependency tree, and a classifier assigning analytical functors. We carried out two parallel experiments with two parsers available for Czech, parser I (Hajie et al., 1998) and parser II (Charniak, 1999). In the second step, we used a module for automatic analytical functor assignment (2abokrtskyT et al., 2002). 3.3 Conversion into Tectogrammatical Representation During the tectogrammatical parsing of Czech, the analytical tree structure is converted into the tectogrammatical one. These automatic transformations are based on linguistic rules (Bohmova, 2001). Subsequently, tectogrammatical functors are assigned by the C4.5 classifier (2abokrtsk9 et al., 2002). 4 Czech-English Word-to-Word Translation Dictionaries 4.1 Manual Dictionary Sources There were three different sources of CzechEnglish manual dictionaries available, two of them were downloaded from the Web (WinGED, GNU/FDL), and one was extracted from the Czech and English EuroWordNet. See dictionary parameters in Table 2. 4.2 Dictionary Filtering For a subsequent use of these dictionaries for a simple transfer from the Czech to the English tectogrammatical trees (see Section 5), a relativ","@endWordPosition":"1170","@position":"7743","annotationId":"T1","@startWordPosition":"1169","@citStr":"Bohmova, 2001"}},"title":{"#tail":"\n","#text":"Automatic procedures in tectogrammatical tagging."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Alena Bohmova"}}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Technical Report CS-99-12."},"date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"Eugene Charniak. 1999. A maximum-entropyinspired parser. Technical Report CS-99-12."},"#text":"\n","marker":{"#tail":"\n","#text":"Charniak, 1999"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ber 1996). 84 3 Czech Data Processing 3.1 Morphological Tagging and Lemmatization The Czech translations of Penn Treebank were automatically tokenized and morphologically tagged, each word form was assigned a basic form \u2014 lemma by Hajie and Hladka (1998) tagging tools. 3.2 Analytical Parsing The analytical parsing of Czech runs in two steps: the statistical dependency parser, which creates the structure of a dependency tree, and a classifier assigning analytical functors. We carried out two parallel experiments with two parsers available for Czech, parser I (Hajie et al., 1998) and parser II (Charniak, 1999). In the second step, we used a module for automatic analytical functor assignment (2abokrtskyT et al., 2002). 3.3 Conversion into Tectogrammatical Representation During the tectogrammatical parsing of Czech, the analytical tree structure is converted into the tectogrammatical one. These automatic transformations are based on linguistic rules (Bohmova, 2001). Subsequently, tectogrammatical functors are assigned by the C4.5 classifier (2abokrtsk9 et al., 2002). 4 Czech-English Word-to-Word Translation Dictionaries 4.1 Manual Dictionary Sources There were three different sources of CzechEnglish ","@endWordPosition":"1120","@position":"7383","annotationId":"T2","@startWordPosition":"1119","@citStr":"Charniak, 1999"}},"title":{"#tail":"\n","#text":"A maximum-entropyinspired parser."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Eugene Charniak"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"F. J. Och and H. Ney. 2000. Improved statistical alignment models. In Proc. of the 38th Annual Meeting of the Association for Computational Linguistics, pages 440-447, Hongkong, China, October."},"#text":"\n","pages":{"#tail":"\n","#text":"440--447"},"marker":{"#tail":"\n","#text":"Och, Ney, 2000"},"location":{"#tail":"\n","#text":"Hongkong, China,"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"the transfer procedure (for its characterization, see Section 5). The generation process consisting mainly of word reordering and lexical insertions is explained in Section 6, an example illustrating the generation steps is presented in Sec83 tion 7. For the evaluation of the results we use the BLEU score (Papineni et al., 2001). Section 8 compares translations generated from automatically built and manually annotated tectogrammatical representations. We also compare the results with the output generated by the statistical translation system GIZA++/ISI ReWrite Decoder (AlOnaizan et al., 1999; Och and Ney, 2000; Germann et al., 2001), trained on the same parallel corpus. 2 Data Resources 2.1 The Prague Dependency Treebank The Prague Dependency Treebank project (Bohmova et al., 2001) aims at complex annotation of a corpus containing about 1.8M word occurrences (about 80,000 running text sentences) in Czech. The annotation, which is based on dependency syntax, is carried out in three steps: morphological, analytical, and tectogrammatical. The first two have been finished so far, presently, there are about 18,000 sentences tectogrammatically annotated. See Haji 6 et al. (2001) and Haji6ova et al. (2000","@endWordPosition":"510","@position":"3438","annotationId":"T3","@startWordPosition":"507","@citStr":"Och and Ney, 2000"},{"#tail":"\n","#text":"anslation, was used. Also 1-2 translations were handled as 1-1 \u2014 two words in one trlemma attribute. Compare an example of a Czech tectogrammatical tree after the lexical transfer step (Figure 3), with the original English sentence in Figure 2. [FSG]<tr>selection<trt>N<prob>0.542169 [FSG1<tr>choice<trt>N<prob>0.457831 [S] ... dictionary weight selection [G] ... GIZA++ selection [F] ... final selection Figure 1: Sample of the Czech-English dictionary used for the transfer. financial news, we created a probabilistic CzechEnglish dictionary by running GIZA++ training (translation models 1-4, see Och and Ney (2000)) on the training part of the English-Czech WSJ parallel corpus extended by the parallel corpus of entry/translation pairs from the manual dictionary. As a result, the entry/translation pairs seen in the parallel corpus of WSJ become more probable. For entry/translation pairs not seen in the parallel text, the probability distribution among translations is uniform. The translation is &quot;GIZA++ selected&quot; if its probability is higher than a threshold, which is in our case set to 0.10. The final selection contains translations selected by both the dictionary and GIZA++ selectors. In addition, trans","@endWordPosition":"1713","@position":"11708","annotationId":"T4","@startWordPosition":"1710","@citStr":"Och and Ney (2000)"}]},"title":{"#tail":"\n","#text":"Improved statistical alignment models."},"booktitle":{"#tail":"\n","#text":"In Proc. of the 38th Annual Meeting of the Association for Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"F J Och"},{"#tail":"\n","#text":"H Ney"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Technical Report RC22176, IBM."},"date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2001. Bleu: a method for automatic evaluation of machine translation. Technical Report RC22176, IBM."},"#text":"\n","marker":{"#tail":"\n","#text":"Papineni, Roukos, Ward, Zhu, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ts (Section 2). Section 3 describes the automatic procedures used for the preparation of both training and testing data, including morphological tagging, and analytical and tectogrammatical parsing of Czech input. In Section 4 we describe the process of the filtering of dictionaries used in the transfer procedure (for its characterization, see Section 5). The generation process consisting mainly of word reordering and lexical insertions is explained in Section 6, an example illustrating the generation steps is presented in Sec83 tion 7. For the evaluation of the results we use the BLEU score (Papineni et al., 2001). Section 8 compares translations generated from automatically built and manually annotated tectogrammatical representations. We also compare the results with the output generated by the statistical translation system GIZA++/ISI ReWrite Decoder (AlOnaizan et al., 1999; Och and Ney, 2000; Germann et al., 2001), trained on the same parallel corpus. 2 Data Resources 2.1 The Prague Dependency Treebank The Prague Dependency Treebank project (Bohmova et al., 2001) aims at complex annotation of a corpus containing about 1.8M word occurrences (about 80,000 running text sentences) in Czech. The annotat","@endWordPosition":"468","@position":"3151","annotationId":"T5","@startWordPosition":"465","@citStr":"Papineni et al., 2001"},{"#tail":"\n","#text":"ng to contextual boundness and their tectogrammatical functors. The form of the complex verb is handled in step 3. In the next step, prepositions and articles are inserted. However, not every functor's realization can be reconstructed easily, as can be seen in the case of the missing preposition &quot;in&quot;. It is also hard to decide whether a particular word was used in an uncountable sense (see the wrongly inserted indefinite article). The last line contains the final morphological realization of the sentence. 8 Evaluation of Results We evaluated our translations with IBM's BLEU evaluation metric (Papineni et al., 2001), using the same evaluation method and reference retranslations that were used for evaluation at HLT Workshop 2002 at CLSP (Haji 6 et al., 2002). We used four reference retranslations of 490 sentences selected from the WSJ sections 22, 23, and 24, which were themselves used as the fifth reference. The evaluation method used is to hold out each reference in turn and evaluate it against the remaining four, averaging the five BLEU scores. Table 3 shows final results of our system compared with GIZA++ and MAGENTA's results. The DBMT with parser I and parser II experiments represent a fully automat","@endWordPosition":"3234","@position":"21480","annotationId":"T6","@startWordPosition":"3231","@citStr":"Papineni et al., 2001"}]},"title":{"#tail":"\n","#text":"Bleu: a method for automatic evaluation of machine translation."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kishore Papineni"},{"#tail":"\n","#text":"Salim Roukos"},{"#tail":"\n","#text":"Todd Ward"},{"#tail":"\n","#text":"WeiJing Zhu"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Technical Report RC22176, IBM."},"date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2001. Bleu: a method for automatic evaluation of machine translation. Technical Report RC22176, IBM."},"#text":"\n","marker":{"#tail":"\n","#text":"Papineni, Roukos, Ward, Zhu, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ts (Section 2). Section 3 describes the automatic procedures used for the preparation of both training and testing data, including morphological tagging, and analytical and tectogrammatical parsing of Czech input. In Section 4 we describe the process of the filtering of dictionaries used in the transfer procedure (for its characterization, see Section 5). The generation process consisting mainly of word reordering and lexical insertions is explained in Section 6, an example illustrating the generation steps is presented in Sec83 tion 7. For the evaluation of the results we use the BLEU score (Papineni et al., 2001). Section 8 compares translations generated from automatically built and manually annotated tectogrammatical representations. We also compare the results with the output generated by the statistical translation system GIZA++/ISI ReWrite Decoder (AlOnaizan et al., 1999; Och and Ney, 2000; Germann et al., 2001), trained on the same parallel corpus. 2 Data Resources 2.1 The Prague Dependency Treebank The Prague Dependency Treebank project (Bohmova et al., 2001) aims at complex annotation of a corpus containing about 1.8M word occurrences (about 80,000 running text sentences) in Czech. The annotat","@endWordPosition":"468","@position":"3151","annotationId":"T7","@startWordPosition":"465","@citStr":"Papineni et al., 2001"},{"#tail":"\n","#text":"ng to contextual boundness and their tectogrammatical functors. The form of the complex verb is handled in step 3. In the next step, prepositions and articles are inserted. However, not every functor's realization can be reconstructed easily, as can be seen in the case of the missing preposition &quot;in&quot;. It is also hard to decide whether a particular word was used in an uncountable sense (see the wrongly inserted indefinite article). The last line contains the final morphological realization of the sentence. 8 Evaluation of Results We evaluated our translations with IBM's BLEU evaluation metric (Papineni et al., 2001), using the same evaluation method and reference retranslations that were used for evaluation at HLT Workshop 2002 at CLSP (Haji 6 et al., 2002). We used four reference retranslations of 490 sentences selected from the WSJ sections 22, 23, and 24, which were themselves used as the fifth reference. The evaluation method used is to hold out each reference in turn and evaluate it against the remaining four, averaging the five BLEU scores. Table 3 shows final results of our system compared with GIZA++ and MAGENTA's results. The DBMT with parser I and parser II experiments represent a fully automat","@endWordPosition":"3234","@position":"21480","annotationId":"T8","@startWordPosition":"3231","@citStr":"Papineni et al., 2001"}]},"title":{"#tail":"\n","#text":"Bleu: a method for automatic evaluation of machine translation."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kishore Papineni"},{"#tail":"\n","#text":"Salim Roukos"},{"#tail":"\n","#text":"Todd Ward"},{"#tail":"\n","#text":"WeiJing Zhu"}]}}]}}}}
