{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","figure":[{"#tail":"\n","@confidence":"0.928308736842105","#text":"\nComputational Linguistics (ACL), Philadelphia, July 2002, pp. 1-8.\nProceedings of the 40th Annual Meeting of the Association for\n(a) (b)\n0/.15\na:x/.63 1/.15a: /.07?\n2/.5b: /.003? b:z/.12\n3/.5\nb:x/.027\na: /.7? b: /.03?\nb:z/.12 b: /.1? b:z/.4\nb: /.01?\nb:z/.4b:x/.09\n4/.15\na:p/.7\n5/.5b:p/.03b:q/.12\nb:p/.1b:q/.4\n(c)\n6/1\np:x/.9\n"},{"#tail":"\n","@confidence":"0.469461","#text":"\n?\nj,k p0jv\n1\n"}],"address":{"#tail":"\n","@confidence":"0.994573","#text":"\nBaltimore, MD, USA 21218-2691\n"},"author":{"#tail":"\n","@confidence":"0.995919","#text":"\nJason Eisner\n"},"equation":[{"#tail":"\n","@confidence":"0.964826071428572","#text":"\n0?a:x/.63?? 0?\na:/.07\n?? 1?\nb:/.03\n?? 2?\nb:z/.4\n?? 2/.5?\n0?a:x/.63?? 0?\na:/.07\n?? 1?\nb:z/.12\n?? 2?\nb:/.1\n?? 2/.5?\n"},{"#tail":"\n","@confidence":"0.83642675","#text":"\ning P (input, output) =\n?\nmid P (input,mid) ?\nP (output  |mid). If Fig. 1b?c are required to re-\n"},{"#tail":"\n","@confidence":"0.955735666666667","#text":"\ndef\n=\n?E + (1 ? ?)F means ?flip a ?-weighted coin and\ngenerateE if heads, F if tails.? E??\ndef\n= (?E)?(1??)\n"},{"#tail":"\n","@confidence":"0.9902724","#text":"\nP (v, z)\ndef\n=\n?\nw,x,y P (v|w)P (w, x)P (y|x)P (z|y),\n"},{"#tail":"\n","@confidence":"0.87569275","#text":"\nIn\n?\nw,x P (v|w)P (v\n?|w)P (w, x)P (y|x), the true transcrip-\n"},{"#tail":"\n","@confidence":"0.167397","#text":"\n8 9a:x/.63 10a:x/.63 11b:x/.027\n"},{"#tail":"\n","@confidence":"0.846747","#text":"\n?\ni P (yi  |xi) and f?(x, y) is a conditional FST that\n"},{"#tail":"\n","@confidence":"0.839146","#text":"\nmaximizing\n?\ni P (xi) ? P (yi  |xi). (Of course,\n"},{"#tail":"\n","@confidence":"0.973712","#text":"\n?\ni\n?\ny(P (xi, y)\n?/\n?\ny? P (xi, y\n?)?) ? error(y, yi).\n"},{"#tail":"\n","@confidence":"0.884017142857143","#text":"\na:x\n?? 10?\na:\n?? 10?\na:\n?? 10?\nb:z\n"},{"#tail":"\n","@confidence":"0.992850142857143","#text":"\n?\ni\n?\nu???? P (u |\nxi, yi) ? ech(u,???). The term\n?\ni P (u  |xi, yi) computes the\n"},{"#tail":"\n","@confidence":"0.9822856","#text":"\nE[val(pi)  |xi, yi] =\n?\npi?? P (pi) val(pi)?\npi?? P (pi)\n(1)\n"},{"#tail":"\n","@confidence":"0.904745333333333","#text":"\n??\ni=0 k\ni\n"},{"#tail":"\n","@confidence":"0.756501285714286","#text":"\n(\n?\npi P (pi, xi, yi) val(pi))/P (xi, yi) = (\n?\npi P (xi, yi |\npi)P (pi) val(pi))/\n?\n"},{"#tail":"\n","@confidence":"0.966724857142857","#text":"\nV -expectation semiring, (R?0 ? V,?,?, ?):\n(p1, v1)? (p2, v2)\ndef\n= (p1p2, p1v2 + v1p2) (2)\n(p1, v1)? (p2, v2)\ndef\n= (p1 + p2, v1 + v2) (3)\n"}],"footnote":[{"#tail":"\n","@confidence":"0.907166","#text":"\n1Given output, find input to maximize P (input, output).\n"},{"#tail":"\n","@confidence":"0.95259225","#text":"\n6P (w, x) defines the source model, and is often an ?identity\nFST? that requires w = x, really just an FSA.\n7We propose also using n-tape automata to generalize to\n?branching noisy channels? (a case of dendroid distributions).\n"}],"title":{"#tail":"\n","@confidence":"0.923161","#text":"\nParameter Estimation for Probabilistic Finite-State Transducers?\n"},"@confidence":"0.000000","#tail":"\n","reference":{"#tail":"\n","@confidence":"0.9860750125","#text":"\nL. E. Baum. 1972. An inequality and associated max-\nimization technique in statistical estimation of proba-\nbilistic functions of a Markov process. Inequalities, 3.\nJean Berstel and Christophe Reutenauer. 1988. Rational\nSeries and their Languages. Springer-Verlag.\nStanley F. Chen and Ronald Rosenfeld. 1999. A Gaus-\nsian prior for smoothing maximum entropy models.\nTechnical Report CMU-CS-99-108, Carnegie Mellon.\nS. Della Pietra, V. Della Pietra, and J. Lafferty. 1997.\nInducing features of random fields. IEEE Transactions\non Pattern Analysis and Machine Intelligence, 19(4).\nA. P. Dempster, N. M. Laird, and D. B. Rubin. 1977.\nMaximum likelihood from incomplete data via the EM\nalgorithm. J. Royal Statist. Soc. Ser. B, 39(1):1?38.\nJason Eisner. 2001a. Expectation semirings: Flexible\nEM for finite-state transducers. In G. van Noord, ed.,\nProc. of the ESSLLI Workshop on Finite-State Methods\nin Natural Language Processing. Extended abstract.\nJason Eisner. 2001b. Smoothing a Probabilistic Lexicon\nvia Syntactic Transformations. Ph.D. thesis, Univer-\nsity of Pennsylvania.\nD. Gerdemann and G. van Noord. 1999. Transducers\nfrom rewrite rules with backreferences. Proc. of EACL.\nAnne Greenbaum. 1997. Iterative Methods for Solving\nLinear Systems. Soc. for Industrial and Applied Math.\nKevin Knight and Yaser Al-Onaizan. 1998. Translation\nwith finite-state devices. In Proc. of AMTA.\nKevin Knight and Jonathan Graehl. 1998. Machine\ntransliteration. Computational Linguistics, 24(4).\nJ. Lafferty, A. McCallum, and F. Pereira. 2001. Con-\nditional random fields: Probabilistic models for seg-\nmenting and labeling sequence data. Proc. of ICML.\nD. J. Lehmann. 1977. Algebraic structures for transitive\nclosure. Theoretical Computer Science, 4(1):59?76.\nA. McCallum, D. Freitag, and F. Pereira. 2000. Maxi-\nmum entropy Markov models for information extrac-\ntion and segmentation. Proc. of ICML, 591?598.\nM. Mohri and M.-J. Nederhof. 2001. Regular approxi-\nmation of context-free grammars through transforma-\ntion. In J.-C. Junqua and G. van Noord, eds., Robust-\nness in Language and Speech Technology. Kluwer.\nMehryar Mohri and Richard Sproat. 1996. An efficient\ncompiler for weighted rewrite rules. In Proc. of ACL.\nM. Mohri, F. Pereira, and M. Riley. 1998. A rational de-\nsign for a weighted finite-state transducer library. Lec-\nture Notes in Computer Science, 1436.\nM. Mohri. 2002. Generic epsilon-removal and input\nepsilon-normalization algorithms for weighted trans-\nducers. Int. J. of Foundations of Comp. Sci., 1(13).\nMark-Jan Nederhof. 2000. Practical experiments\nwith regular approximation of context-free languages.\nComputational Linguistics, 26(1).\nFernando C. N. Pereira and Michael Riley. 1997. Speech\nrecognition by composition of weighted finite au-\ntomata. In E. Roche and Y. Schabes, eds., Finite-State\nLanguage Processing. MIT Press, Cambridge, MA.\nA. Rao and K. Rose. 2001 Deterministically annealed\ndesign of hidden Markov movel speech recognizers.\nIn IEEE Trans. on Speech and Audio Processing, 9(2).\nStefan Riezler. 1999. Probabilistic Constraint Logic\nProgramming. Ph.D. thesis, Universita?t Tu?bingen.\nE. Ristad and P. Yianilos. 1996. Learning string edit\ndistance. Tech. Report CS-TR-532-96, Princeton.\nE. Ristad. 1998. Hidden Markov models with finite state\nsupervision. In A. Kornai, ed., Extended Finite State\nModels of Language. Cambridge University Press.\nEmmanuel Roche and Yves Schabes, editors. 1997.\nFinite-State Language Processing. MIT Press.\nGu?nter Rote. 1985. A systolic array algorithm for the\nalgebraic path problem (shortest paths; matrix inver-\nsion). Computing, 34(3):191?219.\nRichard Sproat and Michael Riley. 1996. Compilation of\nweighted finite-state transducers from decision trees.\nIn Proceedings of the 34th Annual Meeting of the ACL.\nAndreas Stolcke and Stephen M. Omohundro. 1994.\nBest-first model merging for hidden Markov model in-\nduction. Tech. Report ICSI TR-94-003, Berkeley, CA.\nRobert Endre Tarjan. 1981a. A unified approach to path\nproblems. Journal of the ACM, 28(3):577?593, July.\nRobert Endre Tarjan. 1981b. Fast algorithms for solving\n"},"bodyText":[{"#tail":"\n","@confidence":"0.99939875","#text":"\nWeighted finite-state transducers suffer from the lack of a train-\ning algorithm. Training is even harder for transducers that have\nbeen assembled via finite-state operations such as composition,\nminimization, union, concatenation, and closure, as this yields\ntricky parameter tying. We formulate a ?parameterized FST?\nparadigm and give training algorithms for it, including a gen-\neral bookkeeping trick (?expectation semirings?) that cleanly\nand efficiently computes expectations and gradients.\n"},{"#tail":"\n","@confidence":"0.997366","#text":"\nRational relations on strings have become wide-\nspread in language and speech engineering (Roche\nand Schabes, 1997). Despite bounded memory they\nare well-suited to describe many linguistic and tex-\ntual processes, either exactly or approximately.\nA relation is a set of (input, output) pairs. Re-\nlations are more general than functions because they\nmay pair a given input string with more or fewer than\none output string.\nThe class of so-called rational relations admits\na nice declarative programming paradigm. Source\ncode describing the relation (a regular expression)\nis compiled into efficient object code (in the form\nof a 2-tape automaton called a finite-state trans-\nducer). The object code can even be optimized for\nruntime and code size (via algorithms such as deter-\nminization and minimization of transducers).\nThis programming paradigm supports efficient\nnondeterminism, including parallel processing over\ninfinite sets of input strings, and even allows ?re-\nverse? computation from output to input. Its unusual\nflexibility for the practiced programmer stems from\nthe many operations under which rational relations\nare closed. It is common to define further useful\noperations (as macros), which modify existing rela-\ntions not by editing their source code but simply by\noperating on them ?from outside.?\n?A brief version of this work, with some additional mate-\nrial, first appeared as (Eisner, 2001a). A leisurely journal-length\nversion with more details has been prepared and is available.\nThe entire paradigm has been generalized to\nweighted relations, which assign a weight to each\n(input, output) pair rather than simply including or\nexcluding it. If these weights represent probabili-\nties P (input, output) or P (output  |input), the\nweighted relation is called a joint or conditional\n(probabilistic) relation and constitutes a statistical\nmodel. Such models can be efficiently restricted,\nmanipulated or combined using rational operations\nas before. An artificial example will appear in ?2.\nThe availability of toolkits for this weighted case\n(Mohri et al, 1998; van Noord and Gerdemann,\n2001) promises to unify much of statistical NLP.\nSuch tools make it easy to run most current ap-\nproaches to statistical markup, chunking, normal-\nization, segmentation, alignment, and noisy-channel\ndecoding,1 including classic models for speech\nrecognition (Pereira and Riley, 1997) and machine\ntranslation (Knight and Al-Onaizan, 1998). More-\nover, once the models are expressed in the finite-\nstate framework, it is easy to use operators to tweak\nthem, to apply them to speech lattices or other sets,\nand to combine them with linguistic resources.\nUnfortunately, there is a stumbling block: Where\ndo the weights come from? After all, statistical mod-\nels require supervised or unsupervised training. Cur-\nrently, finite-state practitioners derive weights using\nexogenous training methods, then patch them onto\ntransducer arcs. Not only do these methods require\nadditional programming outside the toolkit, but they\nare limited to particular kinds of models and train-\ning regimens. For example, the forward-backward\nalgorithm (Baum, 1972) trains only Hidden Markov\nModels, while (Ristad and Yianilos, 1996) trains\nonly stochastic edit distance.\nIn short, current finite-state toolkits include no\ntraining algorithms, because none exist for the large\nspace of statistical models that the toolkits can in\nprinciple describe and run.\n"},{"#tail":"\n","@confidence":"0.972693176470588","#text":"\ndistribution. Defining (a)=(b)?(c) means that the weights in (a)\ncan be altered by adjusting the fewer weights in (b) and (c).\nThis paper aims to provide a remedy through a\nnew paradigm, which we call parameterized finite-\nstate machines. It lays out a fully general approach\nfor training the weights of weighted rational rela-\ntions. First ?2 considers how to parameterize such\nmodels, so that weights are defined in terms of un-\nderlying parameters to be learned. ?3 asks what it\nmeans to learn these parameters from training data\n(what is to be optimized?), and notes the apparently\nformidable bookkeeping involved. ?4 cuts through\nthe difficulty with a surprisingly simple trick. Fi-\nnally, ?5 removes inefficiencies from the basic algo-\nrithm, making it suitable for inclusion in an actual\ntoolkit. Such a toolkit could greatly shorten the de-\nvelopment cycle in natural language engineering.\n"},{"#tail":"\n","@confidence":"0.987828888888889","#text":"\nFinite-state machines, including finite-state au-\ntomata (FSAs) and transducers (FSTs), are a kind\nof labeled directed multigraph. For ease and brevity,\nwe explain them by example. Fig. 1a shows a proba-\nbilistic FST with input alphabet ? = {a, b}, output\nalphabet ? = {x, z}, and all states final. It may\nbe regarded as a device for generating a string pair\nin ?? ? ?? by a random walk from 0?. Two paths\nexist that generate both input aabb and output xz:\n"},{"#tail":"\n","@confidence":"0.999022387096774","#text":"\nEach of the paths has probability .0002646, so\nthe probability of somehow generating the pair\n(aabb, xz) is .0002646 + .0002646 = .0005292.\nAbstracting away from the idea of random walks,\narc weights need not be probabilities. Still, define a\npath?s weight as the product of its arc weights and\nthe stopping weight of its final state. Thus Fig. 1a\ndefines a weighted relation f where f(aabb, xz) =\n.0005292. This particular relation does happen to be\nprobabilistic (see ?1). It represents a joint distribu-\ntion (since ?x,y f(x, y) = 1). Meanwhile, Fig. 1c\ndefines a conditional one (?x?y f(x, y) = 1).\nThis paper explains how to adjust probability dis-\ntributions like that of Fig. 1a so as to model training\ndata better. The algorithm improves an FST?s nu-\nmeric weights while leaving its topology fixed.\nHow many parameters are there to adjust in\nFig. 1a? That is up to the user who built it! An\nFST model with few parameters is more constrained,\nmaking optimization easier. Some possibilities:\n? Most simply, the algorithm can be asked to tune\nthe 17 numbers in Fig. 1a separately, subject to the\nconstraint that the paths retain total probability 1. A\nmore specific version of the constraint requires the\nFST to remain Markovian: each of the 4 states must\npresent options with total probability 1 (at state 1?,\n15+.7+.03.+.12=1). This preserves the random-walk\ninterpretation and (we will show) entails no loss of\ngenerality. The 4 restrictions leave 13 free params.\n? But perhaps Fig. 1a was actually obtained as\nthe composition of Fig. 1b?c, effectively defin-\n"},{"#tail":"\n","@confidence":"0.872126285714286","#text":"\nmain Markovian, they have 5 and 1 degrees of free-\ndom respectively, so now Fig. 1a has only 6 param-\neters total.2 In general, composing machines mul-\ntiplies their arc counts but only adds their param-\neter counts. We wish to optimize just the few un-\nderlying parameters, not independently optimize the\nmany arc weights of the composed machine.\n? Perhaps Fig. 1b was itself obtained by the proba-\nbilistic regular expression (a : p)??(b : (p +? q))??\nwith the 3 parameters (?, ?, ?) = (.7, .2, .5). With\n? = .1 from footnote 2, the composed machine\n2Why does Fig. 1c have only 1 degree of freedom? The\nMarkovian requirement means something different in Fig. 1c,\nwhich defines a conditional relation P (output  |mid) rather\nthan a joint one. A random walk on Fig. 1c chooses among arcs\nwith a given input label. So the arcs from state 6? with input\np must have total probability 1 (currently .9+.1). All other arc\nchoices are forced by the input label and so have probability 1.\nThe only tunable value is .1 (denote it by ?), with .9 = 1? ?.\n(Fig. 1a) has now been described with a total of just\n4 parameters!3 Here, probabilistic union E +? F\n"},{"#tail":"\n","@confidence":"0.955634222222222","#text":"\nmeans ?repeatedly flip an ?-weighted coin and keep\nrepeating E as long as it comes up heads.?\nThese 4 parameters have global effects on Fig. 1a,\nthanks to complex parameter tying: arcs 4? b:p?? 5?,\n5? b:q?? 5? in Fig. 1b get respective probabilities (1?\n?)?? and (1 ? ?)?, which covary with ? and vary\noppositely with ?. Each of these probabilities in turn\naffects multiple arcs in the composed FST of Fig. 1a.\nWe offer a theorem that highlights the broad\napplicability of these modeling techniques.4 If\nf(input, output) is a weighted regular relation,\nthen the following statements are equivalent: (1) f is\na joint probabilistic relation; (2) f can be computed\nby a Markovian FST that halts with probability 1;\n(3) f can be expressed as a probabilistic regexp,\ni.e., a regexp built up from atomic expressions a : b\n(for a ? ?? {}, b ? ?? {}) using concatenation,\nprobabilistic union +p, and probabilistic closure ?p.\nFor defining conditional relations, a good regexp\nlanguage is unknown to us, but they can be defined\nin several other ways: (1) via FSTs as in Fig. 1c, (2)\nby compilation of weighted rewrite rules (Mohri and\nSproat, 1996), (3) by compilation of decision trees\n(Sproat and Riley, 1996), (4) as a relation that per-\nforms contextual left-to-right replacement of input\nsubstrings by a smaller conditional relation (Gerde-\nmann and van Noord, 1999),5 (5) by conditionaliza-\ntion of a joint relation as discussed below.\nA central technique is to define a joint relation as a\nnoisy-channel model, by composing a joint relation\nwith a cascade of one or more conditional relations\nas in Fig. 1 (Pereira and Riley, 1997; Knight and\nGraehl, 1998). The general form is illustrated by\n3Conceptually, the parameters represent the probabilities of\nreading another a (?); reading another b (?); transducing b to p\nrather than q (?); starting to transduce p to  rather than x (?).\n4To prove (1)?(3), express f as an FST and apply the\nwell-known Kleene-Schu?tzenberger construction (Berstel and\nReutenauer, 1988), taking care to write each regexp in the con-\nstruction as a constant times a probabilistic regexp. A full proof\nis straightforward, as are proofs of (3)?(2), (2)?(1).\n5In (4), the randomness is in the smaller relation?s choice of\nhow to replace a match. One can also get randomness through\nthe choice of matches, ignoring match possibilities by randomly\ndeleting markers in Gerdemann and van Noord?s construction.\n"},{"#tail":"\n","@confidence":"0.951767236842105","#text":"\nimplemented by composing 4 machines.6,7\nThere are also procedures for defining weighted\nFSTs that are not probabilistic (Berstel and\nReutenauer, 1988). Arbitrary weights such as 2.7\nmay be assigned to arcs or sprinkled through a reg-\nexp (to be compiled into :/2.7?? arcs). A more subtle\nexample is weighted FSAs that approximate PCFGs\n(Nederhof, 2000; Mohri and Nederhof, 2001), or\nto extend the idea, weighted FSTs that approximate\njoint or conditional synchronous PCFGs built for\ntranslation. These are parameterized by the PCFG?s\nparameters, but add or remove strings of the PCFG\nto leave an improper probability distribution.\nFortunately for those techniques, an FST with\npositive arc weights can be normalized to make it\njointly or conditionally probabilistic:\n? An easy approach is to normalize the options at\neach state to make the FST Markovian. Unfortu-\nnately, the result may differ for equivalent FSTs that\nexpress the same weighted relation. Undesirable\nconsequences of this fact have been termed ?label\nbias? (Lafferty et al, 2001). Also, in the conditional\ncase such per-state normalization is only correct if\nall states accept all input suffixes (since ?dead ends?\nleak probability mass).8\n? A better-founded approach is global normal-\nization, which simply divides each f(x, y) by\n?\nx?,y? f(x\n?, y?) (joint case) or by?y? f(x, y?) (con-\nditional case). To implement the joint case, just di-\nvide stopping weights by the total weight of all paths\n(which ?4 shows how to find), provided this is finite.\nIn the conditional case, let g be a copy of f with the\noutput labels removed, so that g(x) finds the desired\ndivisor; determinize g if possible (but this fails for\nsome weighted FSAs), replace all weights with their\nreciprocals, and compose the result with f .9\n"},{"#tail":"\n","@confidence":"0.995739891891892","#text":"\ntion w can be triply constrained by observing speech y and two\nerrorful transcriptions v, v?, which independently depend on w.\n8A corresponding problem exists in the joint case, but may\nbe easily avoided there by first pruning non-coaccessible states.\n9It suffices to make g unambiguous (one accepting path per\nstring), a weaker condition than determinism. When this is not\npossible (as in the inverse of Fig. 1b, whose conditionaliza-\nNormalization is particularly important because it\nenables the use of log-linear (maximum-entropy)\nparameterizations. Here one defines each arc\nweight, coin weight, or regexp weight in terms of\nmeaningful features associated by hand with that\narc, coin, etc. Each feature has a strength ? R>0,\nand a weight is computed as the product of the\nstrengths of its features.10 It is now the strengths\nthat are the learnable parameters. This allows mean-\ningful parameter tying: if certain arcs such as u:i??,\no:e\n??, and a:ae?? share a contextual ?vowel-fronting?\nfeature, then their weights rise and fall together with\nthe strength of that feature. The resulting machine\nmust be normalized, either per-state or globally, to\nobtain a joint or a conditional distribution as de-\nsired. Such approaches have been tried recently\nin restricted cases (McCallum et al, 2000; Eisner,\n2001b; Lafferty et al, 2001).\nNormalization may be postponed and applied in-\nstead to the result of combining the FST with other\nFSTs by composition, union, concatenation, etc. A\nsimple example is a probabilistic FSA defined by\nnormalizing the intersection of other probabilistic\nFSAs f1, f2, . . .. (This is in fact a log-linear model\nin which the component FSAs define the features:\nstring x has log fi(x) occurrences of feature i.)\nIn short, weighted finite-state operators provide a\nlanguage for specifying a wide variety of parameter-\nized statistical models. Let us turn to their training.\n"},{"#tail":"\n","@confidence":"0.951733777777778","#text":"\nWe are primarily concerned with the following train-\ning paradigm, novel in its generality. Let f? :\n????? ? R?0 be a joint probabilistic relation that\nis computed by a weighted FST. The FST was built\nby some recipe that used the parameter vector ?.\nChanging ? may require us to rebuild the FST to get\nupdated weights; this can involve composition, reg-\nexp compilation, multiplication of feature strengths,\netc. (Lazy algorithms that compute arcs and states of\ntion cannot be realized by any weighted FST), one can some-\ntimes succeed by first intersecting g with a smaller regular set\nin which the input being considered is known to fall. In the ex-\ntreme, if each input string is fully observed (not the case if the\ninput is bound by composition to the output of a one-to-many\nFST), one can succeed by restricting g to each input string in\nturn; this amounts to manually dividing f(x, y) by g(x).\n10Traditionally log(strength) values are called weights, but\nthis paper uses ?weight? to mean something else.\n"},{"#tail":"\n","@confidence":"0.944244186274509","#text":"\nonly input ? a(a + b)? and output = xxz.\nf? on demand (Mohri et al, 1998) can pay off here,\nsince only part of f? may be needed subsequently.)\nAs training data we are given a set of observed\n(input, output) pairs, (xi, yi). These are assumed\nto be independent random samples from a joint dis-\ntribution of the form f??(x, y); the goal is to recover\nthe true ??. Samples need not be fully observed\n(partly supervised training): thus xi ? ??, yi ? ??\nmay be given as regular sets in which input and out-\nput were observed to fall. For example, in ordinary\nHMM training, xi = ?? and represents a completely\nhidden state sequence (cf. Ristad (1998), who allows\nany regular set), while yi is a single string represent-\ning a completely observed emission sequence.11\nWhat to optimize? Maximum-likelihood es-\ntimation guesses ?? to be the ? maximizing\n?\ni f?(xi, yi). Maximum-posterior estimation\ntries to maximize P (?) ?\n?\ni f?(xi, yi) where P (?) is\na prior probability. In a log-linear parameterization,\nfor example, a prior that penalizes feature strengths\nfar from 1 can be used to do feature selection and\navoid overfitting (Chen and Rosenfeld, 1999).\nThe EM algorithm (Dempster et al, 1977) can\nmaximize these functions. Roughly, the E step\nguesses hidden information: if (xi, yi) was gener-\nated from the current f?, which FST paths stand a\nchance of having been the path used? (Guessing the\npath also guesses the exact input and output.) The\nM step updates ? to make those paths more likely.\nEM alternates these steps and converges to a local\noptimum. The M step?s form depends on the param-\neterization and the E step serves the M step?s needs.\nLet f? be Fig. 1a and suppose (xi, yi) = (a(a +\nb)?, xxz). During the E step, we restrict to paths\ncompatible with this observation by computing xi ?\nf? ? yi, shown in Fig. 2. To find each path?s pos-\nterior probability given the observation (xi, yi), just\nconditionalize: divide its raw probability by the total\nprobability (? 0.1003) of all paths in Fig. 2.\n11To implement an HMM by an FST, compose a probabilistic\nFSA that generates a state sequence of the HMM with a condi-\ntional FST that transduces HMM states to emitted symbols.\nBut that is not the full E step. The M step uses\nnot individual path probabilities (Fig. 2 has infinitely\nmany) but expected counts derived from the paths.\nCrucially, ?4 will show how the E step can accumu-\nlate these counts effortlessly. We first explain their\nuse by the M step, repeating the presentation of ?2:\n? If the parameters are the 17 weights in Fig. 1a, the\nM step reestimates the probabilities of the arcs from\neach state to be proportional to the expected number\nof traversals of each arc (normalizing at each state\nto make the FST Markovian). So the E step must\ncount traversals. This requires mapping Fig. 2 back\nonto Fig. 1a: to traverse either 8? a:x?? 9? or 9? a:x?? 10?\nin Fig. 2 is ?really? to traverse 0? a:x?? 0? in Fig. 1a.\n? If Fig. 1a was built by composition, the M step\nis similar but needs the expected traversals of the\narcs in Fig. 1b?c. This requires further unwinding of\nFig. 1a?s 0? a:x?? 0?: to traverse that arc is ?really? to\ntraverse Fig. 1b?s 4? a:p?? 4? and Fig. 1c?s 6? p:x?? 6?.\n? If Fig. 1b was defined by the regexp given earlier,\ntraversing 4? a:p?? 4? is in turn ?really? just evidence\nthat the ?-coin came up heads. To learn the weights\n?, ?, ?, ?, count expected heads/tails for each coin.\n? If arc probabilities (or even ?, ?, ?, ?) have log-\nlinear parameterization, then the E step must com-\npute c =\n?\ni ecf (xi, yi), where ec(x, y) denotes\nthe expected vector of total feature counts along a\nrandom path in f? whose (input, output) matches\n(x, y). The M step then treats c as fixed, observed\ndata and adjusts ? until the predicted vector of to-\ntal feature counts equals c, using Improved Itera-\ntive Scaling (Della Pietra et al, 1997; Chen and\nRosenfeld, 1999).12 For globally normalized, joint\nmodels, the predicted vector is ecf (??,??). If the\nlog-linear probabilities are conditioned on the state\nand/or the input, the predicted vector is harder to de-\nscribe (though usually much easier to compute).13\n12IIS is itself iterative; to avoid nested loops, run only one it-\neration at each M step, giving a GEM algorithm (Riezler, 1999).\nAlternatively, discard EM and use gradient-based optimization.\n13For per-state conditional normalization, let Dj,a be the set\nof arcs from state j with input symbol a ? ?; their weights are\nnormalized to sum to 1. Besides computing c, the E step must\ncount the expected number dj,a of traversals of arcs in each\nDj,a. Then the predicted vector given ? is\n?\nj,a dj,a ?(expected\nfeature counts on a randomly chosen arc in Dj,a). Per-state\njoint normalization (Eisner, 2001b, ?8.2) is similar but drops the\ndependence on a. The difficult case is global conditional nor-\nmalization. It arises, for example, when training a joint model\nof the form f? = ? ? ? (g? ? h?) ? ? ?, where h? is a conditional\nIt is also possible to use this EM approach for dis-\ncriminative training, where we wish to maximize\n"},{"#tail":"\n","@confidence":"0.601818","#text":"\ndefines P (y  |x). The trick is to instead train a joint\nmodel g ? f?, where g(xi) defines P (xi), thereby\n"},{"#tail":"\n","@confidence":"0.998386476190476","#text":"\nthe method of this paper can train such composi-\ntions.) If x1, . . . xn are fully observed, just define\neach g(xi) = 1/n. But by choosing a more gen-\neral model of g, we can also handle incompletely\nobserved xi: training g ? f? then forces g and f?\nto cooperatively reconstruct a distribution over the\npossible inputs and do discriminative training of f?\ngiven those inputs. (Any parameters of g may be ei-\nther frozen before training or optimized along with\nthe parameters of f?.) A final possibility is that each\nxi is defined by a probabilistic FSA that already sup-\nplies a distribution over the inputs; then we consider\nxi ? f? ? yi directly, just as in the joint model.\nFinally, note that EM is not all-purpose. It only\nmaximizes probabilistic objective functions, and\neven there it is not necessarily as fast as (say) conju-\ngate gradient. For this reason, we will also show be-\nlow how to compute the gradient of f?(xi, yi) with\nrespect to ?, for an arbitrary parameterized FST f?.\nWe remark without elaboration that this can help\noptimize task-related objective functions, such as\n"},{"#tail":"\n","@confidence":"0.9731068","#text":"\nIt remains to devise appropriate E steps, which looks\nrather daunting. Each path in Fig. 2 weaves together\nparameters from other machines, which we must un-\ntangle and tally. In the 4-coin parameterization, path\n8? a:x?? 9?\n"},{"#tail":"\n","@confidence":"0.974726272727273","#text":"\n?? 12? must yield up a\nvector ?H?, T?,H?, T?,H? , T? ,H?, T?? that counts\nobserved heads and tails of the 4 coins. This non-\ntrivially works out to ?4, 1, 0, 1, 1, 1, 1, 2?. For other\nparameterizations, the path must instead yield a vec-\ntor of arc traversal counts or feature counts.\nComputing a count vector for one path is hard\nenough, but it is the E step?s job to find the expected\nvalue of this vector?an average over the infinitely\nlog-linear model of P (v  |u) for u ? ???, v ? ???. Then the\npredicted count vector contributed by h is\n"},{"#tail":"\n","@confidence":"0.999610533333333","#text":"\nexpected count of each u ? ???. It may be found by a variant\nof ?4 in which path values are regular expressions over ???.\nmany paths pi through Fig. 2 in proportion to their\nposterior probabilities P (pi  |xi, yi). The results for\nall (xi, yi) are summed and passed to the M step.\nAbstractly, let us say that each path pi has not only\na probability P (pi) ? [0, 1] but also a value val(pi)\nin a vector space V , which counts the arcs, features,\nor coin flips encountered along path pi. The value of\na path is the sum of the values assigned to its arcs.\nThe E step must return the expected value of the\nunknown path that generated (xi, yi). For example,\nif every arc had value 1, then expected value would\nbe expected path length. Letting ? denote the set of\npaths in xi ? f? ? yi (Fig. 2), the expected value is14\n"},{"#tail":"\n","@confidence":"0.941122652173913","#text":"\nThe denominator of equation (1) is the total prob-\nability of all accepting paths in xi ?f ?yi. But while\ncomputing this, we will also compute the numerator.\nThe idea is to augment the weight data structure with\nexpectation information, so each weight records a\nprobability and a vector counting the parameters\nthat contributed to that probability. We will enforce\nan invariant: the weight of any pathset ? must\nbe (\n?\npi?? P (pi),\n?\npi?? P (pi) val(pi)) ? R?0 ? V ,\nfrom which (1) is trivial to compute.\nBerstel and Reutenauer (1988) give a sufficiently\ngeneral finite-state framework to allow this: weights\nmay fall in any set K (instead of R). Multiplica-\ntion and addition are replaced by binary operations\n? and ? on K. Thus ? is used to combine arc\nweights into a path weight and ? is used to com-\nbine the weights of alternative paths. To sum over\ninfinite sets of cyclic paths we also need a closure\noperation ?, interpreted as k? =\n"},{"#tail":"\n","@confidence":"0.954214833333333","#text":"\n. The usual\nfinite-state algorithms work if (K,?,?, ?) has the\nstructure of a closed semiring.15\nOrdinary probabilities fall in the semiring\n(R?0,+,?, ?).16 Our novel weights fall in a novel\n14Formal derivation of (1): ?pi P (pi  |xi, yi) val(pi) =\n"},{"#tail":"\n","@confidence":"0.818454333333333","#text":"\npi P (xi, yi  |pi)P (pi); now observe that\nP (xi, yi  |pi) = 1 or 0 according to whether pi ? ?.\n15That is: (K,?) is a monoid (i.e., ? : K ? K ? K is\nassociative) with identity 1. (K,?) is a commutative monoid\nwith identity 0. ? distributes over ? from both sides, 0 ? k =\nk? 0 = 0, and k? = 1? k? k? = 1? k?? k. For finite-state\ncomposition, commutativity of ? is needed as well.\n16The closure operation is defined for p ? [0, 1) as p? =\n1/(1? p), so cycles with weights in [0, 1) are allowed.\n"},{"#tail":"\n","@confidence":"0.993816","#text":"\nif p? defined, (p, v)? def= (p?, p?vp?) (4)\nIf an arc has probability p and value v, we give it\nthe weight (p, pv), so that our invariant (see above)\nholds if ? consists of a single length-0 or length-1\npath. The above definitions are designed to preserve\nour invariant as we build up larger paths and path-\nsets. ? lets us concatenate (e.g.) simple paths pi1, pi2\nto get a longer path pi with P (pi) = P (pi1)P (pi2)\nand val(pi) = val(pi1) + val(pi2). The defini-\ntion of ? guarantees that path pi?s weight will be\n(P (pi), P (pi) ? val(pi)). ? lets us take the union of\ntwo disjoint pathsets, and ? computes infinite unions.\nTo compute (1) now, we only need the total\nweight ti of accepting paths in xi ? f ? yi (Fig. 2).\nThis can be computed with finite-state methods: the\nmachine (?xi)?f?(yi?) is a version that replaces\nall input:output labels with  : , so it maps (, ) to\nthe same total weight ti. Minimizing it yields a one-\nstate FST from which ti can be read directly!\nThe other ?magical? property of the expecta-\ntion semiring is that it automatically keeps track of\nthe tangled parameter counts. For instance, recall\nthat traversing 0? a:x?? 0? should have the same ef-\nfect as traversing both the underlying arcs 4? a:p?? 4?\nand 6? p:x?? 6?. And indeed, if the underlying arcs\nhave values v1 and v2, then the composed arc\n0? a:x?? 0? gets weight (p1, p1v1) ? (p2, p2v2) =\n(p1p2, p1p2(v1 + v2)), just as if it had value v1 + v2.\nSome concrete examples of values may be useful:\n? To count traversals of the arcs of Figs. 1b?c, num-\nber these arcs and let arc ` have value e`, the `th basis\nvector. Then the `th element of val(pi) counts the ap-\npearances of arc ` in path pi, or underlying path pi.\n? A regexp of formE+?F = ?E+(1??)F should\nbe weighted as (?, ?ek)E + (1? ?, (1? ?)ek+1)F\nin the new semiring. Then elements k and k + 1 of\nval(pi) count the heads and tails of the ?-coin.\n? For a global log-linear parameterization, an arc?s\nvalue is a vector specifying the arc?s features. Then\nval(pi) counts all the features encountered along pi.\nReally we are manipulating weighted relations,\nnot FSTs. We may combine FSTs, or determinize\nor minimize them, with any variant of the semiring-\nweighted algorithms.17 As long as the resulting FST\ncomputes the right weighted relation, the arrange-\nment of its states, arcs, and labels is unimportant.\nThe same semiring may be used to compute gradi-\nents. We would like to find f?(xi, yi) and its gradient\nwith respect to ?, where f? is real-valued but need\nnot be probabilistic. Whatever procedures are used\nto evaluate f?(xi, yi) exactly or approximately?for\nexample, FST operations to compile f? followed by\nminimization of (?xi) ? f? ? (yi? )?can simply\nbe applied over the expectation semiring, replacing\neach weight p by (p,?p) and replacing the usual\narithmetic operations with ?, ?, etc.18 (2)?(4) pre-\nserve the gradient ((2) is the derivative product rule),\nso this computation yields (f?(xi, yi),?f?(xi, yi)).\n"},{"#tail":"\n","@confidence":"0.997737461538461","#text":"\nNow for some important remarks on efficiency:\n? Computing ti is an instance of the well-known\nalgebraic path problem (Lehmann, 1977; Tarjan,\n1981a). Let Ti = xi?f?yi. Then ti is the total semir-\ning weight w0n of paths in Ti from initial state 0 to\nfinal state n (assumed WLOG to be unique and un-\nweighted). It is wasteful to compute ti as suggested\nearlier, by minimizing (?xi)?f?(yi?), since then\nthe real work is done by an -closure step (Mohri,\n2002) that implements the all-pairs version of alge-\nbraic path, whereas all we need is the single-source\nversion. If n and m are the number of states and\nedges,19 then both problems are O(n3) in the worst\ncase, but the single-source version can be solved in\nessentially O(m) time for acyclic graphs and other\nreducible flow graphs (Tarjan, 1981b). For a gen-\neral graph Ti, Tarjan (1981b) shows how to partition\ninto ?hard? subgraphs that localize the cyclicity or\nirreducibility, then run the O(n3) algorithm on each\nsubgraph (thereby reducing n to as little as 1), and\nrecombine the results. The overhead of partitioning\nand recombining is essentially only O(m).\n? For speeding up theO(n3) problem on subgraphs,\none can use an approximate relaxation technique\n17Eisner (submitted) develops fast minimization algorithms\nthat work for the real and V -expectation semirings.\n18Division and subtraction are also possible: ?(p, v) =\n(?p,?v) and (p, v)?1 = (p?1,?p?1vp?1). Division is com-\nmonly used in defining f? (for normalization).\n19Multiple edges from j to k are summed into a single edge.\n(Mohri, 2002). Efficient hardware implementation is\nalso possible via chip-level parallelism (Rote, 1985).\n? In many cases of interest, Ti is an acyclic graph.20\nThen Tarjan?s method computes w0j for each j in\ntopologically sorted order, thereby finding ti in a\nlinear number of ? and ? operations. For HMMs\n(footnote 11), Ti is the familiar trellis, and we would\nlike this computation of ti to reduce to the forward-\nbackward algorithm (Baum, 1972). But notice that\nit has no backward pass. In place of pushing cumu-\nlative probabilities backward to the arcs, it pushes\ncumulative arcs (more generally, values in V ) for-\nward to the probabilities. This is slower because\nour ? and ? are vector operations, and the vec-\ntors rapidly lose sparsity as they are added together.\nWe therefore reintroduce a backward pass that lets\nus avoid ? and ? when computing ti (so they are\nneeded only to construct Ti). This speedup also\nworks for cyclic graphs and for any V . Write wjk\nas (pjk, vjk), and let w1jk = (p1jk, v1jk) denote the\nweight of the edge from j to k.19 Then it can be\nshown that w0n = (p0n,\n"},{"#tail":"\n","@confidence":"0.967530916666667","#text":"\njkpkn). The for-\nward and backward probabilities, p0j and pkn, can\nbe computed using single-source algebraic path for\nthe simpler semiring (R,+,?, ?)?or equivalently,\nby solving a sparse linear system of equations over\nR, a much-studied problem at O(n) space, O(nm)\ntime, and faster approximations (Greenbaum, 1997).\n? A Viterbi variant of the expectation semiring ex-\nists: replace (3) with if(p1 > p2, (p1, v1), (p2, v2)).\nHere, the forward and backward probabilities can be\ncomputed in time only O(m + n log n) (Fredman\nand Tarjan, 1987). k-best variants are also possible.\n"},{"#tail":"\n","@confidence":"0.998354666666666","#text":"\nWe have exhibited a training algorithm for param-\neterized finite-state machines. Some specific conse-\nquences that we believe to be novel are (1) an EM al-\ngorithm for FSTs with cycles and epsilons; (2) train-\ning algorithms for HMMs and weighted contextual\nedit distance that work on incomplete data; (3) end-\nto-end training of noisy channel cascades, so that it\nis not necessary to have separate training data for\neach machine in the cascade (cf. Knight and Graehl,\n20If xi and yi are acyclic (e.g., fully observed strings), and\nf (or rather its FST) has no  :  cycles, then composition will\n?unroll? f into an acyclic machine. If only xi is acyclic, then\nthe composition is still acyclic if domain(f) has no  cycles.\n1998), although such data could also be used; (4)\ntraining of branching noisy channels (footnote 7);\n(5) discriminative training with incomplete data; (6)\ntraining of conditional MEMMs (McCallum et al,\n2000) and conditional random fields (Lafferty et al,\n2001) on unbounded sequences.\nWe are particularly interested in the potential for\nquickly building statistical models that incorporate\nlinguistic and engineering insights. Many models of\ninterest can be constructed in our paradigm, without\nhaving to write new code. Bringing diverse models\ninto the same declarative framework also allows one\nto apply new optimization methods, objective func-\ntions, and finite-state algorithms to all of them.\nTo avoid local maxima, one might try determinis-\ntic annealing (Rao and Rose, 2001), or randomized\nmethods, or place a prior on ?. Another extension is\nto adjust the machine topology, say by model merg-\ning (Stolcke and Omohundro, 1994). Such tech-\nniques build on our parameter estimation method.\nThe key algorithmic ideas of this paper extend\nfrom forward-backward-style to inside-outside-style\nmethods. For example, it should be possible to do\nend-to-end training of a weighted relation defined\nby an interestingly parameterized synchronous CFG\ncomposed with tree transducers and then FSTs.\n"},{"#tail":"\n","@confidence":"0.9540724","#text":"\npath problems. J. of the ACM, 28(3):594?614, July.\nG. van Noord and D. Gerdemann. 2001. An extendible\nregular expression compiler for finite-state approaches\nin natural language processing. In Automata Imple-\nmentation, no. 22 in Springer Lecture Notes in CS.\n"}],"#text":"\n","affiliation":{"#tail":"\n","@confidence":"0.971565","#text":"\nDepartment of Computer Science\nJohns Hopkins University\n"},"sectionHeader":[{"#tail":"\n","@confidence":"0.990798","@genericHeader":"abstract","#text":"\nAbstract\n"},{"#tail":"\n","@confidence":"0.842164","@genericHeader":"keywords","#text":"\n1 Background and Motivation\n"},{"#tail":"\n","@confidence":"0.729585","@genericHeader":"introduction","#text":"\n2 Transducers and Parameters\n"},{"#tail":"\n","@confidence":"0.828175","@genericHeader":"method","#text":"\n3 Estimation in Parameterized FSTs\n"},{"#tail":"\n","@confidence":"0.953194","@genericHeader":"method","#text":"\n4 The E Step: Expectation Semirings\n"},{"#tail":"\n","@confidence":"0.994131","@genericHeader":"method","#text":"\n5 Removing Inefficiencies\n"},{"#tail":"\n","@confidence":"0.998347","@genericHeader":"conclusions","#text":"\n6 Discussion\n"},{"#tail":"\n","@confidence":"0.985856","@genericHeader":"references","#text":"\nReferences\n"}],"figureCaption":[{"#tail":"\n","@confidence":"0.8324965","#text":"\n7/1p: /.1? q:z/1\np: /1? q:z/1\nFigure 1: (a) A probabilistic FST defining a joint probability\ndistribution. (b) A smaller joint distribution. (c) A conditional\n"},{"#tail":"\n","@confidence":"0.8573245","#text":"\na: /.7?\nb: /.0051? 12/.5b:z/.1284b: /.1? b:z/.404\nb: /.1?\nFigure 2: The joint model of Fig. 1a constrained to generate\n"}],"email":{"#tail":"\n","@confidence":"0.997852","#text":"\njason@cs.jhu.edu\n"}}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.000173","#tail":"\n","@no":"0","note":[{"#tail":"\n","@confidence":"0.91119145","#text":"1Given output, find input to maximize P (input, output). Computational Linguistics (ACL), Philadelphia, July 2002, pp. 1-8. Proceedings of the 40th Annual Meeting of the Association for (a) (b) 0/.15 a:x/.63 1/.15a: /.07? 2/.5b: /.003? b:z/.12 3/.5 b:x/.027 a: /.7? b: /.03? b:z/.12 b: /.1? b:z/.4 b: /.01? b:z/.4b:x/.09 4/.15 a:p/.7 5/.5b:p/.03b:q/.12 b:p/.1b:q/.4 (c) 6/1 p:x/.9"},{"#tail":"\n","@confidence":"0.746393652173913","#text":"Technical Report CMU-CS-99-108, Carnegie Mellon. S. Della Pietra, V. Della Pietra, and J. Lafferty. 1997. Inducing features of random fields. IEEE Transactions on Pattern Analysis and Machine Intelligence, 19(4). A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. J. Royal Statist. Soc. Ser. B, 39(1):1?38. Jason Eisner. 2001a. Expectation semirings: Flexible EM for finite-state transducers. In G. van Noord, ed., Proc. of the ESSLLI Workshop on Finite-State Methods in Natural Language Processing. Extended abstract. Jason Eisner. 2001b. Smoothing a Probabilistic Lexicon via Syntactic Transformations. Ph.D. thesis, University of Pennsylvania. D. Gerdemann and G. van Noord. 1999. Transducers from rewrite rules with backreferences. Proc. of EACL. Anne Greenbaum. 1997. Iterative Methods for Solving Linear Systems. Soc. for Industrial and Applied Math. Kevin Knight and Yaser Al-Onaizan. 1998. Translation with finite-state devices. In Proc. of AMTA. Kevin Knight and Jonathan Graehl. 1998. Machine transliteration. Computational Linguistics, 24(4). J. Lafferty, A. McCallum, and F. Pereira. 2001. Con-"},{"#tail":"\n","@confidence":"0.793733814814815","#text":"Computational Linguistics, 26(1). Fernando C. N. Pereira and Michael Riley. 1997. Speech recognition by composition of weighted finite automata. In E. Roche and Y. Schabes, eds., Finite-State Language Processing. MIT Press, Cambridge, MA. A. Rao and K. Rose. 2001 Deterministically annealed design of hidden Markov movel speech recognizers. In IEEE Trans. on Speech and Audio Processing, 9(2). Stefan Riezler. 1999. Probabilistic Constraint Logic Programming. Ph.D. thesis, Universita?t Tu?bingen. E. Ristad and P. Yianilos. 1996. Learning string edit distance. Tech. Report CS-TR-532-96, Princeton. E. Ristad. 1998. Hidden Markov models with finite state supervision. In A. Kornai, ed., Extended Finite State Models of Language. Cambridge University Press. Emmanuel Roche and Yves Schabes, editors. 1997. Finite-State Language Processing. MIT Press. Gu?nter Rote. 1985. A systolic array algorithm for the algebraic path problem (shortest paths; matrix inversion). Computing, 34(3):191?219. Richard Sproat and Michael Riley. 1996. Compilation of weighted finite-state transducers from decision trees. In Proceedings of the 34th Annual Meeting of the ACL. Andreas Stolcke and Stephen M. Omohundro. 1994. Best-first model merging for hidden Markov model induction. Tech. Report ICSI TR-94-003, Berkeley, CA. Robert Endre Tarjan. 1981a. A unified approach to path"}],"address":{"#tail":"\n","@confidence":"0.999456","#text":"Baltimore, MD, USA 21218-2691"},"#text":"\n","phone":{"#tail":"\n","@confidence":"0.334748","#text":"7/1p: /.1? q:z/1"},"affiliation":{"#tail":"\n","@confidence":"0.999611","#text":"Department of Computer Science Johns Hopkins University"},"author":{"#tail":"\n","@confidence":"0.999993","#text":"Jason Eisner"},"abstract":[{"#tail":"\n","@confidence":"0.998908417721519","#text":"Weighted finite-state transducers suffer from the lack of a training algorithm. Training is even harder for transducers that have been assembled via finite-state operations such as composition, minimization, union, concatenation, and closure, as this yields tricky parameter tying. We formulate a ?parameterized FST? paradigm and give training algorithms for it, including a general bookkeeping trick (?expectation semirings?) that cleanly and efficiently computes expectations and gradients. 1 Background and Motivation Rational relations on strings have become widespread in language and speech engineering (Roche and Schabes, 1997). Despite bounded memory they are well-suited to describe many linguistic and textual processes, either exactly or approximately. A relation is a set of (input, output) pairs. Relations are more general than functions because they may pair a given input string with more or fewer than one output string. The class of so-called rational relations admits a nice declarative programming paradigm. Source code describing the relation (a regular expression) is compiled into efficient object code (in the form of a 2-tape automaton called a finite-state transducer). The object code can even be optimized for runtime and code size (via algorithms such as determinization and minimization of transducers). This programming paradigm supports efficient nondeterminism, including parallel processing over infinite sets of input strings, and even allows ?reverse? computation from output to input. Its unusual flexibility for the practiced programmer stems from the many operations under which rational relations are closed. It is common to define further useful operations (as macros), which modify existing relations not by editing their source code but simply by operating on them ?from outside.? ?A brief version of this work, with some additional material, first appeared as (Eisner, 2001a). A leisurely journal-length version with more details has been prepared and is available. The entire paradigm has been generalized to weighted relations, which assign a weight to each (input, output) pair rather than simply including or excluding it. If these weights represent probabilities P (input, output) or P (output  |input), the weighted relation is called a joint or conditional (probabilistic) relation and constitutes a statistical model. Such models can be efficiently restricted, manipulated or combined using rational operations as before. An artificial example will appear in ?2. The availability of toolkits for this weighted case (Mohri et al, 1998; van Noord and Gerdemann, 2001) promises to unify much of statistical NLP. Such tools make it easy to run most current approaches to statistical markup, chunking, normalization, segmentation, alignment, and noisy-channel decoding,1 including classic models for speech recognition (Pereira and Riley, 1997) and machine translation (Knight and Al-Onaizan, 1998). Moreover, once the models are expressed in the finitestate framework, it is easy to use operators to tweak them, to apply them to speech lattices or other sets, and to combine them with linguistic resources. Unfortunately, there is a stumbling block: Where do the weights come from? After all, statistical models require supervised or unsupervised training. Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs. Not only do these methods require additional programming outside the toolkit, but they are limited to particular kinds of models and training regimens. For example, the forward-backward algorithm (Baum, 1972) trains only Hidden Markov Models, while (Ristad and Yianilos, 1996) trains only stochastic edit distance. In short, current finite-state toolkits include no training algorithms, because none exist for the large space of statistical models that the toolkits can in principle describe and run."},{"#tail":"\n","@confidence":"0.994092632892806","#text":"p: /1? q:z/1 Figure 1: (a) A probabilistic FST defining a joint probability distribution. (b) A smaller joint distribution. (c) A conditional distribution. Defining (a)=(b)?(c) means that the weights in (a) can be altered by adjusting the fewer weights in (b) and (c). This paper aims to provide a remedy through a new paradigm, which we call parameterized finitestate machines. It lays out a fully general approach for training the weights of weighted rational relations. First ?2 considers how to parameterize such models, so that weights are defined in terms of underlying parameters to be learned. ?3 asks what it means to learn these parameters from training data (what is to be optimized?), and notes the apparently formidable bookkeeping involved. ?4 cuts through the difficulty with a surprisingly simple trick. Finally, ?5 removes inefficiencies from the basic algorithm, making it suitable for inclusion in an actual toolkit. Such a toolkit could greatly shorten the development cycle in natural language engineering. 2 Transducers and Parameters Finite-state machines, including finite-state automata (FSAs) and transducers (FSTs), are a kind of labeled directed multigraph. For ease and brevity, we explain them by example. Fig. 1a shows a probabilistic FST with input alphabet ? = {a, b}, output alphabet ? = {x, z}, and all states final. It may be regarded as a device for generating a string pair in ?? ? ?? by a random walk from 0?. Two paths exist that generate both input aabb and output xz: 0?a:x/.63?? 0? a:/.07 ?? 1? b:/.03 ?? 2? b:z/.4 ?? 2/.5? 0?a:x/.63?? 0? a:/.07 ?? 1? b:z/.12 ?? 2? b:/.1 ?? 2/.5? Each of the paths has probability .0002646, so the probability of somehow generating the pair (aabb, xz) is .0002646 + .0002646 = .0005292. Abstracting away from the idea of random walks, arc weights need not be probabilities. Still, define a path?s weight as the product of its arc weights and the stopping weight of its final state. Thus Fig. 1a defines a weighted relation f where f(aabb, xz) = .0005292. This particular relation does happen to be probabilistic (see ?1). It represents a joint distribution (since ?x,y f(x, y) = 1). Meanwhile, Fig. 1c defines a conditional one (?x?y f(x, y) = 1). This paper explains how to adjust probability distributions like that of Fig. 1a so as to model training data better. The algorithm improves an FST?s numeric weights while leaving its topology fixed. How many parameters are there to adjust in Fig. 1a? That is up to the user who built it! An FST model with few parameters is more constrained, making optimization easier. Some possibilities: ? Most simply, the algorithm can be asked to tune the 17 numbers in Fig. 1a separately, subject to the constraint that the paths retain total probability 1. A more specific version of the constraint requires the FST to remain Markovian: each of the 4 states must present options with total probability 1 (at state 1?, 15+.7+.03.+.12=1). This preserves the random-walk interpretation and (we will show) entails no loss of generality. The 4 restrictions leave 13 free params. ? But perhaps Fig. 1a was actually obtained as the composition of Fig. 1b?c, effectively defining P (input, output) = ? mid P (input,mid) ? P (output  |mid). If Fig. 1b?c are required to remain Markovian, they have 5 and 1 degrees of freedom respectively, so now Fig. 1a has only 6 parameters total.2 In general, composing machines multiplies their arc counts but only adds their parameter counts. We wish to optimize just the few underlying parameters, not independently optimize the many arc weights of the composed machine. ? Perhaps Fig. 1b was itself obtained by the probabilistic regular expression (a : p)??(b : (p +? q))?? with the 3 parameters (?, ?, ?) = (.7, .2, .5). With ? = .1 from footnote 2, the composed machine 2Why does Fig. 1c have only 1 degree of freedom? The Markovian requirement means something different in Fig. 1c, which defines a conditional relation P (output  |mid) rather than a joint one. A random walk on Fig. 1c chooses among arcs with a given input label. So the arcs from state 6? with input p must have total probability 1 (currently .9+.1). All other arc choices are forced by the input label and so have probability 1. The only tunable value is .1 (denote it by ?), with .9 = 1? ?. (Fig. 1a) has now been described with a total of just 4 parameters!3 Here, probabilistic union E +? F def = ?E + (1 ? ?)F means ?flip a ?-weighted coin and generateE if heads, F if tails.? E?? def = (?E)?(1??) means ?repeatedly flip an ?-weighted coin and keep repeating E as long as it comes up heads.? These 4 parameters have global effects on Fig. 1a, thanks to complex parameter tying: arcs 4? b:p?? 5?, 5? b:q?? 5? in Fig. 1b get respective probabilities (1? ?)?? and (1 ? ?)?, which covary with ? and vary oppositely with ?. Each of these probabilities in turn affects multiple arcs in the composed FST of Fig. 1a. We offer a theorem that highlights the broad applicability of these modeling techniques.4 If f(input, output) is a weighted regular relation, then the following statements are equivalent: (1) f is a joint probabilistic relation; (2) f can be computed by a Markovian FST that halts with probability 1; (3) f can be expressed as a probabilistic regexp, i.e., a regexp built up from atomic expressions a : b (for a ? ?? {}, b ? ?? {}) using concatenation, probabilistic union +p, and probabilistic closure ?p. For defining conditional relations, a good regexp language is unknown to us, but they can be defined in several other ways: (1) via FSTs as in Fig. 1c, (2) by compilation of weighted rewrite rules (Mohri and Sproat, 1996), (3) by compilation of decision trees (Sproat and Riley, 1996), (4) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation (Gerdemann and van Noord, 1999),5 (5) by conditionalization of a joint relation as discussed below. A central technique is to define a joint relation as a noisy-channel model, by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 (Pereira and Riley, 1997; Knight and Graehl, 1998). The general form is illustrated by 3Conceptually, the parameters represent the probabilities of reading another a (?); reading another b (?); transducing b to p rather than q (?); starting to transduce p to  rather than x (?). 4To prove (1)?(3), express f as an FST and apply the well-known Kleene-Schu?tzenberger construction (Berstel and Reutenauer, 1988), taking care to write each regexp in the construction as a constant times a probabilistic regexp. A full proof is straightforward, as are proofs of (3)?(2), (2)?(1). 5In (4), the randomness is in the smaller relation?s choice of how to replace a match. One can also get randomness through the choice of matches, ignoring match possibilities by randomly deleting markers in Gerdemann and van Noord?s construction. P (v, z) def = ? w,x,y P (v|w)P (w, x)P (y|x)P (z|y), implemented by composing 4 machines.6,7 There are also procedures for defining weighted FSTs that are not probabilistic (Berstel and Reutenauer, 1988). Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into :/2.7?? arcs). A more subtle example is weighted FSAs that approximate PCFGs (Nederhof, 2000; Mohri and Nederhof, 2001), or to extend the idea, weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation. These are parameterized by the PCFG?s parameters, but add or remove strings of the PCFG to leave an improper probability distribution. Fortunately for those techniques, an FST with positive arc weights can be normalized to make it jointly or conditionally probabilistic: ? An easy approach is to normalize the options at each state to make the FST Markovian. Unfortunately, the result may differ for equivalent FSTs that express the same weighted relation. Undesirable consequences of this fact have been termed ?label bias? (Lafferty et al, 2001). Also, in the conditional case such per-state normalization is only correct if all states accept all input suffixes (since ?dead ends? leak probability mass).8 ? A better-founded approach is global normalization, which simply divides each f(x, y) by ? x?,y? f(x ?, y?) (joint case) or by?y? f(x, y?) (conditional case). To implement the joint case, just divide stopping weights by the total weight of all paths (which ?4 shows how to find), provided this is finite. In the conditional case, let g be a copy of f with the output labels removed, so that g(x) finds the desired divisor; determinize g if possible (but this fails for some weighted FSAs), replace all weights with their reciprocals, and compose the result with f .9 6P (w, x) defines the source model, and is often an ?identity FST? that requires w = x, really just an FSA. 7We propose also using n-tape automata to generalize to ?branching noisy channels? (a case of dendroid distributions). In ? w,x P (v|w)P (v ?|w)P (w, x)P (y|x), the true transcription w can be triply constrained by observing speech y and two errorful transcriptions v, v?, which independently depend on w. 8A corresponding problem exists in the joint case, but may be easily avoided there by first pruning non-coaccessible states. 9It suffices to make g unambiguous (one accepting path per string), a weaker condition than determinism. When this is not possible (as in the inverse of Fig. 1b, whose conditionaliza- Normalization is particularly important because it enables the use of log-linear (maximum-entropy) parameterizations. Here one defines each arc weight, coin weight, or regexp weight in terms of meaningful features associated by hand with that arc, coin, etc. Each feature has a strength ? R>0, and a weight is computed as the product of the strengths of its features.10 It is now the strengths that are the learnable parameters. This allows meaningful parameter tying: if certain arcs such as u:i??, o:e ??, and a:ae?? share a contextual ?vowel-fronting? feature, then their weights rise and fall together with the strength of that feature. The resulting machine must be normalized, either per-state or globally, to obtain a joint or a conditional distribution as desired. Such approaches have been tried recently in restricted cases (McCallum et al, 2000; Eisner, 2001b; Lafferty et al, 2001). Normalization may be postponed and applied instead to the result of combining the FST with other FSTs by composition, union, concatenation, etc. A simple example is a probabilistic FSA defined by normalizing the intersection of other probabilistic FSAs f1, f2, . . .. (This is in fact a log-linear model in which the component FSAs define the features: string x has log fi(x) occurrences of feature i.) In short, weighted finite-state operators provide a language for specifying a wide variety of parameterized statistical models. Let us turn to their training. 3 Estimation in Parameterized FSTs We are primarily concerned with the following training paradigm, novel in its generality. Let f? : ????? ? R?0 be a joint probabilistic relation that is computed by a weighted FST. The FST was built by some recipe that used the parameter vector ?. Changing ? may require us to rebuild the FST to get updated weights; this can involve composition, regexp compilation, multiplication of feature strengths, etc. (Lazy algorithms that compute arcs and states of tion cannot be realized by any weighted FST), one can sometimes succeed by first intersecting g with a smaller regular set in which the input being considered is known to fall. In the extreme, if each input string is fully observed (not the case if the input is bound by composition to the output of a one-to-many FST), one can succeed by restricting g to each input string in turn; this amounts to manually dividing f(x, y) by g(x). 10Traditionally log(strength) values are called weights, but this paper uses ?weight? to mean something else. 8 9a:x/.63 10a:x/.63 11b:x/.027 a: /.7? b: /.0051? 12/.5b:z/.1284b: /.1? b:z/.404 b: /.1? Figure 2: The joint model of Fig. 1a constrained to generate only input ? a(a + b)? and output = xxz. f? on demand (Mohri et al, 1998) can pay off here, since only part of f? may be needed subsequently.) As training data we are given a set of observed (input, output) pairs, (xi, yi). These are assumed to be independent random samples from a joint distribution of the form f??(x, y); the goal is to recover the true ??. Samples need not be fully observed (partly supervised training): thus xi ? ??, yi ? ?? may be given as regular sets in which input and output were observed to fall. For example, in ordinary HMM training, xi = ?? and represents a completely hidden state sequence (cf. Ristad (1998), who allows any regular set), while yi is a single string representing a completely observed emission sequence.11 What to optimize? Maximum-likelihood estimation guesses ?? to be the ? maximizing ? i f?(xi, yi). Maximum-posterior estimation tries to maximize P (?) ? ? i f?(xi, yi) where P (?) is a prior probability. In a log-linear parameterization, for example, a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting (Chen and Rosenfeld, 1999). The EM algorithm (Dempster et al, 1977) can maximize these functions. Roughly, the E step guesses hidden information: if (xi, yi) was generated from the current f?, which FST paths stand a chance of having been the path used? (Guessing the path also guesses the exact input and output.) The M step updates ? to make those paths more likely. EM alternates these steps and converges to a local optimum. The M step?s form depends on the parameterization and the E step serves the M step?s needs. Let f? be Fig. 1a and suppose (xi, yi) = (a(a + b)?, xxz). During the E step, we restrict to paths compatible with this observation by computing xi ? f? ? yi, shown in Fig. 2. To find each path?s posterior probability given the observation (xi, yi), just conditionalize: divide its raw probability by the total probability (? 0.1003) of all paths in Fig. 2. 11To implement an HMM by an FST, compose a probabilistic FSA that generates a state sequence of the HMM with a conditional FST that transduces HMM states to emitted symbols. But that is not the full E step. The M step uses not individual path probabilities (Fig. 2 has infinitely many) but expected counts derived from the paths. Crucially, ?4 will show how the E step can accumulate these counts effortlessly. We first explain their use by the M step, repeating the presentation of ?2: ? If the parameters are the 17 weights in Fig. 1a, the M step reestimates the probabilities of the arcs from each state to be proportional to the expected number of traversals of each arc (normalizing at each state to make the FST Markovian). So the E step must count traversals. This requires mapping Fig. 2 back onto Fig. 1a: to traverse either 8? a:x?? 9? or 9? a:x?? 10? in Fig. 2 is ?really? to traverse 0? a:x?? 0? in Fig. 1a. ? If Fig. 1a was built by composition, the M step is similar but needs the expected traversals of the arcs in Fig. 1b?c. This requires further unwinding of Fig. 1a?s 0? a:x?? 0?: to traverse that arc is ?really? to traverse Fig. 1b?s 4? a:p?? 4? and Fig. 1c?s 6? p:x?? 6?. ? If Fig. 1b was defined by the regexp given earlier, traversing 4? a:p?? 4? is in turn ?really? just evidence that the ?-coin came up heads. To learn the weights ?, ?, ?, ?, count expected heads/tails for each coin. ? If arc probabilities (or even ?, ?, ?, ?) have loglinear parameterization, then the E step must compute c = ? i ecf (xi, yi), where ec(x, y) denotes the expected vector of total feature counts along a random path in f? whose (input, output) matches (x, y). The M step then treats c as fixed, observed data and adjusts ? until the predicted vector of total feature counts equals c, using Improved Iterative Scaling (Della Pietra et al, 1997; Chen and Rosenfeld, 1999).12 For globally normalized, joint models, the predicted vector is ecf (??,??). If the log-linear probabilities are conditioned on the state and/or the input, the predicted vector is harder to describe (though usually much easier to compute).13 12IIS is itself iterative; to avoid nested loops, run only one iteration at each M step, giving a GEM algorithm (Riezler, 1999). Alternatively, discard EM and use gradient-based optimization. 13For per-state conditional normalization, let Dj,a be the set of arcs from state j with input symbol a ? ?; their weights are normalized to sum to 1. Besides computing c, the E step must count the expected number dj,a of traversals of arcs in each Dj,a. Then the predicted vector given ? is ? j,a dj,a ?(expected feature counts on a randomly chosen arc in Dj,a). Per-state joint normalization (Eisner, 2001b, ?8.2) is similar but drops the dependence on a. The difficult case is global conditional normalization. It arises, for example, when training a joint model of the form f? = ? ? ? (g? ? h?) ? ? ?, where h? is a conditional It is also possible to use this EM approach for discriminative training, where we wish to maximize ? i P (yi  |xi) and f?(x, y) is a conditional FST that defines P (y  |x). The trick is to instead train a joint model g ? f?, where g(xi) defines P (xi), thereby maximizing ? i P (xi) ? P (yi  |xi). (Of course, the method of this paper can train such compositions.) If x1, . . . xn are fully observed, just define each g(xi) = 1/n. But by choosing a more general model of g, we can also handle incompletely observed xi: training g ? f? then forces g and f? to cooperatively reconstruct a distribution over the possible inputs and do discriminative training of f? given those inputs. (Any parameters of g may be either frozen before training or optimized along with the parameters of f?.) A final possibility is that each xi is defined by a probabilistic FSA that already supplies a distribution over the inputs; then we consider xi ? f? ? yi directly, just as in the joint model. Finally, note that EM is not all-purpose. It only maximizes probabilistic objective functions, and even there it is not necessarily as fast as (say) conjugate gradient. For this reason, we will also show below how to compute the gradient of f?(xi, yi) with respect to ?, for an arbitrary parameterized FST f?. We remark without elaboration that this can help optimize task-related objective functions, such as ? i ? y(P (xi, y) ?/ ? y? P (xi, y ?)?) ? error(y, yi). 4 The E Step: Expectation Semirings It remains to devise appropriate E steps, which looks rather daunting. Each path in Fig. 2 weaves together parameters from other machines, which we must untangle and tally. In the 4-coin parameterization, path 8? a:x?? 9? a:x ?? 10? a: ?? 10? a: ?? 10? b:z ?? 12? must yield up a vector ?H?, T?,H?, T?,H? , T? ,H?, T?? that counts observed heads and tails of the 4 coins. This nontrivially works out to ?4, 1, 0, 1, 1, 1, 1, 2?. For other parameterizations, the path must instead yield a vector of arc traversal counts or feature counts. Computing a count vector for one path is hard enough, but it is the E step?s job to find the expected value of this vector?an average over the infinitely log-linear model of P (v  |u) for u ? ???, v ? ???. Then the predicted count vector contributed by h is ? i ? u???? P (u | xi, yi) ? ech(u,???). The term ? i P (u  |xi, yi) computes the expected count of each u ? ???. It may be found by a variant of ?4 in which path values are regular expressions over ???. many paths pi through Fig. 2 in proportion to their posterior probabilities P (pi  |xi, yi). The results for all (xi, yi) are summed and passed to the M step. Abstractly, let us say that each path pi has not only a probability P (pi) ? [0, 1] but also a value val(pi) in a vector space V , which counts the arcs, features, or coin flips encountered along path pi. The value of a path is the sum of the values assigned to its arcs. The E step must return the expected value of the unknown path that generated (xi, yi). For example, if every arc had value 1, then expected value would be expected path length. Letting ? denote the set of paths in xi ? f? ? yi (Fig. 2), the expected value is14 E[val(pi)  |xi, yi] = ? pi?? P (pi) val(pi)? pi?? P (pi) (1) The denominator of equation (1) is the total probability of all accepting paths in xi ?f ?yi. But while computing this, we will also compute the numerator. The idea is to augment the weight data structure with expectation information, so each weight records a probability and a vector counting the parameters that contributed to that probability. We will enforce an invariant: the weight of any pathset ? must be ( ? pi?? P (pi), ? pi?? P (pi) val(pi)) ? R?0 ? V , from which (1) is trivial to compute. Berstel and Reutenauer (1988) give a sufficiently general finite-state framework to allow this: weights may fall in any set K (instead of R). Multiplication and addition are replaced by binary operations ? and ? on K. Thus ? is used to combine arc weights into a path weight and ? is used to combine the weights of alternative paths. To sum over infinite sets of cyclic paths we also need a closure operation ?, interpreted as k? = ?? i=0 k i . The usual finite-state algorithms work if (K,?,?, ?) has the structure of a closed semiring.15 Ordinary probabilities fall in the semiring (R?0,+,?, ?).16 Our novel weights fall in a novel 14Formal derivation of (1): ?pi P (pi  |xi, yi) val(pi) = ( ? pi P (pi, xi, yi) val(pi))/P (xi, yi) = ( ? pi P (xi, yi | pi)P (pi) val(pi))/ ? pi P (xi, yi  |pi)P (pi); now observe that P (xi, yi  |pi) = 1 or 0 according to whether pi ? ?. 15That is: (K,?) is a monoid (i.e., ? : K ? K ? K is associative) with identity 1. (K,?) is a commutative monoid with identity 0. ? distributes over ? from both sides, 0 ? k = k? 0 = 0, and k? = 1? k? k? = 1? k?? k. For finite-state composition, commutativity of ? is needed as well. 16The closure operation is defined for p ? [0, 1) as p? = 1/(1? p), so cycles with weights in [0, 1) are allowed. V -expectation semiring, (R?0 ? V,?,?, ?): (p1, v1)? (p2, v2) def = (p1p2, p1v2 + v1p2) (2) (p1, v1)? (p2, v2) def = (p1 + p2, v1 + v2) (3) if p? defined, (p, v)? def= (p?, p?vp?) (4) If an arc has probability p and value v, we give it the weight (p, pv), so that our invariant (see above) holds if ? consists of a single length-0 or length-1 path. The above definitions are designed to preserve our invariant as we build up larger paths and pathsets. ? lets us concatenate (e.g.) simple paths pi1, pi2 to get a longer path pi with P (pi) = P (pi1)P (pi2) and val(pi) = val(pi1) + val(pi2). The definition of ? guarantees that path pi?s weight will be (P (pi), P (pi) ? val(pi)). ? lets us take the union of two disjoint pathsets, and ? computes infinite unions. To compute (1) now, we only need the total weight ti of accepting paths in xi ? f ? yi (Fig. 2). This can be computed with finite-state methods: the machine (?xi)?f?(yi?) is a version that replaces all input:output labels with  : , so it maps (, ) to the same total weight ti. Minimizing it yields a onestate FST from which ti can be read directly! The other ?magical? property of the expectation semiring is that it automatically keeps track of the tangled parameter counts. For instance, recall that traversing 0? a:x?? 0? should have the same effect as traversing both the underlying arcs 4? a:p?? 4? and 6? p:x?? 6?. And indeed, if the underlying arcs have values v1 and v2, then the composed arc 0? a:x?? 0? gets weight (p1, p1v1) ? (p2, p2v2) = (p1p2, p1p2(v1 + v2)), just as if it had value v1 + v2. Some concrete examples of values may be useful: ? To count traversals of the arcs of Figs. 1b?c, number these arcs and let arc ` have value e`, the `th basis vector. Then the `th element of val(pi) counts the appearances of arc ` in path pi, or underlying path pi. ? A regexp of formE+?F = ?E+(1??)F should be weighted as (?, ?ek)E + (1? ?, (1? ?)ek+1)F in the new semiring. Then elements k and k + 1 of val(pi) count the heads and tails of the ?-coin. ? For a global log-linear parameterization, an arc?s value is a vector specifying the arc?s features. Then val(pi) counts all the features encountered along pi. Really we are manipulating weighted relations, not FSTs. We may combine FSTs, or determinize or minimize them, with any variant of the semiringweighted algorithms.17 As long as the resulting FST computes the right weighted relation, the arrangement of its states, arcs, and labels is unimportant. The same semiring may be used to compute gradients. We would like to find f?(xi, yi) and its gradient with respect to ?, where f? is real-valued but need not be probabilistic. Whatever procedures are used to evaluate f?(xi, yi) exactly or approximately?for example, FST operations to compile f? followed by minimization of (?xi) ? f? ? (yi? )?can simply be applied over the expectation semiring, replacing each weight p by (p,?p) and replacing the usual arithmetic operations with ?, ?, etc.18 (2)?(4) preserve the gradient ((2) is the derivative product rule), so this computation yields (f?(xi, yi),?f?(xi, yi)). 5 Removing Inefficiencies Now for some important remarks on efficiency: ? Computing ti is an instance of the well-known algebraic path problem (Lehmann, 1977; Tarjan, 1981a). Let Ti = xi?f?yi. Then ti is the total semiring weight w0n of paths in Ti from initial state 0 to final state n (assumed WLOG to be unique and unweighted). It is wasteful to compute ti as suggested earlier, by minimizing (?xi)?f?(yi?), since then the real work is done by an -closure step (Mohri, 2002) that implements the all-pairs version of algebraic path, whereas all we need is the single-source version. If n and m are the number of states and edges,19 then both problems are O(n3) in the worst case, but the single-source version can be solved in essentially O(m) time for acyclic graphs and other reducible flow graphs (Tarjan, 1981b). For a general graph Ti, Tarjan (1981b) shows how to partition into ?hard? subgraphs that localize the cyclicity or irreducibility, then run the O(n3) algorithm on each subgraph (thereby reducing n to as little as 1), and recombine the results. The overhead of partitioning and recombining is essentially only O(m). ? For speeding up theO(n3) problem on subgraphs, one can use an approximate relaxation technique 17Eisner (submitted) develops fast minimization algorithms that work for the real and V -expectation semirings. 18Division and subtraction are also possible: ?(p, v) = (?p,?v) and (p, v)?1 = (p?1,?p?1vp?1). Division is commonly used in defining f? (for normalization). 19Multiple edges from j to k are summed into a single edge. (Mohri, 2002). Efficient hardware implementation is also possible via chip-level parallelism (Rote, 1985). ? In many cases of interest, Ti is an acyclic graph.20 Then Tarjan?s method computes w0j for each j in topologically sorted order, thereby finding ti in a linear number of ? and ? operations. For HMMs (footnote 11), Ti is the familiar trellis, and we would like this computation of ti to reduce to the forwardbackward algorithm (Baum, 1972). But notice that it has no backward pass. In place of pushing cumulative probabilities backward to the arcs, it pushes cumulative arcs (more generally, values in V ) forward to the probabilities. This is slower because our ? and ? are vector operations, and the vectors rapidly lose sparsity as they are added together. We therefore reintroduce a backward pass that lets us avoid ? and ? when computing ti (so they are needed only to construct Ti). This speedup also works for cyclic graphs and for any V . Write wjk as (pjk, vjk), and let w1jk = (p1jk, v1jk) denote the weight of the edge from j to k.19 Then it can be shown that w0n = (p0n, ? j,k p0jv 1 jkpkn). The forward and backward probabilities, p0j and pkn, can be computed using single-source algebraic path for the simpler semiring (R,+,?, ?)?or equivalently, by solving a sparse linear system of equations over R, a much-studied problem at O(n) space, O(nm) time, and faster approximations (Greenbaum, 1997). ? A Viterbi variant of the expectation semiring exists: replace (3) with if(p1 > p2, (p1, v1), (p2, v2)). Here, the forward and backward probabilities can be computed in time only O(m + n log n) (Fredman and Tarjan, 1987). k-best variants are also possible. 6 Discussion We have exhibited a training algorithm for parameterized finite-state machines. Some specific consequences that we believe to be novel are (1) an EM algorithm for FSTs with cycles and epsilons; (2) training algorithms for HMMs and weighted contextual edit distance that work on incomplete data; (3) endto-end training of noisy channel cascades, so that it is not necessary to have separate training data for each machine in the cascade (cf. Knight and Graehl, 20If xi and yi are acyclic (e.g., fully observed strings), and f (or rather its FST) has no  :  cycles, then composition will ?unroll? f into an acyclic machine. If only xi is acyclic, then the composition is still acyclic if domain(f) has no  cycles. 1998), although such data could also be used; (4) training of branching noisy channels (footnote 7); (5) discriminative training with incomplete data; (6) training of conditional MEMMs (McCallum et al, 2000) and conditional random fields (Lafferty et al, 2001) on unbounded sequences. We are particularly interested in the potential for quickly building statistical models that incorporate linguistic and engineering insights. Many models of interest can be constructed in our paradigm, without having to write new code. Bringing diverse models into the same declarative framework also allows one to apply new optimization methods, objective functions, and finite-state algorithms to all of them. To avoid local maxima, one might try deterministic annealing (Rao and Rose, 2001), or randomized methods, or place a prior on ?. Another extension is to adjust the machine topology, say by model merging (Stolcke and Omohundro, 1994). Such techniques build on our parameter estimation method. The key algorithmic ideas of this paper extend from forward-backward-style to inside-outside-style methods. For example, it should be possible to do end-to-end training of a weighted relation defined by an interestingly parameterized synchronous CFG composed with tree transducers and then FSTs. References L. E. Baum. 1972. An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process. Inequalities, 3. Jean Berstel and Christophe Reutenauer. 1988. Rational Series and their Languages. Springer-Verlag. Stanley F. Chen and Ronald Rosenfeld. 1999. A Gaussian prior for smoothing maximum entropy models."},{"#tail":"\n","@confidence":"0.931555761904762","#text":"ditional random fields: Probabilistic models for segmenting and labeling sequence data. Proc. of ICML. D. J. Lehmann. 1977. Algebraic structures for transitive closure. Theoretical Computer Science, 4(1):59?76. A. McCallum, D. Freitag, and F. Pereira. 2000. Maximum entropy Markov models for information extraction and segmentation. Proc. of ICML, 591?598. M. Mohri and M.-J. Nederhof. 2001. Regular approximation of context-free grammars through transformation. In J.-C. Junqua and G. van Noord, eds., Robustness in Language and Speech Technology. Kluwer. Mehryar Mohri and Richard Sproat. 1996. An efficient compiler for weighted rewrite rules. In Proc. of ACL. M. Mohri, F. Pereira, and M. Riley. 1998. A rational design for a weighted finite-state transducer library. Lecture Notes in Computer Science, 1436. M. Mohri. 2002. Generic epsilon-removal and input epsilon-normalization algorithms for weighted transducers. Int. J. of Foundations of Comp. Sci., 1(13). Mark-Jan Nederhof. 2000. Practical experiments with regular approximation of context-free languages."},{"#tail":"\n","@confidence":"0.870727714285714","#text":"problems. Journal of the ACM, 28(3):577?593, July. Robert Endre Tarjan. 1981b. Fast algorithms for solving path problems. J. of the ACM, 28(3):594?614, July. G. van Noord and D. Gerdemann. 2001. An extendible regular expression compiler for finite-state approaches in natural language processing. In Automata Implementation, no. 22 in Springer Lecture Notes in CS."}],"title":{"#tail":"\n","@confidence":"0.999889","#text":"Parameter Estimation for Probabilistic Finite-State Transducers?"},"email":{"#tail":"\n","@confidence":"0.999883","#text":"jason@cs.jhu.edu"}}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"volume":{"#tail":"\n","#text":"3"},"#tail":"\n","date":{"#tail":"\n","#text":"1972"},"rawString":{"#tail":"\n","#text":"L. E. Baum. 1972. An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process. Inequalities, 3."},"journal":{"#tail":"\n","#text":"Inequalities,"},"#text":"\n","marker":{"#tail":"\n","#text":"Baum, 1972"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" to use operators to tweak them, to apply them to speech lattices or other sets, and to combine them with linguistic resources. Unfortunately, there is a stumbling block: Where do the weights come from? After all, statistical models require supervised or unsupervised training. Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs. Not only do these methods require additional programming outside the toolkit, but they are limited to particular kinds of models and training regimens. For example, the forward-backward algorithm (Baum, 1972) trains only Hidden Markov Models, while (Ristad and Yianilos, 1996) trains only stochastic edit distance. In short, current finite-state toolkits include no training algorithms, because none exist for the large space of statistical models that the toolkits can in principle describe and run. 1Given output, find input to maximize P (input, output). Computational Linguistics (ACL), Philadelphia, July 2002, pp. 1-8. Proceedings of the 40th Annual Meeting of the Association for (a) (b) 0/.15 a:x/.63 1/.15a: /.07? 2/.5b: /.003? b:z/.12 3/.5 b:x/.027 a: /.7? b: /.03? b:z/.12 b: /.1? b:z/.4 b: /.01? ","@endWordPosition":"564","@position":"3828","annotationId":"T1","@startWordPosition":"563","@citStr":"Baum, 1972"},{"#tail":"\n","#text":" = (?p,?v) and (p, v)?1 = (p?1,?p?1vp?1). Division is commonly used in defining f? (for normalization). 19Multiple edges from j to k are summed into a single edge. (Mohri, 2002). Efficient hardware implementation is also possible via chip-level parallelism (Rote, 1985). ? In many cases of interest, Ti is an acyclic graph.20 Then Tarjan?s method computes w0j for each j in topologically sorted order, thereby finding ti in a linear number of ? and ? operations. For HMMs (footnote 11), Ti is the familiar trellis, and we would like this computation of ti to reduce to the forwardbackward algorithm (Baum, 1972). But notice that it has no backward pass. In place of pushing cumulative probabilities backward to the arcs, it pushes cumulative arcs (more generally, values in V ) forward to the probabilities. This is slower because our ? and ? are vector operations, and the vectors rapidly lose sparsity as they are added together. We therefore reintroduce a backward pass that lets us avoid ? and ? when computing ti (so they are needed only to construct Ti). This speedup also works for cyclic graphs and for any V . Write wjk as (pjk, vjk), and let w1jk = (p1jk, v1jk) denote the weight of the edge from j to","@endWordPosition":"5524","@position":"31727","annotationId":"T2","@startWordPosition":"5523","@citStr":"Baum, 1972"}]},"title":{"#tail":"\n","#text":"An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"L E Baum"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1988"},"rawString":{"#tail":"\n","#text":"Jean Berstel and Christophe Reutenauer. 1988. Rational Series and their Languages. Springer-Verlag."},"#text":"\n","marker":{"#tail":"\n","#text":"Berstel, Reutenauer, 1988"},"publisher":{"#tail":"\n","#text":"Springer-Verlag."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ization of a joint relation as discussed below. A central technique is to define a joint relation as a noisy-channel model, by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 (Pereira and Riley, 1997; Knight and Graehl, 1998). The general form is illustrated by 3Conceptually, the parameters represent the probabilities of reading another a (?); reading another b (?); transducing b to p rather than q (?); starting to transduce p to  rather than x (?). 4To prove (1)?(3), express f as an FST and apply the well-known Kleene-Schu?tzenberger construction (Berstel and Reutenauer, 1988), taking care to write each regexp in the construction as a constant times a probabilistic regexp. A full proof is straightforward, as are proofs of (3)?(2), (2)?(1). 5In (4), the randomness is in the smaller relation?s choice of how to replace a match. One can also get randomness through the choice of matches, ignoring match possibilities by randomly deleting markers in Gerdemann and van Noord?s construction. P (v, z) def = ? w,x,y P (v|w)P (w, x)P (y|x)P (z|y), implemented by composing 4 machines.6,7 There are also procedures for defining weighted FSTs that are not probabilistic (Berstel and","@endWordPosition":"1803","@position":"11054","annotationId":"T3","@startWordPosition":"1800","@citStr":"Berstel and Reutenauer, 1988"},{"#tail":"\n","#text":"i (Fig. 2), the expected value is14 E[val(pi) | xi, yi] = ? pi?? P (pi) val(pi)? pi?? P (pi) (1) The denominator of equation (1) is the total probability of all accepting paths in xi ?f ?yi. But while computing this, we will also compute the numerator. The idea is to augment the weight data structure with expectation information, so each weight records a probability and a vector counting the parameters that contributed to that probability. We will enforce an invariant: the weight of any pathset ? must be ( ? pi?? P (pi), ? pi?? P (pi) val(pi)) ? R?0 ? V , from which (1) is trivial to compute. Berstel and Reutenauer (1988) give a sufficiently general finite-state framework to allow this: weights may fall in any set K (instead of R). Multiplication and addition are replaced by binary operations ? and ? on K. Thus ? is used to combine arc weights into a path weight and ? is used to combine the weights of alternative paths. To sum over infinite sets of cyclic paths we also need a closure operation ?, interpreted as k? = ?? i=0 k i . The usual finite-state algorithms work if (K,?,?, ?) has the structure of a closed semiring.15 Ordinary probabilities fall in the semiring (R?0,+,?, ?).16 Our novel weights fall in a n","@endWordPosition":"4362","@position":"25370","annotationId":"T4","@startWordPosition":"4359","@citStr":"Berstel and Reutenauer (1988)"}]},"title":{"#tail":"\n","#text":"Rational Series and their Languages."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Jean Berstel"},{"#tail":"\n","#text":"Christophe Reutenauer"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Technical Report CMU-CS-99-108,"},"date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"Stanley F. Chen and Ronald Rosenfeld. 1999. A Gaussian prior for smoothing maximum entropy models. Technical Report CMU-CS-99-108, Carnegie Mellon."},"#text":"\n","marker":{"#tail":"\n","#text":"Chen, Rosenfeld, 1999"},"location":{"#tail":"\n","#text":"Carnegie Mellon."},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"o fall. For example, in ordinary HMM training, xi = ?? and represents a completely hidden state sequence (cf. Ristad (1998), who allows any regular set), while yi is a single string representing a completely observed emission sequence.11 What to optimize? Maximum-likelihood estimation guesses ?? to be the ? maximizing ? i f?(xi, yi). Maximum-posterior estimation tries to maximize P (?) ? ? i f?(xi, yi) where P (?) is a prior probability. In a log-linear parameterization, for example, a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting (Chen and Rosenfeld, 1999). The EM algorithm (Dempster et al, 1977) can maximize these functions. Roughly, the E step guesses hidden information: if (xi, yi) was generated from the current f?, which FST paths stand a chance of having been the path used? (Guessing the path also guesses the exact input and output.) The M step updates ? to make those paths more likely. EM alternates these steps and converges to a local optimum. The M step?s form depends on the parameterization and the E step serves the M step?s needs. Let f? be Fig. 1a and suppose (xi, yi) = (a(a + b)?, xxz). During the E step, we restrict to paths compat","@endWordPosition":"2937","@position":"17802","annotationId":"T5","@startWordPosition":"2934","@citStr":"Chen and Rosenfeld, 1999"},{"#tail":"\n","#text":"sing 4? a:p?? 4? is in turn ?really? just evidence that the ?-coin came up heads. To learn the weights ?, ?, ?, ?, count expected heads/tails for each coin. ? If arc probabilities (or even ?, ?, ?, ?) have loglinear parameterization, then the E step must compute c = ? i ecf (xi, yi), where ec(x, y) denotes the expected vector of total feature counts along a random path in f? whose (input, output) matches (x, y). The M step then treats c as fixed, observed data and adjusts ? until the predicted vector of total feature counts equals c, using Improved Iterative Scaling (Della Pietra et al, 1997; Chen and Rosenfeld, 1999).12 For globally normalized, joint models, the predicted vector is ecf (??,??). If the log-linear probabilities are conditioned on the state and/or the input, the predicted vector is harder to describe (though usually much easier to compute).13 12IIS is itself iterative; to avoid nested loops, run only one iteration at each M step, giving a GEM algorithm (Riezler, 1999). Alternatively, discard EM and use gradient-based optimization. 13For per-state conditional normalization, let Dj,a be the set of arcs from state j with input symbol a ? ?; their weights are normalized to sum to 1. Besides comp","@endWordPosition":"3446","@position":"20533","annotationId":"T6","@startWordPosition":"3443","@citStr":"Chen and Rosenfeld, 1999"}]},"title":{"#tail":"\n","#text":"A Gaussian prior for smoothing maximum entropy models."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Stanley F Chen"},{"#tail":"\n","#text":"Ronald Rosenfeld"}]}},{"volume":{"#tail":"\n","#text":"19"},"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"S. Della Pietra, V. Della Pietra, and J. Lafferty. 1997. Inducing features of random fields. IEEE Transactions on Pattern Analysis and Machine Intelligence, 19(4)."},"journal":{"#tail":"\n","#text":"IEEE Transactions on Pattern Analysis and Machine Intelligence,"},"#text":"\n","issue":{"#tail":"\n","#text":"4"},"marker":{"#tail":"\n","#text":"Pietra, Pietra, Lafferty, 1997"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"iven earlier, traversing 4? a:p?? 4? is in turn ?really? just evidence that the ?-coin came up heads. To learn the weights ?, ?, ?, ?, count expected heads/tails for each coin. ? If arc probabilities (or even ?, ?, ?, ?) have loglinear parameterization, then the E step must compute c = ? i ecf (xi, yi), where ec(x, y) denotes the expected vector of total feature counts along a random path in f? whose (input, output) matches (x, y). The M step then treats c as fixed, observed data and adjusts ? until the predicted vector of total feature counts equals c, using Improved Iterative Scaling (Della Pietra et al, 1997; Chen and Rosenfeld, 1999).12 For globally normalized, joint models, the predicted vector is ecf (??,??). If the log-linear probabilities are conditioned on the state and/or the input, the predicted vector is harder to describe (though usually much easier to compute).13 12IIS is itself iterative; to avoid nested loops, run only one iteration at each M step, giving a GEM algorithm (Riezler, 1999). Alternatively, discard EM and use gradient-based optimization. 13For per-state conditional normalization, let Dj,a be the set of arcs from state j with input symbol a ? ?; their weights are normalize","@endWordPosition":"3442","@position":"20506","annotationId":"T7","@startWordPosition":"3439","@citStr":"Pietra et al, 1997"}},"title":{"#tail":"\n","#text":"Inducing features of random fields."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"S Della Pietra"},{"#tail":"\n","#text":"V Della Pietra"},{"#tail":"\n","#text":"J Lafferty"}]}},{"volume":{"#tail":"\n","#text":"39"},"#tail":"\n","date":{"#tail":"\n","#text":"1977"},"rawString":{"#tail":"\n","#text":"A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. J. Royal Statist. Soc. Ser. B, 39(1):1?38."},"journal":{"#tail":"\n","#text":"J. Royal Statist. Soc. Ser. B,"},"#text":"\n","issue":{"#tail":"\n","#text":"1"},"marker":{"#tail":"\n","#text":"Dempster, Laird, Rubin, 1977"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":", xi = ?? and represents a completely hidden state sequence (cf. Ristad (1998), who allows any regular set), while yi is a single string representing a completely observed emission sequence.11 What to optimize? Maximum-likelihood estimation guesses ?? to be the ? maximizing ? i f?(xi, yi). Maximum-posterior estimation tries to maximize P (?) ? ? i f?(xi, yi) where P (?) is a prior probability. In a log-linear parameterization, for example, a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting (Chen and Rosenfeld, 1999). The EM algorithm (Dempster et al, 1977) can maximize these functions. Roughly, the E step guesses hidden information: if (xi, yi) was generated from the current f?, which FST paths stand a chance of having been the path used? (Guessing the path also guesses the exact input and output.) The M step updates ? to make those paths more likely. EM alternates these steps and converges to a local optimum. The M step?s form depends on the parameterization and the E step serves the M step?s needs. Let f? be Fig. 1a and suppose (xi, yi) = (a(a + b)?, xxz). During the E step, we restrict to paths compatible with this observation by computing x","@endWordPosition":"2944","@position":"17843","annotationId":"T8","@startWordPosition":"2941","@citStr":"Dempster et al, 1977"}},"title":{"#tail":"\n","#text":"Maximum likelihood from incomplete data via the EM algorithm."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A P Dempster"},{"#tail":"\n","#text":"N M Laird"},{"#tail":"\n","#text":"D B Rubin"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"editor":{"#tail":"\n","#text":"In G. van Noord, ed.,"},"rawString":{"#tail":"\n","#text":"Jason Eisner. 2001a. Expectation semirings: Flexible EM for finite-state transducers. In G. van Noord, ed., Proc. of the ESSLLI Workshop on Finite-State Methods in Natural Language Processing. Extended abstract."},"#text":"\n","marker":{"#tail":"\n","#text":"Eisner, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"inimization of transducers). This programming paradigm supports efficient nondeterminism, including parallel processing over infinite sets of input strings, and even allows ?reverse? computation from output to input. Its unusual flexibility for the practiced programmer stems from the many operations under which rational relations are closed. It is common to define further useful operations (as macros), which modify existing relations not by editing their source code but simply by operating on them ?from outside.? ?A brief version of this work, with some additional material, first appeared as (Eisner, 2001a). A leisurely journal-length version with more details has been prepared and is available. The entire paradigm has been generalized to weighted relations, which assign a weight to each (input, output) pair rather than simply including or excluding it. If these weights represent probabilities P (input, output) or P (output | input), the weighted relation is called a joint or conditional (probabilistic) relation and constitutes a statistical model. Such models can be efficiently restricted, manipulated or combined using rational operations as before. An artificial example will appear in ?2. Th","@endWordPosition":"306","@position":"2107","annotationId":"T9","@startWordPosition":"305","@citStr":"Eisner, 2001"},{"#tail":"\n","#text":". Each feature has a strength ? R>0, and a weight is computed as the product of the strengths of its features.10 It is now the strengths that are the learnable parameters. This allows meaningful parameter tying: if certain arcs such as u:i??, o:e ??, and a:ae?? share a contextual ?vowel-fronting? feature, then their weights rise and fall together with the strength of that feature. The resulting machine must be normalized, either per-state or globally, to obtain a joint or a conditional distribution as desired. Such approaches have been tried recently in restricted cases (McCallum et al, 2000; Eisner, 2001b; Lafferty et al, 2001). Normalization may be postponed and applied instead to the result of combining the FST with other FSTs by composition, union, concatenation, etc. A simple example is a probabilistic FSA defined by normalizing the intersection of other probabilistic FSAs f1, f2, . . .. (This is in fact a log-linear model in which the component FSAs define the features: string x has log fi(x) occurrences of feature i.) In short, weighted finite-state operators provide a language for specifying a wide variety of parameterized statistical models. Let us turn to their training. 3 Estimation","@endWordPosition":"2433","@position":"14884","annotationId":"T10","@startWordPosition":"2432","@citStr":"Eisner, 2001"},{"#tail":"\n","#text":" compute).13 12IIS is itself iterative; to avoid nested loops, run only one iteration at each M step, giving a GEM algorithm (Riezler, 1999). Alternatively, discard EM and use gradient-based optimization. 13For per-state conditional normalization, let Dj,a be the set of arcs from state j with input symbol a ? ?; their weights are normalized to sum to 1. Besides computing c, the E step must count the expected number dj,a of traversals of arcs in each Dj,a. Then the predicted vector given ? is ? j,a dj,a ?(expected feature counts on a randomly chosen arc in Dj,a). Per-state joint normalization (Eisner, 2001b, ?8.2) is similar but drops the dependence on a. The difficult case is global conditional normalization. It arises, for example, when training a joint model of the form f? = ? ? ? (g? ? h?) ? ? ?, where h? is a conditional It is also possible to use this EM approach for discriminative training, where we wish to maximize ? i P (yi | xi) and f?(x, y) is a conditional FST that defines P (y | x). The trick is to instead train a joint model g ? f?, where g(xi) defines P (xi), thereby maximizing ? i P (xi) ? P (yi | xi). (Of course, the method of this paper can train such compositions.) If x1, . .","@endWordPosition":"3585","@position":"21377","annotationId":"T11","@startWordPosition":"3584","@citStr":"Eisner, 2001"}]},"title":{"#tail":"\n","#text":"Expectation semirings: Flexible EM for finite-state transducers."},"booktitle":{"#tail":"\n","#text":"Proc. of the ESSLLI Workshop on Finite-State Methods in Natural Language Processing. Extended abstract."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Jason Eisner"}}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Ph.D. thesis,"},"date":{"#tail":"\n","#text":"2001"},"institution":{"#tail":"\n","#text":"University of Pennsylvania."},"rawString":{"#tail":"\n","#text":"Jason Eisner. 2001b. Smoothing a Probabilistic Lexicon via Syntactic Transformations. Ph.D. thesis, University of Pennsylvania."},"#text":"\n","marker":{"#tail":"\n","#text":"Eisner, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"inimization of transducers). This programming paradigm supports efficient nondeterminism, including parallel processing over infinite sets of input strings, and even allows ?reverse? computation from output to input. Its unusual flexibility for the practiced programmer stems from the many operations under which rational relations are closed. It is common to define further useful operations (as macros), which modify existing relations not by editing their source code but simply by operating on them ?from outside.? ?A brief version of this work, with some additional material, first appeared as (Eisner, 2001a). A leisurely journal-length version with more details has been prepared and is available. The entire paradigm has been generalized to weighted relations, which assign a weight to each (input, output) pair rather than simply including or excluding it. If these weights represent probabilities P (input, output) or P (output | input), the weighted relation is called a joint or conditional (probabilistic) relation and constitutes a statistical model. Such models can be efficiently restricted, manipulated or combined using rational operations as before. An artificial example will appear in ?2. Th","@endWordPosition":"306","@position":"2107","annotationId":"T12","@startWordPosition":"305","@citStr":"Eisner, 2001"},{"#tail":"\n","#text":". Each feature has a strength ? R>0, and a weight is computed as the product of the strengths of its features.10 It is now the strengths that are the learnable parameters. This allows meaningful parameter tying: if certain arcs such as u:i??, o:e ??, and a:ae?? share a contextual ?vowel-fronting? feature, then their weights rise and fall together with the strength of that feature. The resulting machine must be normalized, either per-state or globally, to obtain a joint or a conditional distribution as desired. Such approaches have been tried recently in restricted cases (McCallum et al, 2000; Eisner, 2001b; Lafferty et al, 2001). Normalization may be postponed and applied instead to the result of combining the FST with other FSTs by composition, union, concatenation, etc. A simple example is a probabilistic FSA defined by normalizing the intersection of other probabilistic FSAs f1, f2, . . .. (This is in fact a log-linear model in which the component FSAs define the features: string x has log fi(x) occurrences of feature i.) In short, weighted finite-state operators provide a language for specifying a wide variety of parameterized statistical models. Let us turn to their training. 3 Estimation","@endWordPosition":"2433","@position":"14884","annotationId":"T13","@startWordPosition":"2432","@citStr":"Eisner, 2001"},{"#tail":"\n","#text":" compute).13 12IIS is itself iterative; to avoid nested loops, run only one iteration at each M step, giving a GEM algorithm (Riezler, 1999). Alternatively, discard EM and use gradient-based optimization. 13For per-state conditional normalization, let Dj,a be the set of arcs from state j with input symbol a ? ?; their weights are normalized to sum to 1. Besides computing c, the E step must count the expected number dj,a of traversals of arcs in each Dj,a. Then the predicted vector given ? is ? j,a dj,a ?(expected feature counts on a randomly chosen arc in Dj,a). Per-state joint normalization (Eisner, 2001b, ?8.2) is similar but drops the dependence on a. The difficult case is global conditional normalization. It arises, for example, when training a joint model of the form f? = ? ? ? (g? ? h?) ? ? ?, where h? is a conditional It is also possible to use this EM approach for discriminative training, where we wish to maximize ? i P (yi | xi) and f?(x, y) is a conditional FST that defines P (y | x). The trick is to instead train a joint model g ? f?, where g(xi) defines P (xi), thereby maximizing ? i P (xi) ? P (yi | xi). (Of course, the method of this paper can train such compositions.) If x1, . .","@endWordPosition":"3585","@position":"21377","annotationId":"T14","@startWordPosition":"3584","@citStr":"Eisner, 2001"}]},"title":{"#tail":"\n","#text":"Smoothing a Probabilistic Lexicon via Syntactic Transformations."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Jason Eisner"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1999"},"rawString":{"#tail":"\n","#text":"D. Gerdemann and G. van Noord. 1999. Transducers from rewrite rules with backreferences. Proc. of EACL."},"#text":"\n","marker":{"#tail":"\n","#text":"Gerdemann, van Noord, 1999"},"title":{"#tail":"\n","#text":"Transducers from rewrite rules with backreferences."},"booktitle":{"#tail":"\n","#text":"Proc. of EACL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"D Gerdemann"},{"#tail":"\n","#text":"G van Noord"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"Anne Greenbaum. 1997. Iterative Methods for Solving Linear Systems. Soc. for Industrial and Applied Math."},"journal":{"#tail":"\n","#text":"Soc. for Industrial and Applied Math."},"#text":"\n","marker":{"#tail":"\n","#text":"Greenbaum, 1997"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"rd pass that lets us avoid ? and ? when computing ti (so they are needed only to construct Ti). This speedup also works for cyclic graphs and for any V . Write wjk as (pjk, vjk), and let w1jk = (p1jk, v1jk) denote the weight of the edge from j to k.19 Then it can be shown that w0n = (p0n, ? j,k p0jv 1 jkpkn). The forward and backward probabilities, p0j and pkn, can be computed using single-source algebraic path for the simpler semiring (R,+,?, ?)?or equivalently, by solving a sparse linear system of equations over R, a much-studied problem at O(n) space, O(nm) time, and faster approximations (Greenbaum, 1997). ? A Viterbi variant of the expectation semiring exists: replace (3) with if(p1 > p2, (p1, v1), (p2, v2)). Here, the forward and backward probabilities can be computed in time only O(m + n log n) (Fredman and Tarjan, 1987). k-best variants are also possible. 6 Discussion We have exhibited a training algorithm for parameterized finite-state machines. Some specific consequences that we believe to be novel are (1) an EM algorithm for FSTs with cycles and epsilons; (2) training algorithms for HMMs and weighted contextual edit distance that work on incomplete data; (3) endto-end training of noisy ","@endWordPosition":"5698","@position":"32697","annotationId":"T15","@startWordPosition":"5697","@citStr":"Greenbaum, 1997"}},"title":{"#tail":"\n","#text":"Iterative Methods for Solving Linear Systems."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Anne Greenbaum"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Kevin Knight and Yaser Al-Onaizan. 1998. Translation with finite-state devices. In Proc. of AMTA."},"#text":"\n","marker":{"#tail":"\n","#text":"Knight, Al-Onaizan, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"istic) relation and constitutes a statistical model. Such models can be efficiently restricted, manipulated or combined using rational operations as before. An artificial example will appear in ?2. The availability of toolkits for this weighted case (Mohri et al, 1998; van Noord and Gerdemann, 2001) promises to unify much of statistical NLP. Such tools make it easy to run most current approaches to statistical markup, chunking, normalization, segmentation, alignment, and noisy-channel decoding,1 including classic models for speech recognition (Pereira and Riley, 1997) and machine translation (Knight and Al-Onaizan, 1998). Moreover, once the models are expressed in the finitestate framework, it is easy to use operators to tweak them, to apply them to speech lattices or other sets, and to combine them with linguistic resources. Unfortunately, there is a stumbling block: Where do the weights come from? After all, statistical models require supervised or unsupervised training. Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs. Not only do these methods require additional programming outside the toolkit, but they are limited to particular ki","@endWordPosition":"458","@position":"3135","annotationId":"T16","@startWordPosition":"455","@citStr":"Knight and Al-Onaizan, 1998"}},"title":{"#tail":"\n","#text":"Translation with finite-state devices."},"booktitle":{"#tail":"\n","#text":"In Proc. of AMTA."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kevin Knight"},{"#tail":"\n","#text":"Yaser Al-Onaizan"}]}},{"volume":{"#tail":"\n","#text":"24"},"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"Kevin Knight and Jonathan Graehl. 1998. Machine transliteration. Computational Linguistics, 24(4)."},"#text":"\n","issue":{"#tail":"\n","#text":"4"},"marker":{"#tail":"\n","#text":"Knight, Graehl, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"veral other ways: (1) via FSTs as in Fig. 1c, (2) by compilation of weighted rewrite rules (Mohri and Sproat, 1996), (3) by compilation of decision trees (Sproat and Riley, 1996), (4) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation (Gerdemann and van Noord, 1999),5 (5) by conditionalization of a joint relation as discussed below. A central technique is to define a joint relation as a noisy-channel model, by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 (Pereira and Riley, 1997; Knight and Graehl, 1998). The general form is illustrated by 3Conceptually, the parameters represent the probabilities of reading another a (?); reading another b (?); transducing b to p rather than q (?); starting to transduce p to  rather than x (?). 4To prove (1)?(3), express f as an FST and apply the well-known Kleene-Schu?tzenberger construction (Berstel and Reutenauer, 1988), taking care to write each regexp in the construction as a constant times a probabilistic regexp. A full proof is straightforward, as are proofs of (3)?(2), (2)?(1). 5In (4), the randomness is in the smaller relation?s choice of how to rep","@endWordPosition":"1746","@position":"10694","annotationId":"T17","@startWordPosition":"1743","@citStr":"Knight and Graehl, 1998"}},"booktitle":{"#tail":"\n","#text":"Machine transliteration. Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Kevin Knight"},{"#tail":"\n","#text":"Jonathan Graehl"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. Proc. of ICML."},"#text":"\n","marker":{"#tail":"\n","#text":"Lafferty, McCallum, Pereira, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"approximate joint or conditional synchronous PCFGs built for translation. These are parameterized by the PCFG?s parameters, but add or remove strings of the PCFG to leave an improper probability distribution. Fortunately for those techniques, an FST with positive arc weights can be normalized to make it jointly or conditionally probabilistic: ? An easy approach is to normalize the options at each state to make the FST Markovian. Unfortunately, the result may differ for equivalent FSTs that express the same weighted relation. Undesirable consequences of this fact have been termed ?label bias? (Lafferty et al, 2001). Also, in the conditional case such per-state normalization is only correct if all states accept all input suffixes (since ?dead ends? leak probability mass).8 ? A better-founded approach is global normalization, which simply divides each f(x, y) by ? x?,y? f(x ?, y?) (joint case) or by?y? f(x, y?) (conditional case). To implement the joint case, just divide stopping weights by the total weight of all paths (which ?4 shows how to find), provided this is finite. In the conditional case, let g be a copy of f with the output labels removed, so that g(x) finds the desired divisor; determinize g i","@endWordPosition":"2046","@position":"12565","annotationId":"T18","@startWordPosition":"2043","@citStr":"Lafferty et al, 2001"},{"#tail":"\n","#text":"has a strength ? R>0, and a weight is computed as the product of the strengths of its features.10 It is now the strengths that are the learnable parameters. This allows meaningful parameter tying: if certain arcs such as u:i??, o:e ??, and a:ae?? share a contextual ?vowel-fronting? feature, then their weights rise and fall together with the strength of that feature. The resulting machine must be normalized, either per-state or globally, to obtain a joint or a conditional distribution as desired. Such approaches have been tried recently in restricted cases (McCallum et al, 2000; Eisner, 2001b; Lafferty et al, 2001). Normalization may be postponed and applied instead to the result of combining the FST with other FSTs by composition, union, concatenation, etc. A simple example is a probabilistic FSA defined by normalizing the intersection of other probabilistic FSAs f1, f2, . . .. (This is in fact a log-linear model in which the component FSAs define the features: string x has log fi(x) occurrences of feature i.) In short, weighted finite-state operators provide a language for specifying a wide variety of parameterized statistical models. Let us turn to their training. 3 Estimation in Parameterized FSTs W","@endWordPosition":"2437","@position":"14908","annotationId":"T19","@startWordPosition":"2434","@citStr":"Lafferty et al, 2001"},{"#tail":"\n","#text":"t is not necessary to have separate training data for each machine in the cascade (cf. Knight and Graehl, 20If xi and yi are acyclic (e.g., fully observed strings), and f (or rather its FST) has no  :  cycles, then composition will ?unroll? f into an acyclic machine. If only xi is acyclic, then the composition is still acyclic if domain(f) has no  cycles. 1998), although such data could also be used; (4) training of branching noisy channels (footnote 7); (5) discriminative training with incomplete data; (6) training of conditional MEMMs (McCallum et al, 2000) and conditional random fields (Lafferty et al, 2001) on unbounded sequences. We are particularly interested in the potential for quickly building statistical models that incorporate linguistic and engineering insights. Many models of interest can be constructed in our paradigm, without having to write new code. Bringing diverse models into the same declarative framework also allows one to apply new optimization methods, objective functions, and finite-state algorithms to all of them. To avoid local maxima, one might try deterministic annealing (Rao and Rose, 2001), or randomized methods, or place a prior on ?. Another extension is to adjust the","@endWordPosition":"5911","@position":"33945","annotationId":"T20","@startWordPosition":"5908","@citStr":"Lafferty et al, 2001"}]},"title":{"#tail":"\n","#text":"Conditional random fields: Probabilistic models for segmenting and labeling sequence data."},"booktitle":{"#tail":"\n","#text":"Proc. of ICML."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"J Lafferty"},{"#tail":"\n","#text":"A McCallum"},{"#tail":"\n","#text":"F Pereira"}]}},{"volume":{"#tail":"\n","#text":"4"},"#tail":"\n","date":{"#tail":"\n","#text":"1977"},"rawString":{"#tail":"\n","#text":"D. J. Lehmann. 1977. Algebraic structures for transitive closure. Theoretical Computer Science, 4(1):59?76."},"journal":{"#tail":"\n","#text":"Theoretical Computer Science,"},"#text":"\n","issue":{"#tail":"\n","#text":"1"},"marker":{"#tail":"\n","#text":"Lehmann, 1977"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"probabilistic. Whatever procedures are used to evaluate f?(xi, yi) exactly or approximately?for example, FST operations to compile f? followed by minimization of (?xi) ? f? ? (yi? )?can simply be applied over the expectation semiring, replacing each weight p by (p,?p) and replacing the usual arithmetic operations with ?, ?, etc.18 (2)?(4) preserve the gradient ((2) is the derivative product rule), so this computation yields (f?(xi, yi),?f?(xi, yi)). 5 Removing Inefficiencies Now for some important remarks on efficiency: ? Computing ti is an instance of the well-known algebraic path problem (Lehmann, 1977; Tarjan, 1981a). Let Ti = xi?f?yi. Then ti is the total semiring weight w0n of paths in Ti from initial state 0 to final state n (assumed WLOG to be unique and unweighted). It is wasteful to compute ti as suggested earlier, by minimizing (?xi)?f?(yi?), since then the real work is done by an -closure step (Mohri, 2002) that implements the all-pairs version of algebraic path, whereas all we need is the single-source version. If n and m are the number of states and edges,19 then both problems are O(n3) in the worst case, but the single-source version can be solved in essentially O(m) time for","@endWordPosition":"5214","@position":"29874","annotationId":"T21","@startWordPosition":"5213","@citStr":"Lehmann, 1977"}},"title":{"#tail":"\n","#text":"Algebraic structures for transitive closure."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"D J Lehmann"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"A. McCallum, D. Freitag, and F. Pereira. 2000. Maximum entropy Markov models for information extraction and segmentation. Proc. of ICML, 591?598."},"#text":"\n","pages":{"#tail":"\n","#text":"591--598"},"marker":{"#tail":"\n","#text":"McCallum, Freitag, Pereira, 2000"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"th that arc, coin, etc. Each feature has a strength ? R>0, and a weight is computed as the product of the strengths of its features.10 It is now the strengths that are the learnable parameters. This allows meaningful parameter tying: if certain arcs such as u:i??, o:e ??, and a:ae?? share a contextual ?vowel-fronting? feature, then their weights rise and fall together with the strength of that feature. The resulting machine must be normalized, either per-state or globally, to obtain a joint or a conditional distribution as desired. Such approaches have been tried recently in restricted cases (McCallum et al, 2000; Eisner, 2001b; Lafferty et al, 2001). Normalization may be postponed and applied instead to the result of combining the FST with other FSTs by composition, union, concatenation, etc. A simple example is a probabilistic FSA defined by normalizing the intersection of other probabilistic FSAs f1, f2, . . .. (This is in fact a log-linear model in which the component FSAs define the features: string x has log fi(x) occurrences of feature i.) In short, weighted finite-state operators provide a language for specifying a wide variety of parameterized statistical models. Let us turn to their training","@endWordPosition":"2431","@position":"14870","annotationId":"T22","@startWordPosition":"2428","@citStr":"McCallum et al, 2000"},{"#tail":"\n","#text":"dto-end training of noisy channel cascades, so that it is not necessary to have separate training data for each machine in the cascade (cf. Knight and Graehl, 20If xi and yi are acyclic (e.g., fully observed strings), and f (or rather its FST) has no  :  cycles, then composition will ?unroll? f into an acyclic machine. If only xi is acyclic, then the composition is still acyclic if domain(f) has no  cycles. 1998), although such data could also be used; (4) training of branching noisy channels (footnote 7); (5) discriminative training with incomplete data; (6) training of conditional MEMMs (McCallum et al, 2000) and conditional random fields (Lafferty et al, 2001) on unbounded sequences. We are particularly interested in the potential for quickly building statistical models that incorporate linguistic and engineering insights. Many models of interest can be constructed in our paradigm, without having to write new code. Bringing diverse models into the same declarative framework also allows one to apply new optimization methods, objective functions, and finite-state algorithms to all of them. To avoid local maxima, one might try deterministic annealing (Rao and Rose, 2001), or randomized methods, or p","@endWordPosition":"5903","@position":"33892","annotationId":"T23","@startWordPosition":"5900","@citStr":"McCallum et al, 2000"}]},"title":{"#tail":"\n","#text":"Maximum entropy Markov models for information extraction and segmentation."},"booktitle":{"#tail":"\n","#text":"Proc. of ICML,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A McCallum"},{"#tail":"\n","#text":"D Freitag"},{"#tail":"\n","#text":"F Pereira"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"editor":{"#tail":"\n","#text":"In J.-C. Junqua and G. van Noord, eds.,"},"rawString":{"#tail":"\n","#text":"M. Mohri and M.-J. Nederhof. 2001. Regular approximation of context-free grammars through transformation. In J.-C. Junqua and G. van Noord, eds., Robustness in Language and Speech Technology. Kluwer."},"#text":"\n","marker":{"#tail":"\n","#text":"Mohri, Nederhof, 2001"},"publisher":{"#tail":"\n","#text":"Speech Technology. Kluwer."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"hoice of how to replace a match. One can also get randomness through the choice of matches, ignoring match possibilities by randomly deleting markers in Gerdemann and van Noord?s construction. P (v, z) def = ? w,x,y P (v|w)P (w, x)P (y|x)P (z|y), implemented by composing 4 machines.6,7 There are also procedures for defining weighted FSTs that are not probabilistic (Berstel and Reutenauer, 1988). Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into :/2.7?? arcs). A more subtle example is weighted FSAs that approximate PCFGs (Nederhof, 2000; Mohri and Nederhof, 2001), or to extend the idea, weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation. These are parameterized by the PCFG?s parameters, but add or remove strings of the PCFG to leave an improper probability distribution. Fortunately for those techniques, an FST with positive arc weights can be normalized to make it jointly or conditionally probabilistic: ? An easy approach is to normalize the options at each state to make the FST Markovian. Unfortunately, the result may differ for equivalent FSTs that express the same weighted relation. Undesirable consequences ","@endWordPosition":"1942","@position":"11900","annotationId":"T24","@startWordPosition":"1939","@citStr":"Mohri and Nederhof, 2001"}},"title":{"#tail":"\n","#text":"Regular approximation of context-free grammars through transformation."},"booktitle":{"#tail":"\n","#text":"Robustness in Language and"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"M Mohri"},{"#tail":"\n","#text":"M-J Nederhof"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"Mehryar Mohri and Richard Sproat. 1996. An efficient compiler for weighted rewrite rules. In Proc. of ACL."},"#text":"\n","marker":{"#tail":"\n","#text":"Mohri, Sproat, 1996"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"t) is a weighted regular relation, then the following statements are equivalent: (1) f is a joint probabilistic relation; (2) f can be computed by a Markovian FST that halts with probability 1; (3) f can be expressed as a probabilistic regexp, i.e., a regexp built up from atomic expressions a : b (for a ? ?? {}, b ? ?? {}) using concatenation, probabilistic union +p, and probabilistic closure ?p. For defining conditional relations, a good regexp language is unknown to us, but they can be defined in several other ways: (1) via FSTs as in Fig. 1c, (2) by compilation of weighted rewrite rules (Mohri and Sproat, 1996), (3) by compilation of decision trees (Sproat and Riley, 1996), (4) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation (Gerdemann and van Noord, 1999),5 (5) by conditionalization of a joint relation as discussed below. A central technique is to define a joint relation as a noisy-channel model, by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 (Pereira and Riley, 1997; Knight and Graehl, 1998). The general form is illustrated by 3Conceptually, the parameters represent the probabilit","@endWordPosition":"1662","@position":"10185","annotationId":"T25","@startWordPosition":"1659","@citStr":"Mohri and Sproat, 1996"}},"title":{"#tail":"\n","#text":"An efficient compiler for weighted rewrite rules."},"booktitle":{"#tail":"\n","#text":"In Proc. of ACL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Mehryar Mohri"},{"#tail":"\n","#text":"Richard Sproat"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"rawString":{"#tail":"\n","#text":"M. Mohri, F. Pereira, and M. Riley. 1998. A rational design for a weighted finite-state transducer library. Lecture Notes in Computer Science, 1436."},"journal":{"#tail":"\n","#text":"Lecture Notes in Computer Science,"},"#text":"\n","pages":{"#tail":"\n","#text":"1436"},"marker":{"#tail":"\n","#text":"Mohri, Pereira, Riley, 1998"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"tails has been prepared and is available. The entire paradigm has been generalized to weighted relations, which assign a weight to each (input, output) pair rather than simply including or excluding it. If these weights represent probabilities P (input, output) or P (output | input), the weighted relation is called a joint or conditional (probabilistic) relation and constitutes a statistical model. Such models can be efficiently restricted, manipulated or combined using rational operations as before. An artificial example will appear in ?2. The availability of toolkits for this weighted case (Mohri et al, 1998; van Noord and Gerdemann, 2001) promises to unify much of statistical NLP. Such tools make it easy to run most current approaches to statistical markup, chunking, normalization, segmentation, alignment, and noisy-channel decoding,1 including classic models for speech recognition (Pereira and Riley, 1997) and machine translation (Knight and Al-Onaizan, 1998). Moreover, once the models are expressed in the finitestate framework, it is easy to use operators to tweak them, to apply them to speech lattices or other sets, and to combine them with linguistic resources. Unfortunately, there is a stum","@endWordPosition":"407","@position":"2775","annotationId":"T26","@startWordPosition":"404","@citStr":"Mohri et al, 1998"},{"#tail":"\n","#text":"nsidered is known to fall. In the extreme, if each input string is fully observed (not the case if the input is bound by composition to the output of a one-to-many FST), one can succeed by restricting g to each input string in turn; this amounts to manually dividing f(x, y) by g(x). 10Traditionally log(strength) values are called weights, but this paper uses ?weight? to mean something else. 8 9a:x/.63 10a:x/.63 11b:x/.027 a: /.7? b: /.0051? 12/.5b:z/.1284b: /.1? b:z/.404 b: /.1? Figure 2: The joint model of Fig. 1a constrained to generate only input ? a(a + b)? and output = xxz. f? on demand (Mohri et al, 1998) can pay off here, since only part of f? may be needed subsequently.) As training data we are given a set of observed (input, output) pairs, (xi, yi). These are assumed to be independent random samples from a joint distribution of the form f??(x, y); the goal is to recover the true ??. Samples need not be fully observed (partly supervised training): thus xi ? ??, yi ? ?? may be given as regular sets in which input and output were observed to fall. For example, in ordinary HMM training, xi = ?? and represents a completely hidden state sequence (cf. Ristad (1998), who allows any regular set), wh","@endWordPosition":"2749","@position":"16733","annotationId":"T27","@startWordPosition":"2746","@citStr":"Mohri et al, 1998"}]},"title":{"#tail":"\n","#text":"A rational design for a weighted finite-state transducer library."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"M Mohri"},{"#tail":"\n","#text":"F Pereira"},{"#tail":"\n","#text":"M Riley"}]}},{"volume":{"#tail":"\n","#text":"1"},"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"M. Mohri. 2002. Generic epsilon-removal and input epsilon-normalization algorithms for weighted transducers. Int. J. of Foundations of Comp. Sci., 1(13)."},"journal":{"#tail":"\n","#text":"Int. J. of Foundations of Comp. Sci.,"},"#text":"\n","issue":{"#tail":"\n","#text":"13"},"marker":{"#tail":"\n","#text":"Mohri, 2002"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" ?, etc.18 (2)?(4) preserve the gradient ((2) is the derivative product rule), so this computation yields (f?(xi, yi),?f?(xi, yi)). 5 Removing Inefficiencies Now for some important remarks on efficiency: ? Computing ti is an instance of the well-known algebraic path problem (Lehmann, 1977; Tarjan, 1981a). Let Ti = xi?f?yi. Then ti is the total semiring weight w0n of paths in Ti from initial state 0 to final state n (assumed WLOG to be unique and unweighted). It is wasteful to compute ti as suggested earlier, by minimizing (?xi)?f?(yi?), since then the real work is done by an -closure step (Mohri, 2002) that implements the all-pairs version of algebraic path, whereas all we need is the single-source version. If n and m are the number of states and edges,19 then both problems are O(n3) in the worst case, but the single-source version can be solved in essentially O(m) time for acyclic graphs and other reducible flow graphs (Tarjan, 1981b). For a general graph Ti, Tarjan (1981b) shows how to partition into ?hard? subgraphs that localize the cyclicity or irreducibility, then run the O(n3) algorithm on each subgraph (thereby reducing n to as little as 1), and recombine the results. The overhead o","@endWordPosition":"5274","@position":"30197","annotationId":"T28","@startWordPosition":"5273","@citStr":"Mohri, 2002"}},"title":{"#tail":"\n","#text":"Generic epsilon-removal and input epsilon-normalization algorithms for weighted transducers."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"M Mohri"}}},{"volume":{"#tail":"\n","#text":"26"},"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Mark-Jan Nederhof. 2000. Practical experiments with regular approximation of context-free languages. Computational Linguistics, 26(1)."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"1"},"marker":{"#tail":"\n","#text":"Nederhof, 2000"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ler relation?s choice of how to replace a match. One can also get randomness through the choice of matches, ignoring match possibilities by randomly deleting markers in Gerdemann and van Noord?s construction. P (v, z) def = ? w,x,y P (v|w)P (w, x)P (y|x)P (z|y), implemented by composing 4 machines.6,7 There are also procedures for defining weighted FSTs that are not probabilistic (Berstel and Reutenauer, 1988). Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into :/2.7?? arcs). A more subtle example is weighted FSAs that approximate PCFGs (Nederhof, 2000; Mohri and Nederhof, 2001), or to extend the idea, weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation. These are parameterized by the PCFG?s parameters, but add or remove strings of the PCFG to leave an improper probability distribution. Fortunately for those techniques, an FST with positive arc weights can be normalized to make it jointly or conditionally probabilistic: ? An easy approach is to normalize the options at each state to make the FST Markovian. Unfortunately, the result may differ for equivalent FSTs that express the same weighted relation","@endWordPosition":"1938","@position":"11873","annotationId":"T29","@startWordPosition":"1937","@citStr":"Nederhof, 2000"}},"title":{"#tail":"\n","#text":"Practical experiments with regular approximation of context-free languages."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Mark-Jan Nederhof"}}},{"date":{"#tail":"\n","#text":"1997"},"editor":{"#tail":"\n","#text":"In E. Roche and Y. Schabes, eds.,"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"elation is called a joint or conditional (probabilistic) relation and constitutes a statistical model. Such models can be efficiently restricted, manipulated or combined using rational operations as before. An artificial example will appear in ?2. The availability of toolkits for this weighted case (Mohri et al, 1998; van Noord and Gerdemann, 2001) promises to unify much of statistical NLP. Such tools make it easy to run most current approaches to statistical markup, chunking, normalization, segmentation, alignment, and noisy-channel decoding,1 including classic models for speech recognition (Pereira and Riley, 1997) and machine translation (Knight and Al-Onaizan, 1998). Moreover, once the models are expressed in the finitestate framework, it is easy to use operators to tweak them, to apply them to speech lattices or other sets, and to combine them with linguistic resources. Unfortunately, there is a stumbling block: Where do the weights come from? After all, statistical models require supervised or unsupervised training. Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs. Not only do these methods require additional programming outs","@endWordPosition":"451","@position":"3081","annotationId":"T30","@startWordPosition":"448","@citStr":"Pereira and Riley, 1997"},{"#tail":"\n","#text":"they can be defined in several other ways: (1) via FSTs as in Fig. 1c, (2) by compilation of weighted rewrite rules (Mohri and Sproat, 1996), (3) by compilation of decision trees (Sproat and Riley, 1996), (4) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation (Gerdemann and van Noord, 1999),5 (5) by conditionalization of a joint relation as discussed below. A central technique is to define a joint relation as a noisy-channel model, by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 (Pereira and Riley, 1997; Knight and Graehl, 1998). The general form is illustrated by 3Conceptually, the parameters represent the probabilities of reading another a (?); reading another b (?); transducing b to p rather than q (?); starting to transduce p to  rather than x (?). 4To prove (1)?(3), express f as an FST and apply the well-known Kleene-Schu?tzenberger construction (Berstel and Reutenauer, 1988), taking care to write each regexp in the construction as a constant times a probabilistic regexp. A full proof is straightforward, as are proofs of (3)?(2), (2)?(1). 5In (4), the randomness is in the smaller relat","@endWordPosition":"1742","@position":"10668","annotationId":"T31","@startWordPosition":"1739","@citStr":"Pereira and Riley, 1997"}]},"title":{"#tail":"\n","#text":"Speech recognition by composition of weighted finite automata."},"#tail":"\n","rawString":{"#tail":"\n","#text":"Fernando C. N. Pereira and Michael Riley. 1997. Speech recognition by composition of weighted finite automata. In E. Roche and Y. Schabes, eds., Finite-State Language Processing. MIT Press, Cambridge, MA."},"#text":"\n","marker":{"#tail":"\n","#text":"Pereira, Riley, 1997"},"publisher":{"#tail":"\n","#text":"MIT Press,"},"location":{"#tail":"\n","#text":"Cambridge, MA."},"booktitle":{"#tail":"\n","#text":"Finite-State Language Processing."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Fernando C N Pereira"},{"#tail":"\n","#text":"Michael Riley"}]}},{"volume":{"#tail":"\n","#text":"9"},"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"A. Rao and K. Rose. 2001 Deterministically annealed design of hidden Markov movel speech recognizers. In IEEE Trans. on Speech and Audio Processing, 9(2)."},"#text":"\n","issue":{"#tail":"\n","#text":"2"},"marker":{"#tail":"\n","#text":"Rao, Rose, 2001"},"title":{"#tail":"\n","#text":"Deterministically annealed design of hidden Markov movel speech recognizers."},"booktitle":{"#tail":"\n","#text":"In IEEE Trans. on Speech and Audio Processing,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A Rao"},{"#tail":"\n","#text":"K Rose"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Ph.D. thesis,"},"date":{"#tail":"\n","#text":"1999"},"institution":{"#tail":"\n","#text":"Universita?t Tu?bingen."},"rawString":{"#tail":"\n","#text":"Stefan Riezler. 1999. Probabilistic Constraint Logic Programming. Ph.D. thesis, Universita?t Tu?bingen."},"#text":"\n","marker":{"#tail":"\n","#text":"Riezler, 1999"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" (input, output) matches (x, y). The M step then treats c as fixed, observed data and adjusts ? until the predicted vector of total feature counts equals c, using Improved Iterative Scaling (Della Pietra et al, 1997; Chen and Rosenfeld, 1999).12 For globally normalized, joint models, the predicted vector is ecf (??,??). If the log-linear probabilities are conditioned on the state and/or the input, the predicted vector is harder to describe (though usually much easier to compute).13 12IIS is itself iterative; to avoid nested loops, run only one iteration at each M step, giving a GEM algorithm (Riezler, 1999). Alternatively, discard EM and use gradient-based optimization. 13For per-state conditional normalization, let Dj,a be the set of arcs from state j with input symbol a ? ?; their weights are normalized to sum to 1. Besides computing c, the E step must count the expected number dj,a of traversals of arcs in each Dj,a. Then the predicted vector given ? is ? j,a dj,a ?(expected feature counts on a randomly chosen arc in Dj,a). Per-state joint normalization (Eisner, 2001b, ?8.2) is similar but drops the dependence on a. The difficult case is global conditional normalization. It arises, for exampl","@endWordPosition":"3506","@position":"20905","annotationId":"T32","@startWordPosition":"3505","@citStr":"Riezler, 1999"}},"title":{"#tail":"\n","#text":"Probabilistic Constraint Logic Programming."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Stefan Riezler"}}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Tech. Report CS-TR-532-96,"},"date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"E. Ristad and P. Yianilos. 1996. Learning string edit distance. Tech. Report CS-TR-532-96, Princeton."},"#text":"\n","marker":{"#tail":"\n","#text":"Ristad, Yianilos, 1996"},"location":{"#tail":"\n","#text":"Princeton."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ech lattices or other sets, and to combine them with linguistic resources. Unfortunately, there is a stumbling block: Where do the weights come from? After all, statistical models require supervised or unsupervised training. Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs. Not only do these methods require additional programming outside the toolkit, but they are limited to particular kinds of models and training regimens. For example, the forward-backward algorithm (Baum, 1972) trains only Hidden Markov Models, while (Ristad and Yianilos, 1996) trains only stochastic edit distance. In short, current finite-state toolkits include no training algorithms, because none exist for the large space of statistical models that the toolkits can in principle describe and run. 1Given output, find input to maximize P (input, output). Computational Linguistics (ACL), Philadelphia, July 2002, pp. 1-8. Proceedings of the 40th Annual Meeting of the Association for (a) (b) 0/.15 a:x/.63 1/.15a: /.07? 2/.5b: /.003? b:z/.12 3/.5 b:x/.027 a: /.7? b: /.03? b:z/.12 b: /.1? b:z/.4 b: /.01? b:z/.4b:x/.09 4/.15 a:p/.7 5/.5b:p/.03b:q/.12 b:p/.1b:q/.4 (c) 6/1 p","@endWordPosition":"574","@position":"3896","annotationId":"T33","@startWordPosition":"571","@citStr":"Ristad and Yianilos, 1996"}},"title":{"#tail":"\n","#text":"Learning string edit distance."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"E Ristad"},{"#tail":"\n","#text":"P Yianilos"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1998"},"editor":{"#tail":"\n","#text":"A. Kornai, ed.,"},"rawString":{"#tail":"\n","#text":"E. Ristad. 1998. Hidden Markov models with finite state supervision. In A. Kornai, ed., Extended Finite State Models of Language. Cambridge University Press."},"#text":"\n","marker":{"#tail":"\n","#text":"Ristad, 1998"},"publisher":{"#tail":"\n","#text":"Cambridge University Press."},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"output = xxz. f? on demand (Mohri et al, 1998) can pay off here, since only part of f? may be needed subsequently.) As training data we are given a set of observed (input, output) pairs, (xi, yi). These are assumed to be independent random samples from a joint distribution of the form f??(x, y); the goal is to recover the true ??. Samples need not be fully observed (partly supervised training): thus xi ? ??, yi ? ?? may be given as regular sets in which input and output were observed to fall. For example, in ordinary HMM training, xi = ?? and represents a completely hidden state sequence (cf. Ristad (1998), who allows any regular set), while yi is a single string representing a completely observed emission sequence.11 What to optimize? Maximum-likelihood estimation guesses ?? to be the ? maximizing ? i f?(xi, yi). Maximum-posterior estimation tries to maximize P (?) ? ? i f?(xi, yi) where P (?) is a prior probability. In a log-linear parameterization, for example, a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting (Chen and Rosenfeld, 1999). The EM algorithm (Dempster et al, 1977) can maximize these functions. Roughly, the E step guesse","@endWordPosition":"2854","@position":"17300","annotationId":"T34","@startWordPosition":"2853","@citStr":"Ristad (1998)"}},"title":{"#tail":"\n","#text":"Hidden Markov models with finite state supervision. In"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"E Ristad"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"editor":{"#tail":"\n","#text":"Emmanuel Roche and Yves Schabes, editors."},"rawString":{"#tail":"\n","#text":"Emmanuel Roche and Yves Schabes, editors. 1997. Finite-State Language Processing. MIT Press."},"#text":"\n","marker":{"#tail":"\n","#text":"1997"},"publisher":{"#tail":"\n","#text":"MIT Press."},"title":{"#tail":"\n","#text":"Finite-State Language Processing."},"@valid":"true"},{"volume":{"#tail":"\n","#text":"34"},"#tail":"\n","date":{"#tail":"\n","#text":"1985"},"rawString":{"#tail":"\n","#text":"Gu?nter Rote. 1985. A systolic array algorithm for the algebraic path problem (shortest paths; matrix inversion). Computing, 34(3):191?219."},"journal":{"#tail":"\n","#text":"Computing,"},"#text":"\n","issue":{"#tail":"\n","#text":"3"},"marker":{"#tail":"\n","#text":"Rote, 1985"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"results. The overhead of partitioning and recombining is essentially only O(m). ? For speeding up theO(n3) problem on subgraphs, one can use an approximate relaxation technique 17Eisner (submitted) develops fast minimization algorithms that work for the real and V -expectation semirings. 18Division and subtraction are also possible: ?(p, v) = (?p,?v) and (p, v)?1 = (p?1,?p?1vp?1). Division is commonly used in defining f? (for normalization). 19Multiple edges from j to k are summed into a single edge. (Mohri, 2002). Efficient hardware implementation is also possible via chip-level parallelism (Rote, 1985). ? In many cases of interest, Ti is an acyclic graph.20 Then Tarjan?s method computes w0j for each j in topologically sorted order, thereby finding ti in a linear number of ? and ? operations. For HMMs (footnote 11), Ti is the familiar trellis, and we would like this computation of ti to reduce to the forwardbackward algorithm (Baum, 1972). But notice that it has no backward pass. In place of pushing cumulative probabilities backward to the arcs, it pushes cumulative arcs (more generally, values in V ) forward to the probabilities. This is slower because our ? and ? are vector operations, and","@endWordPosition":"5463","@position":"31385","annotationId":"T35","@startWordPosition":"5462","@citStr":"Rote, 1985"}},"title":{"#tail":"\n","#text":"A systolic array algorithm for the algebraic path problem (shortest paths; matrix inversion)."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Gunter Rote"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"1996"},"rawString":{"#tail":"\n","#text":"Richard Sproat and Michael Riley. 1996. Compilation of weighted finite-state transducers from decision trees. In Proceedings of the 34th Annual Meeting of the ACL."},"#text":"\n","marker":{"#tail":"\n","#text":"Sproat, Riley, 1996"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"s are equivalent: (1) f is a joint probabilistic relation; (2) f can be computed by a Markovian FST that halts with probability 1; (3) f can be expressed as a probabilistic regexp, i.e., a regexp built up from atomic expressions a : b (for a ? ?? {}, b ? ?? {}) using concatenation, probabilistic union +p, and probabilistic closure ?p. For defining conditional relations, a good regexp language is unknown to us, but they can be defined in several other ways: (1) via FSTs as in Fig. 1c, (2) by compilation of weighted rewrite rules (Mohri and Sproat, 1996), (3) by compilation of decision trees (Sproat and Riley, 1996), (4) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation (Gerdemann and van Noord, 1999),5 (5) by conditionalization of a joint relation as discussed below. A central technique is to define a joint relation as a noisy-channel model, by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 (Pereira and Riley, 1997; Knight and Graehl, 1998). The general form is illustrated by 3Conceptually, the parameters represent the probabilities of reading another a (?); reading another b (?); transducin","@endWordPosition":"1672","@position":"10248","annotationId":"T36","@startWordPosition":"1669","@citStr":"Sproat and Riley, 1996"}},"title":{"#tail":"\n","#text":"Compilation of weighted finite-state transducers from decision trees."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the 34th Annual Meeting of the ACL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Richard Sproat"},{"#tail":"\n","#text":"Michael Riley"}]}},{"#tail":"\n","tech":{"#tail":"\n","#text":"Tech. Report ICSI TR-94-003,"},"date":{"#tail":"\n","#text":"1994"},"rawString":{"#tail":"\n","#text":"Andreas Stolcke and Stephen M. Omohundro. 1994. Best-first model merging for hidden Markov model induction. Tech. Report ICSI TR-94-003, Berkeley, CA."},"#text":"\n","marker":{"#tail":"\n","#text":"Stolcke, Omohundro, 1994"},"location":{"#tail":"\n","#text":"Berkeley, CA."},"title":{"#tail":"\n","#text":"Best-first model merging for hidden Markov model induction."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Andreas Stolcke"},{"#tail":"\n","#text":"Stephen M Omohundro"}]}},{"volume":{"#tail":"\n","#text":"28"},"#tail":"\n","date":{"#tail":"\n","#text":"1981"},"rawString":{"#tail":"\n","#text":"Robert Endre Tarjan. 1981a. A unified approach to path problems. Journal of the ACM, 28(3):577?593, July."},"journal":{"#tail":"\n","#text":"Journal of the ACM,"},"#text":"\n","issue":{"#tail":"\n","#text":"3"},"marker":{"#tail":"\n","#text":"Tarjan, 1981"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"Whatever procedures are used to evaluate f?(xi, yi) exactly or approximately?for example, FST operations to compile f? followed by minimization of (?xi) ? f? ? (yi? )?can simply be applied over the expectation semiring, replacing each weight p by (p,?p) and replacing the usual arithmetic operations with ?, ?, etc.18 (2)?(4) preserve the gradient ((2) is the derivative product rule), so this computation yields (f?(xi, yi),?f?(xi, yi)). 5 Removing Inefficiencies Now for some important remarks on efficiency: ? Computing ti is an instance of the well-known algebraic path problem (Lehmann, 1977; Tarjan, 1981a). Let Ti = xi?f?yi. Then ti is the total semiring weight w0n of paths in Ti from initial state 0 to final state n (assumed WLOG to be unique and unweighted). It is wasteful to compute ti as suggested earlier, by minimizing (?xi)?f?(yi?), since then the real work is done by an -closure step (Mohri, 2002) that implements the all-pairs version of algebraic path, whereas all we need is the single-source version. If n and m are the number of states and edges,19 then both problems are O(n3) in the worst case, but the single-source version can be solved in essentially O(m) time for acyclic graph","@endWordPosition":"5216","@position":"29888","annotationId":"T37","@startWordPosition":"5215","@citStr":"Tarjan, 1981"}},"title":{"#tail":"\n","#text":"A unified approach to path problems."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Robert Endre Tarjan"}}},{"volume":{"#tail":"\n","#text":"28"},"#tail":"\n","date":{"#tail":"\n","#text":"1981"},"rawString":{"#tail":"\n","#text":"Robert Endre Tarjan. 1981b. Fast algorithms for solving path problems. J. of the ACM, 28(3):594?614, July."},"journal":{"#tail":"\n","#text":"J. of the ACM,"},"#text":"\n","issue":{"#tail":"\n","#text":"3"},"marker":{"#tail":"\n","#text":"Tarjan, 1981"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"Whatever procedures are used to evaluate f?(xi, yi) exactly or approximately?for example, FST operations to compile f? followed by minimization of (?xi) ? f? ? (yi? )?can simply be applied over the expectation semiring, replacing each weight p by (p,?p) and replacing the usual arithmetic operations with ?, ?, etc.18 (2)?(4) preserve the gradient ((2) is the derivative product rule), so this computation yields (f?(xi, yi),?f?(xi, yi)). 5 Removing Inefficiencies Now for some important remarks on efficiency: ? Computing ti is an instance of the well-known algebraic path problem (Lehmann, 1977; Tarjan, 1981a). Let Ti = xi?f?yi. Then ti is the total semiring weight w0n of paths in Ti from initial state 0 to final state n (assumed WLOG to be unique and unweighted). It is wasteful to compute ti as suggested earlier, by minimizing (?xi)?f?(yi?), since then the real work is done by an -closure step (Mohri, 2002) that implements the all-pairs version of algebraic path, whereas all we need is the single-source version. If n and m are the number of states and edges,19 then both problems are O(n3) in the worst case, but the single-source version can be solved in essentially O(m) time for acyclic graph","@endWordPosition":"5216","@position":"29888","annotationId":"T38","@startWordPosition":"5215","@citStr":"Tarjan, 1981"}},"title":{"#tail":"\n","#text":"Fast algorithms for solving path problems."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Robert Endre Tarjan"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"G. van Noord and D. Gerdemann. 2001. An extendible regular expression compiler for finite-state approaches in natural language processing. In Automata Implementation, no. 22 in Springer Lecture Notes in CS."},"#text":"\n","marker":{"#tail":"\n","#text":"van Noord, Gerdemann, 2001"},"title":{"#tail":"\n","#text":"An extendible regular expression compiler for finite-state approaches in natural language processing."},"booktitle":{"#tail":"\n","#text":"In Automata Implementation, no. 22 in Springer Lecture Notes in CS."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"G van Noord"},{"#tail":"\n","#text":"D Gerdemann"}]}}]}}]}}
