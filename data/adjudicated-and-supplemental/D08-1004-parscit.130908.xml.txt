on Eisner Dept. of Computer Science, Johns Hopkins University Baltimore, MD 21218, USA {ozaidan,jason}@cs.jhu.edu Abstract A human annotator can provide hints to a machine learner by highlighting contextual “rationales” for each of his or her annotations (Zaidan et al., 2007). How can one exploit this side information to better learn the desired parameters 0? We present a generative model of how a given annotator, knowing the true 0, stochastically chooses rationales. Thus, observing the rationales helps us infer the true 0. We collect substring rationales for a sentiment classification task (Pang and Lee, 2004) and use them to obtain significant accuracy improvements for each annotator. Our new generative approach exploits the rationales more effectively than our previous “masking SVM” approach. It is also more principled, and could be adapted to help learn other kinds of probabilistic classifiers for quite different tasks. 1 Background Many recent papers aim to reduce the amount of annotated data needed to train the parameters of a statistical model. Well-known paradigms include active learning, semi-supervised learning, and either domain adaptation or cross-lingual transfer from existing annotated
cribes (e.g.) how to derive a binomial parameter nonlinearly from Oh. This approach would not how often h was marked and infer how relevant is feature h (i.e., infer Bh). In this case, po is a simple channel that transforms relevant features into direct indicators of the feature. Our side information merely requires a more complex transformation—from relevant features into wellformed rationales, modulated by documents. 4 Experimental Data: Movie Reviews In Zaidan et al. (2007), we introduced the “Movie Review Polarity Dataset Enriched with Annotator Rationales.”8 It is based on the dataset of Pang and Lee (2004),9 which consists of 1000 positive and 1000 negative movie reviews, tokenized and divided into 10 folds (F0–F9). All our experiments use F9 as their final blind test set. The enriched dataset adds rationale annotations produced by an annotator A0, who annotated folds F0–F8 of the movie review set with rationales (in the form of textual substrings) that supported the goldstandard classifications. We will use A0’s data to determine the improvement of our method over a (log-linear) baseline model without rationales. We also use A0 to compare against the “masking SVM” method and SVM baseline of Za
 and xM are special boundary symbols, tagged with O. We predict the full tag sequence r~at once using a conditional random field (Lafferty et al., 2001). A CRF is just another conditional log-linear model: u(r, x, y, ~θ) pφ(r|x,y, def exp ~θ) = def � ~θ) ~θ) Zφ(x, y, def pθ(y |x) def = exp(~θ · ~f(x, y)) = u(x, y) Zθ(x) (2) Zθ(x) ~φ · ~g(r,x,y, ~θ)) Zφ(x, y, where ~f(·) extracts a feature vector from a classified ~ document, θ are the corresponding weights of those features, and Zθ(x) def � Ey u(x, y) is a normalizer. We use the same set of binary features as in previous work on this dataset (Pang et al., 2002; Pang and Lee, 2004; Zaidan et al., 2007). Specifically, let V = {v1, ..., v177441 be the set of word types with count > 4 in the full 2000-document corpus. Define fh(x, y) to be y if vh appears at least once in x, and 0 otherwise. Thus θ E 817744, and positive weights in θ favor class label y = +1 and equally discourage y = -1, while negative weights do the opposite. This standard unigram feature set is linguistically impoverished, but serves as a good starting point for studying rationales. Future work should consider more complex features and how they are signaled by rationales, as discuss
 boundary symbols, tagged with O. We predict the full tag sequence r~at once using a conditional random field (Lafferty et al., 2001). A CRF is just another conditional log-linear model: u(r, x, y, ~θ) pφ(r|x,y, def exp ~θ) = def � ~θ) ~θ) Zφ(x, y, def pθ(y |x) def = exp(~θ · ~f(x, y)) = u(x, y) Zθ(x) (2) Zθ(x) ~φ · ~g(r,x,y, ~θ)) Zφ(x, y, where ~f(·) extracts a feature vector from a classified ~ document, θ are the corresponding weights of those features, and Zθ(x) def � Ey u(x, y) is a normalizer. We use the same set of binary features as in previous work on this dataset (Pang et al., 2002; Pang and Lee, 2004; Zaidan et al., 2007). Specifically, let V = {v1, ..., v177441 be the set of word types with count > 4 in the full 2000-document corpus. Define fh(x, y) to be y if vh appears at least once in x, and 0 otherwise. Thus θ E 817744, and positive weights in θ favor class label y = +1 and equally discourage y = -1, while negative weights do the opposite. This standard unigram feature set is linguistically impoverished, but serves as a good starting point for studying rationales. Future work should consider more complex features and how they are signaled by rationales, as discussed in section 3.2. 5
OP, S, SBAR, FRAG, PRN, NP, VP, PP, ADJP, QP). 6 Training: Joint Optimization of 0 and 0 To train our model, we use L-BFGS to locally maximize the log of the objective function (1):15 13These are the function words with count > 40 in a random sample of 100 documents, and which were associated with the O-I tag transition at more than twice the average rate. We do not use any other lexical 0-features that reference x, for fear that they would enable the learner to explain the rationales without changing 0 as desired (see the end of section 5.3). 14We parse each sentence with the Collins parser (Collins, 1999). Then the document has one big parse tree, whose root is DOC, with each sentence being a child of DOC. 15One might expect this function to be convex because pe and po are both log-linear models with no hidden variables. However, log po(ri |xi, yi, 0) is not necessarily convex in 0. log pθ(yi |xi) 212kθk2 θ log pφ(ri |xi, yi, θ)) − 212kφk2 (4) φ This defines ppoor from (1) to be a standard diagonal Gaussian prior, with variances σ2θ and σ2φ for the two sets of parameters. We optimize σ2 θ in our experiments. As for σ2φ, different values did not affect the results, since we have a large number 
