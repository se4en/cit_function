{"algorithms":{"#text":"\n","@version":"110505","algorithm":[{"#tail":"\n","@name":"SectLabel","#text":"\n","@version":"110505","variant":{"@no":"0","listItem":{"#tail":"\n","@confidence":"0.826774333333333","#text":"\nlist of trees. For our experiments we focus on two\ndependency parsers.\n? Transition-based: An implementation of the\n"},"author":{"#tail":"\n","@confidence":"0.803381","#text":"\nKeith Hall Ryan McDonald Jason Katz-Brown Michael Ringgaard\n"},"equation":[{"#tail":"\n","@confidence":"0.926919","#text":"\nrepeat\nfor i = 1 . . . N do\n{Compute structured loss}\ny?i = F?(xi)\nif L(y?i, yi) > 0 then\n{Update model Parameters}\n? = ? + ?(yi)? ?(y?i)\nend if\nend for\n"},{"#tail":"\n","@confidence":"0.8369811","#text":"\nAlgorithm 2 Augmented-Loss Perceptron\n{Input data sets}:\nD1 = {d11 = (x11, y11) . . . d1N1 = (x1N1 , y1N1)},\n. . .\nDM = {dM1 = (xM1 , yM1 ) . . . dMNM = (xMNM , yMNM )}\n{Input loss functions: L1 . . . LM}\n{Initialize indexes: c1 . . . cM = ~0}\n{Initialize model parameters: ? = ~0}\ni = 0\nrepeat\n"},{"#tail":"\n","@confidence":"0.991176111111111","#text":"\ny? = F?(xjcj )\nif Lj(y?, yjcj ) > 0 then\n? = ? + ?(yjcj )? ?(y?) {yjcj is a tree}end if\nelse if Lj is an extrinsic loss then\n{See Section 2.2}?\nend if\nend if\nend for\ni = i+ 1\n"},{"#tail":"\n","@confidence":"0.736928875","#text":"\nat line ?.\nAlgorithm 3 Reranker Loss\n{y?1, . . . , y?k} = Fk-best? (xi)\n? = min? C(xjcj , y?? , yjcj ) {? is min const index}\nLj(y?1, yjcj ) = C(xjcj , y?1, yjcj )? C(xjcj , y?? , yjcj )\nif Lj(y?1, yjcj ) > 0 then\n? = ? + ?(y?? )? ?(y?1)\nend if\n"},{"#tail":"\n","@confidence":"0.490026666666667","#text":"\nL(y?, y) = 0 (or equivalent minimal loss).\nProof. It must be the case for all (x, y) ? D that\nL(y?1, y) = 0 (and y?1 is the argmax) after a finite\n"},{"#tail":"\n","@confidence":"0.729754","#text":"\nreorder-score = 1? # chunks? 1# unigrams matched? 1\nreorder-cost = 1? reorder-score\n"},{"#tail":"\n","@confidence":"0.94237225","#text":"\nALS =\n?\ni ?(??i, ?i)(i? ?i)?\ni(i? ?i)\n"}],"subsectionHeader":[{"#tail":"\n","@confidence":"0.993195","#text":"\n2.1 Augmented-Loss Training\n"},{"#tail":"\n","@confidence":"0.985331","#text":"\n2.2 Inline Ranker Training\n"},{"#tail":"\n","@confidence":"0.998554","#text":"\n2.3 Convergence of Inline Ranker Training\n"},{"#tail":"\n","@confidence":"0.991457","#text":"\n3.1 Dependency Parsers\n"},{"#tail":"\n","@confidence":"0.993202","#text":"\n3.2 Data and Tasks\n"},{"#tail":"\n","@confidence":"0.90687","#text":"\n4.1 Machine Translation Reordering Score\n"},{"#tail":"\n","@confidence":"0.994949","#text":"\n4.2 Semi-supervised domain adaptation\n"},{"#tail":"\n","@confidence":"0.999605","#text":"\n4.3 Average Arc Length Score\n"}],"footnote":[{"#tail":"\n","@confidence":"0.7324","#text":"\n1Our rules are similar to those from Xu et al (2009).\n"},{"#tail":"\n","@confidence":"0.633639666666667","#text":"\n2For the graph-based parser one can also find the higest scor-\ning tree with correct root by setting the score of all competing\narcs to ??.\n"}],"construct":[{"#tail":"\n","@confidence":"0.9083755","#text":"\nL(y??, y), then u??(y?)?u??(y??) ? ?. Furthermore,\nlet R ? ||?(y)? ?(y?)||, for all y, y?.\nAssumption 1. Assume training set D is loss-\nseparable with margin ?.\nTheorem 1. Given Assumption 1. Letm be the num-\nber of mistakes made when training the perceptron\n(Algorithm 2) with inline ranker loss (Algorithm 3)\non D, where a mistake occurs for (x, y) ? D with\n"},{"#tail":"\n","@confidence":"0.961574833333333","#text":"\nAssumption 2. For any parameter vector ? that ex-\nists during training, either 1) for all (x, y) ? D,\nL(y?1, y) = 0 (or some optimal minimum loss),\nor 2) there exists at least one (x, y) ? D where\n?y?j ? F k-best? (x) such that L(y?j , y) < L(y?1, y).\nAssumption 2 states that for any ? that exists\n"},{"#tail":"\n","@confidence":"0.835754928571429","#text":"\nisolated features: wi, ti, w?(i), t?(i)\nword-tag pairs: (wi, ti); (w?(i), t?(i))\nword-head pairs: (wi, w?(i)), (ti, t?(i))\nword-head-tag triples: (t?(i), wi, ti)\n(w?(i), wi, ti)\n(w?(i), t?(i), ti)\n(w?(i), t?(i), wi)\ntag-neighbourhood: (t?(i), t?(i)+1, ti?1, ti)\n(t?(i), t?(i)+1, ti+1, ti)\n(t?(i), t?(i)?1, ti?1, ti)\n(t?(i), t?(i)?1, ti+1, ti)\nbetween features: ?j i < j < ?(i)  ||?(i) < j < i\n(t?(i), tj , ti)\narc-direction/length : (i? ?(i) > 0, |i? ?(i)|)\n"}],"@confidence":"0.000000","reference":{"#tail":"\n","@confidence":"0.995680158878505","#text":"\nS. Banerjee and A. Lavie. 2005. METEOR: An auto-\nmatic metric for MT evaluation with improved corre-\nlation with human judgments. In Proceedings of the\nACL Workshop on Intrinsic and Extrinsic Evaluation\nMeasures for Machine Translation and/or Summariza-\ntion.\nJ. Berant, I. Dagan, and J. Goldberger. 2010. Global\nlearning of focused entailment graphs. In Proc. of\nACL.\nJ. Blitzer, R. McDonald, and F. Pereira. 2006. Domain\nadaptation with structural correspondence learning. In\nProc. of EMNLP.\nS. Buchholz and E. Marsi. 2006. CoNLL-X shared\ntask on multilingual dependency parsing. In Proc. of\nCoNLL.\nD. Burkett, J. Blitzer, and D. Klein. 2010. Joint parsing\nand alignment with weakly synchronized grammars.\nIn Proc. of NAACL.\nR. Caruana. 1997. Multitask learning. Machine Learn-\ning, 28(1):41?75.\nM.W. Chang, L. Ratinov, and D. Roth. 2007. Guiding\nsemi-supervision with constraint-driven learning. In\nProc. of ACL.\nM. Chang, D. Goldwasser, D. Roth, and V. Srikumar.\n2010. Structured output learning with indirect super-\nvision. In Proc. of ICML.\nM. Collins, P. Koehn, and I. Kuc?erova?. 2005. Clause re-\nstructuring for statistical machine translation. In Proc.\nof ACL.\nMichael Collins. 2000. Discriminative reranking for nat-\nural language parsing. In Proc. of ICML.\nM. Collins. 2002. Discriminative training methods for\nhidden markov models: Theory and experiments with\nperceptron algorithms. In Proc. of ACL.\nM.C. de Marneffe, B. MacCartney, and C. Manning.\n2006. Generating typed dependency parses from\nphrase structure parses. In Proc. of LREC, Genoa,\nItaly.\nJ.R. Finkel and C.D. Manning. 2009. Joint parsing and\nnamed entity recognition. In Proc. of NAACL.\nK. Ganchev, J. Grac?a, J. Gillenwater, and B. Taskar.\n2010. Posterior regularization for structured latent\nvariable models. Journal of Machine Learning Re-\nsearch.\nD. Gildea. 2001. Corpus variation and parser perfor-\nmance. In Proc. of EMNLP.\nK. Hall. 2007. k-best spanning tree parsing. In Proc. of\nACL, June.\nJ. Judge, A. Cahill, and J. Van Genabith. 2006. Question-\nbank: Creating a corpus of parse-annotated questions.\nIn Proc. of ACL, pages 497?504.\nJ. Katz-Brown, S. Petrov, R. McDonald, D. Talbot,\nF. Och, H. Ichikawa, M. Seno, and H. Kazawa. 2011.\nTraining a parser for machine translation reordering.\nIn Proc. of EMNLP.\nS. Ku?bler, R. McDonald, and J. Nivre. 2009. Depen-\ndency parsing. Synthesis Lectures on Human Lan-\nguage Technologies. Morgan & Claypool Publishers.\nP. Liang, A. Bouchard-Ct, D. Klein, and B. Taskar. 2006.\nAn end-to-end discriminative approach to machine\ntranslation. In Proc. of COLING/ACL.\nG.S. Mann and A. McCallum. 2010. Generalized Ex-\npectation Criteria for Semi-Supervised Learning with\nWeakly Labeled Data. The Journal of Machine Learn-\ning Research, 11:955?984.\nM. Marcus, B. Santorini, and M.A. Marcinkiewicz.\n1993. Building a large annotated corpus of en-\nglish: The penn treebank. Computational Linguistics,\n19:313?330.\nD. McClosky, E. Charniak, and M. Johnson. 2006.\nReranking and self-training for parser adaptation. In\nProc. of ACL.\nR. McDonald and J. Nivre. 2007. Characterizing the\nerrors of data-driven dependency parsing models. In\nProc. of EMNLP-CoNLL.\n1498\nR. McDonald, K. Crammer, and F. Pereira. 2005. Online\nlarge-margin training of dependency parsers. In Proc.\nof ACL.\nT. Nakagawa, K. Inui, and S. Kurohashi. 2010. De-\npendency tree-based sentiment classification using crfs\nwith hidden variables. In Proc. of NAACL.\nJ. Nivre. 2008. Algorithms for deterministic incremen-\ntal dependency parsing. Computational Linguistics,\n34(4):513?553.\nS. Petrov, P.C. Chang, M. Ringgaard, and H. Alshawi.\n2010. Uptraining for accurate deterministic question\nparsing. In Proc. of EMNLP, pages 705?713.\nD. Talbot, H. Kazawa, H. Ichikawa, J. Katz-Brown,\nM. Seno, and F. Och. 2011. A lightweight evalu-\nation framework for machine translation reordering.\nIn Proc. of the Sixth Workshop on Statistical Machine\nTranslation.\nM. Wang, N.A. Smith, and T. Mitamura. 2007. What is\nthe Jeopardy model? A quasi-synchronous grammar\nfor QA. In Proc. of EMNLP-CoNLL.\nP. Xu, J. Kang, M. Ringgaard, and F. Och. 2009. Us-\ning a dependency parser to improve SMT for Subject-\nObject-Verb languages. In Proc. of NAACL.\nA. Yates and O. Etzioni. 2009. Unsupervised meth-\nods for determining object and relation synonyms on\nthe web. Journal of Artificial Intelligence Research,\n34(1):255?296.\nY. Zhang and S. Clark. 2008. A Tale of Two\nParsers: Investigating and Combining Graph-based\nand Transition-based Dependency Parsing. In Proc.\nof EMNLP, pages 562?571.\n"},"#tail":"\n","bodyText":[{"#tail":"\n","@confidence":"0.322180333333333","#text":"\nProceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1489?1499,\nEdinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational Linguistics\nTraining dependency parsers by jointly optimizing multiple objectives\n"},{"#tail":"\n","@confidence":"0.999750571428571","#text":"\nWe present an online learning algorithm for\ntraining parsers which allows for the inclusion\nof multiple objective functions. The primary\nexample is the extension of a standard su-\npervised parsing objective function with addi-\ntional loss-functions, either based on intrinsic\nparsing quality or task-specific extrinsic mea-\nsures of quality. Our empirical results show\nhow this approach performs for two depen-\ndency parsing algorithms (graph-based and\ntransition-based parsing) and how it achieves\nincreased performance on multiple target tasks\nincluding reordering for machine translation\nand parser adaptation.\n"},{"#tail":"\n","@confidence":"0.999707803921568","#text":"\nThe accuracy and speed of state-of-the-art depen-\ndency parsers has motivated a resumed interest in\nutilizing the output of parsing as an input to many\ndownstream natural language processing tasks. This\nincludes work on question answering (Wang et al,\n2007), sentiment analysis (Nakagawa et al, 2010),\nMT reordering (Xu et al, 2009), and many other\ntasks. In most cases, the accuracy of parsers de-\ngrades when run on out-of-domain data (Gildea,\n2001; McClosky et al, 2006; Blitzer et al, 2006;\nPetrov et al, 2010). But these accuracies are mea-\nsured with respect to gold-standard out-of-domain\nparse trees. There are few tasks that actually depend\non the complete parse tree. Furthermore, when eval-\nuated on a downstream task, often the optimal parse\noutput has a model score lower than the best parse\nas predicted by the parsing model. While this means\nthat we are not properly modeling the downstream\ntask in the parsers, it also means that there is some\ninformation from small task or domain-specific data\nsets which could help direct our search for optimal\nparameters during parser training. The goal being\nnot necessarily to obtain better parse performance,\nbut to exploit the structure induced from human la-\nbeled treebank data while targeting specific extrinsic\nmetrics of quality, which can include task specific\nmetrics or external weak constraints on the parse\nstructure.\nOne obvious approach to this problem is to em-\nploy parser reranking (Collins, 2000). In such a\nsetting, an auxiliary reranker is added in a pipeline\nfollowing the parser. The standard setting involves\ntraining the base parser and applying it to a devel-\nopment set (this is often done in a cross-validated\njack-knife training framework). The reranker can\nthen be trained to optimize for the downstream or\nextrinsic objective. While this will bias the reranker\ntowards the target task, it is limited by the oracle\nperformance of the original base parser.\nIn this paper, we propose a training algorithm for\nstatistical dependency parsers (Ku?bler et al, 2009)\nin which a single model is jointly optimized for a\nregular supervised training objective over the tree-\nbank data as well as a task-specific objective ? or\nmore generally an extrinsic objective ? on an ad-\nditional data set. The case where there are both\ngold-standard trees and a task-specific objective for\nthe entire training set is a specific instance of the\nlarger problem that we address here. Specifically,\nthe algorithm takes the form of an online learner\nwhere a training instance is selected and the param-\n"},{"#tail":"\n","@confidence":"0.99896535","#text":"\neters are optimized based on the objective function\nassociated with the instance (either intrinsic or ex-\ntrinsic), thus jointly optimizing multiple objectives.\nAn update schedule trades-off the relative impor-\ntance of each objective function. We call our algo-\nrithm augmented-loss training as it optimizes mul-\ntiple losses to augment the traditional supervised\nparser loss.\nThere have been a number of efforts to exploit\nweak or external signals of quality to train better pre-\ndiction models. This includes work on generalized\nexpectation (Mann and McCallum, 2010), posterior\nregularization (Ganchev et al, 2010) and constraint\ndriven learning (Chang et al, 2007; Chang et al,\n2010). The work of Chang et al (2007) on constraint\ndriven learning is perhaps the closest to our frame-\nwork and we draw connections to it in Section 5.\nIn these studies the typical goal is to use the weak\nsignal to improve the structured prediction models\non the intrinsic evaluation metrics. For our setting\nthis would mean using weak application specific sig-\nnals to improve dependency parsing. Though we\nexplore such ideas in our experiments, in particular\nfor semi-supervised domain adaptation, we are pri-\nmarily interested in the case where the weak signal\nis precisely what we wish to optimize, but also de-\nsire the benefit from using both data with annotated\nparse structures and data specific to the task at hand\nto guide parser training.\nIn Section 2 we outline the augmented-loss algo-\nrithm and provide a convergence analysis. In Sec-\ntion 3 and 4 we present a set of experiments defin-\ning diffent augmented losses covering a task-specific\nextrinsic loss (MT reordering), a domain adapta-\ntion loss, and an alternate intrinsic parser loss. In\nall cases we show the augmented-loss framework\ncan lead to significant gains in performance. In\nSection 5 we tie our augmented-loss algorithm to\nother frameworks for encoding auxiliary informa-\ntion and/or joint objective optimization.\n"},{"#tail":"\n","@confidence":"0.841814","#text":"\nWe present the augmented-loss algorithm in the con-\ntext of the structured perceptron. The structured\nperceptron (Algorithm 1) is an on-line learning al-\ngorithm which takes as input: 1) a set of training\nexamples di = (xi, yi) consisting of an input sen-\nAlgorithm 1 Structured Perceptron\n{Input data sets: D = {d1 = (x1, y1) . . . dN = (xN , yN )}}\n{Input 0/1 loss: L(F?(x), y) = [F?(x) 6= y ? 1 : 0]}\n{Let: F?(x) = arg maxy?Y ? ? ?(y)}\n{Initialize model parameters: ? = ~0}\n"},{"#tail":"\n","@confidence":"0.954200071428571","#text":"\nuntil converged\n{Return model ?}\ntence xi and an output yi; and 2) a loss-function,\nL(y?, y), that measures the cost of predicting out-\nput y? relative to the gold standard y and is usu-\nally the 0/1 loss (Collins, 2002). For dependency\nparser training, this set-up consists of input sen-\ntences x and the corresponding gold dependency\ntree y ? Yx, where Yx is the space of possible\nparse trees for sentence x. In the perceptron setting,\nF?(x) = arg maxy?Yx ? ??(y) where ? is mappingfrom a parse tree y for sentence x to a high dimen-\nsional feature space. Learning proceeds by predict-\ning a structured output given the current model, and\nif that structure is incorrect, updating the model: re-\nwarding features that fire in the gold-standard ?(yi),\nand discounting features that fire in the predicted\noutput, ?(y?i).\nThe structured perceptron, as given in Algo-\nrithm 1, only updates when there is a positive loss,\nmeaning that there was a prediction mistake. For\nthe moment we will abstract away from details such\nas the precise definition of F (x) and ?(y). We\nwill show in the next section that our augmented-\nloss method is general and can be applied to any de-\npendency parsing framework that can be trained by\nthe perceptron algorithm, such as transition-based\nparsers (Nivre, 2008; Zhang and Clark, 2008) and\ngraph-based parsers (McDonald et al, 2005).\n"},{"#tail":"\n","@confidence":"0.994594333333333","#text":"\nThe augmented-loss training algorithm that we pro-\npose is based on the structured perceptron; however,\nthe augmented-loss training framework is a general\n"},{"#tail":"\n","@confidence":"0.998179535714286","#text":"\nmechanism to incorporate multiple loss functions in\nonline learner training. Algorithm 2 is the pseudo-\ncode for the augmented-loss structured perceptron\nalgorithm. The algorithm is an extension to Algo-\nrithm 1 where there are 1) multiple loss functions\nbeing evaluated L1, . . . , LM ; 2) there are multiple\ndatasets associated with each of these loss functions\nD1, . . . ,DM ; and 3) there is a schedule for pro-\ncessing examples from each of these datasets, where\nSched(j, i) is true if the jth loss function should be\nupdated on the ith iteration of training. Note that\nfor data point dji = (x, y), which is the ith training\ninstance of the jth data set, that y does not neces-\nsarily have to be a dependency tree. It can either\nbe a task-specific output of interest, a partial tree, or\neven null, in the case where learning will be guided\nstrictly by the loss Lj . The training algorithm is ef-\nfectively the same as the perceptron, the primary dif-\nference is that if Lj is an extrinsic loss, we cannot\ncompute the standard updates since we do not nec-\nessarily know the correct parse (the line indicated by\n?). Section 2.2 shows one method for updating the\nparser parameters for extrinsic losses.\nIn the experiments in this paper, we only consider\nthe case where there are two loss functions: a super-\nvised dependency parsing labeled-attachment loss;\nand an additional loss, examples of which are pre-\nsented in Section 3.\n"},{"#tail":"\n","@confidence":"0.999240888888889","#text":"\nIn order to make Algorithm 2 more concrete, we\nneed a way of defining the loss and resulting pa-\nrameter updates for the case when Lj is not a stan-\ndard supervised parsing loss (? from Algorithm 2).\nAssume that we have a cost function C(xi, y?, yi)\nwhich, given a training example (xi, yi) will give a\nscore for a parse y? ? Yxi relative to some output\nyi. While we can compute the score for any parse,\nwe are unable to determine the features associated\nwith the optimal parse, as yi need not be a parse\ntree. For example, consider a machine translation re-\nordering system which uses the parse y? to reorder the\nwords of xi, the optimal reordering being yi. Then\nC(xi, y?, yi) is a reordering cost which is large if the\npredicted parse induces a poor reordering of xi.\nWe propose a general purpose loss function which\nis based on parser k-best lists. The inline reranker\nuses the currently trained parser model ? to parse\n"},{"#tail":"\n","@confidence":"0.959545","#text":"\nfor j = 1 . . .M do\n{Check whether to update Lj on iteration i}\nif Sched(j, i) then\n{Compute index of instance ? reset if cj ? N j}\ncj = [(cj ? N j) ? 0 : cj + 1]\n{Compute structured loss for instance}\nif Lj is intrinsic loss then\n"},{"#tail":"\n","@confidence":"0.894342090909091","#text":"\nuntil converged\n{Return model ?}\nthe external input, producing a k-best set of parses:\nFk-best? (xi) = {y?1, . . . , y?k}. We can compute the\ncost function C(xi, y?, yi) for all y? ? Fk-best? (xi). If\nthe 1-best parse, y?1, has the lowest cost, then there is\nno lower cost parse in this k-best list. Otherwise, the\nlowest-cost parse in Fk-best? (xi) is taken to be the\ncorrect output structure yi, and the 1-best parse is\ntaken to be an incorrect prediction. We can achieve\nthis by substituting the following into Algorithm 2\n"},{"#tail":"\n","@confidence":"0.972251","#text":"\nAgain the algorithm only updates when there is\nan error ? when the 1-best output has a higher cost\nthan any other output in the k-best list ? resulting\n"},{"#tail":"\n","@confidence":"0.999594142857143","#text":"\nin positive Lj . The intuition behind this method is\nthat in the presence of only a cost function and a\nk-best list, the parameters will be updated towards\nthe parse structure that has the lowest cost, which\nover time will move the parameters of the model to\na place with low extrinsic loss.\nWe exploit this formulation of the general-\npurpose augmented-loss function as it allows one to\ninclude any extrinsic cost function which is depen-\ndent of parses. The scoring function used does not\nneed to be factored, requiring no internal knowledge\nof the function itself. Furthermore, we can apply this\nto any parsing algorithm which can generate k-best\nlists. For each parse, we must retain the features\nassociated with the parse (e.g., for transition-based\nparsing, the features associated with the transition\nsequence resulting in the parse).\nThere are two significant differences from the in-\nline reranker loss function and standard reranker\ntraining. First, we are performing this decision per\nexample as each data item is processed (this is done\nin the inner loop of the Algorithm 2). Second, the\nfeedback function for selecting a parse is based on\nan external objective function. The second point is\nactually true for many minimum-error-rate training\nscenarios, but in those settings the model is updated\nas a post-processing stage (after the base-model is\ntrained).\n"},{"#tail":"\n","@confidence":"0.928995666666667","#text":"\nA training setD is loss-separable with margin ? > 0\nif there exists a vector u with ?u? = 1 such that\nfor all y?, y?? ? Yx and (x, y) ? D, if L(y?, y) <\n"},{"#tail":"\n","@confidence":"0.91723975","#text":"\nparameter vector ? when ?y?j ? F k-best? (x) where\ny?j 6= y?1 and L(y?j , y) < L(y?1, y). If training is run\nindefinitely, then m ? R2?2 .\nProof. Identical to the standard perceptron proof,\ne.g., Collins (2002), by inserting in loss-separability\nfor normal separability.\nLike the original perceptron theorem, this implies\nthat the algorithm will converge. However, unlike\nthe original theorem, it does not imply that it will\nconverge to a parameter vector ? such that for all\n(x, y) ? D, if y? = arg maxy? ? ??(y?) then L(y?, y) =\n0. Even if we assume for every x there exists an out-\nput with zero loss, Theorem 1 still makes no guar-\nantees. Consider a training set with one instance\n(x, y). Now, set k = 2 for the k-best output list and\nlet y?1, y?2, and y?3 be the top-3 scoring outputs and\nlet L(y?1, y) = 1, L(y?2, y) = 2 and L(y?3, y) = 0.\nIn this case, no updates will ever be made and y?1\nwill remain unchanged even though it doesn?t have\nminimal loss. Consider the following assumption:\n"},{"#tail":"\n","@confidence":"0.836931","#text":"\nduring training, but before convergence, there is at\nleast one example in the training data where k is\nlarge enough to include one output with a lower loss\nwhen y?1 does not have the optimal minimal loss. If\nk = ?, then this is the standard perceptron as it\nguarantees the optimal loss output to be in the k-best\nlist. But we are assuming something much weaker\nhere, i.e., not that the k-best list will include the min-\nimal loss output, only a single output with a lower\nloss than the current best guess. However, it is strong\nenough to show the following:\nTheorem 2. Given Assumption 1 and Assumption 2.\nTraining the perceptron (Algorithm 2) with inline\nranker loss (Algorithm 3) on D 1) converges in fi-\nnite time, and 2) produces parameters ? such that\nfor all (x, y) ? D, if y? = arg maxy? ? ? ?(y?) then\n"},{"#tail":"\n","@confidence":"0.953738857142857","#text":"\namount of time. Otherwise, by Assumption 2, there\nexists some x, such that when it is next processed,\nthere would exist an output in the k-best list that\nhad a lower loss, which will result in an additional\nmistake. Theorem 1 guarantees that this can not\ncontinue indefinitely as the number of mistakes is\nbounded.\n"},{"#tail":"\n","@confidence":"0.998427518518518","#text":"\nThus, the perceptron algorithm will converge to\noptimal minimal loss under the assumption that k\nis large enough so that the model can keep improv-\ning. Note that this does not mean k must be large\nenough to include a zero or minimum loss output,\njust large enough to include a better output than\nthe current best hypothesis. Theorem 2, when cou-\npled with Theorem 1, implies that augmented-loss\nlearning will make at most R2/?2 mistakes at train-\ning, but does not guarantee the rate at which these\nmistakes will be made, only that convergence is fi-\nnite, providing that the scheduling time (defined by\nSched()) between seeing the same instance is always\nfinite, which is always true in our experiments.\nThis analysis does not assume anything about the\nloss L. Every instance (x, y) can use a different loss.\nIt is only required that the loss for a specific input-\noutput pair is fixed throughout training. Thus, the\nabove analysis covers the case where some training\ninstances use an extrinsic loss and others an intrin-\nsic parsing loss. This also suggests more efficient\ntraining methods when extracting the k-best list is\nprohibitive. One can parse with k = 2, 4, 8, 16, . . .\nuntil an k is reached that includes a lower loss parse.\nIt may be the case that for most instances a small\nk is required, but the algorithm is doing more work\nunnecessarily if k is large.\n"},{"#tail":"\n","@confidence":"0.983075","#text":"\nThe augmented-loss framework we present is gen-\neral in the sense that it can be combined with any\nloss function and any parser, provided the parser can\nbe parameterized as a linear classifier, trained with\nthe perceptron and is capable of producing a k-best\n"},{"#tail":"\n","@confidence":"0.977061193548387","#text":"\ntransition-based dependency parsing frame-\nwork (Nivre, 2008) using an arc-eager transi-\ntion strategy and are trained using the percep-\ntron algorithm as in Zhang and Clark (2008)\nwith a beam size of 8. Beams with varying\nsizes can be used to produce k-best lists. The\nfeatures used by all models are: the part-of-\nspeech tags of the first four words on the buffer\nand of the top two words on the stack; the word\nidentities of the first two words on the buffer\nand of the top word on the stack; the word iden-\ntity of the syntactic head of the top word on the\nstack (if available); dependency arc label iden-\ntities for the top word on the stack, the left and\nrightmost modifier of the top word on the stack,\nand the left most modifier of the first word in\nthe buffer (if available). All feature conjunc-\ntions are included.\n? Graph-based: An implementation of graph-\nbased parsing algorithms with an arc-factored\nparameterization (McDonald et al, 2005). We\nuse the non-projective k-best MST algorithm to\ngenerate k-best lists (Hall, 2007), where k = 8\nfor the experiments in this paper. The graph-\nbased parser features used in the experiments\nin this paper are defined over a word, wi at po-\nsition i; the head of this word w?(i) where ?(i)\nprovides the index of the head word; and part-\nof-speech tags of these words ti. We use the\nfollowing set of features similar to McDonald\net al (2005):\n"},{"#tail":"\n","@confidence":"0.9998323","#text":"\nIn the next section, we present a set of scoring func-\ntions that can be used in the inline reranker loss\nframework, resulting in a new augmented-loss for\neach one. Augmented-loss learning is then applied\nto target a downstream task using the loss functions\nto measure gains. We show empirical results for two\nextrinsic loss-functions (optimizing for the down-\nstream task): machine translation and domain adap-\ntation; and for one intrinsic loss-function: an arc-\nlength parsing score. For some experiments we also\n"},{"#tail":"\n","@confidence":"0.685390857142857","#text":"\nmeasure the standard intrinsic parser metrics unla-\nbeled attachment score (UAS) and labeled attach-\nment score (LAS) (Buchholz and Marsi, 2006).\nIn terms of treebank data, the primary training\ncorpus is the Penn Wall Street Journal Treebank\n(PTB) (Marcus et al, 1993). We also make use\nof the Brown corpus, and the Question Treebank\n(QTB) (Judge et al, 2006). For PTB and Brown\nwe use standard training/development/testing splits\nof the data. For the QTB we split the data into\nthree sections: 2000 training, 1000 development,\nand 1000 test. All treebanks are converted to de-\npendency format using the Stanford converter v1.6\n(de Marneffe et al, 2006).\n"},{"#tail":"\n","@confidence":"0.9881430625","#text":"\nAs alluded to in Section 2.2, we use a reordering-\nbased loss function to improve word order in a ma-\nchine translation system. In particular, we use a sys-\ntem of source-side reordering rules which, given a\nparse of the source sentence, will reorder the sen-\ntence into a target-side order (Collins et al, 2005).\nIn our experiments we work with a set of English-\nJapanese reordering rules1 and gold reorderings\nbased on human generated correct reordering of an\naligned target sentences. We use a reordering score\nbased on the reordering penalty from the METEOR\nscoring metric. Though we could have used a fur-\nther downstream measure like BLEU, METEOR has\nalso been shown to directly correlate with translation\nquality (Banerjee and Lavie, 2005) and is simpler to\nmeasure.\n"},{"#tail":"\n","@confidence":"0.97959025","#text":"\nAll reordering augmented-loss experiments are\nrun with the same treebank data as the baseline\n(the training portions of PTB, Brown, and QTB).\nThe extrinsic reordering training data consists of\n10930 examples of English sentences and their cor-\nrect Japanese word-order. We evaluate our results on\nan evaluation set of 6338 examples of similarly cre-\nated reordering data. The reordering cost, evaluation\n"},{"#tail":"\n","@confidence":"0.995811","#text":"\n(English-to-Japanese). Exact is the number of correctly\nreordered sentences. All models use the same treebank-\ndata (PTB, QTB, and the Brown corpus). Results for\nthree augmented-loss schedules are shown: 0.5 where for\nevery two treebank updates we make one augmented-loss\nupdate, 1 is a 1-to-1 mix, and 2 is where we make twice\nas many augmented-loss updates as treebank updates.\ncriteria and data used in our experiments are based\non the work of Talbot et al (2011).\nTable 1 shows the results of using the reordering\ncost as an augmented-loss to the standard treebank\nobjective function. Results are presented as mea-\nsured by the reordering score as well as a coarse\nexact-match score (the number of sentences which\nwould have correct word-order given the parse and\nthe fixed reordering rules). We see continued im-\nprovements as we adjust the schedule to process the\nextrinsic loss more frequently, the best result being\nwhen we make two augmented-loss updates for ev-\nery one treebank-based loss update.\n"},{"#tail":"\n","@confidence":"0.998852214285714","#text":"\nAnother application of the augmented-loss frame-\nwork is to improve parser domain portability in the\npresence of partially labeled data. Consider, for ex-\nample, the case of questions. Petrov et al (2010)\nobserved that dependency parsers tend to do quite\npoorly when parsing questions due to their lim-\nited exposure to them in the news corpora from\nthe PennTreebank. Table 2 shows the accuracy\nof two parsers (LAS, UAS and the F1 of the root\ndependency attachment) on the QuestionBank test\ndata. The first is a parser trained on the standard\ntraining sections of the PennTreebank (PTB) and\nthe second is a parser trained on the training por-\ntion of the QuestionBank (QTB). Results for both\n"},{"#tail":"\n","@confidence":"0.998148803571429","#text":"\nboth transition and graph-based parsers) the labeled ac-\ncuracy score (LAS), unlabeled accuracy score (UAS)\nand Root-F1 for parsers trained on the PTB and QTB\nand tested on the QTB. The augmented-loss parsers are\ntrained on the PTB but with a partial tree loss on QTB\nthat considers only root dependencies.\ntransition-based parsers and graph-based parsers are\ngiven. Clearly there is significant drop in accu-\nracy for a parser trained on the PTB. For example,\nthe transition-based PTB parser achieves a LAS of\n67.97% relative to 84.59% for the parser trained on\nthe QTB.\nWe consider the situation where it is possible to\nask annotators a single question about the target do-\nmain that is relatively easy to answer. The question\nshould be posed so that the resulting answer pro-\nduces a partially labeled dependency tree. Root-F1\nscores from Table 2 suggest that one simple ques-\ntion is ?what is the main verb of this sentence?? for\nsentences that are questions. In most cases this task\nis straight-forward and will result in a single depen-\ndency, that from the root to the main verb of the sen-\ntence. We feel this is a realistic partial labeled train-\ning setting where it would be possible to quickly col-\nlect a significant amount of data.\nTo test whether such weak information can signif-\nicantly improve the parsing of questions, we trained\nan augmented-loss parser using the training set of\nthe QTB stripped of all dependencies except the de-\npendency from the root to the main verb of the sen-\ntence. In other words, for each sentence, the parser\nmay only observe a single dependency at training\nfrom the QTB ? the dependency to the main verb.\nOur augmented-loss function in this case is a simple\nbinary function: 0 if a parse has the correct root de-\npendency and 1 if it does not. Thus, the algorithm\nwill select the first parse in the k-best list that has the\ncorrect root as the proxy to a gold standard parse.2\nThe last row in each section of Table 2 shows the\nresults for this augmented-loss system when weight-\ning both losses equally during training. By simply\nhaving the main verb annotated in each sentence ?\nthe sentences from the training portion of the QTB\n? the parser can eliminate half of the errors of the\noriginal parser. This is reflected by both the Root-\nF1 as well as LAS/UAS. It is important to point out\nthat these improvements are not limited to simply\nbetter root predictions. Due to the fact that parsing\nalgorithms make many parsing decisions jointly at\ntest time, all such decisions influence each other and\nimprovements are seen across the board. For exam-\nple, the transition-based PTB parser has an F1 score\nof 41.22% for verb subjects (nsubj), whereas the\naugmented-loss parser has an F1 of 73.52%. Clearly\nimproving just a single (and simple to annotate) de-\npendency leads to general parser improvements.\n"},{"#tail":"\n","@confidence":"0.940179","#text":"\nThe augmented-loss framework can be used to in-\ncorporate multiple treebank-based loss functions as\nwell. Labeled attachment score is used as our base\nmodel loss function. In this set of experiments we\nconsider adding an additional loss function which\nweights the lengths of correct and incorrect arcs, the\naverage (labeled) arc-length score:\n"},{"#tail":"\n","@confidence":"0.987476071428572","#text":"\nFor each word of the sentence we compute the dis-\ntance between the word?s position i and the posi-\ntion of the words head ?i. The arc-length score is\nthe summed length of all those with correct head as-\nsignments (?(??i, ?i) is 1 if the predicted head and\nthe correct head match, 0 otherwise). The score is\nnormalized by the summed arc lengths for the sen-\ntence. The labeled version of this score requires that\nthe labels of the arc are also correct. Optimizing\nfor dependency arc length is particularly important\nas parsers tend to do worse on longer dependencies\n(McDonald and Nivre, 2007) and these dependen-\ncies are typically the most meaningful for down-\nstream tasks, e.g., main verb dependencies for tasks\n"},{"#tail":"\n","@confidence":"0.998033311111111","#text":"\nof the PTB. When training with ALS (labeled and unla-\nbeled), we see an improvement in UAS, LAS, and ALS.\nFurthermore, if we use a labeled-ALS as the metric for\naugmented-loss training, we also see a considerable in-\ncrease in LAS.\nlike information extraction (Yates and Etzioni, 2009)\nand textual entailment (Berant et al, 2010).\nIn Table 3 we show results for parsing with the\nALS augmented-loss objective. For each parser, we\nconsider two different ALS objective functions; one\nbased on unlabeled-ALS and the other on labeled-\nALS. The arc-length score penalizes incorrect long-\ndistance dependencies more than local dependen-\ncies; long-distance dependencies are often more de-\nstructive in preserving sentence meaning and can be\nmore difficult to predict correctly due to the larger\ncontext on which they depend. Combining this with\nthe standard attachment scores biases training to fo-\ncus on the difficult head dependencies.\nFor both experiments we see that by adding the\nALS augmented-loss we achieve an improvement in\nLAS and UAS in addition to ALS. The augmented-\nloss not only helps us improve on the longer depen-\ndencies (as reflected in the increased ALS), but also\nin the main parser objective function of LAS and\nUAS. Using the labeled loss function provides better\nreinforcement as can be seen in the improvements\nover the unlabeled loss-function. As with all experi-\nments in this paper, the graph-based parser baselines\nare much lower than the transition-based parser due\nto the use of arc-factored features. In these experi-\nments we used an inline-ranker loss with 8 parses.\nWe experimented with larger sizes (16 and 64) and\nfound very similar improvements: for example, the\ntransition parser?s LAS for the labeled loss is 88.68\nand 88.84, respectively).\nWe note that ALS can be decomposed locally and\ncould be used as the primary objective function for\nparsing. A parse with perfect scores under ALS\nand LAS will match the gold-standard training tree.\nHowever, if we were to order incorrect parses of a\nsentence, ALS and LAS will suggest different order-\nings. Our results show that by optimizing for losses\nbased on a combination of these metrics we train a\nmore robust parsing model.\n"},{"#tail":"\n","@confidence":"0.999191131578947","#text":"\nA recent study by Katz-Brown et al (2011) also in-\nvestigates the task of training parsers to improve MT\nreordering. In that work, a parser is used to first\nparse a set of manually reordered sentences to pro-\nduce k-best lists. The parse with the best reordering\nscore is then fixed and added back to the training set\nand a new parser is trained on resulting data. The\nmethod is called targeted self-training as it is simi-\nlar in vein to self-training (McClosky et al, 2006),\nwith the exception that the new parse data is targeted\nto produce accurate word reorderings. Our method\ndiffers as it does not statically fix a new parse, but\ndynamically updates the parameters and parse selec-\ntion by incorporating the additional loss in the inner\nloop of online learning. This allows us to give guar-\nantees of convergence. Furthermore, we also evalu-\nate the method on alternate extrinsic loss functions.\nLiang et al (2006) presented a perceptron-based\nalgorithm for learning the phrase-translation param-\neters in a statistical machine translation system.\nSimilar to the inline-ranker loss function presented\nhere, they use a k-best lists of hypotheses in order to\nidentify parameters which can improve a global ob-\njective function: BLEU score. In their work, they\nare interested in learning a parameterization over\ntranslation phrases (including the underlying word-\nalignment) which optimizes the BLEU score. Their\ngoal is considerably different; they want to incor-\nporate additional features into their model and de-\nfine an objective function which allows them to do\nso; whereas, we are interested in allowing for mul-\ntiple objective functions in order to adapt the parser\nmodel parameters to downstream tasks or alternative\nintrinsic (parsing) objectives.\nThe work that is most similar to ours is that\nof Chang et al (2007), who introduced the Con-\nstraint Driven Learning algorithm (CODL). Their al-\ngorithm specifically optimizes a loss function with\n"},{"#tail":"\n","@confidence":"0.999801326530612","#text":"\nthe addition of constraints based on unlabeled data\n(what we call extrinsic datasets). For each unla-\nbeled example, they use the current model along\nwith their set of constraints to select a set of k au-\ntomatically labeled examples which best meet the\nconstraints. These induced examples are then added\nto their training set and, after processing each unla-\nbeled dataset, they perform full model optimization\nwith the concatenation of training data and newly\ngenerated training items. The augmented-loss al-\ngorithm can be viewed as an online version of this\nalgorithm which performs model updates based on\nthe augmented-loss functions directly (rather than\nadding a set of examples to the training set). Un-\nlike the CODL approach, we do not perform com-\nplete optimization on each iteration over the unla-\nbeled dataset; rather, we incorporate the updates in\nour online learning algorithm. As mentioned earlier,\nCODL is one example of learning algorithms that\nuse weak supervision, others include Mann and Mc-\nCallum (2010) and Ganchev et al (2010). Again,\nthese works are typically interested in using the ex-\ntrinsic metric ? or, in general, extrinsic information\n? to optimize the intrinsic metric in the absence of\nany labeled intrinsic data. Our goal is to optimize\nboth simultaneously.\nThe idea of jointly training parsers to optimize\nmultiple objectives is related to joint learning and in-\nference for tasks like information extraction (Finkel\nand Manning, 2009) and machine translation (Bur-\nkett et al, 2010). In such works, a large search space\nthat covers both the space of parse structures and\nthe space of task-specific structures is defined and\nparameterized so that standard learning and infer-\nence algorithms can be applied. What sets our work\napart is that there is still just a single parameter set\nthat is being optimized ? the parser parameters. Our\nmethod only uses feedback from task specific objec-\ntives in order to update the parser parameters, guid-\ning it towards better downstream performance. This\nis advantageous for two reasons. First, it decouples\nthe tasks, making inference and learning more effi-\ncient. Second, it does not force arbitrary paraemter\nfactorizations in order to define a joint search space\nthat can be searched efficiently.\nFinally, augmented-loss training can be viewed\nas multi-task learning (Caruana, 1997) as the model\noptimizes multiple objectives over multiple data sets\nwith a shared underlying parameter space.\n"},{"#tail":"\n","@confidence":"0.999835475","#text":"\nThe empirical results show that incorporating an\naugmented-loss using the inline-ranker loss frame-\nwork achieves better performance under metrics as-\nsociated with the external loss function. For the in-\ntrinsic loss, we see that the augmented-loss frame-\nwork can also result in an improvement in parsing\nperformance; however, in the case of ALS, this is\ndue to the fact that the loss function is very closely\nrelated to the standard evaluation metrics of UAS\nand LAS.\nAlthough our analysis suggests that this algorithm\nis guaranteed to converge only for the separable\ncase, it makes a further assumption that if there is\na better parse under the augmented-loss, then there\nmust be a lower cost parse in the k-best list. The em-\npirical evaluation presented here is based on a very\nconservative approximation by choosing lists with\nat most 8 parses. However, in our experiments, we\nfound that increasing the size of the lists did not sig-\nnificantly increase our accuracy under the external\nmetrics. If we do have at least one improvement\nin our k-best lists, the analysis suggests that this is\nenough to move in the correct direction for updating\nthe model. The assumption that there will always\nbe an improvement in the k-best list if there is some\nbetter parse breaks down as training continues. We\nsuspect that an increasing k, as suggested in Sec-\ntion 2.3, will allow for continued improvements.\nDependency parsing, as presented in this pa-\nper, is performed over (k-best) part-of-speech tags\nand is therefore dependent on the quality of the\ntagger. The experiments presented in this paper\nmade use of a tagger trained on the source treebank\ndata which severely limits the variation in parses.\nThe augmented-loss perceptron algorithm presented\nhere can be applied to any online learning prob-\nlem, including part-of-speech tagger training. To\nbuild a dependency parser which is better adapted\nto a downstream task, one would want to perform\naugmented-loss training on the tagger as well.\n"},{"#tail":"\n","@confidence":"0.999827","#text":"\nWe introduced the augmented-loss training algo-\nrithm and show that the algorithm can incorporate\n"},{"#tail":"\n","@confidence":"0.999431782608696","#text":"\nadditional loss functions to adapt the model towards\nextrinsic evaluation metrics. Analytical results are\npresented that show that the algorithm can opti-\nmize multiple objective functions simultaneously.\nWe present an empirical analysis for training depen-\ndency parsers for multiple parsing algorithms and\nmultiple loss functions.\nThe augmented-loss framework supports both in-\ntrinsic and extrinsic losses, allowing for both com-\nbinations of objectives as well as multiple sources\nof data for which the results of a parser can be eval-\nuated. This flexibility makes it possible to tune a\nmodel for a downstream task. The only requirement\nis a metric which can be defined over parses of the\ndownstream data. Our dependency parsing results\nshow that we are not limited to increasing parser\nperformance via more data or external domain adap-\ntation techniques, but that we can incorporate the\ndownstream task into parser training.\nAcknowledgements: We would like to thank Kuz-\nman Ganchev for feedback on an earlier draft of this\npaper as well as Slav Petrov for frequent discussions\non this topic.\n"}],"#text":"\n","affiliation":{"#tail":"\n","@confidence":"0.717867","#text":"\nGoogle Research\n"},"sectionHeader":[{"#tail":"\n","@confidence":"0.98994","@genericHeader":"abstract","#text":"\nAbstract\n"},{"#tail":"\n","@confidence":"0.998326","@genericHeader":"keywords","#text":"\n1 Introduction\n"},{"#tail":"\n","@confidence":"0.998591","@genericHeader":"introduction","#text":"\n2 Methodology\n"},{"#tail":"\n","@confidence":"0.998317","@genericHeader":"method","#text":"\n3 Experimental Set-up\n"},{"#tail":"\n","@confidence":"0.993481","@genericHeader":"method","#text":"\n4 Experiments\n"},{"#tail":"\n","@confidence":"0.999453","@genericHeader":"method","#text":"\n5 Related Work\n"},{"#tail":"\n","@confidence":"0.998345","@genericHeader":"method","#text":"\n6 Discussion\n"},{"#tail":"\n","@confidence":"0.997229","@genericHeader":"conclusions","#text":"\n7 Conclusion\n"},{"#tail":"\n","@confidence":"0.991984","@genericHeader":"references","#text":"\nReferences\n"}],"tableCaption":[{"#tail":"\n","@confidence":"0.999273","#text":"\nTable 1: Reordering scores for parser-based reordering\n"},{"#tail":"\n","@confidence":"0.995349","#text":"\nTable 2: Domain adaptation results. Table shows (for\n"},{"#tail":"\n","@confidence":"0.993943","#text":"\nTable 3: Results for both parsers on the development set\n"}],"page":[{"#tail":"\n","@confidence":"0.959409","#text":"\n1489\n"},{"#tail":"\n","@confidence":"0.969819","#text":"\n1490\n"},{"#tail":"\n","@confidence":"0.877702","#text":"\n1491\n"},{"#tail":"\n","@confidence":"0.952027","#text":"\n1492\n"},{"#tail":"\n","@confidence":"0.763621","#text":"\n1493\n"},{"#tail":"\n","@confidence":"0.974191","#text":"\n1494\n"},{"#tail":"\n","@confidence":"0.887831","#text":"\n1495\n"},{"#tail":"\n","@confidence":"0.835055","#text":"\n1496\n"},{"#tail":"\n","@confidence":"0.820701","#text":"\n1497\n"},{"#tail":"\n","@confidence":"0.968475","#text":"\n1499\n"}],"table":[{"#tail":"\n","@confidence":"0.977672555555556","#text":"\nExact Reorder\ntrans?PTB + Brown + QTB 35.29 76.49\ntrans?0.5?aug.-loss 38.71 78.19\ntrans?1.0?aug.-loss 39.02 78.39\ntrans?2.0?aug.-loss 39.58 78.67\ngraph?PTB + Brown + QTB 25.71 69.84\ngraph?0.5? aug.-loss 28.99 72.23\ngraph?1.0?aug.-loss 29.99 72.88\ngraph?2.0?aug.-loss 30.03 73.15\n"},{"#tail":"\n","@confidence":"0.998115285714286","#text":"\nLAS UAS Root-F1\ntrans?PTB 67.97 73.52 47.60\ntrans?QTB 84.59 89.59 91.06\ntrans?aug.-loss 76.27 86.42 83.41\ngraph?PTB 65.27 72.72 43.10\ngraph?QTB 82.73 87.44 91.58\ngraph?aug.-loss 72.82 80.68 86.26\n"},{"#tail":"\n","@confidence":"0.986167285714286","#text":"\nLAS UAS ALS\ntrans?PTB 88.64 91.64 82.96\ntrans?unlabeled aug.-loss 88.74 91.91 83.65\ntrans?labeled aug.-loss 88.84 91.91 83.46\ngraph?PTB 85.75 88.70 73.88\ngraph?unlabeled aug.-loss 85.80 88.81 74.26\ngraph?labeled aug.-loss 85.85 88.93 74.40\n"}],"email":{"#tail":"\n","@confidence":"0.976593","#text":"\n{kbhall|ryanmcd|jasonkb|ringgaard}@google.com\n"}}},{"#tail":"\n","@name":"ParsHed","#text":"\n","@version":"110505","variant":{"@confidence":"0.927277","#tail":"\n","@no":"0","note":{"#tail":"\n","@confidence":"0.993166","#text":"Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1489?1499, Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational Linguistics"},"#text":"\n","affiliation":{"#tail":"\n","@confidence":"0.969306","#text":"Google Research"},"author":{"#tail":"\n","@confidence":"0.995592","#text":"Keith Hall Ryan McDonald Jason Katz-Brown Michael Ringgaard"},"abstract":{"#tail":"\n","@confidence":"0.9991578","#text":"We present an online learning algorithm for training parsers which allows for the inclusion of multiple objective functions. The primary example is the extension of a standard supervised parsing objective function with additional loss-functions, either based on intrinsic parsing quality or task-specific extrinsic measures of quality. Our empirical results show how this approach performs for two dependency parsing algorithms (graph-based and transition-based parsing) and how it achieves increased performance on multiple target tasks including reordering for machine translation and parser adaptation."},"title":{"#tail":"\n","@confidence":"0.981301","#text":"Training dependency parsers by jointly optimizing multiple objectives"},"email":{"#tail":"\n","@confidence":"0.998692","#text":"{kbhall|ryanmcd|jasonkb|ringgaard}@google.com"}}},{"#tail":"\n","@name":"ParsCit","#text":"\n","@version":"110505","citationList":{"#tail":"\n","#text":"\n","citation":[{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"S. Banerjee and A. Lavie. 2005. METEOR: An automatic metric for MT evaluation with improved correlation with human judgments. In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization."},"#text":"\n","marker":{"#tail":"\n","#text":"Banerjee, Lavie, 2005"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"lation system. In particular, we use a system of source-side reordering rules which, given a parse of the source sentence, will reorder the sentence into a target-side order (Collins et al, 2005). In our experiments we work with a set of EnglishJapanese reordering rules1 and gold reorderings based on human generated correct reordering of an aligned target sentences. We use a reordering score based on the reordering penalty from the METEOR scoring metric. Though we could have used a further downstream measure like BLEU, METEOR has also been shown to directly correlate with translation quality (Banerjee and Lavie, 2005) and is simpler to measure. reorder-score = 1? # chunks? 1# unigrams matched? 1 reorder-cost = 1? reorder-score All reordering augmented-loss experiments are run with the same treebank data as the baseline (the training portions of PTB, Brown, and QTB). The extrinsic reordering training data consists of 10930 examples of English sentences and their correct Japanese word-order. We evaluate our results on an evaluation set of 6338 examples of similarly created reordering data. The reordering cost, evaluation 1Our rules are similar to those from Xu et al (2009). Exact Reorder trans?PTB + Brown + ","@endWordPosition":"3816","@position":"21731","annotationId":"T1","@startWordPosition":"3813","@citStr":"Banerjee and Lavie, 2005"}},"title":{"#tail":"\n","#text":"METEOR: An automatic metric for MT evaluation with improved correlation with human judgments."},"booktitle":{"#tail":"\n","#text":"In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"S Banerjee"},{"#tail":"\n","#text":"A Lavie"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2010"},"rawString":{"#tail":"\n","#text":"J. Berant, I. Dagan, and J. Goldberger. 2010. Global learning of focused entailment graphs. In Proc. of ACL."},"#text":"\n","marker":{"#tail":"\n","#text":"Berant, Dagan, Goldberger, 2010"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":" UAS ALS trans?PTB 88.64 91.64 82.96 trans?unlabeled aug.-loss 88.74 91.91 83.65 trans?labeled aug.-loss 88.84 91.91 83.46 graph?PTB 85.75 88.70 73.88 graph?unlabeled aug.-loss 85.80 88.81 74.26 graph?labeled aug.-loss 85.85 88.93 74.40 Table 3: Results for both parsers on the development set of the PTB. When training with ALS (labeled and unlabeled), we see an improvement in UAS, LAS, and ALS. Furthermore, if we use a labeled-ALS as the metric for augmented-loss training, we also see a considerable increase in LAS. like information extraction (Yates and Etzioni, 2009) and textual entailment (Berant et al, 2010). In Table 3 we show results for parsing with the ALS augmented-loss objective. For each parser, we consider two different ALS objective functions; one based on unlabeled-ALS and the other on labeledALS. The arc-length score penalizes incorrect longdistance dependencies more than local dependencies; long-distance dependencies are often more destructive in preserving sentence meaning and can be more difficult to predict correctly due to the larger context on which they depend. Combining this with the standard attachment scores biases training to focus on the difficult head dependencies. For bot","@endWordPosition":"5073","@position":"29300","annotationId":"T2","@startWordPosition":"5070","@citStr":"Berant et al, 2010"}},"title":{"#tail":"\n","#text":"Global learning of focused entailment graphs."},"booktitle":{"#tail":"\n","#text":"In Proc. of ACL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"J Berant"},{"#tail":"\n","#text":"I Dagan"},{"#tail":"\n","#text":"J Goldberger"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"J. Blitzer, R. McDonald, and F. Pereira. 2006. Domain adaptation with structural correspondence learning. In Proc. of EMNLP."},"#text":"\n","marker":{"#tail":"\n","#text":"Blitzer, McDonald, Pereira, 2006"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"increased performance on multiple target tasks including reordering for machine translation and parser adaptation. 1 Introduction The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks. This includes work on question answering (Wang et al, 2007), sentiment analysis (Nakagawa et al, 2010), MT reordering (Xu et al, 2009), and many other tasks. In most cases, the accuracy of parsers degrades when run on out-of-domain data (Gildea, 2001; McClosky et al, 2006; Blitzer et al, 2006; Petrov et al, 2010). But these accuracies are measured with respect to gold-standard out-of-domain parse trees. There are few tasks that actually depend on the complete parse tree. Furthermore, when evaluated on a downstream task, often the optimal parse output has a model score lower than the best parse as predicted by the parsing model. While this means that we are not properly modeling the downstream task in the parsers, it also means that there is some information from small task or domain-specific data sets which could help direct our search for optimal parameters during parser training","@endWordPosition":"211","@position":"1508","annotationId":"T3","@startWordPosition":"208","@citStr":"Blitzer et al, 2006"}},"title":{"#tail":"\n","#text":"Domain adaptation with structural correspondence learning."},"booktitle":{"#tail":"\n","#text":"In Proc. of EMNLP."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"J Blitzer"},{"#tail":"\n","#text":"R McDonald"},{"#tail":"\n","#text":"F Pereira"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"S. Buchholz and E. Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proc. of CoNLL."},"#text":"\n","marker":{"#tail":"\n","#text":"Buchholz, Marsi, 2006"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ent a set of scoring functions that can be used in the inline reranker loss framework, resulting in a new augmented-loss for each one. Augmented-loss learning is then applied to target a downstream task using the loss functions to measure gains. We show empirical results for two extrinsic loss-functions (optimizing for the downstream task): machine translation and domain adaptation; and for one intrinsic loss-function: an arclength parsing score. For some experiments we also 1493 measure the standard intrinsic parser metrics unlabeled attachment score (UAS) and labeled attachment score (LAS) (Buchholz and Marsi, 2006). In terms of treebank data, the primary training corpus is the Penn Wall Street Journal Treebank (PTB) (Marcus et al, 1993). We also make use of the Brown corpus, and the Question Treebank (QTB) (Judge et al, 2006). For PTB and Brown we use standard training/development/testing splits of the data. For the QTB we split the data into three sections: 2000 training, 1000 development, and 1000 test. All treebanks are converted to dependency format using the Stanford converter v1.6 (de Marneffe et al, 2006). 4 Experiments 4.1 Machine Translation Reordering Score As alluded to in Section 2.2, we use","@endWordPosition":"3600","@position":"20433","annotationId":"T4","@startWordPosition":"3597","@citStr":"Buchholz and Marsi, 2006"}},"title":{"#tail":"\n","#text":"CoNLL-X shared task on multilingual dependency parsing."},"booktitle":{"#tail":"\n","#text":"In Proc. of CoNLL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"S Buchholz"},{"#tail":"\n","#text":"E Marsi"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2010"},"rawString":{"#tail":"\n","#text":"D. Burkett, J. Blitzer, and D. Klein. 2010. Joint parsing and alignment with weakly synchronized grammars. In Proc. of NAACL."},"#text":"\n","marker":{"#tail":"\n","#text":"Burkett, Blitzer, Klein, 2010"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"As mentioned earlier, CODL is one example of learning algorithms that use weak supervision, others include Mann and McCallum (2010) and Ganchev et al (2010). Again, these works are typically interested in using the extrinsic metric ? or, in general, extrinsic information ? to optimize the intrinsic metric in the absence of any labeled intrinsic data. Our goal is to optimize both simultaneously. The idea of jointly training parsers to optimize multiple objectives is related to joint learning and inference for tasks like information extraction (Finkel and Manning, 2009) and machine translation (Burkett et al, 2010). In such works, a large search space that covers both the space of parse structures and the space of task-specific structures is defined and parameterized so that standard learning and inference algorithms can be applied. What sets our work apart is that there is still just a single parameter set that is being optimized ? the parser parameters. Our method only uses feedback from task specific objectives in order to update the parser parameters, guiding it towards better downstream performance. This is advantageous for two reasons. First, it decouples the tasks, making inference and learning m","@endWordPosition":"5939","@position":"34611","annotationId":"T5","@startWordPosition":"5935","@citStr":"Burkett et al, 2010"}},"title":{"#tail":"\n","#text":"Joint parsing and alignment with weakly synchronized grammars."},"booktitle":{"#tail":"\n","#text":"In Proc. of NAACL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"D Burkett"},{"#tail":"\n","#text":"J Blitzer"},{"#tail":"\n","#text":"D Klein"}]}},{"volume":{"#tail":"\n","#text":"28"},"#tail":"\n","date":{"#tail":"\n","#text":"1997"},"rawString":{"#tail":"\n","#text":"R. Caruana. 1997. Multitask learning. Machine Learning, 28(1):41?75."},"#text":"\n","issue":{"#tail":"\n","#text":"1"},"marker":{"#tail":"\n","#text":"Caruana, 1997"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":". What sets our work apart is that there is still just a single parameter set that is being optimized ? the parser parameters. Our method only uses feedback from task specific objectives in order to update the parser parameters, guiding it towards better downstream performance. This is advantageous for two reasons. First, it decouples the tasks, making inference and learning more efficient. Second, it does not force arbitrary paraemter factorizations in order to define a joint search space that can be searched efficiently. Finally, augmented-loss training can be viewed as multi-task learning (Caruana, 1997) as the model optimizes multiple objectives over multiple data sets with a shared underlying parameter space. 6 Discussion The empirical results show that incorporating an augmented-loss using the inline-ranker loss framework achieves better performance under metrics associated with the external loss function. For the intrinsic loss, we see that the augmented-loss framework can also result in an improvement in parsing performance; however, in the case of ALS, this is due to the fact that the loss function is very closely related to the standard evaluation metrics of UAS and LAS. Although our a","@endWordPosition":"6072","@position":"35446","annotationId":"T6","@startWordPosition":"6071","@citStr":"Caruana, 1997"}},"booktitle":{"#tail":"\n","#text":"Multitask learning. Machine Learning,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"R Caruana"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"M.W. Chang, L. Ratinov, and D. Roth. 2007. Guiding semi-supervision with constraint-driven learning. In Proc. of ACL."},"#text":"\n","marker":{"#tail":"\n","#text":"Chang, Ratinov, Roth, 2007"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"ve function associated with the instance (either intrinsic or extrinsic), thus jointly optimizing multiple objectives. An update schedule trades-off the relative importance of each objective function. We call our algorithm augmented-loss training as it optimizes multiple losses to augment the traditional supervised parser loss. There have been a number of efforts to exploit weak or external signals of quality to train better prediction models. This includes work on generalized expectation (Mann and McCallum, 2010), posterior regularization (Ganchev et al, 2010) and constraint driven learning (Chang et al, 2007; Chang et al, 2010). The work of Chang et al (2007) on constraint driven learning is perhaps the closest to our framework and we draw connections to it in Section 5. In these studies the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics. For our setting this would mean using weak application specific signals to improve dependency parsing. Though we explore such ideas in our experiments, in particular for semi-supervised domain adaptation, we are primarily interested in the case where the weak signal is precisely what we wish","@endWordPosition":"647","@position":"4223","annotationId":"T7","@startWordPosition":"644","@citStr":"Chang et al, 2007"},{"#tail":"\n","#text":"a global objective function: BLEU score. In their work, they are interested in learning a parameterization over translation phrases (including the underlying wordalignment) which optimizes the BLEU score. Their goal is considerably different; they want to incorporate additional features into their model and define an objective function which allows them to do so; whereas, we are interested in allowing for multiple objective functions in order to adapt the parser model parameters to downstream tasks or alternative intrinsic (parsing) objectives. The work that is most similar to ours is that of Chang et al (2007), who introduced the Constraint Driven Learning algorithm (CODL). Their algorithm specifically optimizes a loss function with 1496 the addition of constraints based on unlabeled data (what we call extrinsic datasets). For each unlabeled example, they use the current model along with their set of constraints to select a set of k automatically labeled examples which best meet the constraints. These induced examples are then added to their training set and, after processing each unlabeled dataset, they perform full model optimization with the concatenation of training data and newly generated tra","@endWordPosition":"5678","@position":"32979","annotationId":"T8","@startWordPosition":"5675","@citStr":"Chang et al (2007)"}]},"title":{"#tail":"\n","#text":"Guiding semi-supervision with constraint-driven learning."},"booktitle":{"#tail":"\n","#text":"In Proc. of ACL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"M W Chang"},{"#tail":"\n","#text":"L Ratinov"},{"#tail":"\n","#text":"D Roth"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2010"},"rawString":{"#tail":"\n","#text":"M. Chang, D. Goldwasser, D. Roth, and V. Srikumar. 2010. Structured output learning with indirect supervision. In Proc. of ICML."},"#text":"\n","marker":{"#tail":"\n","#text":"Chang, Goldwasser, Roth, Srikumar, 2010"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ted with the instance (either intrinsic or extrinsic), thus jointly optimizing multiple objectives. An update schedule trades-off the relative importance of each objective function. We call our algorithm augmented-loss training as it optimizes multiple losses to augment the traditional supervised parser loss. There have been a number of efforts to exploit weak or external signals of quality to train better prediction models. This includes work on generalized expectation (Mann and McCallum, 2010), posterior regularization (Ganchev et al, 2010) and constraint driven learning (Chang et al, 2007; Chang et al, 2010). The work of Chang et al (2007) on constraint driven learning is perhaps the closest to our framework and we draw connections to it in Section 5. In these studies the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics. For our setting this would mean using weak application specific signals to improve dependency parsing. Though we explore such ideas in our experiments, in particular for semi-supervised domain adaptation, we are primarily interested in the case where the weak signal is precisely what we wish to optimize, but al","@endWordPosition":"651","@position":"4243","annotationId":"T9","@startWordPosition":"648","@citStr":"Chang et al, 2010"}},"title":{"#tail":"\n","#text":"Structured output learning with indirect supervision."},"booktitle":{"#tail":"\n","#text":"In Proc. of ICML."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"M Chang"},{"#tail":"\n","#text":"D Goldwasser"},{"#tail":"\n","#text":"D Roth"},{"#tail":"\n","#text":"V Srikumar"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"M. Collins, P. Koehn, and I. Kuc?erova?. 2005. Clause restructuring for statistical machine translation. In Proc. of ACL."},"#text":"\n","marker":{"#tail":"\n","#text":"Collins, Koehn, Kucerova, 2005"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"rd training/development/testing splits of the data. For the QTB we split the data into three sections: 2000 training, 1000 development, and 1000 test. All treebanks are converted to dependency format using the Stanford converter v1.6 (de Marneffe et al, 2006). 4 Experiments 4.1 Machine Translation Reordering Score As alluded to in Section 2.2, we use a reorderingbased loss function to improve word order in a machine translation system. In particular, we use a system of source-side reordering rules which, given a parse of the source sentence, will reorder the sentence into a target-side order (Collins et al, 2005). In our experiments we work with a set of EnglishJapanese reordering rules1 and gold reorderings based on human generated correct reordering of an aligned target sentences. We use a reordering score based on the reordering penalty from the METEOR scoring metric. Though we could have used a further downstream measure like BLEU, METEOR has also been shown to directly correlate with translation quality (Banerjee and Lavie, 2005) and is simpler to measure. reorder-score = 1? # chunks? 1# unigrams matched? 1 reorder-cost = 1? reorder-score All reordering augmented-loss experiments are run with the","@endWordPosition":"3747","@position":"21301","annotationId":"T10","@startWordPosition":"3744","@citStr":"Collins et al, 2005"}},"title":{"#tail":"\n","#text":"Clause restructuring for statistical machine translation."},"booktitle":{"#tail":"\n","#text":"In Proc. of ACL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"M Collins"},{"#tail":"\n","#text":"P Koehn"},{"#tail":"\n","#text":"I Kucerova"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2000"},"rawString":{"#tail":"\n","#text":"Michael Collins. 2000. Discriminative reranking for natural language parsing. In Proc. of ICML."},"#text":"\n","marker":{"#tail":"\n","#text":"Collins, 2000"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"eans that we are not properly modeling the downstream task in the parsers, it also means that there is some information from small task or domain-specific data sets which could help direct our search for optimal parameters during parser training. The goal being not necessarily to obtain better parse performance, but to exploit the structure induced from human labeled treebank data while targeting specific extrinsic metrics of quality, which can include task specific metrics or external weak constraints on the parse structure. One obvious approach to this problem is to employ parser reranking (Collins, 2000). In such a setting, an auxiliary reranker is added in a pipeline following the parser. The standard setting involves training the base parser and applying it to a development set (this is often done in a cross-validated jack-knife training framework). The reranker can then be trained to optimize for the downstream or extrinsic objective. While this will bias the reranker towards the target task, it is limited by the oracle performance of the original base parser. In this paper, we propose a training algorithm for statistical dependency parsers (Ku?bler et al, 2009) in which a single model is ","@endWordPosition":"367","@position":"2477","annotationId":"T11","@startWordPosition":"366","@citStr":"Collins, 2000"}},"title":{"#tail":"\n","#text":"Discriminative reranking for natural language parsing."},"booktitle":{"#tail":"\n","#text":"In Proc. of ICML."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"Michael Collins"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2002"},"rawString":{"#tail":"\n","#text":"M. Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proc. of ACL."},"#text":"\n","marker":{"#tail":"\n","#text":"Collins, 2002"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"nsisting of an input senAlgorithm 1 Structured Perceptron {Input data sets: D = {d1 = (x1, y1) . . . dN = (xN , yN )}} {Input 0/1 loss: L(F?(x), y) = [F?(x) 6= y ? 1 : 0]} {Let: F?(x) = arg maxy?Y ? ? ?(y)} {Initialize model parameters: ? = ~0} repeat for i = 1 . . . N do {Compute structured loss} y?i = F?(xi) if L(y?i, yi) > 0 then {Update model Parameters} ? = ? + ?(yi)? ?(y?i) end if end for until converged {Return model ?} tence xi and an output yi; and 2) a loss-function, L(y?, y), that measures the cost of predicting output y? relative to the gold standard y and is usually the 0/1 loss (Collins, 2002). For dependency parser training, this set-up consists of input sentences x and the corresponding gold dependency tree y ? Yx, where Yx is the space of possible parse trees for sentence x. In the perceptron setting, F?(x) = arg maxy?Yx ? ??(y) where ? is mappingfrom a parse tree y for sentence x to a high dimensional feature space. Learning proceeds by predicting a structured output given the current model, and if that structure is incorrect, updating the model: rewarding features that fire in the gold-standard ?(yi), and discounting features that fire in the predicted output, ?(y?i). The stru","@endWordPosition":"1031","@position":"6370","annotationId":"T12","@startWordPosition":"1030","@citStr":"Collins, 2002"},{"#tail":"\n","#text":" all y?, y?? ? Yx and (x, y) ? D, if L(y?, y) < L(y??, y), then u??(y?)?u??(y??) ? ?. Furthermore, let R ? ||?(y)? ?(y?)||, for all y, y?. Assumption 1. Assume training set D is lossseparable with margin ?. Theorem 1. Given Assumption 1. Letm be the number of mistakes made when training the perceptron (Algorithm 2) with inline ranker loss (Algorithm 3) on D, where a mistake occurs for (x, y) ? D with parameter vector ? when ?y?j ? F k-best? (x) where y?j 6= y?1 and L(y?j , y) < L(y?1, y). If training is run indefinitely, then m ? R2?2 . Proof. Identical to the standard perceptron proof, e.g., Collins (2002), by inserting in loss-separability for normal separability. Like the original perceptron theorem, this implies that the algorithm will converge. However, unlike the original theorem, it does not imply that it will converge to a parameter vector ? such that for all (x, y) ? D, if y? = arg maxy? ? ??(y?) then L(y?, y) = 0. Even if we assume for every x there exists an output with zero loss, Theorem 1 still makes no guarantees. Consider a training set with one instance (x, y). Now, set k = 2 for the k-best output list and let y?1, y?2, and y?3 be the top-3 scoring outputs and let L(y?1, y) = 1, ","@endWordPosition":"2403","@position":"13799","annotationId":"T13","@startWordPosition":"2402","@citStr":"Collins (2002)"}]},"title":{"#tail":"\n","#text":"Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms."},"booktitle":{"#tail":"\n","#text":"In Proc. of ACL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"M Collins"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"M.C. de Marneffe, B. MacCartney, and C. Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proc. of LREC, Genoa, Italy."},"#text":"\n","marker":{"#tail":"\n","#text":"de Marneffe, MacCartney, Manning, 2006"},"location":{"#tail":"\n","#text":"Genoa, Italy."},"title":{"#tail":"\n","#text":"Generating typed dependency parses from phrase structure parses."},"booktitle":{"#tail":"\n","#text":"In Proc. of LREC,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"M C de Marneffe"},{"#tail":"\n","#text":"B MacCartney"},{"#tail":"\n","#text":"C Manning"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2009"},"rawString":{"#tail":"\n","#text":"J.R. Finkel and C.D. Manning. 2009. Joint parsing and named entity recognition. In Proc. of NAACL."},"#text":"\n","marker":{"#tail":"\n","#text":"Finkel, Manning, 2009"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"rate the updates in our online learning algorithm. As mentioned earlier, CODL is one example of learning algorithms that use weak supervision, others include Mann and McCallum (2010) and Ganchev et al (2010). Again, these works are typically interested in using the extrinsic metric ? or, in general, extrinsic information ? to optimize the intrinsic metric in the absence of any labeled intrinsic data. Our goal is to optimize both simultaneously. The idea of jointly training parsers to optimize multiple objectives is related to joint learning and inference for tasks like information extraction (Finkel and Manning, 2009) and machine translation (Burkett et al, 2010). In such works, a large search space that covers both the space of parse structures and the space of task-specific structures is defined and parameterized so that standard learning and inference algorithms can be applied. What sets our work apart is that there is still just a single parameter set that is being optimized ? the parser parameters. Our method only uses feedback from task specific objectives in order to update the parser parameters, guiding it towards better downstream performance. This is advantageous for two reasons. First, it decoup","@endWordPosition":"5931","@position":"34565","annotationId":"T14","@startWordPosition":"5928","@citStr":"Finkel and Manning, 2009"}},"title":{"#tail":"\n","#text":"Joint parsing and named entity recognition."},"booktitle":{"#tail":"\n","#text":"In Proc. of NAACL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"J R Finkel"},{"#tail":"\n","#text":"C D Manning"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2010"},"rawString":{"#tail":"\n","#text":"K. Ganchev, J. Grac?a, J. Gillenwater, and B. Taskar. 2010. Posterior regularization for structured latent variable models. Journal of Machine Learning Research."},"journal":{"#tail":"\n","#text":"Journal of Machine Learning Research."},"#text":"\n","marker":{"#tail":"\n","#text":"Ganchev, Graca, Gillenwater, Taskar, 2010"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"he param1489 eters are optimized based on the objective function associated with the instance (either intrinsic or extrinsic), thus jointly optimizing multiple objectives. An update schedule trades-off the relative importance of each objective function. We call our algorithm augmented-loss training as it optimizes multiple losses to augment the traditional supervised parser loss. There have been a number of efforts to exploit weak or external signals of quality to train better prediction models. This includes work on generalized expectation (Mann and McCallum, 2010), posterior regularization (Ganchev et al, 2010) and constraint driven learning (Chang et al, 2007; Chang et al, 2010). The work of Chang et al (2007) on constraint driven learning is perhaps the closest to our framework and we draw connections to it in Section 5. In these studies the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics. For our setting this would mean using weak application specific signals to improve dependency parsing. Though we explore such ideas in our experiments, in particular for semi-supervised domain adaptation, we are primarily interested in the ca","@endWordPosition":"639","@position":"4173","annotationId":"T15","@startWordPosition":"636","@citStr":"Ganchev et al, 2010"},{"#tail":"\n","#text":"ncatenation of training data and newly generated training items. The augmented-loss algorithm can be viewed as an online version of this algorithm which performs model updates based on the augmented-loss functions directly (rather than adding a set of examples to the training set). Unlike the CODL approach, we do not perform complete optimization on each iteration over the unlabeled dataset; rather, we incorporate the updates in our online learning algorithm. As mentioned earlier, CODL is one example of learning algorithms that use weak supervision, others include Mann and McCallum (2010) and Ganchev et al (2010). Again, these works are typically interested in using the extrinsic metric ? or, in general, extrinsic information ? to optimize the intrinsic metric in the absence of any labeled intrinsic data. Our goal is to optimize both simultaneously. The idea of jointly training parsers to optimize multiple objectives is related to joint learning and inference for tasks like information extraction (Finkel and Manning, 2009) and machine translation (Burkett et al, 2010). In such works, a large search space that covers both the space of parse structures and the space of task-specific structures is define","@endWordPosition":"5865","@position":"34147","annotationId":"T16","@startWordPosition":"5862","@citStr":"Ganchev et al (2010)"}]},"title":{"#tail":"\n","#text":"Posterior regularization for structured latent variable models."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"K Ganchev"},{"#tail":"\n","#text":"J Graca"},{"#tail":"\n","#text":"J Gillenwater"},{"#tail":"\n","#text":"B Taskar"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2001"},"rawString":{"#tail":"\n","#text":"D. Gildea. 2001. Corpus variation and parser performance. In Proc. of EMNLP."},"#text":"\n","marker":{"#tail":"\n","#text":"Gildea, 2001"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"-based parsing) and how it achieves increased performance on multiple target tasks including reordering for machine translation and parser adaptation. 1 Introduction The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks. This includes work on question answering (Wang et al, 2007), sentiment analysis (Nakagawa et al, 2010), MT reordering (Xu et al, 2009), and many other tasks. In most cases, the accuracy of parsers degrades when run on out-of-domain data (Gildea, 2001; McClosky et al, 2006; Blitzer et al, 2006; Petrov et al, 2010). But these accuracies are measured with respect to gold-standard out-of-domain parse trees. There are few tasks that actually depend on the complete parse tree. Furthermore, when evaluated on a downstream task, often the optimal parse output has a model score lower than the best parse as predicted by the parsing model. While this means that we are not properly modeling the downstream task in the parsers, it also means that there is some information from small task or domain-specific data sets which could help direct our search fo","@endWordPosition":"203","@position":"1465","annotationId":"T17","@startWordPosition":"202","@citStr":"Gildea, 2001"}},"title":{"#tail":"\n","#text":"Corpus variation and parser performance."},"booktitle":{"#tail":"\n","#text":"In Proc. of EMNLP."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"D Gildea"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"K. Hall. 2007. k-best spanning tree parsing. In Proc. of ACL, June."},"#text":"\n","marker":{"#tail":"\n","#text":"Hall, 2007"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ies of the first two words on the buffer and of the top word on the stack; the word identity of the syntactic head of the top word on the stack (if available); dependency arc label identities for the top word on the stack, the left and rightmost modifier of the top word on the stack, and the left most modifier of the first word in the buffer (if available). All feature conjunctions are included. ? Graph-based: An implementation of graphbased parsing algorithms with an arc-factored parameterization (McDonald et al, 2005). We use the non-projective k-best MST algorithm to generate k-best lists (Hall, 2007), where k = 8 for the experiments in this paper. The graphbased parser features used in the experiments in this paper are defined over a word, wi at position i; the head of this word w?(i) where ?(i) provides the index of the head word; and partof-speech tags of these words ti. We use the following set of features similar to McDonald et al (2005): isolated features: wi, ti, w?(i), t?(i) word-tag pairs: (wi, ti); (w?(i), t?(i)) word-head pairs: (wi, w?(i)), (ti, t?(i)) word-head-tag triples: (t?(i), wi, ti) (w?(i), wi, ti) (w?(i), t?(i), ti) (w?(i), t?(i), wi) tag-neighbourhood: (t?(i), t?(i)+1","@endWordPosition":"3349","@position":"18953","annotationId":"T18","@startWordPosition":"3348","@citStr":"Hall, 2007"}},"title":{"#tail":"\n","#text":"k-best spanning tree parsing."},"booktitle":{"#tail":"\n","#text":"In Proc. of ACL,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"K Hall"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"J. Judge, A. Cahill, and J. Van Genabith. 2006. Questionbank: Creating a corpus of parse-annotated questions. In Proc. of ACL, pages 497?504."},"#text":"\n","pages":{"#tail":"\n","#text":"497--504"},"marker":{"#tail":"\n","#text":"Judge, Cahill, Van Genabith, 2006"},"title":{"#tail":"\n","#text":"Questionbank: Creating a corpus of parse-annotated questions."},"booktitle":{"#tail":"\n","#text":"In Proc. of ACL,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"J Judge"},{"#tail":"\n","#text":"A Cahill"},{"#tail":"\n","#text":"J Van Genabith"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2011"},"rawString":{"#tail":"\n","#text":"J. Katz-Brown, S. Petrov, R. McDonald, D. Talbot, F. Och, H. Ichikawa, M. Seno, and H. Kazawa. 2011. Training a parser for machine translation reordering. In Proc. of EMNLP."},"#text":"\n","marker":{"#tail":"\n","#text":"Katz-Brown, Petrov, McDonald, Talbot, Och, Ichikawa, Seno, Kazawa, 2011"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"4) and found very similar improvements: for example, the transition parser?s LAS for the labeled loss is 88.68 and 88.84, respectively). We note that ALS can be decomposed locally and could be used as the primary objective function for parsing. A parse with perfect scores under ALS and LAS will match the gold-standard training tree. However, if we were to order incorrect parses of a sentence, ALS and LAS will suggest different orderings. Our results show that by optimizing for losses based on a combination of these metrics we train a more robust parsing model. 5 Related Work A recent study by Katz-Brown et al (2011) also investigates the task of training parsers to improve MT reordering. In that work, a parser is used to first parse a set of manually reordered sentences to produce k-best lists. The parse with the best reordering score is then fixed and added back to the training set and a new parser is trained on resulting data. The method is called targeted self-training as it is similar in vein to self-training (McClosky et al, 2006), with the exception that the new parse data is targeted to produce accurate word reorderings. Our method differs as it does not statically fix a new parse, but dynamically","@endWordPosition":"5389","@position":"31215","annotationId":"T19","@startWordPosition":"5386","@citStr":"Katz-Brown et al (2011)"}},"title":{"#tail":"\n","#text":"Training a parser for machine translation reordering."},"booktitle":{"#tail":"\n","#text":"In Proc. of EMNLP."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"J Katz-Brown"},{"#tail":"\n","#text":"S Petrov"},{"#tail":"\n","#text":"R McDonald"},{"#tail":"\n","#text":"D Talbot"},{"#tail":"\n","#text":"F Och"},{"#tail":"\n","#text":"H Ichikawa"},{"#tail":"\n","#text":"M Seno"},{"#tail":"\n","#text":"H Kazawa"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2009"},"rawString":{"#tail":"\n","#text":"S. Ku?bler, R. McDonald, and J. Nivre. 2009. Dependency parsing. Synthesis Lectures on Human Language Technologies. Morgan & Claypool Publishers."},"#text":"\n","marker":{"#tail":"\n","#text":"Kubler, McDonald, Nivre, 2009"},"publisher":{"#tail":"\n","#text":"Morgan & Claypool Publishers."},"title":{"#tail":"\n","#text":"Dependency parsing. Synthesis Lectures on Human Language Technologies."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"S Kubler"},{"#tail":"\n","#text":"R McDonald"},{"#tail":"\n","#text":"J Nivre"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"P. Liang, A. Bouchard-Ct, D. Klein, and B. Taskar. 2006. An end-to-end discriminative approach to machine translation. In Proc. of COLING/ACL."},"#text":"\n","marker":{"#tail":"\n","#text":"Liang, Bouchard-Ct, Klein, Taskar, 2006"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ack to the training set and a new parser is trained on resulting data. The method is called targeted self-training as it is similar in vein to self-training (McClosky et al, 2006), with the exception that the new parse data is targeted to produce accurate word reorderings. Our method differs as it does not statically fix a new parse, but dynamically updates the parameters and parse selection by incorporating the additional loss in the inner loop of online learning. This allows us to give guarantees of convergence. Furthermore, we also evaluate the method on alternate extrinsic loss functions. Liang et al (2006) presented a perceptron-based algorithm for learning the phrase-translation parameters in a statistical machine translation system. Similar to the inline-ranker loss function presented here, they use a k-best lists of hypotheses in order to identify parameters which can improve a global objective function: BLEU score. In their work, they are interested in learning a parameterization over translation phrases (including the underlying wordalignment) which optimizes the BLEU score. Their goal is considerably different; they want to incorporate additional features into their model and define an ob","@endWordPosition":"5540","@position":"32082","annotationId":"T20","@startWordPosition":"5537","@citStr":"Liang et al (2006)"}},"title":{"#tail":"\n","#text":"An end-to-end discriminative approach to machine translation."},"booktitle":{"#tail":"\n","#text":"In Proc. of COLING/ACL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"P Liang"},{"#tail":"\n","#text":"A Bouchard-Ct"},{"#tail":"\n","#text":"D Klein"},{"#tail":"\n","#text":"B Taskar"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2010"},"rawString":{"#tail":"\n","#text":"G.S. Mann and A. McCallum. 2010. Generalized Expectation Criteria for Semi-Supervised Learning with Weakly Labeled Data. The Journal of Machine Learning Research, 11:955?984."},"journal":{"#tail":"\n","#text":"The Journal of Machine Learning Research,"},"#text":"\n","pages":{"#tail":"\n","#text":"11--955"},"marker":{"#tail":"\n","#text":"Mann, McCallum, 2010"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" learner where a training instance is selected and the param1489 eters are optimized based on the objective function associated with the instance (either intrinsic or extrinsic), thus jointly optimizing multiple objectives. An update schedule trades-off the relative importance of each objective function. We call our algorithm augmented-loss training as it optimizes multiple losses to augment the traditional supervised parser loss. There have been a number of efforts to exploit weak or external signals of quality to train better prediction models. This includes work on generalized expectation (Mann and McCallum, 2010), posterior regularization (Ganchev et al, 2010) and constraint driven learning (Chang et al, 2007; Chang et al, 2010). The work of Chang et al (2007) on constraint driven learning is perhaps the closest to our framework and we draw connections to it in Section 5. In these studies the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics. For our setting this would mean using weak application specific signals to improve dependency parsing. Though we explore such ideas in our experiments, in particular for semi-supervised domain a","@endWordPosition":"633","@position":"4125","annotationId":"T21","@startWordPosition":"630","@citStr":"Mann and McCallum, 2010"},{"#tail":"\n","#text":"odel optimization with the concatenation of training data and newly generated training items. The augmented-loss algorithm can be viewed as an online version of this algorithm which performs model updates based on the augmented-loss functions directly (rather than adding a set of examples to the training set). Unlike the CODL approach, we do not perform complete optimization on each iteration over the unlabeled dataset; rather, we incorporate the updates in our online learning algorithm. As mentioned earlier, CODL is one example of learning algorithms that use weak supervision, others include Mann and McCallum (2010) and Ganchev et al (2010). Again, these works are typically interested in using the extrinsic metric ? or, in general, extrinsic information ? to optimize the intrinsic metric in the absence of any labeled intrinsic data. Our goal is to optimize both simultaneously. The idea of jointly training parsers to optimize multiple objectives is related to joint learning and inference for tasks like information extraction (Finkel and Manning, 2009) and machine translation (Burkett et al, 2010). In such works, a large search space that covers both the space of parse structures and the space of task-spec","@endWordPosition":"5860","@position":"34122","annotationId":"T22","@startWordPosition":"5856","@citStr":"Mann and McCallum (2010)"}]},"title":{"#tail":"\n","#text":"Generalized Expectation Criteria for Semi-Supervised Learning with Weakly Labeled Data."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"G S Mann"},{"#tail":"\n","#text":"A McCallum"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"1993"},"rawString":{"#tail":"\n","#text":"M. Marcus, B. Santorini, and M.A. Marcinkiewicz. 1993. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19:313?330."},"#text":"\n","marker":{"#tail":"\n","#text":"Marcus, Santorini, Marcinkiewicz, 1993"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"one. Augmented-loss learning is then applied to target a downstream task using the loss functions to measure gains. We show empirical results for two extrinsic loss-functions (optimizing for the downstream task): machine translation and domain adaptation; and for one intrinsic loss-function: an arclength parsing score. For some experiments we also 1493 measure the standard intrinsic parser metrics unlabeled attachment score (UAS) and labeled attachment score (LAS) (Buchholz and Marsi, 2006). In terms of treebank data, the primary training corpus is the Penn Wall Street Journal Treebank (PTB) (Marcus et al, 1993). We also make use of the Brown corpus, and the Question Treebank (QTB) (Judge et al, 2006). For PTB and Brown we use standard training/development/testing splits of the data. For the QTB we split the data into three sections: 2000 training, 1000 development, and 1000 test. All treebanks are converted to dependency format using the Stanford converter v1.6 (de Marneffe et al, 2006). 4 Experiments 4.1 Machine Translation Reordering Score As alluded to in Section 2.2, we use a reorderingbased loss function to improve word order in a machine translation system. In particular, we use a system of so","@endWordPosition":"3621","@position":"20557","annotationId":"T23","@startWordPosition":"3618","@citStr":"Marcus et al, 1993"}},"title":{"#tail":"\n","#text":"Building a large annotated corpus of english: The penn treebank. Computational Linguistics,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"M Marcus"},{"#tail":"\n","#text":"B Santorini"},{"#tail":"\n","#text":"M A Marcinkiewicz"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2006"},"rawString":{"#tail":"\n","#text":"D. McClosky, E. Charniak, and M. Johnson. 2006. Reranking and self-training for parser adaptation. In Proc. of ACL."},"#text":"\n","marker":{"#tail":"\n","#text":"McClosky, Charniak, Johnson, 2006"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":") and how it achieves increased performance on multiple target tasks including reordering for machine translation and parser adaptation. 1 Introduction The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks. This includes work on question answering (Wang et al, 2007), sentiment analysis (Nakagawa et al, 2010), MT reordering (Xu et al, 2009), and many other tasks. In most cases, the accuracy of parsers degrades when run on out-of-domain data (Gildea, 2001; McClosky et al, 2006; Blitzer et al, 2006; Petrov et al, 2010). But these accuracies are measured with respect to gold-standard out-of-domain parse trees. There are few tasks that actually depend on the complete parse tree. Furthermore, when evaluated on a downstream task, often the optimal parse output has a model score lower than the best parse as predicted by the parsing model. While this means that we are not properly modeling the downstream task in the parsers, it also means that there is some information from small task or domain-specific data sets which could help direct our search for optimal parameters d","@endWordPosition":"207","@position":"1487","annotationId":"T24","@startWordPosition":"204","@citStr":"McClosky et al, 2006"},{"#tail":"\n","#text":" orderings. Our results show that by optimizing for losses based on a combination of these metrics we train a more robust parsing model. 5 Related Work A recent study by Katz-Brown et al (2011) also investigates the task of training parsers to improve MT reordering. In that work, a parser is used to first parse a set of manually reordered sentences to produce k-best lists. The parse with the best reordering score is then fixed and added back to the training set and a new parser is trained on resulting data. The method is called targeted self-training as it is similar in vein to self-training (McClosky et al, 2006), with the exception that the new parse data is targeted to produce accurate word reorderings. Our method differs as it does not statically fix a new parse, but dynamically updates the parameters and parse selection by incorporating the additional loss in the inner loop of online learning. This allows us to give guarantees of convergence. Furthermore, we also evaluate the method on alternate extrinsic loss functions. Liang et al (2006) presented a perceptron-based algorithm for learning the phrase-translation parameters in a statistical machine translation system. Similar to the inline-ranker ","@endWordPosition":"5467","@position":"31643","annotationId":"T25","@startWordPosition":"5464","@citStr":"McClosky et al, 2006"}]},"title":{"#tail":"\n","#text":"Reranking and self-training for parser adaptation."},"booktitle":{"#tail":"\n","#text":"In Proc. of ACL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"D McClosky"},{"#tail":"\n","#text":"E Charniak"},{"#tail":"\n","#text":"M Johnson"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"R. McDonald and J. Nivre. 2007. Characterizing the errors of data-driven dependency parsing models. In Proc. of EMNLP-CoNLL."},"#text":"\n","marker":{"#tail":"\n","#text":"McDonald, Nivre, 2007"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":": ALS = ? i ?(??i, ?i)(i? ?i)? i(i? ?i) For each word of the sentence we compute the distance between the word?s position i and the position of the words head ?i. The arc-length score is the summed length of all those with correct head assignments (?(??i, ?i) is 1 if the predicted head and the correct head match, 0 otherwise). The score is normalized by the summed arc lengths for the sentence. The labeled version of this score requires that the labels of the arc are also correct. Optimizing for dependency arc length is particularly important as parsers tend to do worse on longer dependencies (McDonald and Nivre, 2007) and these dependencies are typically the most meaningful for downstream tasks, e.g., main verb dependencies for tasks 2For the graph-based parser one can also find the higest scoring tree with correct root by setting the score of all competing arcs to ??. 1495 LAS UAS ALS trans?PTB 88.64 91.64 82.96 trans?unlabeled aug.-loss 88.74 91.91 83.65 trans?labeled aug.-loss 88.84 91.91 83.46 graph?PTB 85.75 88.70 73.88 graph?unlabeled aug.-loss 85.80 88.81 74.26 graph?labeled aug.-loss 85.85 88.93 74.40 Table 3: Results for both parsers on the development set of the PTB. When training with ALS (label","@endWordPosition":"4931","@position":"28416","annotationId":"T26","@startWordPosition":"4928","@citStr":"McDonald and Nivre, 2007"}},"title":{"#tail":"\n","#text":"Characterizing the errors of data-driven dependency parsing models."},"booktitle":{"#tail":"\n","#text":"In Proc. of EMNLP-CoNLL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"R McDonald"},{"#tail":"\n","#text":"J Nivre"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2005"},"rawString":{"#tail":"\n","#text":"R. McDonald, K. Crammer, and F. Pereira. 2005. Online large-margin training of dependency parsers. In Proc. of ACL."},"#text":"\n","marker":{"#tail":"\n","#text":"McDonald, Crammer, Pereira, 2005"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"d-standard ?(yi), and discounting features that fire in the predicted output, ?(y?i). The structured perceptron, as given in Algorithm 1, only updates when there is a positive loss, meaning that there was a prediction mistake. For the moment we will abstract away from details such as the precise definition of F (x) and ?(y). We will show in the next section that our augmentedloss method is general and can be applied to any dependency parsing framework that can be trained by the perceptron algorithm, such as transition-based parsers (Nivre, 2008; Zhang and Clark, 2008) and graph-based parsers (McDonald et al, 2005). 2.1 Augmented-Loss Training The augmented-loss training algorithm that we propose is based on the structured perceptron; however, the augmented-loss training framework is a general 1490 mechanism to incorporate multiple loss functions in online learner training. Algorithm 2 is the pseudocode for the augmented-loss structured perceptron algorithm. The algorithm is an extension to Algorithm 1 where there are 1) multiple loss functions being evaluated L1, . . . , LM ; 2) there are multiple datasets associated with each of these loss functions D1, . . . ,DM ; and 3) there is a schedule for proce","@endWordPosition":"1224","@position":"7497","annotationId":"T27","@startWordPosition":"1221","@citStr":"McDonald et al, 2005"},{"#tail":"\n","#text":"gs of the first four words on the buffer and of the top two words on the stack; the word identities of the first two words on the buffer and of the top word on the stack; the word identity of the syntactic head of the top word on the stack (if available); dependency arc label identities for the top word on the stack, the left and rightmost modifier of the top word on the stack, and the left most modifier of the first word in the buffer (if available). All feature conjunctions are included. ? Graph-based: An implementation of graphbased parsing algorithms with an arc-factored parameterization (McDonald et al, 2005). We use the non-projective k-best MST algorithm to generate k-best lists (Hall, 2007), where k = 8 for the experiments in this paper. The graphbased parser features used in the experiments in this paper are defined over a word, wi at position i; the head of this word w?(i) where ?(i) provides the index of the head word; and partof-speech tags of these words ti. We use the following set of features similar to McDonald et al (2005): isolated features: wi, ti, w?(i), t?(i) word-tag pairs: (wi, ti); (w?(i), t?(i)) word-head pairs: (wi, w?(i)), (ti, t?(i)) word-head-tag triples: (t?(i), wi, ti) (w","@endWordPosition":"3336","@position":"18867","annotationId":"T28","@startWordPosition":"3333","@citStr":"McDonald et al, 2005"}]},"title":{"#tail":"\n","#text":"Online large-margin training of dependency parsers."},"booktitle":{"#tail":"\n","#text":"In Proc. of ACL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"R McDonald"},{"#tail":"\n","#text":"K Crammer"},{"#tail":"\n","#text":"F Pereira"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2010"},"rawString":{"#tail":"\n","#text":"T. Nakagawa, K. Inui, and S. Kurohashi. 2010. Dependency tree-based sentiment classification using crfs with hidden variables. In Proc. of NAACL."},"#text":"\n","marker":{"#tail":"\n","#text":"Nakagawa, Inui, Kurohashi, 2010"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"ecific extrinsic measures of quality. Our empirical results show how this approach performs for two dependency parsing algorithms (graph-based and transition-based parsing) and how it achieves increased performance on multiple target tasks including reordering for machine translation and parser adaptation. 1 Introduction The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks. This includes work on question answering (Wang et al, 2007), sentiment analysis (Nakagawa et al, 2010), MT reordering (Xu et al, 2009), and many other tasks. In most cases, the accuracy of parsers degrades when run on out-of-domain data (Gildea, 2001; McClosky et al, 2006; Blitzer et al, 2006; Petrov et al, 2010). But these accuracies are measured with respect to gold-standard out-of-domain parse trees. There are few tasks that actually depend on the complete parse tree. Furthermore, when evaluated on a downstream task, often the optimal parse output has a model score lower than the best parse as predicted by the parsing model. While this means that we are not properly modeling the downstream ","@endWordPosition":"177","@position":"1317","annotationId":"T29","@startWordPosition":"174","@citStr":"Nakagawa et al, 2010"}},"title":{"#tail":"\n","#text":"Dependency tree-based sentiment classification using crfs with hidden variables."},"booktitle":{"#tail":"\n","#text":"In Proc. of NAACL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"T Nakagawa"},{"#tail":"\n","#text":"K Inui"},{"#tail":"\n","#text":"S Kurohashi"}]}},{"volume":{"#tail":"\n","#text":"34"},"#tail":"\n","date":{"#tail":"\n","#text":"2008"},"rawString":{"#tail":"\n","#text":"J. Nivre. 2008. Algorithms for deterministic incremental dependency parsing. Computational Linguistics, 34(4):513?553."},"journal":{"#tail":"\n","#text":"Computational Linguistics,"},"#text":"\n","issue":{"#tail":"\n","#text":"4"},"marker":{"#tail":"\n","#text":"Nivre, 2008"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":", updating the model: rewarding features that fire in the gold-standard ?(yi), and discounting features that fire in the predicted output, ?(y?i). The structured perceptron, as given in Algorithm 1, only updates when there is a positive loss, meaning that there was a prediction mistake. For the moment we will abstract away from details such as the precise definition of F (x) and ?(y). We will show in the next section that our augmentedloss method is general and can be applied to any dependency parsing framework that can be trained by the perceptron algorithm, such as transition-based parsers (Nivre, 2008; Zhang and Clark, 2008) and graph-based parsers (McDonald et al, 2005). 2.1 Augmented-Loss Training The augmented-loss training algorithm that we propose is based on the structured perceptron; however, the augmented-loss training framework is a general 1490 mechanism to incorporate multiple loss functions in online learner training. Algorithm 2 is the pseudocode for the augmented-loss structured perceptron algorithm. The algorithm is an extension to Algorithm 1 where there are 1) multiple loss functions being evaluated L1, . . . , LM ; 2) there are multiple datasets associated with each of th","@endWordPosition":"1213","@position":"7426","annotationId":"T30","@startWordPosition":"1212","@citStr":"Nivre, 2008"},{"#tail":"\n","#text":"e. It may be the case that for most instances a small k is required, but the algorithm is doing more work unnecessarily if k is large. 3 Experimental Set-up 3.1 Dependency Parsers The augmented-loss framework we present is general in the sense that it can be combined with any loss function and any parser, provided the parser can be parameterized as a linear classifier, trained with the perceptron and is capable of producing a k-best list of trees. For our experiments we focus on two dependency parsers. ? Transition-based: An implementation of the transition-based dependency parsing framework (Nivre, 2008) using an arc-eager transition strategy and are trained using the perceptron algorithm as in Zhang and Clark (2008) with a beam size of 8. Beams with varying sizes can be used to produce k-best lists. The features used by all models are: the part-ofspeech tags of the first four words on the buffer and of the top two words on the stack; the word identities of the first two words on the buffer and of the top word on the stack; the word identity of the syntactic head of the top word on the stack (if available); dependency arc label identities for the top word on the stack, the left and rightmost ","@endWordPosition":"3174","@position":"17988","annotationId":"T31","@startWordPosition":"3173","@citStr":"Nivre, 2008"}]},"title":{"#tail":"\n","#text":"Algorithms for deterministic incremental dependency parsing."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":{"#tail":"\n","#text":"J Nivre"}}},{"#tail":"\n","date":{"#tail":"\n","#text":"2010"},"rawString":{"#tail":"\n","#text":"S. Petrov, P.C. Chang, M. Ringgaard, and H. Alshawi. 2010. Uptraining for accurate deterministic question parsing. In Proc. of EMNLP, pages 705?713."},"#text":"\n","pages":{"#tail":"\n","#text":"705--713"},"marker":{"#tail":"\n","#text":"Petrov, Chang, Ringgaard, Alshawi, 2010"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":" on multiple target tasks including reordering for machine translation and parser adaptation. 1 Introduction The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks. This includes work on question answering (Wang et al, 2007), sentiment analysis (Nakagawa et al, 2010), MT reordering (Xu et al, 2009), and many other tasks. In most cases, the accuracy of parsers degrades when run on out-of-domain data (Gildea, 2001; McClosky et al, 2006; Blitzer et al, 2006; Petrov et al, 2010). But these accuracies are measured with respect to gold-standard out-of-domain parse trees. There are few tasks that actually depend on the complete parse tree. Furthermore, when evaluated on a downstream task, often the optimal parse output has a model score lower than the best parse as predicted by the parsing model. While this means that we are not properly modeling the downstream task in the parsers, it also means that there is some information from small task or domain-specific data sets which could help direct our search for optimal parameters during parser training. The goal being not ","@endWordPosition":"215","@position":"1529","annotationId":"T32","@startWordPosition":"212","@citStr":"Petrov et al, 2010"},{"#tail":"\n","#text":"d by the reordering score as well as a coarse exact-match score (the number of sentences which would have correct word-order given the parse and the fixed reordering rules). We see continued improvements as we adjust the schedule to process the extrinsic loss more frequently, the best result being when we make two augmented-loss updates for every one treebank-based loss update. 4.2 Semi-supervised domain adaptation Another application of the augmented-loss framework is to improve parser domain portability in the presence of partially labeled data. Consider, for example, the case of questions. Petrov et al (2010) observed that dependency parsers tend to do quite poorly when parsing questions due to their limited exposure to them in the news corpora from the PennTreebank. Table 2 shows the accuracy of two parsers (LAS, UAS and the F1 of the root dependency attachment) on the QuestionBank test data. The first is a parser trained on the standard training sections of the PennTreebank (PTB) and the second is a parser trained on the training portion of the QuestionBank (QTB). Results for both 1494 LAS UAS Root-F1 trans?PTB 67.97 73.52 47.60 trans?QTB 84.59 89.59 91.06 trans?aug.-loss 76.27 86.42 83.41 graph","@endWordPosition":"4148","@position":"23869","annotationId":"T33","@startWordPosition":"4145","@citStr":"Petrov et al (2010)"}]},"title":{"#tail":"\n","#text":"Uptraining for accurate deterministic question parsing."},"booktitle":{"#tail":"\n","#text":"In Proc. of EMNLP,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"S Petrov"},{"#tail":"\n","#text":"P C Chang"},{"#tail":"\n","#text":"M Ringgaard"},{"#tail":"\n","#text":"H Alshawi"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2011"},"rawString":{"#tail":"\n","#text":"D. Talbot, H. Kazawa, H. Ichikawa, J. Katz-Brown, M. Seno, and F. Och. 2011. A lightweight evaluation framework for machine translation reordering. In Proc. of the Sixth Workshop on Statistical Machine Translation."},"#text":"\n","marker":{"#tail":"\n","#text":"Talbot, Kazawa, Ichikawa, Katz-Brown, Seno, Och, 2011"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"84 graph?0.5? aug.-loss 28.99 72.23 graph?1.0?aug.-loss 29.99 72.88 graph?2.0?aug.-loss 30.03 73.15 Table 1: Reordering scores for parser-based reordering (English-to-Japanese). Exact is the number of correctly reordered sentences. All models use the same treebankdata (PTB, QTB, and the Brown corpus). Results for three augmented-loss schedules are shown: 0.5 where for every two treebank updates we make one augmented-loss update, 1 is a 1-to-1 mix, and 2 is where we make twice as many augmented-loss updates as treebank updates. criteria and data used in our experiments are based on the work of Talbot et al (2011). Table 1 shows the results of using the reordering cost as an augmented-loss to the standard treebank objective function. Results are presented as measured by the reordering score as well as a coarse exact-match score (the number of sentences which would have correct word-order given the parse and the fixed reordering rules). We see continued improvements as we adjust the schedule to process the extrinsic loss more frequently, the best result being when we make two augmented-loss updates for every one treebank-based loss update. 4.2 Semi-supervised domain adaptation Another application of the","@endWordPosition":"4025","@position":"23095","annotationId":"T34","@startWordPosition":"4022","@citStr":"Talbot et al (2011)"}},"title":{"#tail":"\n","#text":"A lightweight evaluation framework for machine translation reordering."},"booktitle":{"#tail":"\n","#text":"In Proc. of the Sixth Workshop on Statistical Machine Translation."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"D Talbot"},{"#tail":"\n","#text":"H Kazawa"},{"#tail":"\n","#text":"H Ichikawa"},{"#tail":"\n","#text":"J Katz-Brown"},{"#tail":"\n","#text":"M Seno"},{"#tail":"\n","#text":"F Och"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2007"},"rawString":{"#tail":"\n","#text":"M. Wang, N.A. Smith, and T. Mitamura. 2007. What is the Jeopardy model? A quasi-synchronous grammar for QA. In Proc. of EMNLP-CoNLL."},"#text":"\n","marker":{"#tail":"\n","#text":"Wang, Smith, Mitamura, 2007"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"on intrinsic parsing quality or task-specific extrinsic measures of quality. Our empirical results show how this approach performs for two dependency parsing algorithms (graph-based and transition-based parsing) and how it achieves increased performance on multiple target tasks including reordering for machine translation and parser adaptation. 1 Introduction The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks. This includes work on question answering (Wang et al, 2007), sentiment analysis (Nakagawa et al, 2010), MT reordering (Xu et al, 2009), and many other tasks. In most cases, the accuracy of parsers degrades when run on out-of-domain data (Gildea, 2001; McClosky et al, 2006; Blitzer et al, 2006; Petrov et al, 2010). But these accuracies are measured with respect to gold-standard out-of-domain parse trees. There are few tasks that actually depend on the complete parse tree. Furthermore, when evaluated on a downstream task, often the optimal parse output has a model score lower than the best parse as predicted by the parsing model. While this means that w","@endWordPosition":"171","@position":"1274","annotationId":"T35","@startWordPosition":"168","@citStr":"Wang et al, 2007"}},"title":{"#tail":"\n","#text":"What is the Jeopardy model? A quasi-synchronous grammar for QA."},"booktitle":{"#tail":"\n","#text":"In Proc. of EMNLP-CoNLL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"M Wang"},{"#tail":"\n","#text":"N A Smith"},{"#tail":"\n","#text":"T Mitamura"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2009"},"rawString":{"#tail":"\n","#text":"P. Xu, J. Kang, M. Ringgaard, and F. Och. 2009. Using a dependency parser to improve SMT for SubjectObject-Verb languages. In Proc. of NAACL."},"#text":"\n","marker":{"#tail":"\n","#text":"Xu, Kang, Ringgaard, Och, 2009"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"Our empirical results show how this approach performs for two dependency parsing algorithms (graph-based and transition-based parsing) and how it achieves increased performance on multiple target tasks including reordering for machine translation and parser adaptation. 1 Introduction The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks. This includes work on question answering (Wang et al, 2007), sentiment analysis (Nakagawa et al, 2010), MT reordering (Xu et al, 2009), and many other tasks. In most cases, the accuracy of parsers degrades when run on out-of-domain data (Gildea, 2001; McClosky et al, 2006; Blitzer et al, 2006; Petrov et al, 2010). But these accuracies are measured with respect to gold-standard out-of-domain parse trees. There are few tasks that actually depend on the complete parse tree. Furthermore, when evaluated on a downstream task, often the optimal parse output has a model score lower than the best parse as predicted by the parsing model. While this means that we are not properly modeling the downstream task in the parsers, it also mea","@endWordPosition":"183","@position":"1349","annotationId":"T36","@startWordPosition":"180","@citStr":"Xu et al, 2009"},{"#tail":"\n","#text":"with translation quality (Banerjee and Lavie, 2005) and is simpler to measure. reorder-score = 1? # chunks? 1# unigrams matched? 1 reorder-cost = 1? reorder-score All reordering augmented-loss experiments are run with the same treebank data as the baseline (the training portions of PTB, Brown, and QTB). The extrinsic reordering training data consists of 10930 examples of English sentences and their correct Japanese word-order. We evaluate our results on an evaluation set of 6338 examples of similarly created reordering data. The reordering cost, evaluation 1Our rules are similar to those from Xu et al (2009). Exact Reorder trans?PTB + Brown + QTB 35.29 76.49 trans?0.5?aug.-loss 38.71 78.19 trans?1.0?aug.-loss 39.02 78.39 trans?2.0?aug.-loss 39.58 78.67 graph?PTB + Brown + QTB 25.71 69.84 graph?0.5? aug.-loss 28.99 72.23 graph?1.0?aug.-loss 29.99 72.88 graph?2.0?aug.-loss 30.03 73.15 Table 1: Reordering scores for parser-based reordering (English-to-Japanese). Exact is the number of correctly reordered sentences. All models use the same treebankdata (PTB, QTB, and the Brown corpus). Results for three augmented-loss schedules are shown: 0.5 where for every two treebank updates we make one augmented","@endWordPosition":"3906","@position":"22295","annotationId":"T37","@startWordPosition":"3903","@citStr":"Xu et al (2009)"}]},"title":{"#tail":"\n","#text":"Using a dependency parser to improve SMT for SubjectObject-Verb languages. In"},"booktitle":{"#tail":"\n","#text":"Proc. of NAACL."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"P Xu"},{"#tail":"\n","#text":"J Kang"},{"#tail":"\n","#text":"M Ringgaard"},{"#tail":"\n","#text":"F Och"}]}},{"volume":{"#tail":"\n","#text":"34"},"#tail":"\n","date":{"#tail":"\n","#text":"2009"},"rawString":{"#tail":"\n","#text":"A. Yates and O. Etzioni. 2009. Unsupervised methods for determining object and relation synonyms on the web. Journal of Artificial Intelligence Research, 34(1):255?296."},"journal":{"#tail":"\n","#text":"Journal of Artificial Intelligence Research,"},"#text":"\n","issue":{"#tail":"\n","#text":"1"},"marker":{"#tail":"\n","#text":"Yates, Etzioni, 2009"},"contexts":{"#tail":"\n","#text":"\n","context":{"#tail":"\n","#text":"g the score of all competing arcs to ??. 1495 LAS UAS ALS trans?PTB 88.64 91.64 82.96 trans?unlabeled aug.-loss 88.74 91.91 83.65 trans?labeled aug.-loss 88.84 91.91 83.46 graph?PTB 85.75 88.70 73.88 graph?unlabeled aug.-loss 85.80 88.81 74.26 graph?labeled aug.-loss 85.85 88.93 74.40 Table 3: Results for both parsers on the development set of the PTB. When training with ALS (labeled and unlabeled), we see an improvement in UAS, LAS, and ALS. Furthermore, if we use a labeled-ALS as the metric for augmented-loss training, we also see a considerable increase in LAS. like information extraction (Yates and Etzioni, 2009) and textual entailment (Berant et al, 2010). In Table 3 we show results for parsing with the ALS augmented-loss objective. For each parser, we consider two different ALS objective functions; one based on unlabeled-ALS and the other on labeledALS. The arc-length score penalizes incorrect longdistance dependencies more than local dependencies; long-distance dependencies are often more destructive in preserving sentence meaning and can be more difficult to predict correctly due to the larger context on which they depend. Combining this with the standard attachment scores biases training to focus","@endWordPosition":"5066","@position":"29256","annotationId":"T38","@startWordPosition":"5063","@citStr":"Yates and Etzioni, 2009"}},"title":{"#tail":"\n","#text":"Unsupervised methods for determining object and relation synonyms on the web."},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"A Yates"},{"#tail":"\n","#text":"O Etzioni"}]}},{"#tail":"\n","date":{"#tail":"\n","#text":"2008"},"rawString":{"#tail":"\n","#text":"Y. Zhang and S. Clark. 2008. A Tale of Two Parsers: Investigating and Combining Graph-based and Transition-based Dependency Parsing. In Proc. of EMNLP, pages 562?571."},"#text":"\n","pages":{"#tail":"\n","#text":"562--571"},"marker":{"#tail":"\n","#text":"Zhang, Clark, 2008"},"contexts":{"#tail":"\n","#text":"\n","context":[{"#tail":"\n","#text":"e model: rewarding features that fire in the gold-standard ?(yi), and discounting features that fire in the predicted output, ?(y?i). The structured perceptron, as given in Algorithm 1, only updates when there is a positive loss, meaning that there was a prediction mistake. For the moment we will abstract away from details such as the precise definition of F (x) and ?(y). We will show in the next section that our augmentedloss method is general and can be applied to any dependency parsing framework that can be trained by the perceptron algorithm, such as transition-based parsers (Nivre, 2008; Zhang and Clark, 2008) and graph-based parsers (McDonald et al, 2005). 2.1 Augmented-Loss Training The augmented-loss training algorithm that we propose is based on the structured perceptron; however, the augmented-loss training framework is a general 1490 mechanism to incorporate multiple loss functions in online learner training. Algorithm 2 is the pseudocode for the augmented-loss structured perceptron algorithm. The algorithm is an extension to Algorithm 1 where there are 1) multiple loss functions being evaluated L1, . . . , LM ; 2) there are multiple datasets associated with each of these loss functions D1, .","@endWordPosition":"1217","@position":"7450","annotationId":"T39","@startWordPosition":"1214","@citStr":"Zhang and Clark, 2008"},{"#tail":"\n","#text":" unnecessarily if k is large. 3 Experimental Set-up 3.1 Dependency Parsers The augmented-loss framework we present is general in the sense that it can be combined with any loss function and any parser, provided the parser can be parameterized as a linear classifier, trained with the perceptron and is capable of producing a k-best list of trees. For our experiments we focus on two dependency parsers. ? Transition-based: An implementation of the transition-based dependency parsing framework (Nivre, 2008) using an arc-eager transition strategy and are trained using the perceptron algorithm as in Zhang and Clark (2008) with a beam size of 8. Beams with varying sizes can be used to produce k-best lists. The features used by all models are: the part-ofspeech tags of the first four words on the buffer and of the top two words on the stack; the word identities of the first two words on the buffer and of the top word on the stack; the word identity of the syntactic head of the top word on the stack (if available); dependency arc label identities for the top word on the stack, the left and rightmost modifier of the top word on the stack, and the left most modifier of the first word in the buffer (if available). A","@endWordPosition":"3194","@position":"18103","annotationId":"T40","@startWordPosition":"3191","@citStr":"Zhang and Clark (2008)"}]},"title":{"#tail":"\n","#text":"A Tale of Two Parsers: Investigating and Combining Graph-based and Transition-based Dependency Parsing."},"booktitle":{"#tail":"\n","#text":"In Proc. of EMNLP,"},"@valid":"true","authors":{"#tail":"\n","#text":"\n","author":[{"#tail":"\n","#text":"Y Zhang"},{"#tail":"\n","#text":"S Clark"}]}}]}}]}}
