inimization of transducers). This programming paradigm supports efficient nondeterminism, including parallel processing over infinite sets of input strings, and even allows ?reverse? computation from output to input. Its unusual flexibility for the practiced programmer stems from the many operations under which rational relations are closed. It is common to define further useful operations (as macros), which modify existing relations not by editing their source code but simply by operating on them ?from outside.? ?A brief version of this work, with some additional material, first appeared as (Eisner, 2001a). A leisurely journal-length version with more details has been prepared and is available. The entire paradigm has been generalized to weighted relations, which assign a weight to each (input, output) pair rather than simply including or excluding it. If these weights represent probabilities P (input, output) or P (output | input), the weighted relation is called a joint or conditional (probabilistic) relation and constitutes a statistical model. Such models can be efficiently restricted, manipulated or combined using rational operations as before. An artificial example will appear in ?2. Th
tails has been prepared and is available. The entire paradigm has been generalized to weighted relations, which assign a weight to each (input, output) pair rather than simply including or excluding it. If these weights represent probabilities P (input, output) or P (output | input), the weighted relation is called a joint or conditional (probabilistic) relation and constitutes a statistical model. Such models can be efficiently restricted, manipulated or combined using rational operations as before. An artificial example will appear in ?2. The availability of toolkits for this weighted case (Mohri et al, 1998; van Noord and Gerdemann, 2001) promises to unify much of statistical NLP. Such tools make it easy to run most current approaches to statistical markup, chunking, normalization, segmentation, alignment, and noisy-channel decoding,1 including classic models for speech recognition (Pereira and Riley, 1997) and machine translation (Knight and Al-Onaizan, 1998). Moreover, once the models are expressed in the finitestate framework, it is easy to use operators to tweak them, to apply them to speech lattices or other sets, and to combine them with linguistic resources. Unfortunately, there is a stum
elation is called a joint or conditional (probabilistic) relation and constitutes a statistical model. Such models can be efficiently restricted, manipulated or combined using rational operations as before. An artificial example will appear in ?2. The availability of toolkits for this weighted case (Mohri et al, 1998; van Noord and Gerdemann, 2001) promises to unify much of statistical NLP. Such tools make it easy to run most current approaches to statistical markup, chunking, normalization, segmentation, alignment, and noisy-channel decoding,1 including classic models for speech recognition (Pereira and Riley, 1997) and machine translation (Knight and Al-Onaizan, 1998). Moreover, once the models are expressed in the finitestate framework, it is easy to use operators to tweak them, to apply them to speech lattices or other sets, and to combine them with linguistic resources. Unfortunately, there is a stumbling block: Where do the weights come from? After all, statistical models require supervised or unsupervised training. Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs. Not only do these methods require additional programming outs
istic) relation and constitutes a statistical model. Such models can be efficiently restricted, manipulated or combined using rational operations as before. An artificial example will appear in ?2. The availability of toolkits for this weighted case (Mohri et al, 1998; van Noord and Gerdemann, 2001) promises to unify much of statistical NLP. Such tools make it easy to run most current approaches to statistical markup, chunking, normalization, segmentation, alignment, and noisy-channel decoding,1 including classic models for speech recognition (Pereira and Riley, 1997) and machine translation (Knight and Al-Onaizan, 1998). Moreover, once the models are expressed in the finitestate framework, it is easy to use operators to tweak them, to apply them to speech lattices or other sets, and to combine them with linguistic resources. Unfortunately, there is a stumbling block: Where do the weights come from? After all, statistical models require supervised or unsupervised training. Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs. Not only do these methods require additional programming outside the toolkit, but they are limited to particular ki
 to use operators to tweak them, to apply them to speech lattices or other sets, and to combine them with linguistic resources. Unfortunately, there is a stumbling block: Where do the weights come from? After all, statistical models require supervised or unsupervised training. Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs. Not only do these methods require additional programming outside the toolkit, but they are limited to particular kinds of models and training regimens. For example, the forward-backward algorithm (Baum, 1972) trains only Hidden Markov Models, while (Ristad and Yianilos, 1996) trains only stochastic edit distance. In short, current finite-state toolkits include no training algorithms, because none exist for the large space of statistical models that the toolkits can in principle describe and run. 1Given output, find input to maximize P (input, output). Computational Linguistics (ACL), Philadelphia, July 2002, pp. 1-8. Proceedings of the 40th Annual Meeting of the Association for (a) (b) 0/.15 a:x/.63 1/.15a: /.07? 2/.5b: /.003? b:z/.12 3/.5 b:x/.027 a: /.7? b: /.03? b:z/.12 b: /.1? b:z/.4 b: /.01? 
ech lattices or other sets, and to combine them with linguistic resources. Unfortunately, there is a stumbling block: Where do the weights come from? After all, statistical models require supervised or unsupervised training. Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs. Not only do these methods require additional programming outside the toolkit, but they are limited to particular kinds of models and training regimens. For example, the forward-backward algorithm (Baum, 1972) trains only Hidden Markov Models, while (Ristad and Yianilos, 1996) trains only stochastic edit distance. In short, current finite-state toolkits include no training algorithms, because none exist for the large space of statistical models that the toolkits can in principle describe and run. 1Given output, find input to maximize P (input, output). Computational Linguistics (ACL), Philadelphia, July 2002, pp. 1-8. Proceedings of the 40th Annual Meeting of the Association for (a) (b) 0/.15 a:x/.63 1/.15a: /.07? 2/.5b: /.003? b:z/.12 3/.5 b:x/.027 a: /.7? b: /.03? b:z/.12 b: /.1? b:z/.4 b: /.01? b:z/.4b:x/.09 4/.15 a:p/.7 5/.5b:p/.03b:q/.12 b:p/.1b:q/.4 (c) 6/1 p
t) is a weighted regular relation, then the following statements are equivalent: (1) f is a joint probabilistic relation; (2) f can be computed by a Markovian FST that halts with probability 1; (3) f can be expressed as a probabilistic regexp, i.e., a regexp built up from atomic expressions a : b (for a ? ?? {}, b ? ?? {}) using concatenation, probabilistic union +p, and probabilistic closure ?p. For defining conditional relations, a good regexp language is unknown to us, but they can be defined in several other ways: (1) via FSTs as in Fig. 1c, (2) by compilation of weighted rewrite rules (Mohri and Sproat, 1996), (3) by compilation of decision trees (Sproat and Riley, 1996), (4) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation (Gerdemann and van Noord, 1999),5 (5) by conditionalization of a joint relation as discussed below. A central technique is to define a joint relation as a noisy-channel model, by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 (Pereira and Riley, 1997; Knight and Graehl, 1998). The general form is illustrated by 3Conceptually, the parameters represent the probabilit
s are equivalent: (1) f is a joint probabilistic relation; (2) f can be computed by a Markovian FST that halts with probability 1; (3) f can be expressed as a probabilistic regexp, i.e., a regexp built up from atomic expressions a : b (for a ? ?? {}, b ? ?? {}) using concatenation, probabilistic union +p, and probabilistic closure ?p. For defining conditional relations, a good regexp language is unknown to us, but they can be defined in several other ways: (1) via FSTs as in Fig. 1c, (2) by compilation of weighted rewrite rules (Mohri and Sproat, 1996), (3) by compilation of decision trees (Sproat and Riley, 1996), (4) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation (Gerdemann and van Noord, 1999),5 (5) by conditionalization of a joint relation as discussed below. A central technique is to define a joint relation as a noisy-channel model, by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 (Pereira and Riley, 1997; Knight and Graehl, 1998). The general form is illustrated by 3Conceptually, the parameters represent the probabilities of reading another a (?); reading another b (?); transducin
they can be defined in several other ways: (1) via FSTs as in Fig. 1c, (2) by compilation of weighted rewrite rules (Mohri and Sproat, 1996), (3) by compilation of decision trees (Sproat and Riley, 1996), (4) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation (Gerdemann and van Noord, 1999),5 (5) by conditionalization of a joint relation as discussed below. A central technique is to define a joint relation as a noisy-channel model, by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 (Pereira and Riley, 1997; Knight and Graehl, 1998). The general form is illustrated by 3Conceptually, the parameters represent the probabilities of reading another a (?); reading another b (?); transducing b to p rather than q (?); starting to transduce p to  rather than x (?). 4To prove (1)?(3), express f as an FST and apply the well-known Kleene-Schu?tzenberger construction (Berstel and Reutenauer, 1988), taking care to write each regexp in the construction as a constant times a probabilistic regexp. A full proof is straightforward, as are proofs of (3)?(2), (2)?(1). 5In (4), the randomness is in the smaller relat
veral other ways: (1) via FSTs as in Fig. 1c, (2) by compilation of weighted rewrite rules (Mohri and Sproat, 1996), (3) by compilation of decision trees (Sproat and Riley, 1996), (4) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation (Gerdemann and van Noord, 1999),5 (5) by conditionalization of a joint relation as discussed below. A central technique is to define a joint relation as a noisy-channel model, by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 (Pereira and Riley, 1997; Knight and Graehl, 1998). The general form is illustrated by 3Conceptually, the parameters represent the probabilities of reading another a (?); reading another b (?); transducing b to p rather than q (?); starting to transduce p to  rather than x (?). 4To prove (1)?(3), express f as an FST and apply the well-known Kleene-Schu?tzenberger construction (Berstel and Reutenauer, 1988), taking care to write each regexp in the construction as a constant times a probabilistic regexp. A full proof is straightforward, as are proofs of (3)?(2), (2)?(1). 5In (4), the randomness is in the smaller relation?s choice of how to rep
ization of a joint relation as discussed below. A central technique is to define a joint relation as a noisy-channel model, by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 (Pereira and Riley, 1997; Knight and Graehl, 1998). The general form is illustrated by 3Conceptually, the parameters represent the probabilities of reading another a (?); reading another b (?); transducing b to p rather than q (?); starting to transduce p to  rather than x (?). 4To prove (1)?(3), express f as an FST and apply the well-known Kleene-Schu?tzenberger construction (Berstel and Reutenauer, 1988), taking care to write each regexp in the construction as a constant times a probabilistic regexp. A full proof is straightforward, as are proofs of (3)?(2), (2)?(1). 5In (4), the randomness is in the smaller relation?s choice of how to replace a match. One can also get randomness through the choice of matches, ignoring match possibilities by randomly deleting markers in Gerdemann and van Noord?s construction. P (v, z) def = ? w,x,y P (v|w)P (w, x)P (y|x)P (z|y), implemented by composing 4 machines.6,7 There are also procedures for defining weighted FSTs that are not probabilistic (Berstel and
ler relation?s choice of how to replace a match. One can also get randomness through the choice of matches, ignoring match possibilities by randomly deleting markers in Gerdemann and van Noord?s construction. P (v, z) def = ? w,x,y P (v|w)P (w, x)P (y|x)P (z|y), implemented by composing 4 machines.6,7 There are also procedures for defining weighted FSTs that are not probabilistic (Berstel and Reutenauer, 1988). Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into :/2.7?? arcs). A more subtle example is weighted FSAs that approximate PCFGs (Nederhof, 2000; Mohri and Nederhof, 2001), or to extend the idea, weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation. These are parameterized by the PCFG?s parameters, but add or remove strings of the PCFG to leave an improper probability distribution. Fortunately for those techniques, an FST with positive arc weights can be normalized to make it jointly or conditionally probabilistic: ? An easy approach is to normalize the options at each state to make the FST Markovian. Unfortunately, the result may differ for equivalent FSTs that express the same weighted relation
hoice of how to replace a match. One can also get randomness through the choice of matches, ignoring match possibilities by randomly deleting markers in Gerdemann and van Noord?s construction. P (v, z) def = ? w,x,y P (v|w)P (w, x)P (y|x)P (z|y), implemented by composing 4 machines.6,7 There are also procedures for defining weighted FSTs that are not probabilistic (Berstel and Reutenauer, 1988). Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into :/2.7?? arcs). A more subtle example is weighted FSAs that approximate PCFGs (Nederhof, 2000; Mohri and Nederhof, 2001), or to extend the idea, weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation. These are parameterized by the PCFG?s parameters, but add or remove strings of the PCFG to leave an improper probability distribution. Fortunately for those techniques, an FST with positive arc weights can be normalized to make it jointly or conditionally probabilistic: ? An easy approach is to normalize the options at each state to make the FST Markovian. Unfortunately, the result may differ for equivalent FSTs that express the same weighted relation. Undesirable consequences 
approximate joint or conditional synchronous PCFGs built for translation. These are parameterized by the PCFG?s parameters, but add or remove strings of the PCFG to leave an improper probability distribution. Fortunately for those techniques, an FST with positive arc weights can be normalized to make it jointly or conditionally probabilistic: ? An easy approach is to normalize the options at each state to make the FST Markovian. Unfortunately, the result may differ for equivalent FSTs that express the same weighted relation. Undesirable consequences of this fact have been termed ?label bias? (Lafferty et al, 2001). Also, in the conditional case such per-state normalization is only correct if all states accept all input suffixes (since ?dead ends? leak probability mass).8 ? A better-founded approach is global normalization, which simply divides each f(x, y) by ? x?,y? f(x ?, y?) (joint case) or by?y? f(x, y?) (conditional case). To implement the joint case, just divide stopping weights by the total weight of all paths (which ?4 shows how to find), provided this is finite. In the conditional case, let g be a copy of f with the output labels removed, so that g(x) finds the desired divisor; determinize g i
th that arc, coin, etc. Each feature has a strength ? R>0, and a weight is computed as the product of the strengths of its features.10 It is now the strengths that are the learnable parameters. This allows meaningful parameter tying: if certain arcs such as u:i??, o:e ??, and a:ae?? share a contextual ?vowel-fronting? feature, then their weights rise and fall together with the strength of that feature. The resulting machine must be normalized, either per-state or globally, to obtain a joint or a conditional distribution as desired. Such approaches have been tried recently in restricted cases (McCallum et al, 2000; Eisner, 2001b; Lafferty et al, 2001). Normalization may be postponed and applied instead to the result of combining the FST with other FSTs by composition, union, concatenation, etc. A simple example is a probabilistic FSA defined by normalizing the intersection of other probabilistic FSAs f1, f2, . . .. (This is in fact a log-linear model in which the component FSAs define the features: string x has log fi(x) occurrences of feature i.) In short, weighted finite-state operators provide a language for specifying a wide variety of parameterized statistical models. Let us turn to their training
. Each feature has a strength ? R>0, and a weight is computed as the product of the strengths of its features.10 It is now the strengths that are the learnable parameters. This allows meaningful parameter tying: if certain arcs such as u:i??, o:e ??, and a:ae?? share a contextual ?vowel-fronting? feature, then their weights rise and fall together with the strength of that feature. The resulting machine must be normalized, either per-state or globally, to obtain a joint or a conditional distribution as desired. Such approaches have been tried recently in restricted cases (McCallum et al, 2000; Eisner, 2001b; Lafferty et al, 2001). Normalization may be postponed and applied instead to the result of combining the FST with other FSTs by composition, union, concatenation, etc. A simple example is a probabilistic FSA defined by normalizing the intersection of other probabilistic FSAs f1, f2, . . .. (This is in fact a log-linear model in which the component FSAs define the features: string x has log fi(x) occurrences of feature i.) In short, weighted finite-state operators provide a language for specifying a wide variety of parameterized statistical models. Let us turn to their training. 3 Estimation
has a strength ? R>0, and a weight is computed as the product of the strengths of its features.10 It is now the strengths that are the learnable parameters. This allows meaningful parameter tying: if certain arcs such as u:i??, o:e ??, and a:ae?? share a contextual ?vowel-fronting? feature, then their weights rise and fall together with the strength of that feature. The resulting machine must be normalized, either per-state or globally, to obtain a joint or a conditional distribution as desired. Such approaches have been tried recently in restricted cases (McCallum et al, 2000; Eisner, 2001b; Lafferty et al, 2001). Normalization may be postponed and applied instead to the result of combining the FST with other FSTs by composition, union, concatenation, etc. A simple example is a probabilistic FSA defined by normalizing the intersection of other probabilistic FSAs f1, f2, . . .. (This is in fact a log-linear model in which the component FSAs define the features: string x has log fi(x) occurrences of feature i.) In short, weighted finite-state operators provide a language for specifying a wide variety of parameterized statistical models. Let us turn to their training. 3 Estimation in Parameterized FSTs W
nsidered is known to fall. In the extreme, if each input string is fully observed (not the case if the input is bound by composition to the output of a one-to-many FST), one can succeed by restricting g to each input string in turn; this amounts to manually dividing f(x, y) by g(x). 10Traditionally log(strength) values are called weights, but this paper uses ?weight? to mean something else. 8 9a:x/.63 10a:x/.63 11b:x/.027 a: /.7? b: /.0051? 12/.5b:z/.1284b: /.1? b:z/.404 b: /.1? Figure 2: The joint model of Fig. 1a constrained to generate only input ? a(a + b)? and output = xxz. f? on demand (Mohri et al, 1998) can pay off here, since only part of f? may be needed subsequently.) As training data we are given a set of observed (input, output) pairs, (xi, yi). These are assumed to be independent random samples from a joint distribution of the form f??(x, y); the goal is to recover the true ??. Samples need not be fully observed (partly supervised training): thus xi ? ??, yi ? ?? may be given as regular sets in which input and output were observed to fall. For example, in ordinary HMM training, xi = ?? and represents a completely hidden state sequence (cf. Ristad (1998), who allows any regular set), wh
output = xxz. f? on demand (Mohri et al, 1998) can pay off here, since only part of f? may be needed subsequently.) As training data we are given a set of observed (input, output) pairs, (xi, yi). These are assumed to be independent random samples from a joint distribution of the form f??(x, y); the goal is to recover the true ??. Samples need not be fully observed (partly supervised training): thus xi ? ??, yi ? ?? may be given as regular sets in which input and output were observed to fall. For example, in ordinary HMM training, xi = ?? and represents a completely hidden state sequence (cf. Ristad (1998), who allows any regular set), while yi is a single string representing a completely observed emission sequence.11 What to optimize? Maximum-likelihood estimation guesses ?? to be the ? maximizing ? i f?(xi, yi). Maximum-posterior estimation tries to maximize P (?) ? ? i f?(xi, yi) where P (?) is a prior probability. In a log-linear parameterization, for example, a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting (Chen and Rosenfeld, 1999). The EM algorithm (Dempster et al, 1977) can maximize these functions. Roughly, the E step guesse
o fall. For example, in ordinary HMM training, xi = ?? and represents a completely hidden state sequence (cf. Ristad (1998), who allows any regular set), while yi is a single string representing a completely observed emission sequence.11 What to optimize? Maximum-likelihood estimation guesses ?? to be the ? maximizing ? i f?(xi, yi). Maximum-posterior estimation tries to maximize P (?) ? ? i f?(xi, yi) where P (?) is a prior probability. In a log-linear parameterization, for example, a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting (Chen and Rosenfeld, 1999). The EM algorithm (Dempster et al, 1977) can maximize these functions. Roughly, the E step guesses hidden information: if (xi, yi) was generated from the current f?, which FST paths stand a chance of having been the path used? (Guessing the path also guesses the exact input and output.) The M step updates ? to make those paths more likely. EM alternates these steps and converges to a local optimum. The M step?s form depends on the parameterization and the E step serves the M step?s needs. Let f? be Fig. 1a and suppose (xi, yi) = (a(a + b)?, xxz). During the E step, we restrict to paths compat
, xi = ?? and represents a completely hidden state sequence (cf. Ristad (1998), who allows any regular set), while yi is a single string representing a completely observed emission sequence.11 What to optimize? Maximum-likelihood estimation guesses ?? to be the ? maximizing ? i f?(xi, yi). Maximum-posterior estimation tries to maximize P (?) ? ? i f?(xi, yi) where P (?) is a prior probability. In a log-linear parameterization, for example, a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting (Chen and Rosenfeld, 1999). The EM algorithm (Dempster et al, 1977) can maximize these functions. Roughly, the E step guesses hidden information: if (xi, yi) was generated from the current f?, which FST paths stand a chance of having been the path used? (Guessing the path also guesses the exact input and output.) The M step updates ? to make those paths more likely. EM alternates these steps and converges to a local optimum. The M step?s form depends on the parameterization and the E step serves the M step?s needs. Let f? be Fig. 1a and suppose (xi, yi) = (a(a + b)?, xxz). During the E step, we restrict to paths compatible with this observation by computing x
iven earlier, traversing 4? a:p?? 4? is in turn ?really? just evidence that the ?-coin came up heads. To learn the weights ?, ?, ?, ?, count expected heads/tails for each coin. ? If arc probabilities (or even ?, ?, ?, ?) have loglinear parameterization, then the E step must compute c = ? i ecf (xi, yi), where ec(x, y) denotes the expected vector of total feature counts along a random path in f? whose (input, output) matches (x, y). The M step then treats c as fixed, observed data and adjusts ? until the predicted vector of total feature counts equals c, using Improved Iterative Scaling (Della Pietra et al, 1997; Chen and Rosenfeld, 1999).12 For globally normalized, joint models, the predicted vector is ecf (??,??). If the log-linear probabilities are conditioned on the state and/or the input, the predicted vector is harder to describe (though usually much easier to compute).13 12IIS is itself iterative; to avoid nested loops, run only one iteration at each M step, giving a GEM algorithm (Riezler, 1999). Alternatively, discard EM and use gradient-based optimization. 13For per-state conditional normalization, let Dj,a be the set of arcs from state j with input symbol a ? ?; their weights are normalize
sing 4? a:p?? 4? is in turn ?really? just evidence that the ?-coin came up heads. To learn the weights ?, ?, ?, ?, count expected heads/tails for each coin. ? If arc probabilities (or even ?, ?, ?, ?) have loglinear parameterization, then the E step must compute c = ? i ecf (xi, yi), where ec(x, y) denotes the expected vector of total feature counts along a random path in f? whose (input, output) matches (x, y). The M step then treats c as fixed, observed data and adjusts ? until the predicted vector of total feature counts equals c, using Improved Iterative Scaling (Della Pietra et al, 1997; Chen and Rosenfeld, 1999).12 For globally normalized, joint models, the predicted vector is ecf (??,??). If the log-linear probabilities are conditioned on the state and/or the input, the predicted vector is harder to describe (though usually much easier to compute).13 12IIS is itself iterative; to avoid nested loops, run only one iteration at each M step, giving a GEM algorithm (Riezler, 1999). Alternatively, discard EM and use gradient-based optimization. 13For per-state conditional normalization, let Dj,a be the set of arcs from state j with input symbol a ? ?; their weights are normalized to sum to 1. Besides comp
 (input, output) matches (x, y). The M step then treats c as fixed, observed data and adjusts ? until the predicted vector of total feature counts equals c, using Improved Iterative Scaling (Della Pietra et al, 1997; Chen and Rosenfeld, 1999).12 For globally normalized, joint models, the predicted vector is ecf (??,??). If the log-linear probabilities are conditioned on the state and/or the input, the predicted vector is harder to describe (though usually much easier to compute).13 12IIS is itself iterative; to avoid nested loops, run only one iteration at each M step, giving a GEM algorithm (Riezler, 1999). Alternatively, discard EM and use gradient-based optimization. 13For per-state conditional normalization, let Dj,a be the set of arcs from state j with input symbol a ? ?; their weights are normalized to sum to 1. Besides computing c, the E step must count the expected number dj,a of traversals of arcs in each Dj,a. Then the predicted vector given ? is ? j,a dj,a ?(expected feature counts on a randomly chosen arc in Dj,a). Per-state joint normalization (Eisner, 2001b, ?8.2) is similar but drops the dependence on a. The difficult case is global conditional normalization. It arises, for exampl
 compute).13 12IIS is itself iterative; to avoid nested loops, run only one iteration at each M step, giving a GEM algorithm (Riezler, 1999). Alternatively, discard EM and use gradient-based optimization. 13For per-state conditional normalization, let Dj,a be the set of arcs from state j with input symbol a ? ?; their weights are normalized to sum to 1. Besides computing c, the E step must count the expected number dj,a of traversals of arcs in each Dj,a. Then the predicted vector given ? is ? j,a dj,a ?(expected feature counts on a randomly chosen arc in Dj,a). Per-state joint normalization (Eisner, 2001b, ?8.2) is similar but drops the dependence on a. The difficult case is global conditional normalization. It arises, for example, when training a joint model of the form f? = ? ? ? (g? ? h?) ? ? ?, where h? is a conditional It is also possible to use this EM approach for discriminative training, where we wish to maximize ? i P (yi | xi) and f?(x, y) is a conditional FST that defines P (y | x). The trick is to instead train a joint model g ? f?, where g(xi) defines P (xi), thereby maximizing ? i P (xi) ? P (yi | xi). (Of course, the method of this paper can train such compositions.) If x1, . .
i (Fig. 2), the expected value is14 E[val(pi) | xi, yi] = ? pi?? P (pi) val(pi)? pi?? P (pi) (1) The denominator of equation (1) is the total probability of all accepting paths in xi ?f ?yi. But while computing this, we will also compute the numerator. The idea is to augment the weight data structure with expectation information, so each weight records a probability and a vector counting the parameters that contributed to that probability. We will enforce an invariant: the weight of any pathset ? must be ( ? pi?? P (pi), ? pi?? P (pi) val(pi)) ? R?0 ? V , from which (1) is trivial to compute. Berstel and Reutenauer (1988) give a sufficiently general finite-state framework to allow this: weights may fall in any set K (instead of R). Multiplication and addition are replaced by binary operations ? and ? on K. Thus ? is used to combine arc weights into a path weight and ? is used to combine the weights of alternative paths. To sum over infinite sets of cyclic paths we also need a closure operation ?, interpreted as k? = ?? i=0 k i . The usual finite-state algorithms work if (K,?,?, ?) has the structure of a closed semiring.15 Ordinary probabilities fall in the semiring (R?0,+,?, ?).16 Our novel weights fall in a n
probabilistic. Whatever procedures are used to evaluate f?(xi, yi) exactly or approximately?for example, FST operations to compile f? followed by minimization of (?xi) ? f? ? (yi? )?can simply be applied over the expectation semiring, replacing each weight p by (p,?p) and replacing the usual arithmetic operations with ?, ?, etc.18 (2)?(4) preserve the gradient ((2) is the derivative product rule), so this computation yields (f?(xi, yi),?f?(xi, yi)). 5 Removing Inefficiencies Now for some important remarks on efficiency: ? Computing ti is an instance of the well-known algebraic path problem (Lehmann, 1977; Tarjan, 1981a). Let Ti = xi?f?yi. Then ti is the total semiring weight w0n of paths in Ti from initial state 0 to final state n (assumed WLOG to be unique and unweighted). It is wasteful to compute ti as suggested earlier, by minimizing (?xi)?f?(yi?), since then the real work is done by an -closure step (Mohri, 2002) that implements the all-pairs version of algebraic path, whereas all we need is the single-source version. If n and m are the number of states and edges,19 then both problems are O(n3) in the worst case, but the single-source version can be solved in essentially O(m) time for
Whatever procedures are used to evaluate f?(xi, yi) exactly or approximately?for example, FST operations to compile f? followed by minimization of (?xi) ? f? ? (yi? )?can simply be applied over the expectation semiring, replacing each weight p by (p,?p) and replacing the usual arithmetic operations with ?, ?, etc.18 (2)?(4) preserve the gradient ((2) is the derivative product rule), so this computation yields (f?(xi, yi),?f?(xi, yi)). 5 Removing Inefficiencies Now for some important remarks on efficiency: ? Computing ti is an instance of the well-known algebraic path problem (Lehmann, 1977; Tarjan, 1981a). Let Ti = xi?f?yi. Then ti is the total semiring weight w0n of paths in Ti from initial state 0 to final state n (assumed WLOG to be unique and unweighted). It is wasteful to compute ti as suggested earlier, by minimizing (?xi)?f?(yi?), since then the real work is done by an -closure step (Mohri, 2002) that implements the all-pairs version of algebraic path, whereas all we need is the single-source version. If n and m are the number of states and edges,19 then both problems are O(n3) in the worst case, but the single-source version can be solved in essentially O(m) time for acyclic graph
 ?, etc.18 (2)?(4) preserve the gradient ((2) is the derivative product rule), so this computation yields (f?(xi, yi),?f?(xi, yi)). 5 Removing Inefficiencies Now for some important remarks on efficiency: ? Computing ti is an instance of the well-known algebraic path problem (Lehmann, 1977; Tarjan, 1981a). Let Ti = xi?f?yi. Then ti is the total semiring weight w0n of paths in Ti from initial state 0 to final state n (assumed WLOG to be unique and unweighted). It is wasteful to compute ti as suggested earlier, by minimizing (?xi)?f?(yi?), since then the real work is done by an -closure step (Mohri, 2002) that implements the all-pairs version of algebraic path, whereas all we need is the single-source version. If n and m are the number of states and edges,19 then both problems are O(n3) in the worst case, but the single-source version can be solved in essentially O(m) time for acyclic graphs and other reducible flow graphs (Tarjan, 1981b). For a general graph Ti, Tarjan (1981b) shows how to partition into ?hard? subgraphs that localize the cyclicity or irreducibility, then run the O(n3) algorithm on each subgraph (thereby reducing n to as little as 1), and recombine the results. The overhead o
results. The overhead of partitioning and recombining is essentially only O(m). ? For speeding up theO(n3) problem on subgraphs, one can use an approximate relaxation technique 17Eisner (submitted) develops fast minimization algorithms that work for the real and V -expectation semirings. 18Division and subtraction are also possible: ?(p, v) = (?p,?v) and (p, v)?1 = (p?1,?p?1vp?1). Division is commonly used in defining f? (for normalization). 19Multiple edges from j to k are summed into a single edge. (Mohri, 2002). Efficient hardware implementation is also possible via chip-level parallelism (Rote, 1985). ? In many cases of interest, Ti is an acyclic graph.20 Then Tarjan?s method computes w0j for each j in topologically sorted order, thereby finding ti in a linear number of ? and ? operations. For HMMs (footnote 11), Ti is the familiar trellis, and we would like this computation of ti to reduce to the forwardbackward algorithm (Baum, 1972). But notice that it has no backward pass. In place of pushing cumulative probabilities backward to the arcs, it pushes cumulative arcs (more generally, values in V ) forward to the probabilities. This is slower because our ? and ? are vector operations, and
 = (?p,?v) and (p, v)?1 = (p?1,?p?1vp?1). Division is commonly used in defining f? (for normalization). 19Multiple edges from j to k are summed into a single edge. (Mohri, 2002). Efficient hardware implementation is also possible via chip-level parallelism (Rote, 1985). ? In many cases of interest, Ti is an acyclic graph.20 Then Tarjan?s method computes w0j for each j in topologically sorted order, thereby finding ti in a linear number of ? and ? operations. For HMMs (footnote 11), Ti is the familiar trellis, and we would like this computation of ti to reduce to the forwardbackward algorithm (Baum, 1972). But notice that it has no backward pass. In place of pushing cumulative probabilities backward to the arcs, it pushes cumulative arcs (more generally, values in V ) forward to the probabilities. This is slower because our ? and ? are vector operations, and the vectors rapidly lose sparsity as they are added together. We therefore reintroduce a backward pass that lets us avoid ? and ? when computing ti (so they are needed only to construct Ti). This speedup also works for cyclic graphs and for any V . Write wjk as (pjk, vjk), and let w1jk = (p1jk, v1jk) denote the weight of the edge from j to
rd pass that lets us avoid ? and ? when computing ti (so they are needed only to construct Ti). This speedup also works for cyclic graphs and for any V . Write wjk as (pjk, vjk), and let w1jk = (p1jk, v1jk) denote the weight of the edge from j to k.19 Then it can be shown that w0n = (p0n, ? j,k p0jv 1 jkpkn). The forward and backward probabilities, p0j and pkn, can be computed using single-source algebraic path for the simpler semiring (R,+,?, ?)?or equivalently, by solving a sparse linear system of equations over R, a much-studied problem at O(n) space, O(nm) time, and faster approximations (Greenbaum, 1997). ? A Viterbi variant of the expectation semiring exists: replace (3) with if(p1 > p2, (p1, v1), (p2, v2)). Here, the forward and backward probabilities can be computed in time only O(m + n log n) (Fredman and Tarjan, 1987). k-best variants are also possible. 6 Discussion We have exhibited a training algorithm for parameterized finite-state machines. Some specific consequences that we believe to be novel are (1) an EM algorithm for FSTs with cycles and epsilons; (2) training algorithms for HMMs and weighted contextual edit distance that work on incomplete data; (3) endto-end training of noisy 
dto-end training of noisy channel cascades, so that it is not necessary to have separate training data for each machine in the cascade (cf. Knight and Graehl, 20If xi and yi are acyclic (e.g., fully observed strings), and f (or rather its FST) has no  :  cycles, then composition will ?unroll? f into an acyclic machine. If only xi is acyclic, then the composition is still acyclic if domain(f) has no  cycles. 1998), although such data could also be used; (4) training of branching noisy channels (footnote 7); (5) discriminative training with incomplete data; (6) training of conditional MEMMs (McCallum et al, 2000) and conditional random fields (Lafferty et al, 2001) on unbounded sequences. We are particularly interested in the potential for quickly building statistical models that incorporate linguistic and engineering insights. Many models of interest can be constructed in our paradigm, without having to write new code. Bringing diverse models into the same declarative framework also allows one to apply new optimization methods, objective functions, and finite-state algorithms to all of them. To avoid local maxima, one might try deterministic annealing (Rao and Rose, 2001), or randomized methods, or p
t is not necessary to have separate training data for each machine in the cascade (cf. Knight and Graehl, 20If xi and yi are acyclic (e.g., fully observed strings), and f (or rather its FST) has no  :  cycles, then composition will ?unroll? f into an acyclic machine. If only xi is acyclic, then the composition is still acyclic if domain(f) has no  cycles. 1998), although such data could also be used; (4) training of branching noisy channels (footnote 7); (5) discriminative training with incomplete data; (6) training of conditional MEMMs (McCallum et al, 2000) and conditional random fields (Lafferty et al, 2001) on unbounded sequences. We are particularly interested in the potential for quickly building statistical models that incorporate linguistic and engineering insights. Many models of interest can be constructed in our paradigm, without having to write new code. Bringing diverse models into the same declarative framework also allows one to apply new optimization methods, objective functions, and finite-state algorithms to all of them. To avoid local maxima, one might try deterministic annealing (Rao and Rose, 2001), or randomized methods, or place a prior on ?. Another extension is to adjust the
