We also introduce novel semantic tree kernels that help us improve the performance of the best reported system on social event detection and classification by a statistically significant margin. We show results for combining the models for the two aforementioned subtasks into the overall task of social network extraction. We show that a combination of features from all three levels of abstractions (lexical, syntactic and semantic) are required to achieve the best performing system. 1 Introduction Social network extraction from text has recently been gaining a considerable amount of attention (Agarwal and Rambow, 2010; Elson et al., 2010; Agarwal et al., 2013a; Agarwal et al., 2013b; He et al., 2013). One of the reason for this attention, we believe, is that being able to extract social networks from unstructured text may provide a powerful new tool for historians, political scientists, scholars of literature, and journalists to analyze large collections of texts around entities and their interactions. The tool would allow researchers to quickly extract networks and assess their size, nature, and cohesiveness, a task that would otherwise be impossible with corpora numbering millions of documents. It would 
mantic tree kernels that help us improve the performance of the best reported system on social event detection and classification by a statistically significant margin. We show results for combining the models for the two aforementioned subtasks into the overall task of social network extraction. We show that a combination of features from all three levels of abstractions (lexical, syntactic and semantic) are required to achieve the best performing system. 1 Introduction Social network extraction from text has recently been gaining a considerable amount of attention (Agarwal and Rambow, 2010; Elson et al., 2010; Agarwal et al., 2013a; Agarwal et al., 2013b; He et al., 2013). One of the reason for this attention, we believe, is that being able to extract social networks from unstructured text may provide a powerful new tool for historians, political scientists, scholars of literature, and journalists to analyze large collections of texts around entities and their interactions. The tool would allow researchers to quickly extract networks and assess their size, nature, and cohesiveness, a task that would otherwise be impossible with corpora numbering millions of documents. It would also make it possibl
st reported system on social event detection and classification by a statistically significant margin. We show results for combining the models for the two aforementioned subtasks into the overall task of social network extraction. We show that a combination of features from all three levels of abstractions (lexical, syntactic and semantic) are required to achieve the best performing system. 1 Introduction Social network extraction from text has recently been gaining a considerable amount of attention (Agarwal and Rambow, 2010; Elson et al., 2010; Agarwal et al., 2013a; Agarwal et al., 2013b; He et al., 2013). One of the reason for this attention, we believe, is that being able to extract social networks from unstructured text may provide a powerful new tool for historians, political scientists, scholars of literature, and journalists to analyze large collections of texts around entities and their interactions. The tool would allow researchers to quickly extract networks and assess their size, nature, and cohesiveness, a task that would otherwise be impossible with corpora numbering millions of documents. It would also make it possible to make falsifiable claims about these networks, bringing the 
tructured text may provide a powerful new tool for historians, political scientists, scholars of literature, and journalists to analyze large collections of texts around entities and their interactions. The tool would allow researchers to quickly extract networks and assess their size, nature, and cohesiveness, a task that would otherwise be impossible with corpora numbering millions of documents. It would also make it possible to make falsifiable claims about these networks, bringing the experimental method to disciplines like history, where it is still relatively rare. In our previous work (Agarwal et al., 2010), we proposed a definition of a network based on interactions: nodes are entities and links are social events. We defined two broad types of links: one-directional links (one person thinking about or talking about another person) and bi-directional links (two people having a conversation, a meeting, etc.). For example, in the following sentence, we would add two links to the network: a one-directional link between Toujan Faisal and the committee, triggered by the word said (because Toujan is talking about the committee) and a bi-directional link between the same entities triggered by the word 
 add less value to the overall performance in comparison with the frame-semantic tree kernels. We believe this is due to the fact that hand-crafted features require frame parses to be highly accurate and complete. In contrast, tree kernels are able to find and leverage less strict patterns without requiring the semantic parse to be entirely accurate or complete. Apart from introducing semantic features and tree structures, we evaluate on the task of social network extraction, which is a combination of two sub-tasks: social event detection and social event classification. In our previous work (Agarwal and Rambow, 2010), we presented results for the two 211 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 211–219, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics sub-tasks, but no evaluation was presented for the task of social network extraction. We experiment with two different designs of combining models for the two sub-tasks: 1) One-versus-All and 2) Hierarchical. We find that the hierarchical design outperforms the more commonly used Oneversus-All by a statistically significant margin. Following are th
s follows: In Section 2, we give a precise definition of the task and describe the data. In Section 3, we give a brief overview of frame semantics and motivate the need to use frame semantics for the tasks addressed in this paper. In Section 4, we present semantic features and tree kernel representations designed for the tasks. In Section 5, we briefly review tree kernels and support vector machines (SVM). In Section 6 we present experiments and discuss the results. In Section 7 we discuss related work. We conclude and give future directions of work in Section 8. 2 Data and Task Definition In Agarwal et al. (2010), we presented the annotation details of social events on a well-known corpus – Automated Content Extraction1 (ACE2005). We defined a social event to be a happening between two entities (of type person) E1 and E2 (E1 =� E2), in which at least one entity is cognitively aware of the other and of the happening taking place. We defined two broad cate1Version: 6.0, Catalog number: LDC2005E18 No-Event INR OBS # of Examples 1,609 199 199 Table 1: Data distribution; INR are interaction social events. OBS are observation social events. gories of social events: Interaction (INR) and Observation (OBS). I
D), and if they are, to further predict the type of social event (INR or OBS, social event classification, SEC). In this paper, we evaluate our system on the above tasks as well as a combined task: social network extraction (SNE): given a sentence and a pair of entity mentions, predict the class of the example from one of the following three categories: {No-Event, INR, OBS}. For the purposes of this paper, we use gold named entity mentions to avoid errors caused due to named entity recognition systems. This is a common practice used in the literature for reporting relation extraction systems (Zelenko et al., 2003; Kambhatla, 2004; Zhao and Grishman, 2005; GuoDong et al., 2005; Harabagiu et al., 2005; Nguyen et al., 2009). We use standard terminology from the literature to refer to the pair of entities mentions as target entities T1 and T2. 3 Frame Semantics and FrameNet FrameNet (Baker et al., 1998) is a resource which associates words of English with their meaning. Word meanings are based on the notion of “semantic frame”. A frame is a conceptual description of a type of event, relation, or entity, and it 212 includes a list of possible participants in terms of the roles they play; these participants
 the type of social event (INR or OBS, social event classification, SEC). In this paper, we evaluate our system on the above tasks as well as a combined task: social network extraction (SNE): given a sentence and a pair of entity mentions, predict the class of the example from one of the following three categories: {No-Event, INR, OBS}. For the purposes of this paper, we use gold named entity mentions to avoid errors caused due to named entity recognition systems. This is a common practice used in the literature for reporting relation extraction systems (Zelenko et al., 2003; Kambhatla, 2004; Zhao and Grishman, 2005; GuoDong et al., 2005; Harabagiu et al., 2005; Nguyen et al., 2009). We use standard terminology from the literature to refer to the pair of entities mentions as target entities T1 and T2. 3 Frame Semantics and FrameNet FrameNet (Baker et al., 1998) is a resource which associates words of English with their meaning. Word meanings are based on the notion of “semantic frame”. A frame is a conceptual description of a type of event, relation, or entity, and it 212 includes a list of possible participants in terms of the roles they play; these participants are called “frame elements”. Through the 
 (INR or OBS, social event classification, SEC). In this paper, we evaluate our system on the above tasks as well as a combined task: social network extraction (SNE): given a sentence and a pair of entity mentions, predict the class of the example from one of the following three categories: {No-Event, INR, OBS}. For the purposes of this paper, we use gold named entity mentions to avoid errors caused due to named entity recognition systems. This is a common practice used in the literature for reporting relation extraction systems (Zelenko et al., 2003; Kambhatla, 2004; Zhao and Grishman, 2005; GuoDong et al., 2005; Harabagiu et al., 2005; Nguyen et al., 2009). We use standard terminology from the literature to refer to the pair of entities mentions as target entities T1 and T2. 3 Frame Semantics and FrameNet FrameNet (Baker et al., 1998) is a resource which associates words of English with their meaning. Word meanings are based on the notion of “semantic frame”. A frame is a conceptual description of a type of event, relation, or entity, and it 212 includes a list of possible participants in terms of the roles they play; these participants are called “frame elements”. Through the following example, we 
). In this paper, we evaluate our system on the above tasks as well as a combined task: social network extraction (SNE): given a sentence and a pair of entity mentions, predict the class of the example from one of the following three categories: {No-Event, INR, OBS}. For the purposes of this paper, we use gold named entity mentions to avoid errors caused due to named entity recognition systems. This is a common practice used in the literature for reporting relation extraction systems (Zelenko et al., 2003; Kambhatla, 2004; Zhao and Grishman, 2005; GuoDong et al., 2005; Harabagiu et al., 2005; Nguyen et al., 2009). We use standard terminology from the literature to refer to the pair of entities mentions as target entities T1 and T2. 3 Frame Semantics and FrameNet FrameNet (Baker et al., 1998) is a resource which associates words of English with their meaning. Word meanings are based on the notion of “semantic frame”. A frame is a conceptual description of a type of event, relation, or entity, and it 212 includes a list of possible participants in terms of the roles they play; these participants are called “frame elements”. Through the following example, we present the terminology and acronyms that will
 using the Stanford tokenizer (Klein and Manning, 2003) followed by removal of stop words 2An input example is a sentence with a pair of entity mentions between whom we predict and classify social events. and Porter Stemming. We convert each example (~x) to a set of three boolean vectors: {~b1, ~b2, ~b3}. ~b1 is the occurrence of words before the first target, ~b2 between the two targets and ~b3 after the second target. Here the first target and second target are defined in terms of the surface order of words. Though these features have been previously proposed for relation extraction on ACE (GuoDong et al., 2005), they have not been utilized for the task we address in this paper. 4.2 Syntactic structures (AR2010) In Agarwal and Rambow (2010), we explored a wide range of syntactic structures for the two tasks of social event detection (SED) and classification (SEC). All our previous structures were derived from a variation of two underlying tree structures: phrase structure trees and dependency trees. The best structure we proposed was PET_GR_SqGRW, which was a linear combination of two tree kernels and one word kernel: 1) a structure derived from a phrase structure tree (PET); 2) a grammatical role tr
a pair of entity mentions between whom we predict and classify social events. and Porter Stemming. We convert each example (~x) to a set of three boolean vectors: {~b1, ~b2, ~b3}. ~b1 is the occurrence of words before the first target, ~b2 between the two targets and ~b3 after the second target. Here the first target and second target are defined in terms of the surface order of words. Though these features have been previously proposed for relation extraction on ACE (GuoDong et al., 2005), they have not been utilized for the task we address in this paper. 4.2 Syntactic structures (AR2010) In Agarwal and Rambow (2010), we explored a wide range of syntactic structures for the two tasks of social event detection (SED) and classification (SEC). All our previous structures were derived from a variation of two underlying tree structures: phrase structure trees and dependency trees. The best structure we proposed was PET_GR_SqGRW, which was a linear combination of two tree kernels and one word kernel: 1) a structure derived from a phrase structure tree (PET); 2) a grammatical role tree (GR), which is a dependency tree in which words are replaced with their grammatical roles; and 3) a path from one entity to the 
agating the target entity tags to the top of the semantic tree. Model SED SEC SNE Hier. (F1) (%A) (F1) AR2010 0.574 81.1 0.465 + RULES 0.576 80.8 0.465 + BOF 0.569 80.7 0.459 + FrameForest 0.571 82.6 0.472 + FrameTree 0.579 81.5 0.473 + FrameTreeProp 0.585 82.0 0.480 Table 4: A study to show which semantic features and structures add the most value to the baseline. The top row gives the performance of the baseline. Each consecutive row shows the result of the baseline plus the feature/structure mentioned in that row. 7 Related Work There have been recent efforts to extract networks from text (Elson et al., 2010; He et al., 2013). However, these efforts extract a different type of network: a network of only bi-directional links, where the links are triggered by quotation marks. For example, Elson et al. (2010) and He et al. (2013) will extract an interaction link between Emma and Harriet in the following sentence. However, their system will not detect any interaction links in the other examples mentioned in this paper. (6) “Take it,” said Emma, smiling, and pushing the paper towards Harriet “it is for you. Take your own.” Our approach to extract and classify social events builds on our previous work 
ntity tags to the top of the semantic tree. Model SED SEC SNE Hier. (F1) (%A) (F1) AR2010 0.574 81.1 0.465 + RULES 0.576 80.8 0.465 + BOF 0.569 80.7 0.459 + FrameForest 0.571 82.6 0.472 + FrameTree 0.579 81.5 0.473 + FrameTreeProp 0.585 82.0 0.480 Table 4: A study to show which semantic features and structures add the most value to the baseline. The top row gives the performance of the baseline. Each consecutive row shows the result of the baseline plus the feature/structure mentioned in that row. 7 Related Work There have been recent efforts to extract networks from text (Elson et al., 2010; He et al., 2013). However, these efforts extract a different type of network: a network of only bi-directional links, where the links are triggered by quotation marks. For example, Elson et al. (2010) and He et al. (2013) will extract an interaction link between Emma and Harriet in the following sentence. However, their system will not detect any interaction links in the other examples mentioned in this paper. (6) “Take it,” said Emma, smiling, and pushing the paper towards Harriet “it is for you. Take your own.” Our approach to extract and classify social events builds on our previous work (Agarwal and Rambo
 He et al., 2013). However, these efforts extract a different type of network: a network of only bi-directional links, where the links are triggered by quotation marks. For example, Elson et al. (2010) and He et al. (2013) will extract an interaction link between Emma and Harriet in the following sentence. However, their system will not detect any interaction links in the other examples mentioned in this paper. (6) “Take it,” said Emma, smiling, and pushing the paper towards Harriet “it is for you. Take your own.” Our approach to extract and classify social events builds on our previous work (Agarwal and Rambow, 2010), which in turn builds on work from the relation extraction community (Nguyen et al., 2009). Therefore, the task of relation extraction is most closely related to the tasks addressed in this paper. Researchers have used other notions of semantics in the literature such as latent semantic analysis (Plank and Moschitti, 2013) and relation-specific semantics (Zelenko et al., 2003; Culotta and Sorensen, 2004). To the best of our knowledge, there is only one work that uses frame semantics for relation extraction (Harabagiu et al., 2005). Harabagiu et al. (2005) propose a novel semantic kernel that 
 bi-directional links, where the links are triggered by quotation marks. For example, Elson et al. (2010) and He et al. (2013) will extract an interaction link between Emma and Harriet in the following sentence. However, their system will not detect any interaction links in the other examples mentioned in this paper. (6) “Take it,” said Emma, smiling, and pushing the paper towards Harriet “it is for you. Take your own.” Our approach to extract and classify social events builds on our previous work (Agarwal and Rambow, 2010), which in turn builds on work from the relation extraction community (Nguyen et al., 2009). Therefore, the task of relation extraction is most closely related to the tasks addressed in this paper. Researchers have used other notions of semantics in the literature such as latent semantic analysis (Plank and Moschitti, 2013) and relation-specific semantics (Zelenko et al., 2003; Culotta and Sorensen, 2004). To the best of our knowledge, there is only one work that uses frame semantics for relation extraction (Harabagiu et al., 2005). Harabagiu et al. (2005) propose a novel semantic kernel that incorporates frame parse information in the kernel computation that calculates similarity b
ystem will not detect any interaction links in the other examples mentioned in this paper. (6) “Take it,” said Emma, smiling, and pushing the paper towards Harriet “it is for you. Take your own.” Our approach to extract and classify social events builds on our previous work (Agarwal and Rambow, 2010), which in turn builds on work from the relation extraction community (Nguyen et al., 2009). Therefore, the task of relation extraction is most closely related to the tasks addressed in this paper. Researchers have used other notions of semantics in the literature such as latent semantic analysis (Plank and Moschitti, 2013) and relation-specific semantics (Zelenko et al., 2003; Culotta and Sorensen, 2004). To the best of our knowledge, there is only one work that uses frame semantics for relation extraction (Harabagiu et al., 2005). Harabagiu et al. (2005) propose a novel semantic kernel that incorporates frame parse information in the kernel computation that calculates similarity between two dependency trees. They, however, do not propose data representations that are based on frame parses and the resulting arborescent structures, instead adding features to syntactic trees. We believe the implicit feature space
mples mentioned in this paper. (6) “Take it,” said Emma, smiling, and pushing the paper towards Harriet “it is for you. Take your own.” Our approach to extract and classify social events builds on our previous work (Agarwal and Rambow, 2010), which in turn builds on work from the relation extraction community (Nguyen et al., 2009). Therefore, the task of relation extraction is most closely related to the tasks addressed in this paper. Researchers have used other notions of semantics in the literature such as latent semantic analysis (Plank and Moschitti, 2013) and relation-specific semantics (Zelenko et al., 2003; Culotta and Sorensen, 2004). To the best of our knowledge, there is only one work that uses frame semantics for relation extraction (Harabagiu et al., 2005). Harabagiu et al. (2005) propose a novel semantic kernel that incorporates frame parse information in the kernel computation that calculates similarity between two dependency trees. They, however, do not propose data representations that are based on frame parses and the resulting arborescent structures, instead adding features to syntactic trees. We believe the implicit feature space of kernels based on our data representation encode a 
s paper. (6) “Take it,” said Emma, smiling, and pushing the paper towards Harriet “it is for you. Take your own.” Our approach to extract and classify social events builds on our previous work (Agarwal and Rambow, 2010), which in turn builds on work from the relation extraction community (Nguyen et al., 2009). Therefore, the task of relation extraction is most closely related to the tasks addressed in this paper. Researchers have used other notions of semantics in the literature such as latent semantic analysis (Plank and Moschitti, 2013) and relation-specific semantics (Zelenko et al., 2003; Culotta and Sorensen, 2004). To the best of our knowledge, there is only one work that uses frame semantics for relation extraction (Harabagiu et al., 2005). Harabagiu et al. (2005) propose a novel semantic kernel that incorporates frame parse information in the kernel computation that calculates similarity between two dependency trees. They, however, do not propose data representations that are based on frame parses and the resulting arborescent structures, instead adding features to syntactic trees. We believe the implicit feature space of kernels based on our data representation encode a richer and larger feature spa
